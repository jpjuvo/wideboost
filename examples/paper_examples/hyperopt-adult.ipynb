{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from wideboost.wrappers import wxgb\n",
    "from wideboost.wrappers.wxgb import wxgbModel\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = np.asarray(pd.read_csv('/Users/michaelhorrell/Downloads/adult.data'))\n",
    "test = np.asarray(pd.read_csv('/Users/michaelhorrell/Downloads/adult.test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = train.shape[0]\n",
    "full = np.concatenate([train,test],axis=0)\n",
    "\n",
    "c0 = full[:,0].astype(float).reshape([-1,1])\n",
    "c1 = np.asarray(pd.get_dummies(full[:,1]))\n",
    "c2 = full[:,2].astype(float).reshape([-1,1])\n",
    "c3 = np.asarray(pd.get_dummies(full[:,3]))\n",
    "c4 = full[:,4].astype(float).reshape([-1,1])\n",
    "c5 = np.asarray(pd.get_dummies(full[:,5]))\n",
    "c6 = np.asarray(pd.get_dummies(full[:,6]))\n",
    "c7 = np.asarray(pd.get_dummies(full[:,7]))\n",
    "c8 = np.asarray(pd.get_dummies(full[:,8]))\n",
    "c9 = np.asarray(pd.get_dummies(full[:,9]))\n",
    "c10 = full[:,10].astype(float).reshape([-1,1])\n",
    "c11 = full[:,11].astype(float).reshape([-1,1])\n",
    "c12 = full[:,12].astype(float).reshape([-1,1])\n",
    "c13 = np.asarray(pd.get_dummies(full[:,13]))\n",
    "\n",
    "label = np.zeros([full.shape[0],1])\n",
    "label[full[:,14] == ' >50K',0] = 1\n",
    "label[full[:,14] == ' >50K.',0] = 1\n",
    "\n",
    "XFULL = np.concatenate([c0,c1,c2,c3,c4,c5,c6,c7,c8,c9,c10,c11,c12,c13],axis=1)\n",
    "YFULL = label\n",
    "\n",
    "xtrain = XFULL[0:ntrain,:]\n",
    "ytrain = label[0:ntrain,0:1]\n",
    "\n",
    "xtest = XFULL[ntrain:,:]\n",
    "ytest = label[ntrain:,:]\n",
    "\n",
    "dtrain = xgb.DMatrix(xtrain,label=ytrain)\n",
    "dtest = xgb.DMatrix(xtest,label=ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0, 'btype': 'I', 'colsample_bylevel': 0.8737595633131674, 'colsample_bytree': 0.868407054754693, 'eta': 0.23962603231074467, 'eval_metric': ('error',), 'extra_dims': 8, 'gamma': 5.1162970950730665e-06, 'lambda': 0, 'max_depth': 7, 'min_child_weight': 0.4629783355779059, 'objective': 'binary:logistic', 'subsample': 0.6813388798756006}\n",
      "Overwriting param `num_class`                          \n",
      "Overwriting param `objective` while setting `obj` in train.\n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                \n",
      "Setting param `disable_default_eval_metric` to 1.      \n",
      "[22:05:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14054\ttest-error:0.14189             \n",
      "\n",
      "[1]\ttrain-error:0.19398\ttest-error:0.20829             \n",
      "\n",
      "[2]\ttrain-error:0.14168\ttest-error:0.14484             \n",
      "\n",
      "[3]\ttrain-error:0.29696\ttest-error:0.31450             \n",
      "\n",
      "[4]\ttrain-error:0.16139\ttest-error:0.16634             \n",
      "\n",
      "  0%|          | 0/100 [00:04<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhorrell/github/tensorflow/wideboost/wideboost/objectives/binarylogloss.py:20: RuntimeWarning: overflow encountered in exp\n",
      "  P = 1 / (1 + np.exp(-logits))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttrain-error:0.39975\ttest-error:0.40319             \n",
      "\n",
      "[6]\ttrain-error:0.19696\ttest-error:0.20031             \n",
      "\n",
      "[7]\ttrain-error:0.62224\ttest-error:0.62598             \n",
      "\n",
      "[8]\ttrain-error:0.22319\ttest-error:0.21855             \n",
      "\n",
      "[9]\ttrain-error:0.28345\ttest-error:0.28366             \n",
      "\n",
      "[10]\ttrain-error:0.23845\ttest-error:0.23329            \n",
      "\n",
      "[11]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[12]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[13]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[14]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[15]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[16]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[17]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[18]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[19]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[20]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[21]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[22]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[23]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[24]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[25]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[26]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[27]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[28]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[29]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[30]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[31]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[32]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[33]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[34]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[35]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[36]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[37]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[38]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[39]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[40]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[41]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[42]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[43]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[44]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[45]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[46]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[47]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[48]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[49]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[50]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[51]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[52]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[53]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[54]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[55]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[56]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[57]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[58]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[59]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[60]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[61]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[62]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[63]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[64]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[65]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[66]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[67]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[68]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[69]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[70]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[71]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[72]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[73]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[74]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[75]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[76]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[77]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[78]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[79]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[80]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[81]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[82]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[83]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[84]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[85]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[86]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[87]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[88]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[89]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[90]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[91]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[92]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[93]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[94]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[95]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "[96]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[97]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[98]\ttrain-error:0.24082\ttest-error:0.23624            \n",
      "\n",
      "[99]\ttrain-error:0.75918\ttest-error:0.76376            \n",
      "\n",
      "NEW BEST VALUE!                                        \n",
      "{'alpha': 0, 'btype': 'I', 'colsample_bylevel': 0.567572847297602, 'colsample_bytree': 0.7026445728400093, 'eta': 0.0027048661803592998, 'eval_metric': ('error',), 'extra_dims': 7, 'gamma': 0, 'lambda': 0.40454931317177617, 'max_depth': 6, 'min_child_weight': 8.640906894580703e-06, 'objective': 'binary:logistic', 'subsample': 0.8505251274207186}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:06:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14383\ttest-error:0.14453                               \n",
      "\n",
      "[1]\ttrain-error:0.14131\ttest-error:0.14257                               \n",
      "\n",
      "[2]\ttrain-error:0.14183\ttest-error:0.14275                               \n",
      "\n",
      "[3]\ttrain-error:0.14134\ttest-error:0.14269                               \n",
      "\n",
      "[4]\ttrain-error:0.14195\ttest-error:0.14398                               \n",
      "\n",
      "[5]\ttrain-error:0.14367\ttest-error:0.14472                               \n",
      "\n",
      "[6]\ttrain-error:0.14352\ttest-error:0.14453                               \n",
      "\n",
      "[7]\ttrain-error:0.14383\ttest-error:0.14460                               \n",
      "\n",
      "[8]\ttrain-error:0.14361\ttest-error:0.14447                               \n",
      "\n",
      "[9]\ttrain-error:0.14370\ttest-error:0.14447                               \n",
      "\n",
      "[10]\ttrain-error:0.14337\ttest-error:0.14416                              \n",
      "\n",
      "[11]\ttrain-error:0.14327\ttest-error:0.14423                              \n",
      "\n",
      "[12]\ttrain-error:0.14223\ttest-error:0.14392                              \n",
      "\n",
      "[13]\ttrain-error:0.14186\ttest-error:0.14343                              \n",
      "\n",
      "[14]\ttrain-error:0.14149\ttest-error:0.14343                              \n",
      "\n",
      "[15]\ttrain-error:0.14161\ttest-error:0.14361                              \n",
      "\n",
      "[16]\ttrain-error:0.14174\ttest-error:0.14374                              \n",
      "\n",
      "[17]\ttrain-error:0.14186\ttest-error:0.14380                              \n",
      "\n",
      "[18]\ttrain-error:0.14174\ttest-error:0.14349                              \n",
      "\n",
      "[19]\ttrain-error:0.14134\ttest-error:0.14349                              \n",
      "\n",
      "[20]\ttrain-error:0.14125\ttest-error:0.14330                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21]\ttrain-error:0.14097\ttest-error:0.14288                              \n",
      "\n",
      "[22]\ttrain-error:0.14122\ttest-error:0.14288                              \n",
      "\n",
      "[23]\ttrain-error:0.14088\ttest-error:0.14257                              \n",
      "\n",
      "[24]\ttrain-error:0.14060\ttest-error:0.14251                              \n",
      "\n",
      "[25]\ttrain-error:0.14045\ttest-error:0.14263                              \n",
      "\n",
      "[26]\ttrain-error:0.13983\ttest-error:0.14183                              \n",
      "\n",
      "[27]\ttrain-error:0.13965\ttest-error:0.14183                              \n",
      "\n",
      "[28]\ttrain-error:0.13983\ttest-error:0.14202                              \n",
      "\n",
      "[29]\ttrain-error:0.13965\ttest-error:0.14165                              \n",
      "\n",
      "[30]\ttrain-error:0.13968\ttest-error:0.14140                              \n",
      "\n",
      "[31]\ttrain-error:0.13959\ttest-error:0.14091                              \n",
      "\n",
      "[32]\ttrain-error:0.13953\ttest-error:0.14072                              \n",
      "\n",
      "[33]\ttrain-error:0.13944\ttest-error:0.14054                              \n",
      "\n",
      "[34]\ttrain-error:0.13928\ttest-error:0.14060                              \n",
      "\n",
      "[35]\ttrain-error:0.13950\ttest-error:0.14072                              \n",
      "\n",
      "[36]\ttrain-error:0.13937\ttest-error:0.14085                              \n",
      "\n",
      "[37]\ttrain-error:0.13928\ttest-error:0.14060                              \n",
      "\n",
      "[38]\ttrain-error:0.13928\ttest-error:0.14072                              \n",
      "\n",
      "[39]\ttrain-error:0.13928\ttest-error:0.14066                              \n",
      "\n",
      "[40]\ttrain-error:0.13916\ttest-error:0.14030                              \n",
      "\n",
      "[41]\ttrain-error:0.13910\ttest-error:0.14023                              \n",
      "\n",
      "[42]\ttrain-error:0.13913\ttest-error:0.14017                              \n",
      "\n",
      "[43]\ttrain-error:0.13904\ttest-error:0.14017                              \n",
      "\n",
      "[44]\ttrain-error:0.13882\ttest-error:0.13968                              \n",
      "\n",
      "[45]\ttrain-error:0.13879\ttest-error:0.13993                              \n",
      "\n",
      "[46]\ttrain-error:0.13876\ttest-error:0.13944                              \n",
      "\n",
      "[47]\ttrain-error:0.13873\ttest-error:0.13950                              \n",
      "\n",
      "[48]\ttrain-error:0.13854\ttest-error:0.13956                              \n",
      "\n",
      "[49]\ttrain-error:0.13854\ttest-error:0.13937                              \n",
      "\n",
      "[50]\ttrain-error:0.13842\ttest-error:0.13944                              \n",
      "\n",
      "[51]\ttrain-error:0.13836\ttest-error:0.13944                              \n",
      "\n",
      "[52]\ttrain-error:0.13833\ttest-error:0.13919                              \n",
      "\n",
      "[53]\ttrain-error:0.13824\ttest-error:0.13900                              \n",
      "\n",
      "[54]\ttrain-error:0.13793\ttest-error:0.13858                              \n",
      "\n",
      "[55]\ttrain-error:0.13805\ttest-error:0.13864                              \n",
      "\n",
      "[56]\ttrain-error:0.13775\ttest-error:0.13833                              \n",
      "\n",
      "[57]\ttrain-error:0.13775\ttest-error:0.13821                              \n",
      "\n",
      "[58]\ttrain-error:0.13762\ttest-error:0.13802                              \n",
      "\n",
      "[59]\ttrain-error:0.13747\ttest-error:0.13796                              \n",
      "\n",
      "[60]\ttrain-error:0.13753\ttest-error:0.13796                              \n",
      "\n",
      "[61]\ttrain-error:0.13735\ttest-error:0.13827                              \n",
      "\n",
      "[62]\ttrain-error:0.13728\ttest-error:0.13814                              \n",
      "\n",
      "[63]\ttrain-error:0.13728\ttest-error:0.13814                              \n",
      "\n",
      "[64]\ttrain-error:0.13741\ttest-error:0.13790                              \n",
      "\n",
      "[65]\ttrain-error:0.13722\ttest-error:0.13790                              \n",
      "\n",
      "[66]\ttrain-error:0.13704\ttest-error:0.13790                              \n",
      "\n",
      "[67]\ttrain-error:0.13722\ttest-error:0.13802                              \n",
      "\n",
      "[68]\ttrain-error:0.13719\ttest-error:0.13790                              \n",
      "\n",
      "[69]\ttrain-error:0.13725\ttest-error:0.13796                              \n",
      "\n",
      "[70]\ttrain-error:0.13722\ttest-error:0.13784                              \n",
      "\n",
      "[71]\ttrain-error:0.13701\ttest-error:0.13772                              \n",
      "\n",
      "[72]\ttrain-error:0.13673\ttest-error:0.13759                              \n",
      "\n",
      "[73]\ttrain-error:0.13682\ttest-error:0.13747                              \n",
      "\n",
      "[74]\ttrain-error:0.13682\ttest-error:0.13735                              \n",
      "\n",
      "[75]\ttrain-error:0.13673\ttest-error:0.13728                              \n",
      "\n",
      "[76]\ttrain-error:0.13667\ttest-error:0.13728                              \n",
      "\n",
      "[77]\ttrain-error:0.13679\ttest-error:0.13710                              \n",
      "\n",
      "[78]\ttrain-error:0.13664\ttest-error:0.13710                              \n",
      "\n",
      "[79]\ttrain-error:0.13664\ttest-error:0.13686                              \n",
      "\n",
      "[80]\ttrain-error:0.13670\ttest-error:0.13667                              \n",
      "\n",
      "[81]\ttrain-error:0.13661\ttest-error:0.13649                              \n",
      "\n",
      "[82]\ttrain-error:0.13646\ttest-error:0.13679                              \n",
      "\n",
      "[83]\ttrain-error:0.13652\ttest-error:0.13686                              \n",
      "\n",
      "[84]\ttrain-error:0.13636\ttest-error:0.13686                              \n",
      "\n",
      "[85]\ttrain-error:0.13627\ttest-error:0.13686                              \n",
      "\n",
      "[86]\ttrain-error:0.13630\ttest-error:0.13667                              \n",
      "\n",
      "[87]\ttrain-error:0.13621\ttest-error:0.13661                              \n",
      "\n",
      "[88]\ttrain-error:0.13606\ttest-error:0.13655                              \n",
      "\n",
      "[89]\ttrain-error:0.13612\ttest-error:0.13636                              \n",
      "\n",
      "[90]\ttrain-error:0.13615\ttest-error:0.13624                              \n",
      "\n",
      "[91]\ttrain-error:0.13609\ttest-error:0.13618                              \n",
      "\n",
      "[92]\ttrain-error:0.13575\ttest-error:0.13569                              \n",
      "\n",
      "[93]\ttrain-error:0.13584\ttest-error:0.13563                              \n",
      "\n",
      "[94]\ttrain-error:0.13584\ttest-error:0.13556                              \n",
      "\n",
      "[95]\ttrain-error:0.13572\ttest-error:0.13532                              \n",
      "\n",
      "[96]\ttrain-error:0.13556\ttest-error:0.13532                              \n",
      "\n",
      "[97]\ttrain-error:0.13550\ttest-error:0.13526                              \n",
      "\n",
      "[98]\ttrain-error:0.13544\ttest-error:0.13526                              \n",
      "\n",
      "[99]\ttrain-error:0.13538\ttest-error:0.13514                              \n",
      "\n",
      "NEW BEST VALUE!                                                          \n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.9979174516909006, 'colsample_bytree': 0.560589837105198, 'eta': 0.010767474802564762, 'eval_metric': ('error',), 'extra_dims': 11, 'gamma': 4.422212487823927e-05, 'lambda': 0, 'max_depth': 1, 'min_child_weight': 2.1583504579254963e-06, 'objective': 'binary:logistic', 'subsample': 0.6815291512102286}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:07:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[1]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[2]\ttrain-error:0.20863\ttest-error:0.20565                               \n",
      "\n",
      "[3]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[4]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[5]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[6]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[7]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[8]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[9]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[10]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[11]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[12]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[13]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[15]\ttrain-error:0.20452\ttest-error:0.20190                              \n",
      "\n",
      "[16]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[17]\ttrain-error:0.20452\ttest-error:0.20190                              \n",
      "\n",
      "[18]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[19]\ttrain-error:0.20172\ttest-error:0.19908                              \n",
      "\n",
      "[20]\ttrain-error:0.19091\ttest-error:0.18993                              \n",
      "\n",
      "[21]\ttrain-error:0.17623\ttest-error:0.17543                              \n",
      "\n",
      "[22]\ttrain-error:0.17181\ttest-error:0.17138                              \n",
      "\n",
      "[23]\ttrain-error:0.17168\ttest-error:0.17113                              \n",
      "\n",
      "[24]\ttrain-error:0.17122\ttest-error:0.17076                              \n",
      "\n",
      "[25]\ttrain-error:0.16256\ttest-error:0.16192                              \n",
      "\n",
      "[26]\ttrain-error:0.16207\ttest-error:0.16155                              \n",
      "\n",
      "[27]\ttrain-error:0.16216\ttest-error:0.16468                              \n",
      "\n",
      "[28]\ttrain-error:0.16161\ttest-error:0.16394                              \n",
      "\n",
      "[29]\ttrain-error:0.16118\ttest-error:0.16001                              \n",
      "\n",
      "[30]\ttrain-error:0.16063\ttest-error:0.16020                              \n",
      "\n",
      "[31]\ttrain-error:0.16053\ttest-error:0.15977                              \n",
      "\n",
      "[32]\ttrain-error:0.16026\ttest-error:0.15971                              \n",
      "\n",
      "[33]\ttrain-error:0.15998\ttest-error:0.15952                              \n",
      "\n",
      "[34]\ttrain-error:0.15971\ttest-error:0.15915                              \n",
      "\n",
      "[35]\ttrain-error:0.15946\ttest-error:0.15866                              \n",
      "\n",
      "[36]\ttrain-error:0.15927\ttest-error:0.15866                              \n",
      "\n",
      "[37]\ttrain-error:0.15912\ttest-error:0.15835                              \n",
      "\n",
      "[38]\ttrain-error:0.15826\ttest-error:0.15762                              \n",
      "\n",
      "[39]\ttrain-error:0.15805\ttest-error:0.15712                              \n",
      "\n",
      "[40]\ttrain-error:0.15796\ttest-error:0.15706                              \n",
      "\n",
      "[41]\ttrain-error:0.15743\ttest-error:0.15645                              \n",
      "\n",
      "[42]\ttrain-error:0.15534\ttest-error:0.15510                              \n",
      "\n",
      "[43]\ttrain-error:0.15445\ttest-error:0.15393                              \n",
      "\n",
      "[44]\ttrain-error:0.15362\ttest-error:0.15369                              \n",
      "\n",
      "[45]\ttrain-error:0.15362\ttest-error:0.15338                              \n",
      "\n",
      "[46]\ttrain-error:0.15347\ttest-error:0.15362                              \n",
      "\n",
      "[47]\ttrain-error:0.15341\ttest-error:0.15369                              \n",
      "\n",
      "[48]\ttrain-error:0.15295\ttest-error:0.15356                              \n",
      "\n",
      "[49]\ttrain-error:0.15286\ttest-error:0.15332                              \n",
      "\n",
      "[50]\ttrain-error:0.15289\ttest-error:0.15326                              \n",
      "\n",
      "[51]\ttrain-error:0.15135\ttest-error:0.15147                              \n",
      "\n",
      "[52]\ttrain-error:0.15114\ttest-error:0.15129                              \n",
      "\n",
      "[53]\ttrain-error:0.15107\ttest-error:0.15135                              \n",
      "\n",
      "[54]\ttrain-error:0.15074\ttest-error:0.15092                              \n",
      "\n",
      "[55]\ttrain-error:0.15012\ttest-error:0.15068                              \n",
      "\n",
      "[56]\ttrain-error:0.15003\ttest-error:0.15068                              \n",
      "\n",
      "[57]\ttrain-error:0.15000\ttest-error:0.15037                              \n",
      "\n",
      "[58]\ttrain-error:0.14954\ttest-error:0.15000                              \n",
      "\n",
      "[59]\ttrain-error:0.14932\ttest-error:0.14945                              \n",
      "\n",
      "[60]\ttrain-error:0.14923\ttest-error:0.14920                              \n",
      "\n",
      "[61]\ttrain-error:0.14917\ttest-error:0.14932                              \n",
      "\n",
      "[62]\ttrain-error:0.14920\ttest-error:0.14920                              \n",
      "\n",
      "[63]\ttrain-error:0.14914\ttest-error:0.14902                              \n",
      "\n",
      "[64]\ttrain-error:0.14929\ttest-error:0.14889                              \n",
      "\n",
      "[65]\ttrain-error:0.14917\ttest-error:0.14865                              \n",
      "\n",
      "[66]\ttrain-error:0.14917\ttest-error:0.14846                              \n",
      "\n",
      "[67]\ttrain-error:0.14880\ttest-error:0.14840                              \n",
      "\n",
      "[68]\ttrain-error:0.14822\ttest-error:0.14779                              \n",
      "\n",
      "[69]\ttrain-error:0.14810\ttest-error:0.14767                              \n",
      "\n",
      "[70]\ttrain-error:0.14797\ttest-error:0.14754                              \n",
      "\n",
      "[71]\ttrain-error:0.14794\ttest-error:0.14724                              \n",
      "\n",
      "[72]\ttrain-error:0.14785\ttest-error:0.14705                              \n",
      "\n",
      "[73]\ttrain-error:0.14782\ttest-error:0.14699                              \n",
      "\n",
      "[74]\ttrain-error:0.14782\ttest-error:0.14693                              \n",
      "\n",
      "[75]\ttrain-error:0.14760\ttest-error:0.14644                              \n",
      "\n",
      "[76]\ttrain-error:0.14757\ttest-error:0.14644                              \n",
      "\n",
      "[77]\ttrain-error:0.14739\ttest-error:0.14656                              \n",
      "\n",
      "[78]\ttrain-error:0.14724\ttest-error:0.14638                              \n",
      "\n",
      "[79]\ttrain-error:0.14641\ttest-error:0.14502                              \n",
      "\n",
      "[80]\ttrain-error:0.14644\ttest-error:0.14502                              \n",
      "\n",
      "[81]\ttrain-error:0.14625\ttest-error:0.14484                              \n",
      "\n",
      "[82]\ttrain-error:0.14607\ttest-error:0.14435                              \n",
      "\n",
      "[83]\ttrain-error:0.14582\ttest-error:0.14460                              \n",
      "\n",
      "[84]\ttrain-error:0.14582\ttest-error:0.14460                              \n",
      "\n",
      "[85]\ttrain-error:0.14582\ttest-error:0.14429                              \n",
      "\n",
      "[86]\ttrain-error:0.14579\ttest-error:0.14423                              \n",
      "\n",
      "[87]\ttrain-error:0.14576\ttest-error:0.14453                              \n",
      "\n",
      "[88]\ttrain-error:0.14576\ttest-error:0.14447                              \n",
      "\n",
      "[89]\ttrain-error:0.14558\ttest-error:0.14429                              \n",
      "\n",
      "[90]\ttrain-error:0.14567\ttest-error:0.14447                              \n",
      "\n",
      "[91]\ttrain-error:0.14552\ttest-error:0.14441                              \n",
      "\n",
      "[92]\ttrain-error:0.14576\ttest-error:0.14460                              \n",
      "\n",
      "[93]\ttrain-error:0.14570\ttest-error:0.14460                              \n",
      "\n",
      "[94]\ttrain-error:0.14582\ttest-error:0.14435                              \n",
      "\n",
      "[95]\ttrain-error:0.14555\ttest-error:0.14410                              \n",
      "\n",
      "[96]\ttrain-error:0.14542\ttest-error:0.14429                              \n",
      "\n",
      "[97]\ttrain-error:0.14546\ttest-error:0.14441                              \n",
      "\n",
      "[98]\ttrain-error:0.14549\ttest-error:0.14429                              \n",
      "\n",
      "[99]\ttrain-error:0.14533\ttest-error:0.14416                              \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.7672950475106064, 'colsample_bytree': 0.509383451450351, 'eta': 0.0034342496728663554, 'eval_metric': ('error',), 'extra_dims': 14, 'gamma': 0, 'lambda': 0, 'max_depth': 5, 'min_child_weight': 1.3880887120241347e-07, 'objective': 'binary:logistic', 'subsample': 0.8952044043997798}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:08:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14119\ttest-error:0.13993                               \n",
      "\n",
      "[1]\ttrain-error:0.14177\ttest-error:0.14183                               \n",
      "\n",
      "[2]\ttrain-error:0.14275\ttest-error:0.14343                               \n",
      "\n",
      "[3]\ttrain-error:0.14469\ttest-error:0.14496                               \n",
      "\n",
      "[4]\ttrain-error:0.14533\ttest-error:0.14570                               \n",
      "\n",
      "[5]\ttrain-error:0.14438\ttest-error:0.14496                               \n",
      "\n",
      "[6]\ttrain-error:0.14401\ttest-error:0.14490                               \n",
      "\n",
      "[7]\ttrain-error:0.14346\ttest-error:0.14441                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain-error:0.14352\ttest-error:0.14423                               \n",
      "\n",
      "[9]\ttrain-error:0.14364\ttest-error:0.14441                               \n",
      "\n",
      "[10]\ttrain-error:0.14340\ttest-error:0.14416                              \n",
      "\n",
      "[11]\ttrain-error:0.14330\ttest-error:0.14398                              \n",
      "\n",
      "[12]\ttrain-error:0.14309\ttest-error:0.14361                              \n",
      "\n",
      "[13]\ttrain-error:0.14303\ttest-error:0.14343                              \n",
      "\n",
      "[14]\ttrain-error:0.14330\ttest-error:0.14361                              \n",
      "\n",
      "[15]\ttrain-error:0.14247\ttest-error:0.14330                              \n",
      "\n",
      "[16]\ttrain-error:0.14186\ttest-error:0.14337                              \n",
      "\n",
      "[17]\ttrain-error:0.14082\ttest-error:0.14171                              \n",
      "\n",
      "[18]\ttrain-error:0.14063\ttest-error:0.14122                              \n",
      "\n",
      "[19]\ttrain-error:0.14069\ttest-error:0.14152                              \n",
      "\n",
      "[20]\ttrain-error:0.14066\ttest-error:0.14128                              \n",
      "\n",
      "[21]\ttrain-error:0.14066\ttest-error:0.14109                              \n",
      "\n",
      "[22]\ttrain-error:0.14033\ttest-error:0.14085                              \n",
      "\n",
      "[23]\ttrain-error:0.14017\ttest-error:0.14066                              \n",
      "\n",
      "[24]\ttrain-error:0.13986\ttest-error:0.14030                              \n",
      "\n",
      "[25]\ttrain-error:0.13977\ttest-error:0.13999                              \n",
      "\n",
      "[26]\ttrain-error:0.13962\ttest-error:0.13986                              \n",
      "\n",
      "[27]\ttrain-error:0.13959\ttest-error:0.13956                              \n",
      "\n",
      "[28]\ttrain-error:0.13928\ttest-error:0.13968                              \n",
      "\n",
      "[29]\ttrain-error:0.13928\ttest-error:0.13974                              \n",
      "\n",
      "[30]\ttrain-error:0.13904\ttest-error:0.13950                              \n",
      "\n",
      "[31]\ttrain-error:0.13894\ttest-error:0.13956                              \n",
      "\n",
      "[32]\ttrain-error:0.13870\ttest-error:0.13882                              \n",
      "\n",
      "[33]\ttrain-error:0.13848\ttest-error:0.13864                              \n",
      "\n",
      "[34]\ttrain-error:0.13824\ttest-error:0.13821                              \n",
      "\n",
      "[35]\ttrain-error:0.13805\ttest-error:0.13735                              \n",
      "\n",
      "[36]\ttrain-error:0.13802\ttest-error:0.13735                              \n",
      "\n",
      "[37]\ttrain-error:0.13781\ttest-error:0.13722                              \n",
      "\n",
      "[38]\ttrain-error:0.13772\ttest-error:0.13716                              \n",
      "\n",
      "[39]\ttrain-error:0.13768\ttest-error:0.13698                              \n",
      "\n",
      "[40]\ttrain-error:0.13759\ttest-error:0.13716                              \n",
      "\n",
      "[41]\ttrain-error:0.13741\ttest-error:0.13686                              \n",
      "\n",
      "[42]\ttrain-error:0.13728\ttest-error:0.13686                              \n",
      "\n",
      "[43]\ttrain-error:0.13725\ttest-error:0.13679                              \n",
      "\n",
      "[44]\ttrain-error:0.13722\ttest-error:0.13692                              \n",
      "\n",
      "[45]\ttrain-error:0.13707\ttest-error:0.13686                              \n",
      "\n",
      "[46]\ttrain-error:0.13701\ttest-error:0.13667                              \n",
      "\n",
      "[47]\ttrain-error:0.13692\ttest-error:0.13661                              \n",
      "\n",
      "[48]\ttrain-error:0.13676\ttest-error:0.13630                              \n",
      "\n",
      "[49]\ttrain-error:0.13658\ttest-error:0.13618                              \n",
      "\n",
      "[50]\ttrain-error:0.13658\ttest-error:0.13600                              \n",
      "\n",
      "[51]\ttrain-error:0.13664\ttest-error:0.13587                              \n",
      "\n",
      "[52]\ttrain-error:0.13658\ttest-error:0.13587                              \n",
      "\n",
      "[53]\ttrain-error:0.13658\ttest-error:0.13581                              \n",
      "\n",
      "[54]\ttrain-error:0.13633\ttest-error:0.13569                              \n",
      "\n",
      "[55]\ttrain-error:0.13615\ttest-error:0.13569                              \n",
      "\n",
      "[56]\ttrain-error:0.13609\ttest-error:0.13544                              \n",
      "\n",
      "[57]\ttrain-error:0.13603\ttest-error:0.13550                              \n",
      "\n",
      "[58]\ttrain-error:0.13590\ttest-error:0.13550                              \n",
      "\n",
      "[59]\ttrain-error:0.13590\ttest-error:0.13550                              \n",
      "\n",
      "[60]\ttrain-error:0.13581\ttest-error:0.13532                              \n",
      "\n",
      "[61]\ttrain-error:0.13578\ttest-error:0.13526                              \n",
      "\n",
      "[62]\ttrain-error:0.13566\ttest-error:0.13514                              \n",
      "\n",
      "[63]\ttrain-error:0.13560\ttest-error:0.13520                              \n",
      "\n",
      "[64]\ttrain-error:0.13560\ttest-error:0.13507                              \n",
      "\n",
      "[65]\ttrain-error:0.13547\ttest-error:0.13489                              \n",
      "\n",
      "[66]\ttrain-error:0.13523\ttest-error:0.13477                              \n",
      "\n",
      "[67]\ttrain-error:0.13501\ttest-error:0.13440                              \n",
      "\n",
      "[68]\ttrain-error:0.13495\ttest-error:0.13415                              \n",
      "\n",
      "[69]\ttrain-error:0.13483\ttest-error:0.13428                              \n",
      "\n",
      "[70]\ttrain-error:0.13464\ttest-error:0.13421                              \n",
      "\n",
      "[71]\ttrain-error:0.13452\ttest-error:0.13434                              \n",
      "\n",
      "[72]\ttrain-error:0.13437\ttest-error:0.13428                              \n",
      "\n",
      "[73]\ttrain-error:0.13428\ttest-error:0.13421                              \n",
      "\n",
      "[74]\ttrain-error:0.13409\ttest-error:0.13397                              \n",
      "\n",
      "[75]\ttrain-error:0.13394\ttest-error:0.13360                              \n",
      "\n",
      "[76]\ttrain-error:0.13397\ttest-error:0.13348                              \n",
      "\n",
      "[77]\ttrain-error:0.13384\ttest-error:0.13317                              \n",
      "\n",
      "[78]\ttrain-error:0.13375\ttest-error:0.13311                              \n",
      "\n",
      "[79]\ttrain-error:0.13378\ttest-error:0.13292                              \n",
      "\n",
      "[80]\ttrain-error:0.13372\ttest-error:0.13292                              \n",
      "\n",
      "[81]\ttrain-error:0.13363\ttest-error:0.13286                              \n",
      "\n",
      "[82]\ttrain-error:0.13345\ttest-error:0.13219                              \n",
      "\n",
      "[83]\ttrain-error:0.13339\ttest-error:0.13206                              \n",
      "\n",
      "[84]\ttrain-error:0.13342\ttest-error:0.13200                              \n",
      "\n",
      "[85]\ttrain-error:0.13329\ttest-error:0.13139                              \n",
      "\n",
      "[86]\ttrain-error:0.13317\ttest-error:0.13120                              \n",
      "\n",
      "[87]\ttrain-error:0.13302\ttest-error:0.13108                              \n",
      "\n",
      "[88]\ttrain-error:0.13295\ttest-error:0.13096                              \n",
      "\n",
      "[89]\ttrain-error:0.13286\ttest-error:0.13071                              \n",
      "\n",
      "[90]\ttrain-error:0.13283\ttest-error:0.13065                              \n",
      "\n",
      "[91]\ttrain-error:0.13259\ttest-error:0.13065                              \n",
      "\n",
      "[92]\ttrain-error:0.13249\ttest-error:0.13065                              \n",
      "\n",
      "[93]\ttrain-error:0.13234\ttest-error:0.13059                              \n",
      "\n",
      "[94]\ttrain-error:0.13225\ttest-error:0.13047                              \n",
      "\n",
      "[95]\ttrain-error:0.13219\ttest-error:0.13040                              \n",
      "\n",
      "[96]\ttrain-error:0.13194\ttest-error:0.13034                              \n",
      "\n",
      "[97]\ttrain-error:0.13185\ttest-error:0.13022                              \n",
      "\n",
      "[98]\ttrain-error:0.13160\ttest-error:0.13034                              \n",
      "\n",
      "[99]\ttrain-error:0.13130\ttest-error:0.13053                              \n",
      "\n",
      "NEW BEST VALUE!                                                          \n",
      "{'alpha': 3.179739191894652e-07, 'btype': 'I', 'colsample_bylevel': 0.6835021429151027, 'colsample_bytree': 0.6611175552570704, 'eta': 0.06159424110973516, 'eval_metric': ('error',), 'extra_dims': 15, 'gamma': 0, 'lambda': 0, 'max_depth': 5, 'min_child_weight': 0.0002191378137104617, 'objective': 'binary:logistic', 'subsample': 0.8016336092471152}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:10:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14472\ttest-error:0.14496                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-error:0.13904\ttest-error:0.13882                               \n",
      "\n",
      "[2]\ttrain-error:0.13725\ttest-error:0.13667                               \n",
      "\n",
      "[3]\ttrain-error:0.13556\ttest-error:0.13470                               \n",
      "\n",
      "[4]\ttrain-error:0.13222\ttest-error:0.13225                               \n",
      "\n",
      "[5]\ttrain-error:0.12899\ttest-error:0.13071                               \n",
      "\n",
      "[6]\ttrain-error:0.12451\ttest-error:0.12715                               \n",
      "\n",
      "[7]\ttrain-error:0.12291\ttest-error:0.12678                               \n",
      "\n",
      "[8]\ttrain-error:0.12202\ttest-error:0.12697                               \n",
      "\n",
      "[9]\ttrain-error:0.11972\ttest-error:0.12568                               \n",
      "\n",
      "[10]\ttrain-error:0.11886\ttest-error:0.12537                              \n",
      "\n",
      "[11]\ttrain-error:0.11769\ttest-error:0.12549                              \n",
      "\n",
      "[12]\ttrain-error:0.11652\ttest-error:0.12574                              \n",
      "\n",
      "[13]\ttrain-error:0.11582\ttest-error:0.12549                              \n",
      "\n",
      "[14]\ttrain-error:0.11514\ttest-error:0.12543                              \n",
      "\n",
      "[15]\ttrain-error:0.11419\ttest-error:0.12531                              \n",
      "\n",
      "[16]\ttrain-error:0.11293\ttest-error:0.12512                              \n",
      "\n",
      "[17]\ttrain-error:0.11146\ttest-error:0.12592                              \n",
      "\n",
      "[18]\ttrain-error:0.11069\ttest-error:0.12561                              \n",
      "\n",
      "[19]\ttrain-error:0.11023\ttest-error:0.12549                              \n",
      "\n",
      "[20]\ttrain-error:0.10943\ttest-error:0.12512                              \n",
      "\n",
      "[21]\ttrain-error:0.10866\ttest-error:0.12512                              \n",
      "\n",
      "[22]\ttrain-error:0.10786\ttest-error:0.12512                              \n",
      "\n",
      "[23]\ttrain-error:0.10685\ttest-error:0.12531                              \n",
      "\n",
      "[24]\ttrain-error:0.10645\ttest-error:0.12549                              \n",
      "\n",
      "[25]\ttrain-error:0.10608\ttest-error:0.12525                              \n",
      "\n",
      "[26]\ttrain-error:0.10525\ttest-error:0.12537                              \n",
      "\n",
      "[27]\ttrain-error:0.10464\ttest-error:0.12604                              \n",
      "\n",
      "[28]\ttrain-error:0.10381\ttest-error:0.12678                              \n",
      "\n",
      "[29]\ttrain-error:0.10310\ttest-error:0.12697                              \n",
      "\n",
      "[30]\ttrain-error:0.10289\ttest-error:0.12740                              \n",
      "\n",
      "[31]\ttrain-error:0.10224\ttest-error:0.12672                              \n",
      "\n",
      "[32]\ttrain-error:0.10150\ttest-error:0.12641                              \n",
      "\n",
      "[33]\ttrain-error:0.10077\ttest-error:0.12598                              \n",
      "\n",
      "[34]\ttrain-error:0.10037\ttest-error:0.12611                              \n",
      "\n",
      "[35]\ttrain-error:0.09963\ttest-error:0.12654                              \n",
      "\n",
      "[36]\ttrain-error:0.09896\ttest-error:0.12647                              \n",
      "\n",
      "[37]\ttrain-error:0.09859\ttest-error:0.12654                              \n",
      "\n",
      "[38]\ttrain-error:0.09748\ttest-error:0.12623                              \n",
      "\n",
      "[39]\ttrain-error:0.09656\ttest-error:0.12635                              \n",
      "\n",
      "[40]\ttrain-error:0.09607\ttest-error:0.12629                              \n",
      "\n",
      "[41]\ttrain-error:0.09499\ttest-error:0.12641                              \n",
      "\n",
      "[42]\ttrain-error:0.09407\ttest-error:0.12703                              \n",
      "\n",
      "[43]\ttrain-error:0.09318\ttest-error:0.12660                              \n",
      "\n",
      "[44]\ttrain-error:0.09257\ttest-error:0.12617                              \n",
      "\n",
      "[45]\ttrain-error:0.09165\ttest-error:0.12635                              \n",
      "\n",
      "[46]\ttrain-error:0.09122\ttest-error:0.12672                              \n",
      "\n",
      "[47]\ttrain-error:0.09057\ttest-error:0.12703                              \n",
      "\n",
      "[48]\ttrain-error:0.09011\ttest-error:0.12703                              \n",
      "\n",
      "[49]\ttrain-error:0.08974\ttest-error:0.12709                              \n",
      "\n",
      "[50]\ttrain-error:0.08854\ttest-error:0.12721                              \n",
      "\n",
      "[51]\ttrain-error:0.08799\ttest-error:0.12727                              \n",
      "\n",
      "[52]\ttrain-error:0.08765\ttest-error:0.12721                              \n",
      "\n",
      "[53]\ttrain-error:0.08716\ttest-error:0.12746                              \n",
      "\n",
      "[54]\ttrain-error:0.08652\ttest-error:0.12752                              \n",
      "\n",
      "[55]\ttrain-error:0.08584\ttest-error:0.12783                              \n",
      "\n",
      "[56]\ttrain-error:0.08547\ttest-error:0.12807                              \n",
      "\n",
      "[57]\ttrain-error:0.08480\ttest-error:0.12752                              \n",
      "\n",
      "[58]\ttrain-error:0.08443\ttest-error:0.12758                              \n",
      "\n",
      "[59]\ttrain-error:0.08363\ttest-error:0.12826                              \n",
      "\n",
      "[60]\ttrain-error:0.08326\ttest-error:0.12832                              \n",
      "\n",
      "[61]\ttrain-error:0.08274\ttest-error:0.12801                              \n",
      "\n",
      "[62]\ttrain-error:0.08243\ttest-error:0.12795                              \n",
      "\n",
      "[63]\ttrain-error:0.08170\ttest-error:0.12826                              \n",
      "\n",
      "[64]\ttrain-error:0.08148\ttest-error:0.12813                              \n",
      "\n",
      "[65]\ttrain-error:0.08077\ttest-error:0.12826                              \n",
      "\n",
      "[66]\ttrain-error:0.08025\ttest-error:0.12838                              \n",
      "\n",
      "[67]\ttrain-error:0.07998\ttest-error:0.12813                              \n",
      "\n",
      "[68]\ttrain-error:0.07927\ttest-error:0.12856                              \n",
      "\n",
      "[69]\ttrain-error:0.07856\ttest-error:0.12838                              \n",
      "\n",
      "[70]\ttrain-error:0.07795\ttest-error:0.12844                              \n",
      "\n",
      "[71]\ttrain-error:0.07752\ttest-error:0.12856                              \n",
      "\n",
      "[72]\ttrain-error:0.07684\ttest-error:0.12930                              \n",
      "\n",
      "[73]\ttrain-error:0.07580\ttest-error:0.12918                              \n",
      "\n",
      "[74]\ttrain-error:0.07543\ttest-error:0.12899                              \n",
      "\n",
      "[75]\ttrain-error:0.07518\ttest-error:0.12887                              \n",
      "\n",
      "[76]\ttrain-error:0.07454\ttest-error:0.12838                              \n",
      "\n",
      "[77]\ttrain-error:0.07417\ttest-error:0.12838                              \n",
      "\n",
      "[78]\ttrain-error:0.07350\ttest-error:0.12869                              \n",
      "\n",
      "[79]\ttrain-error:0.07307\ttest-error:0.12875                              \n",
      "\n",
      "[80]\ttrain-error:0.07273\ttest-error:0.12905                              \n",
      "\n",
      "[81]\ttrain-error:0.07168\ttest-error:0.12930                              \n",
      "\n",
      "[82]\ttrain-error:0.07128\ttest-error:0.12942                              \n",
      "\n",
      "[83]\ttrain-error:0.07061\ttest-error:0.12954                              \n",
      "\n",
      "[84]\ttrain-error:0.06963\ttest-error:0.12973                              \n",
      "\n",
      "[85]\ttrain-error:0.06935\ttest-error:0.12991                              \n",
      "\n",
      "[86]\ttrain-error:0.06895\ttest-error:0.13004                              \n",
      "\n",
      "[87]\ttrain-error:0.06790\ttest-error:0.13047                              \n",
      "\n",
      "[88]\ttrain-error:0.06778\ttest-error:0.13040                              \n",
      "\n",
      "[89]\ttrain-error:0.06704\ttest-error:0.13077                              \n",
      "\n",
      "[90]\ttrain-error:0.06649\ttest-error:0.13077                              \n",
      "\n",
      "[91]\ttrain-error:0.06606\ttest-error:0.13084                              \n",
      "\n",
      "[92]\ttrain-error:0.06563\ttest-error:0.13114                              \n",
      "\n",
      "[93]\ttrain-error:0.06548\ttest-error:0.13065                              \n",
      "\n",
      "[94]\ttrain-error:0.06456\ttest-error:0.13077                              \n",
      "\n",
      "[95]\ttrain-error:0.06404\ttest-error:0.13120                              \n",
      "\n",
      "[96]\ttrain-error:0.06327\ttest-error:0.13170                              \n",
      "\n",
      "[97]\ttrain-error:0.06324\ttest-error:0.13170                              \n",
      "\n",
      "[98]\ttrain-error:0.06281\ttest-error:0.13176                              \n",
      "\n",
      "[99]\ttrain-error:0.06278\ttest-error:0.13133                              \n",
      "\n",
      "NEW BEST VALUE!                                                          \n",
      "{'alpha': 0.12461409368257602, 'btype': 'Rn', 'colsample_bylevel': 0.6547778674599696, 'colsample_bytree': 0.728360039020157, 'eta': 0.0009673486059257237, 'eval_metric': ('error',), 'extra_dims': 2, 'gamma': 0.03756248471643038, 'lambda': 0, 'max_depth': 3, 'min_child_weight': 1.488120998560875e-06, 'objective': 'binary:logistic', 'subsample': 0.5806169864279989}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:12:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.16637\ttest-error:0.16474                               \n",
      "\n",
      "[1]\ttrain-error:0.16121\ttest-error:0.16087                               \n",
      "\n",
      "[2]\ttrain-error:0.15522\ttest-error:0.15424                               \n",
      "\n",
      "[3]\ttrain-error:0.15516\ttest-error:0.15442                               \n",
      "\n",
      "[4]\ttrain-error:0.15316\ttest-error:0.15209                               \n",
      "\n",
      "[5]\ttrain-error:0.15356\ttest-error:0.15276                               \n",
      "\n",
      "[6]\ttrain-error:0.15540\ttest-error:0.15479                               \n",
      "\n",
      "[7]\ttrain-error:0.15525\ttest-error:0.15516                               \n",
      "\n",
      "[8]\ttrain-error:0.15507\ttest-error:0.15491                               \n",
      "\n",
      "[9]\ttrain-error:0.15501\ttest-error:0.15522                               \n",
      "\n",
      "[10]\ttrain-error:0.15491\ttest-error:0.15510                              \n",
      "\n",
      "[11]\ttrain-error:0.15452\ttest-error:0.15399                              \n",
      "\n",
      "[12]\ttrain-error:0.15491\ttest-error:0.15504                              \n",
      "\n",
      "[13]\ttrain-error:0.15494\ttest-error:0.15498                              \n",
      "\n",
      "[14]\ttrain-error:0.15482\ttest-error:0.15479                              \n",
      "\n",
      "[15]\ttrain-error:0.15488\ttest-error:0.15448                              \n",
      "\n",
      "[16]\ttrain-error:0.15501\ttest-error:0.15504                              \n",
      "\n",
      "[17]\ttrain-error:0.15504\ttest-error:0.15504                              \n",
      "\n",
      "[18]\ttrain-error:0.15519\ttest-error:0.15534                              \n",
      "\n",
      "[19]\ttrain-error:0.15531\ttest-error:0.15547                              \n",
      "\n",
      "[20]\ttrain-error:0.15528\ttest-error:0.15553                              \n",
      "\n",
      "[21]\ttrain-error:0.15538\ttest-error:0.15553                              \n",
      "\n",
      "[22]\ttrain-error:0.15540\ttest-error:0.15547                              \n",
      "\n",
      "[23]\ttrain-error:0.15540\ttest-error:0.15547                              \n",
      "\n",
      "[24]\ttrain-error:0.15540\ttest-error:0.15547                              \n",
      "\n",
      "[25]\ttrain-error:0.15544\ttest-error:0.15540                              \n",
      "\n",
      "[26]\ttrain-error:0.15547\ttest-error:0.15534                              \n",
      "\n",
      "[27]\ttrain-error:0.15544\ttest-error:0.15547                              \n",
      "\n",
      "[28]\ttrain-error:0.15547\ttest-error:0.15540                              \n",
      "\n",
      "[29]\ttrain-error:0.15544\ttest-error:0.15540                              \n",
      "\n",
      "[30]\ttrain-error:0.15540\ttest-error:0.15534                              \n",
      "\n",
      "[31]\ttrain-error:0.15544\ttest-error:0.15534                              \n",
      "\n",
      "[32]\ttrain-error:0.15547\ttest-error:0.15534                              \n",
      "\n",
      "[33]\ttrain-error:0.15547\ttest-error:0.15534                              \n",
      "\n",
      "[34]\ttrain-error:0.15547\ttest-error:0.15534                              \n",
      "\n",
      "[35]\ttrain-error:0.15547\ttest-error:0.15534                              \n",
      "\n",
      "[36]\ttrain-error:0.15544\ttest-error:0.15534                              \n",
      "\n",
      "[37]\ttrain-error:0.15544\ttest-error:0.15534                              \n",
      "\n",
      "[38]\ttrain-error:0.15540\ttest-error:0.15540                              \n",
      "\n",
      "[39]\ttrain-error:0.15540\ttest-error:0.15540                              \n",
      "\n",
      "[40]\ttrain-error:0.15538\ttest-error:0.15540                              \n",
      "\n",
      "[41]\ttrain-error:0.15534\ttest-error:0.15534                              \n",
      "\n",
      "[42]\ttrain-error:0.15540\ttest-error:0.15534                              \n",
      "\n",
      "[43]\ttrain-error:0.15540\ttest-error:0.15534                              \n",
      "\n",
      "[44]\ttrain-error:0.15540\ttest-error:0.15540                              \n",
      "\n",
      "[45]\ttrain-error:0.15540\ttest-error:0.15534                              \n",
      "\n",
      "[46]\ttrain-error:0.15540\ttest-error:0.15540                              \n",
      "\n",
      "[47]\ttrain-error:0.15534\ttest-error:0.15534                              \n",
      "\n",
      "[48]\ttrain-error:0.15540\ttest-error:0.15540                              \n",
      "\n",
      "[49]\ttrain-error:0.15540\ttest-error:0.15534                              \n",
      "\n",
      "[50]\ttrain-error:0.15547\ttest-error:0.15540                              \n",
      "\n",
      "[51]\ttrain-error:0.15534\ttest-error:0.15534                              \n",
      "\n",
      "[52]\ttrain-error:0.15534\ttest-error:0.15540                              \n",
      "\n",
      "[53]\ttrain-error:0.15534\ttest-error:0.15540                              \n",
      "\n",
      "[54]\ttrain-error:0.15534\ttest-error:0.15540                              \n",
      "\n",
      "[55]\ttrain-error:0.15534\ttest-error:0.15528                              \n",
      "\n",
      "[56]\ttrain-error:0.15531\ttest-error:0.15522                              \n",
      "\n",
      "[57]\ttrain-error:0.15531\ttest-error:0.15522                              \n",
      "\n",
      "[58]\ttrain-error:0.15531\ttest-error:0.15528                              \n",
      "\n",
      "[59]\ttrain-error:0.15531\ttest-error:0.15528                              \n",
      "\n",
      "[60]\ttrain-error:0.15531\ttest-error:0.15528                              \n",
      "\n",
      "[61]\ttrain-error:0.15528\ttest-error:0.15528                              \n",
      "\n",
      "[62]\ttrain-error:0.15528\ttest-error:0.15534                              \n",
      "\n",
      "[63]\ttrain-error:0.15528\ttest-error:0.15528                              \n",
      "\n",
      "[64]\ttrain-error:0.15528\ttest-error:0.15528                              \n",
      "\n",
      "[65]\ttrain-error:0.15531\ttest-error:0.15528                              \n",
      "\n",
      "[66]\ttrain-error:0.15531\ttest-error:0.15528                              \n",
      "\n",
      "[67]\ttrain-error:0.15531\ttest-error:0.15528                              \n",
      "\n",
      "[68]\ttrain-error:0.15531\ttest-error:0.15528                              \n",
      "\n",
      "[69]\ttrain-error:0.15531\ttest-error:0.15528                              \n",
      "\n",
      "[70]\ttrain-error:0.15528\ttest-error:0.15528                              \n",
      "\n",
      "[71]\ttrain-error:0.15528\ttest-error:0.15528                              \n",
      "\n",
      "[72]\ttrain-error:0.15525\ttest-error:0.15516                              \n",
      "\n",
      "[73]\ttrain-error:0.15528\ttest-error:0.15504                              \n",
      "\n",
      "[74]\ttrain-error:0.15525\ttest-error:0.15504                              \n",
      "\n",
      "[75]\ttrain-error:0.15525\ttest-error:0.15516                              \n",
      "\n",
      "[76]\ttrain-error:0.15528\ttest-error:0.15528                              \n",
      "\n",
      "[77]\ttrain-error:0.15528\ttest-error:0.15528                              \n",
      "\n",
      "[78]\ttrain-error:0.15525\ttest-error:0.15516                              \n",
      "\n",
      "[79]\ttrain-error:0.15525\ttest-error:0.15510                              \n",
      "\n",
      "[80]\ttrain-error:0.15528\ttest-error:0.15528                              \n",
      "\n",
      "[81]\ttrain-error:0.15528\ttest-error:0.15528                              \n",
      "\n",
      "[82]\ttrain-error:0.15528\ttest-error:0.15528                              \n",
      "\n",
      "[83]\ttrain-error:0.15528\ttest-error:0.15528                              \n",
      "\n",
      "[84]\ttrain-error:0.15525\ttest-error:0.15510                              \n",
      "\n",
      "[85]\ttrain-error:0.15525\ttest-error:0.15510                              \n",
      "\n",
      "[86]\ttrain-error:0.15525\ttest-error:0.15510                              \n",
      "\n",
      "[87]\ttrain-error:0.15540\ttest-error:0.15498                              \n",
      "\n",
      "[88]\ttrain-error:0.15538\ttest-error:0.15498                              \n",
      "\n",
      "[89]\ttrain-error:0.15534\ttest-error:0.15498                              \n",
      "\n",
      "[90]\ttrain-error:0.15531\ttest-error:0.15491                              \n",
      "\n",
      "[91]\ttrain-error:0.15534\ttest-error:0.15491                              \n",
      "\n",
      "[92]\ttrain-error:0.15534\ttest-error:0.15485                              \n",
      "\n",
      "[93]\ttrain-error:0.15538\ttest-error:0.15498                              \n",
      "\n",
      "[94]\ttrain-error:0.15534\ttest-error:0.15491                              \n",
      "\n",
      "[95]\ttrain-error:0.15534\ttest-error:0.15491                              \n",
      "\n",
      "[96]\ttrain-error:0.15538\ttest-error:0.15498                              \n",
      "\n",
      "[97]\ttrain-error:0.15538\ttest-error:0.15491                              \n",
      "\n",
      "[98]\ttrain-error:0.15534\ttest-error:0.15485                              \n",
      "\n",
      "[99]\ttrain-error:0.15540\ttest-error:0.15498                              \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.5411738040322798, 'colsample_bytree': 0.9462856940311716, 'eta': 0.22301212111556537, 'eval_metric': ('error',), 'extra_dims': 7, 'gamma': 0, 'lambda': 0, 'max_depth': 3, 'min_child_weight': 0.5628998193188653, 'objective': 'binary:logistic', 'subsample': 0.8555512638728737}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:12:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15169\ttest-error:0.15178                               \n",
      "\n",
      "[1]\ttrain-error:0.15519\ttest-error:0.15553                               \n",
      "\n",
      "[2]\ttrain-error:0.14687\ttest-error:0.14644                               \n",
      "\n",
      "[3]\ttrain-error:0.14352\ttest-error:0.14306                               \n",
      "\n",
      "[4]\ttrain-error:0.13772\ttest-error:0.13864                               \n",
      "\n",
      "[5]\ttrain-error:0.13556\ttest-error:0.13673                               \n",
      "\n",
      "[6]\ttrain-error:0.13406\ttest-error:0.13538                               \n",
      "\n",
      "[7]\ttrain-error:0.13074\ttest-error:0.13194                               \n",
      "\n",
      "[8]\ttrain-error:0.12899\ttest-error:0.13059                               \n",
      "\n",
      "[9]\ttrain-error:0.12733\ttest-error:0.12979                               \n",
      "\n",
      "[10]\ttrain-error:0.12657\ttest-error:0.12936                              \n",
      "\n",
      "[11]\ttrain-error:0.12509\ttest-error:0.12893                              \n",
      "\n",
      "[12]\ttrain-error:0.12463\ttest-error:0.12844                              \n",
      "\n",
      "[13]\ttrain-error:0.12365\ttest-error:0.12838                              \n",
      "\n",
      "[14]\ttrain-error:0.12248\ttest-error:0.12684                              \n",
      "\n",
      "[15]\ttrain-error:0.12202\ttest-error:0.12678                              \n",
      "\n",
      "[16]\ttrain-error:0.12134\ttest-error:0.12623                              \n",
      "\n",
      "[17]\ttrain-error:0.12095\ttest-error:0.12654                              \n",
      "\n",
      "[18]\ttrain-error:0.12024\ttest-error:0.12604                              \n",
      "\n",
      "[19]\ttrain-error:0.11929\ttest-error:0.12598                              \n",
      "\n",
      "[20]\ttrain-error:0.11904\ttest-error:0.12580                              \n",
      "\n",
      "[21]\ttrain-error:0.11895\ttest-error:0.12666                              \n",
      "\n",
      "[22]\ttrain-error:0.11864\ttest-error:0.12690                              \n",
      "\n",
      "[23]\ttrain-error:0.11781\ttest-error:0.12549                              \n",
      "\n",
      "[24]\ttrain-error:0.11778\ttest-error:0.12598                              \n",
      "\n",
      "[25]\ttrain-error:0.11757\ttest-error:0.12580                              \n",
      "\n",
      "[26]\ttrain-error:0.11775\ttest-error:0.12666                              \n",
      "\n",
      "[27]\ttrain-error:0.11661\ttest-error:0.12635                              \n",
      "\n",
      "[28]\ttrain-error:0.11652\ttest-error:0.12561                              \n",
      "\n",
      "[29]\ttrain-error:0.11606\ttest-error:0.12500                              \n",
      "\n",
      "[30]\ttrain-error:0.11609\ttest-error:0.12555                              \n",
      "\n",
      "[31]\ttrain-error:0.11542\ttest-error:0.12463                              \n",
      "\n",
      "[32]\ttrain-error:0.11529\ttest-error:0.12500                              \n",
      "\n",
      "[33]\ttrain-error:0.11456\ttest-error:0.12574                              \n",
      "\n",
      "[34]\ttrain-error:0.11422\ttest-error:0.12525                              \n",
      "\n",
      "[35]\ttrain-error:0.11431\ttest-error:0.12598                              \n",
      "\n",
      "[36]\ttrain-error:0.11404\ttest-error:0.12574                              \n",
      "\n",
      "[37]\ttrain-error:0.11379\ttest-error:0.12580                              \n",
      "\n",
      "[38]\ttrain-error:0.11345\ttest-error:0.12604                              \n",
      "\n",
      "[39]\ttrain-error:0.11318\ttest-error:0.12617                              \n",
      "\n",
      "[40]\ttrain-error:0.11302\ttest-error:0.12660                              \n",
      "\n",
      "[41]\ttrain-error:0.11290\ttest-error:0.12721                              \n",
      "\n",
      "[42]\ttrain-error:0.11207\ttest-error:0.12697                              \n",
      "\n",
      "[43]\ttrain-error:0.11207\ttest-error:0.12684                              \n",
      "\n",
      "[44]\ttrain-error:0.11198\ttest-error:0.12703                              \n",
      "\n",
      "[45]\ttrain-error:0.11124\ttest-error:0.12672                              \n",
      "\n",
      "[46]\ttrain-error:0.11139\ttest-error:0.12647                              \n",
      "\n",
      "[47]\ttrain-error:0.11032\ttest-error:0.12740                              \n",
      "\n",
      "[48]\ttrain-error:0.11041\ttest-error:0.12629                              \n",
      "\n",
      "[49]\ttrain-error:0.11063\ttest-error:0.12641                              \n",
      "\n",
      "[50]\ttrain-error:0.11007\ttest-error:0.12690                              \n",
      "\n",
      "[51]\ttrain-error:0.11063\ttest-error:0.12684                              \n",
      "\n",
      "[52]\ttrain-error:0.10967\ttest-error:0.12746                              \n",
      "\n",
      "[53]\ttrain-error:0.11032\ttest-error:0.12709                              \n",
      "\n",
      "[54]\ttrain-error:0.11038\ttest-error:0.12641                              \n",
      "\n",
      "[55]\ttrain-error:0.10986\ttest-error:0.12684                              \n",
      "\n",
      "[56]\ttrain-error:0.10943\ttest-error:0.12721                              \n",
      "\n",
      "[57]\ttrain-error:0.10927\ttest-error:0.12733                              \n",
      "\n",
      "[58]\ttrain-error:0.10915\ttest-error:0.12727                              \n",
      "\n",
      "[59]\ttrain-error:0.10906\ttest-error:0.12684                              \n",
      "\n",
      "[60]\ttrain-error:0.10955\ttest-error:0.12746                              \n",
      "\n",
      "[61]\ttrain-error:0.10888\ttest-error:0.12697                              \n",
      "\n",
      "[62]\ttrain-error:0.10857\ttest-error:0.12758                              \n",
      "\n",
      "[63]\ttrain-error:0.10826\ttest-error:0.12709                              \n",
      "\n",
      "[64]\ttrain-error:0.10808\ttest-error:0.12746                              \n",
      "\n",
      "[65]\ttrain-error:0.10762\ttest-error:0.12807                              \n",
      "\n",
      "[66]\ttrain-error:0.10774\ttest-error:0.12776                              \n",
      "\n",
      "[67]\ttrain-error:0.10755\ttest-error:0.12770                              \n",
      "\n",
      "[68]\ttrain-error:0.10762\ttest-error:0.12733                              \n",
      "\n",
      "[69]\ttrain-error:0.10734\ttest-error:0.12764                              \n",
      "\n",
      "[70]\ttrain-error:0.10694\ttest-error:0.12801                              \n",
      "\n",
      "[71]\ttrain-error:0.10673\ttest-error:0.12770                              \n",
      "\n",
      "[72]\ttrain-error:0.10676\ttest-error:0.12764                              \n",
      "\n",
      "[73]\ttrain-error:0.10648\ttest-error:0.12776                              \n",
      "\n",
      "[74]\ttrain-error:0.10605\ttest-error:0.12776                              \n",
      "\n",
      "[75]\ttrain-error:0.10599\ttest-error:0.12746                              \n",
      "\n",
      "[76]\ttrain-error:0.10565\ttest-error:0.12678                              \n",
      "\n",
      "[77]\ttrain-error:0.10534\ttest-error:0.12758                              \n",
      "\n",
      "[78]\ttrain-error:0.10565\ttest-error:0.12727                              \n",
      "\n",
      "[79]\ttrain-error:0.10510\ttest-error:0.12740                              \n",
      "\n",
      "[80]\ttrain-error:0.10479\ttest-error:0.12752                              \n",
      "\n",
      "[81]\ttrain-error:0.10485\ttest-error:0.12752                              \n",
      "\n",
      "[82]\ttrain-error:0.10504\ttest-error:0.12770                              \n",
      "\n",
      "[83]\ttrain-error:0.10451\ttest-error:0.12746                              \n",
      "\n",
      "[84]\ttrain-error:0.10421\ttest-error:0.12807                              \n",
      "\n",
      "[85]\ttrain-error:0.10433\ttest-error:0.12807                              \n",
      "\n",
      "[86]\ttrain-error:0.10448\ttest-error:0.12856                              \n",
      "\n",
      "[87]\ttrain-error:0.10399\ttest-error:0.12795                              \n",
      "\n",
      "[88]\ttrain-error:0.10408\ttest-error:0.12850                              \n",
      "\n",
      "[89]\ttrain-error:0.10362\ttest-error:0.12844                              \n",
      "\n",
      "[90]\ttrain-error:0.10390\ttest-error:0.12948                              \n",
      "\n",
      "[91]\ttrain-error:0.10375\ttest-error:0.12893                              \n",
      "\n",
      "[92]\ttrain-error:0.10329\ttest-error:0.12869                              \n",
      "\n",
      "[93]\ttrain-error:0.10319\ttest-error:0.12930                              \n",
      "\n",
      "[94]\ttrain-error:0.10255\ttest-error:0.12912                              \n",
      "\n",
      "[95]\ttrain-error:0.10255\ttest-error:0.12899                              \n",
      "\n",
      "[96]\ttrain-error:0.10249\ttest-error:0.12887                              \n",
      "\n",
      "[97]\ttrain-error:0.10227\ttest-error:0.12936                              \n",
      "\n",
      "[98]\ttrain-error:0.10233\ttest-error:0.12912                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99]\ttrain-error:0.10193\ttest-error:0.12930                              \n",
      "\n",
      "NEW BEST VALUE!                                                          \n",
      "{'alpha': 0, 'btype': 'In', 'colsample_bylevel': 0.8392502825340482, 'colsample_bytree': 0.6321146709333538, 'eta': 0.08182165114598532, 'eval_metric': ('error',), 'extra_dims': 8, 'gamma': 2.501735165578811e-05, 'lambda': 3.2871642968947863e-05, 'max_depth': 7, 'min_child_weight': 0.00032023198296050745, 'objective': 'binary:logistic', 'subsample': 0.9373961276869333}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:13:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13596\ttest-error:0.13772                               \n",
      "\n",
      "[1]\ttrain-error:0.13283\ttest-error:0.13372                               \n",
      "\n",
      "[2]\ttrain-error:0.12893\ttest-error:0.13249                               \n",
      "\n",
      "[3]\ttrain-error:0.12592\ttest-error:0.12954                               \n",
      "\n",
      "[4]\ttrain-error:0.12325\ttest-error:0.12697                               \n",
      "\n",
      "[5]\ttrain-error:0.12128\ttest-error:0.12623                               \n",
      "\n",
      "[6]\ttrain-error:0.11790\ttest-error:0.12555                               \n",
      "\n",
      "[7]\ttrain-error:0.11609\ttest-error:0.12426                               \n",
      "\n",
      "[8]\ttrain-error:0.11367\ttest-error:0.12494                               \n",
      "\n",
      "[9]\ttrain-error:0.11127\ttest-error:0.12469                               \n",
      "\n",
      "[10]\ttrain-error:0.11023\ttest-error:0.12500                              \n",
      "\n",
      "[11]\ttrain-error:0.10970\ttest-error:0.12445                              \n",
      "\n",
      "[12]\ttrain-error:0.10805\ttest-error:0.12432                              \n",
      "\n",
      "[13]\ttrain-error:0.10654\ttest-error:0.12500                              \n",
      "\n",
      "[14]\ttrain-error:0.10513\ttest-error:0.12494                              \n",
      "\n",
      "[15]\ttrain-error:0.10415\ttest-error:0.12518                              \n",
      "\n",
      "[16]\ttrain-error:0.10319\ttest-error:0.12561                              \n",
      "\n",
      "[17]\ttrain-error:0.10203\ttest-error:0.12506                              \n",
      "\n",
      "[18]\ttrain-error:0.10043\ttest-error:0.12457                              \n",
      "\n",
      "[19]\ttrain-error:0.09917\ttest-error:0.12420                              \n",
      "\n",
      "[20]\ttrain-error:0.09843\ttest-error:0.12500                              \n",
      "\n",
      "[21]\ttrain-error:0.09770\ttest-error:0.12475                              \n",
      "\n",
      "[22]\ttrain-error:0.09616\ttest-error:0.12445                              \n",
      "\n",
      "[23]\ttrain-error:0.09549\ttest-error:0.12445                              \n",
      "\n",
      "[24]\ttrain-error:0.09456\ttest-error:0.12469                              \n",
      "\n",
      "[25]\ttrain-error:0.09343\ttest-error:0.12432                              \n",
      "\n",
      "[26]\ttrain-error:0.09269\ttest-error:0.12463                              \n",
      "\n",
      "[27]\ttrain-error:0.09183\ttest-error:0.12414                              \n",
      "\n",
      "[28]\ttrain-error:0.09048\ttest-error:0.12451                              \n",
      "\n",
      "[29]\ttrain-error:0.08947\ttest-error:0.12445                              \n",
      "\n",
      "[30]\ttrain-error:0.08756\ttest-error:0.12488                              \n",
      "\n",
      "[31]\ttrain-error:0.08603\ttest-error:0.12568                              \n",
      "\n",
      "[32]\ttrain-error:0.08529\ttest-error:0.12574                              \n",
      "\n",
      "[33]\ttrain-error:0.08431\ttest-error:0.12555                              \n",
      "\n",
      "[34]\ttrain-error:0.08345\ttest-error:0.12574                              \n",
      "\n",
      "[35]\ttrain-error:0.08296\ttest-error:0.12611                              \n",
      "\n",
      "[36]\ttrain-error:0.08191\ttest-error:0.12604                              \n",
      "\n",
      "[37]\ttrain-error:0.08013\ttest-error:0.12611                              \n",
      "\n",
      "[38]\ttrain-error:0.07930\ttest-error:0.12678                              \n",
      "\n",
      "[39]\ttrain-error:0.07847\ttest-error:0.12647                              \n",
      "\n",
      "[40]\ttrain-error:0.07761\ttest-error:0.12654                              \n",
      "\n",
      "[41]\ttrain-error:0.07684\ttest-error:0.12641                              \n",
      "\n",
      "[42]\ttrain-error:0.07595\ttest-error:0.12672                              \n",
      "\n",
      "[43]\ttrain-error:0.07420\ttest-error:0.12672                              \n",
      "\n",
      "[44]\ttrain-error:0.07257\ttest-error:0.12635                              \n",
      "\n",
      "[45]\ttrain-error:0.07190\ttest-error:0.12660                              \n",
      "\n",
      "[46]\ttrain-error:0.07125\ttest-error:0.12678                              \n",
      "\n",
      "[47]\ttrain-error:0.07027\ttest-error:0.12660                              \n",
      "\n",
      "[48]\ttrain-error:0.06981\ttest-error:0.12672                              \n",
      "\n",
      "[49]\ttrain-error:0.06913\ttest-error:0.12703                              \n",
      "\n",
      "[50]\ttrain-error:0.06797\ttest-error:0.12746                              \n",
      "\n",
      "[51]\ttrain-error:0.06729\ttest-error:0.12746                              \n",
      "\n",
      "[52]\ttrain-error:0.06631\ttest-error:0.12807                              \n",
      "\n",
      "[53]\ttrain-error:0.06539\ttest-error:0.12838                              \n",
      "\n",
      "[54]\ttrain-error:0.06483\ttest-error:0.12850                              \n",
      "\n",
      "[55]\ttrain-error:0.06391\ttest-error:0.12838                              \n",
      "\n",
      "[56]\ttrain-error:0.06302\ttest-error:0.12862                              \n",
      "\n",
      "[57]\ttrain-error:0.06232\ttest-error:0.12924                              \n",
      "\n",
      "[58]\ttrain-error:0.06149\ttest-error:0.12899                              \n",
      "\n",
      "[59]\ttrain-error:0.06096\ttest-error:0.12991                              \n",
      "\n",
      "[60]\ttrain-error:0.05998\ttest-error:0.13034                              \n",
      "\n",
      "[61]\ttrain-error:0.05842\ttest-error:0.13071                              \n",
      "\n",
      "[62]\ttrain-error:0.05802\ttest-error:0.13065                              \n",
      "\n",
      "[63]\ttrain-error:0.05737\ttest-error:0.13065                              \n",
      "\n",
      "[64]\ttrain-error:0.05673\ttest-error:0.13114                              \n",
      "\n",
      "[65]\ttrain-error:0.05590\ttest-error:0.13157                              \n",
      "\n",
      "[66]\ttrain-error:0.05491\ttest-error:0.13139                              \n",
      "\n",
      "[67]\ttrain-error:0.05390\ttest-error:0.13151                              \n",
      "\n",
      "[68]\ttrain-error:0.05323\ttest-error:0.13114                              \n",
      "\n",
      "[69]\ttrain-error:0.05246\ttest-error:0.13114                              \n",
      "\n",
      "[70]\ttrain-error:0.05172\ttest-error:0.13102                              \n",
      "\n",
      "[71]\ttrain-error:0.05141\ttest-error:0.13182                              \n",
      "\n",
      "[72]\ttrain-error:0.05049\ttest-error:0.13151                              \n",
      "\n",
      "[73]\ttrain-error:0.05006\ttest-error:0.13139                              \n",
      "\n",
      "[74]\ttrain-error:0.04945\ttest-error:0.13176                              \n",
      "\n",
      "[75]\ttrain-error:0.04859\ttest-error:0.13151                              \n",
      "\n",
      "[76]\ttrain-error:0.04736\ttest-error:0.13151                              \n",
      "\n",
      "[77]\ttrain-error:0.04665\ttest-error:0.13163                              \n",
      "\n",
      "[78]\ttrain-error:0.04604\ttest-error:0.13139                              \n",
      "\n",
      "[79]\ttrain-error:0.04546\ttest-error:0.13157                              \n",
      "\n",
      "[80]\ttrain-error:0.04503\ttest-error:0.13139                              \n",
      "\n",
      "[81]\ttrain-error:0.04444\ttest-error:0.13145                              \n",
      "\n",
      "[82]\ttrain-error:0.04407\ttest-error:0.13114                              \n",
      "\n",
      "[83]\ttrain-error:0.04300\ttest-error:0.13084                              \n",
      "\n",
      "[84]\ttrain-error:0.04195\ttest-error:0.13145                              \n",
      "\n",
      "[85]\ttrain-error:0.04140\ttest-error:0.13114                              \n",
      "\n",
      "[86]\ttrain-error:0.04063\ttest-error:0.13102                              \n",
      "\n",
      "[87]\ttrain-error:0.04014\ttest-error:0.13163                              \n",
      "\n",
      "[88]\ttrain-error:0.03910\ttest-error:0.13231                              \n",
      "\n",
      "[89]\ttrain-error:0.03824\ttest-error:0.13268                              \n",
      "\n",
      "[90]\ttrain-error:0.03735\ttest-error:0.13311                              \n",
      "\n",
      "[91]\ttrain-error:0.03689\ttest-error:0.13323                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92]\ttrain-error:0.03624\ttest-error:0.13298                              \n",
      "\n",
      "[93]\ttrain-error:0.03581\ttest-error:0.13298                              \n",
      "\n",
      "[94]\ttrain-error:0.03513\ttest-error:0.13348                              \n",
      "\n",
      "[95]\ttrain-error:0.03440\ttest-error:0.13329                              \n",
      "\n",
      "[96]\ttrain-error:0.03369\ttest-error:0.13311                              \n",
      "\n",
      "[97]\ttrain-error:0.03363\ttest-error:0.13391                              \n",
      "\n",
      "[98]\ttrain-error:0.03308\ttest-error:0.13378                              \n",
      "\n",
      "[99]\ttrain-error:0.03271\ttest-error:0.13378                              \n",
      "\n",
      "NEW BEST VALUE!                                                          \n",
      "{'alpha': 1.6651641910240288e-05, 'btype': 'I', 'colsample_bylevel': 0.6778311535982134, 'colsample_bytree': 0.8023559747285003, 'eta': 0.0066830022270406185, 'eval_metric': ('error',), 'extra_dims': 6, 'gamma': 0, 'lambda': 0, 'max_depth': 4, 'min_child_weight': 0.022649704423212822, 'objective': 'binary:logistic', 'subsample': 0.788237391953672}\n",
      "Overwriting param `num_class`                                           \n",
      "Overwriting param `objective` while setting `obj` in train.             \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                 \n",
      "Setting param `disable_default_eval_metric` to 1.                       \n",
      "[22:15:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14843\ttest-error:0.14724                              \n",
      "\n",
      "[1]\ttrain-error:0.15307\ttest-error:0.15233                              \n",
      "\n",
      "[2]\ttrain-error:0.15387\ttest-error:0.15301                              \n",
      "\n",
      "[3]\ttrain-error:0.15421\ttest-error:0.15350                              \n",
      "\n",
      "[4]\ttrain-error:0.15461\ttest-error:0.15393                              \n",
      "\n",
      "[5]\ttrain-error:0.15175\ttest-error:0.15147                              \n",
      "\n",
      "[6]\ttrain-error:0.14954\ttest-error:0.14969                              \n",
      "\n",
      "[7]\ttrain-error:0.14923\ttest-error:0.14932                              \n",
      "\n",
      "[8]\ttrain-error:0.15120\ttest-error:0.15147                              \n",
      "\n",
      "[9]\ttrain-error:0.15114\ttest-error:0.15135                              \n",
      "\n",
      "[10]\ttrain-error:0.15107\ttest-error:0.15111                             \n",
      "\n",
      "[11]\ttrain-error:0.14932\ttest-error:0.14969                             \n",
      "\n",
      "[12]\ttrain-error:0.15049\ttest-error:0.15037                             \n",
      "\n",
      "[13]\ttrain-error:0.15098\ttest-error:0.15086                             \n",
      "\n",
      "[14]\ttrain-error:0.15080\ttest-error:0.15086                             \n",
      "\n",
      "[15]\ttrain-error:0.15055\ttest-error:0.15080                             \n",
      "\n",
      "[16]\ttrain-error:0.15000\ttest-error:0.14982                             \n",
      "\n",
      "[17]\ttrain-error:0.15055\ttest-error:0.15068                             \n",
      "\n",
      "[18]\ttrain-error:0.14877\ttest-error:0.14902                             \n",
      "\n",
      "[19]\ttrain-error:0.14825\ttest-error:0.14865                             \n",
      "\n",
      "[20]\ttrain-error:0.14794\ttest-error:0.14822                             \n",
      "\n",
      "[21]\ttrain-error:0.14794\ttest-error:0.14803                             \n",
      "\n",
      "[22]\ttrain-error:0.14751\ttest-error:0.14803                             \n",
      "\n",
      "[23]\ttrain-error:0.14696\ttest-error:0.14730                             \n",
      "\n",
      "[24]\ttrain-error:0.14705\ttest-error:0.14730                             \n",
      "\n",
      "[25]\ttrain-error:0.14576\ttest-error:0.14619                             \n",
      "\n",
      "[26]\ttrain-error:0.14539\ttest-error:0.14546                             \n",
      "\n",
      "[27]\ttrain-error:0.14521\ttest-error:0.14539                             \n",
      "\n",
      "[28]\ttrain-error:0.14521\ttest-error:0.14539                             \n",
      "\n",
      "[29]\ttrain-error:0.14518\ttest-error:0.14533                             \n",
      "\n",
      "[30]\ttrain-error:0.14515\ttest-error:0.14546                             \n",
      "\n",
      "[31]\ttrain-error:0.14487\ttest-error:0.14502                             \n",
      "\n",
      "[32]\ttrain-error:0.14469\ttest-error:0.14466                             \n",
      "\n",
      "[33]\ttrain-error:0.14453\ttest-error:0.14453                             \n",
      "\n",
      "[34]\ttrain-error:0.14447\ttest-error:0.14441                             \n",
      "\n",
      "[35]\ttrain-error:0.14398\ttest-error:0.14410                             \n",
      "\n",
      "[36]\ttrain-error:0.14395\ttest-error:0.14410                             \n",
      "\n",
      "[37]\ttrain-error:0.14389\ttest-error:0.14416                             \n",
      "\n",
      "[38]\ttrain-error:0.14398\ttest-error:0.14441                             \n",
      "\n",
      "[39]\ttrain-error:0.14398\ttest-error:0.14423                             \n",
      "\n",
      "[40]\ttrain-error:0.14395\ttest-error:0.14410                             \n",
      "\n",
      "[41]\ttrain-error:0.14377\ttest-error:0.14410                             \n",
      "\n",
      "[42]\ttrain-error:0.14349\ttest-error:0.14404                             \n",
      "\n",
      "[43]\ttrain-error:0.14220\ttest-error:0.14251                             \n",
      "\n",
      "[44]\ttrain-error:0.14238\ttest-error:0.14226                             \n",
      "\n",
      "[45]\ttrain-error:0.14235\ttest-error:0.14214                             \n",
      "\n",
      "[46]\ttrain-error:0.14232\ttest-error:0.14220                             \n",
      "\n",
      "[47]\ttrain-error:0.14235\ttest-error:0.14226                             \n",
      "\n",
      "[48]\ttrain-error:0.14241\ttest-error:0.14183                             \n",
      "\n",
      "[49]\ttrain-error:0.14232\ttest-error:0.14177                             \n",
      "\n",
      "[50]\ttrain-error:0.14217\ttest-error:0.14183                             \n",
      "\n",
      "[51]\ttrain-error:0.14235\ttest-error:0.14158                             \n",
      "\n",
      "[52]\ttrain-error:0.14229\ttest-error:0.14146                             \n",
      "\n",
      "[53]\ttrain-error:0.14211\ttest-error:0.14146                             \n",
      "\n",
      "[54]\ttrain-error:0.14189\ttest-error:0.14122                             \n",
      "\n",
      "[55]\ttrain-error:0.14183\ttest-error:0.14109                             \n",
      "\n",
      "[56]\ttrain-error:0.14174\ttest-error:0.14128                             \n",
      "\n",
      "[57]\ttrain-error:0.14152\ttest-error:0.14128                             \n",
      "\n",
      "[58]\ttrain-error:0.14161\ttest-error:0.14116                             \n",
      "\n",
      "[59]\ttrain-error:0.14161\ttest-error:0.14116                             \n",
      "\n",
      "[60]\ttrain-error:0.14165\ttest-error:0.14103                             \n",
      "\n",
      "[61]\ttrain-error:0.14168\ttest-error:0.14085                             \n",
      "\n",
      "[62]\ttrain-error:0.14161\ttest-error:0.14091                             \n",
      "\n",
      "[63]\ttrain-error:0.14146\ttest-error:0.14079                             \n",
      "\n",
      "[64]\ttrain-error:0.14112\ttest-error:0.14042                             \n",
      "\n",
      "[65]\ttrain-error:0.14109\ttest-error:0.13993                             \n",
      "\n",
      "[66]\ttrain-error:0.14112\ttest-error:0.13956                             \n",
      "\n",
      "[67]\ttrain-error:0.14076\ttest-error:0.13925                             \n",
      "\n",
      "[68]\ttrain-error:0.14085\ttest-error:0.13919                             \n",
      "\n",
      "[69]\ttrain-error:0.14079\ttest-error:0.13900                             \n",
      "\n",
      "[70]\ttrain-error:0.14072\ttest-error:0.13913                             \n",
      "\n",
      "[71]\ttrain-error:0.14079\ttest-error:0.13894                             \n",
      "\n",
      "[72]\ttrain-error:0.14060\ttest-error:0.13882                             \n",
      "\n",
      "[73]\ttrain-error:0.14069\ttest-error:0.13858                             \n",
      "\n",
      "[74]\ttrain-error:0.14054\ttest-error:0.13839                             \n",
      "\n",
      "[75]\ttrain-error:0.14026\ttest-error:0.13845                             \n",
      "\n",
      "[76]\ttrain-error:0.14008\ttest-error:0.13821                             \n",
      "\n",
      "[77]\ttrain-error:0.14002\ttest-error:0.13864                             \n",
      "\n",
      "[78]\ttrain-error:0.14002\ttest-error:0.13839                             \n",
      "\n",
      "[79]\ttrain-error:0.14002\ttest-error:0.13833                             \n",
      "\n",
      "[80]\ttrain-error:0.13993\ttest-error:0.13839                             \n",
      "\n",
      "[81]\ttrain-error:0.13977\ttest-error:0.13827                             \n",
      "\n",
      "[82]\ttrain-error:0.13953\ttest-error:0.13821                             \n",
      "\n",
      "[83]\ttrain-error:0.13925\ttest-error:0.13814                             \n",
      "\n",
      "[84]\ttrain-error:0.13934\ttest-error:0.13827                             \n",
      "\n",
      "[85]\ttrain-error:0.13910\ttest-error:0.13821                             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86]\ttrain-error:0.13904\ttest-error:0.13802                             \n",
      "\n",
      "[87]\ttrain-error:0.13891\ttest-error:0.13790                             \n",
      "\n",
      "[88]\ttrain-error:0.13882\ttest-error:0.13778                             \n",
      "\n",
      "[89]\ttrain-error:0.13873\ttest-error:0.13778                             \n",
      "\n",
      "[90]\ttrain-error:0.13870\ttest-error:0.13784                             \n",
      "\n",
      "[91]\ttrain-error:0.13845\ttest-error:0.13772                             \n",
      "\n",
      "[92]\ttrain-error:0.13845\ttest-error:0.13772                             \n",
      "\n",
      "[93]\ttrain-error:0.13839\ttest-error:0.13765                             \n",
      "\n",
      "[94]\ttrain-error:0.13827\ttest-error:0.13765                             \n",
      "\n",
      "[95]\ttrain-error:0.13805\ttest-error:0.13735                             \n",
      "\n",
      "[96]\ttrain-error:0.13802\ttest-error:0.13716                             \n",
      "\n",
      "[97]\ttrain-error:0.13802\ttest-error:0.13716                             \n",
      "\n",
      "[98]\ttrain-error:0.13805\ttest-error:0.13698                             \n",
      "\n",
      "[99]\ttrain-error:0.13790\ttest-error:0.13692                             \n",
      "\n",
      "{'alpha': 0, 'btype': 'I', 'colsample_bylevel': 0.6201237690985373, 'colsample_bytree': 0.6209146281778603, 'eta': 0.003479382534919986, 'eval_metric': ('error',), 'extra_dims': 8, 'gamma': 1.6781678926565728e-05, 'lambda': 0, 'max_depth': 5, 'min_child_weight': 0.0011064586338929664, 'objective': 'binary:logistic', 'subsample': 0.579763856784276}\n",
      "Overwriting param `num_class`                                           \n",
      "Overwriting param `objective` while setting `obj` in train.             \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                 \n",
      "Setting param `disable_default_eval_metric` to 1.                       \n",
      "[22:16:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14324\ttest-error:0.14177                              \n",
      "\n",
      "[1]\ttrain-error:0.14174\ttest-error:0.14281                              \n",
      "\n",
      "[2]\ttrain-error:0.14223\ttest-error:0.14380                              \n",
      "\n",
      "[3]\ttrain-error:0.14309\ttest-error:0.14416                              \n",
      "\n",
      "[4]\ttrain-error:0.14441\ttest-error:0.14576                              \n",
      "\n",
      "[5]\ttrain-error:0.14518\ttest-error:0.14570                              \n",
      "\n",
      "[6]\ttrain-error:0.14591\ttest-error:0.14650                              \n",
      "\n",
      "[7]\ttrain-error:0.14641\ttest-error:0.14705                              \n",
      "\n",
      "[8]\ttrain-error:0.14512\ttest-error:0.14595                              \n",
      "\n",
      "[9]\ttrain-error:0.14469\ttest-error:0.14564                              \n",
      "\n",
      "[10]\ttrain-error:0.14469\ttest-error:0.14601                             \n",
      "\n",
      "[11]\ttrain-error:0.14438\ttest-error:0.14582                             \n",
      "\n",
      "[12]\ttrain-error:0.14435\ttest-error:0.14576                             \n",
      "\n",
      "[13]\ttrain-error:0.14456\ttest-error:0.14558                             \n",
      "\n",
      "[14]\ttrain-error:0.14416\ttest-error:0.14564                             \n",
      "\n",
      "[15]\ttrain-error:0.14416\ttest-error:0.14564                             \n",
      "\n",
      "[16]\ttrain-error:0.14395\ttest-error:0.14546                             \n",
      "\n",
      "[17]\ttrain-error:0.14395\ttest-error:0.14552                             \n",
      "\n",
      "[18]\ttrain-error:0.14389\ttest-error:0.14533                             \n",
      "\n",
      "[19]\ttrain-error:0.14392\ttest-error:0.14539                             \n",
      "\n",
      "[20]\ttrain-error:0.14395\ttest-error:0.14527                             \n",
      "\n",
      "[21]\ttrain-error:0.14349\ttest-error:0.14496                             \n",
      "\n",
      "[22]\ttrain-error:0.14343\ttest-error:0.14441                             \n",
      "\n",
      "[23]\ttrain-error:0.14330\ttest-error:0.14466                             \n",
      "\n",
      "[24]\ttrain-error:0.14337\ttest-error:0.14410                             \n",
      "\n",
      "[25]\ttrain-error:0.14291\ttest-error:0.14398                             \n",
      "\n",
      "[26]\ttrain-error:0.14281\ttest-error:0.14404                             \n",
      "\n",
      "[27]\ttrain-error:0.14254\ttest-error:0.14343                             \n",
      "\n",
      "[28]\ttrain-error:0.14226\ttest-error:0.14337                             \n",
      "\n",
      "[29]\ttrain-error:0.14158\ttest-error:0.14306                             \n",
      "\n",
      "[30]\ttrain-error:0.14161\ttest-error:0.14306                             \n",
      "\n",
      "[31]\ttrain-error:0.14140\ttest-error:0.14294                             \n",
      "\n",
      "[32]\ttrain-error:0.14119\ttest-error:0.14288                             \n",
      "\n",
      "[33]\ttrain-error:0.14054\ttest-error:0.14214                             \n",
      "\n",
      "[34]\ttrain-error:0.14057\ttest-error:0.14244                             \n",
      "\n",
      "[35]\ttrain-error:0.14048\ttest-error:0.14171                             \n",
      "\n",
      "[36]\ttrain-error:0.14051\ttest-error:0.14140                             \n",
      "\n",
      "[37]\ttrain-error:0.14054\ttest-error:0.14122                             \n",
      "\n",
      "[38]\ttrain-error:0.14045\ttest-error:0.14128                             \n",
      "\n",
      "[39]\ttrain-error:0.14026\ttest-error:0.14128                             \n",
      "\n",
      "[40]\ttrain-error:0.14008\ttest-error:0.14128                             \n",
      "\n",
      "[41]\ttrain-error:0.14008\ttest-error:0.14103                             \n",
      "\n",
      "[42]\ttrain-error:0.14008\ttest-error:0.14103                             \n",
      "\n",
      "[43]\ttrain-error:0.14017\ttest-error:0.14085                             \n",
      "\n",
      "[44]\ttrain-error:0.13993\ttest-error:0.14085                             \n",
      "\n",
      "[45]\ttrain-error:0.13980\ttest-error:0.14072                             \n",
      "\n",
      "[46]\ttrain-error:0.13980\ttest-error:0.14066                             \n",
      "\n",
      "[47]\ttrain-error:0.13980\ttest-error:0.14030                             \n",
      "\n",
      "[48]\ttrain-error:0.13968\ttest-error:0.14042                             \n",
      "\n",
      "[49]\ttrain-error:0.13965\ttest-error:0.14036                             \n",
      "\n",
      "[50]\ttrain-error:0.13986\ttest-error:0.14023                             \n",
      "\n",
      "[51]\ttrain-error:0.13983\ttest-error:0.14005                             \n",
      "\n",
      "[52]\ttrain-error:0.13956\ttest-error:0.13993                             \n",
      "\n",
      "[53]\ttrain-error:0.13940\ttest-error:0.14017                             \n",
      "\n",
      "[54]\ttrain-error:0.13944\ttest-error:0.14017                             \n",
      "\n",
      "[55]\ttrain-error:0.13940\ttest-error:0.14005                             \n",
      "\n",
      "[56]\ttrain-error:0.13937\ttest-error:0.13980                             \n",
      "\n",
      "[57]\ttrain-error:0.13934\ttest-error:0.13962                             \n",
      "\n",
      "[58]\ttrain-error:0.13944\ttest-error:0.13962                             \n",
      "\n",
      "[59]\ttrain-error:0.13940\ttest-error:0.13962                             \n",
      "\n",
      "[60]\ttrain-error:0.13940\ttest-error:0.13950                             \n",
      "\n",
      "[61]\ttrain-error:0.13931\ttest-error:0.13925                             \n",
      "\n",
      "[62]\ttrain-error:0.13907\ttest-error:0.13888                             \n",
      "\n",
      "[63]\ttrain-error:0.13900\ttest-error:0.13876                             \n",
      "\n",
      "[64]\ttrain-error:0.13900\ttest-error:0.13845                             \n",
      "\n",
      "[65]\ttrain-error:0.13882\ttest-error:0.13833                             \n",
      "\n",
      "[66]\ttrain-error:0.13861\ttest-error:0.13845                             \n",
      "\n",
      "[67]\ttrain-error:0.13879\ttest-error:0.13839                             \n",
      "\n",
      "[68]\ttrain-error:0.13876\ttest-error:0.13858                             \n",
      "\n",
      "[69]\ttrain-error:0.13879\ttest-error:0.13839                             \n",
      "\n",
      "[70]\ttrain-error:0.13848\ttest-error:0.13821                             \n",
      "\n",
      "[71]\ttrain-error:0.13864\ttest-error:0.13839                             \n",
      "\n",
      "[72]\ttrain-error:0.13848\ttest-error:0.13833                             \n",
      "\n",
      "[73]\ttrain-error:0.13842\ttest-error:0.13796                             \n",
      "\n",
      "[74]\ttrain-error:0.13836\ttest-error:0.13796                             \n",
      "\n",
      "[75]\ttrain-error:0.13830\ttest-error:0.13802                             \n",
      "\n",
      "[76]\ttrain-error:0.13833\ttest-error:0.13790                             \n",
      "\n",
      "[77]\ttrain-error:0.13833\ttest-error:0.13802                             \n",
      "\n",
      "[78]\ttrain-error:0.13830\ttest-error:0.13772                             \n",
      "\n",
      "[79]\ttrain-error:0.13818\ttest-error:0.13753                             \n",
      "\n",
      "[80]\ttrain-error:0.13827\ttest-error:0.13747                             \n",
      "\n",
      "[81]\ttrain-error:0.13818\ttest-error:0.13741                             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82]\ttrain-error:0.13805\ttest-error:0.13722                             \n",
      "\n",
      "[83]\ttrain-error:0.13811\ttest-error:0.13722                             \n",
      "\n",
      "[84]\ttrain-error:0.13799\ttest-error:0.13704                             \n",
      "\n",
      "[85]\ttrain-error:0.13799\ttest-error:0.13704                             \n",
      "\n",
      "[86]\ttrain-error:0.13799\ttest-error:0.13704                             \n",
      "\n",
      "[87]\ttrain-error:0.13793\ttest-error:0.13704                             \n",
      "\n",
      "[88]\ttrain-error:0.13787\ttest-error:0.13704                             \n",
      "\n",
      "[89]\ttrain-error:0.13784\ttest-error:0.13704                             \n",
      "\n",
      "[90]\ttrain-error:0.13778\ttest-error:0.13698                             \n",
      "\n",
      "[91]\ttrain-error:0.13772\ttest-error:0.13698                             \n",
      "\n",
      "[92]\ttrain-error:0.13768\ttest-error:0.13692                             \n",
      "\n",
      "[93]\ttrain-error:0.13772\ttest-error:0.13692                             \n",
      "\n",
      "[94]\ttrain-error:0.13772\ttest-error:0.13692                             \n",
      "\n",
      "[95]\ttrain-error:0.13762\ttest-error:0.13673                             \n",
      "\n",
      "[96]\ttrain-error:0.13741\ttest-error:0.13673                             \n",
      "\n",
      "[97]\ttrain-error:0.13741\ttest-error:0.13673                             \n",
      "\n",
      "[98]\ttrain-error:0.13732\ttest-error:0.13673                             \n",
      "\n",
      "[99]\ttrain-error:0.13725\ttest-error:0.13667                             \n",
      "\n",
      "{'alpha': 0, 'btype': 'In', 'colsample_bylevel': 0.9520560085903035, 'colsample_bytree': 0.8947916150653035, 'eta': 0.06048722600697361, 'eval_metric': ('error',), 'extra_dims': 8, 'gamma': 0, 'lambda': 0.0002243660229935992, 'max_depth': 8, 'min_child_weight': 1.255094128154986e-05, 'objective': 'binary:logistic', 'subsample': 0.6384168716449898}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:17:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13351\ttest-error:0.13790                               \n",
      "\n",
      "[1]\ttrain-error:0.13087\ttest-error:0.13538                               \n",
      "\n",
      "[2]\ttrain-error:0.12669\ttest-error:0.13084                               \n",
      "\n",
      "[3]\ttrain-error:0.12377\ttest-error:0.12998                               \n",
      "\n",
      "[4]\ttrain-error:0.12171\ttest-error:0.12912                               \n",
      "\n",
      "[5]\ttrain-error:0.11960\ttest-error:0.12758                               \n",
      "\n",
      "[6]\ttrain-error:0.11704\ttest-error:0.12703                               \n",
      "\n",
      "[7]\ttrain-error:0.11539\ttest-error:0.12623                               \n",
      "\n",
      "[8]\ttrain-error:0.11308\ttest-error:0.12604                               \n",
      "\n",
      "[9]\ttrain-error:0.11115\ttest-error:0.12475                               \n",
      "\n",
      "[10]\ttrain-error:0.10915\ttest-error:0.12580                              \n",
      "\n",
      "[11]\ttrain-error:0.10645\ttest-error:0.12604                              \n",
      "\n",
      "[12]\ttrain-error:0.10430\ttest-error:0.12617                              \n",
      "\n",
      "[13]\ttrain-error:0.10233\ttest-error:0.12611                              \n",
      "\n",
      "[14]\ttrain-error:0.10224\ttest-error:0.12611                              \n",
      "\n",
      "[15]\ttrain-error:0.09840\ttest-error:0.12598                              \n",
      "\n",
      "[16]\ttrain-error:0.09693\ttest-error:0.12678                              \n",
      "\n",
      "[17]\ttrain-error:0.09530\ttest-error:0.12660                              \n",
      "\n",
      "[18]\ttrain-error:0.09426\ttest-error:0.12666                              \n",
      "\n",
      "[19]\ttrain-error:0.09229\ttest-error:0.12647                              \n",
      "\n",
      "[20]\ttrain-error:0.09115\ttest-error:0.12666                              \n",
      "\n",
      "[21]\ttrain-error:0.09017\ttest-error:0.12703                              \n",
      "\n",
      "[22]\ttrain-error:0.08818\ttest-error:0.12801                              \n",
      "\n",
      "[23]\ttrain-error:0.08600\ttest-error:0.12746                              \n",
      "\n",
      "[24]\ttrain-error:0.08446\ttest-error:0.12789                              \n",
      "\n",
      "[25]\ttrain-error:0.08339\ttest-error:0.12801                              \n",
      "\n",
      "[26]\ttrain-error:0.08157\ttest-error:0.12740                              \n",
      "\n",
      "[27]\ttrain-error:0.07970\ttest-error:0.12764                              \n",
      "\n",
      "[28]\ttrain-error:0.07859\ttest-error:0.12789                              \n",
      "\n",
      "[29]\ttrain-error:0.07718\ttest-error:0.12844                              \n",
      "\n",
      "[30]\ttrain-error:0.07528\ttest-error:0.12795                              \n",
      "\n",
      "[31]\ttrain-error:0.07374\ttest-error:0.12770                              \n",
      "\n",
      "[32]\ttrain-error:0.07288\ttest-error:0.12819                              \n",
      "\n",
      "[33]\ttrain-error:0.07159\ttest-error:0.12758                              \n",
      "\n",
      "[34]\ttrain-error:0.06984\ttest-error:0.12813                              \n",
      "\n",
      "[35]\ttrain-error:0.06781\ttest-error:0.12826                              \n",
      "\n",
      "[36]\ttrain-error:0.06634\ttest-error:0.12844                              \n",
      "\n",
      "[37]\ttrain-error:0.06471\ttest-error:0.12881                              \n",
      "\n",
      "[38]\ttrain-error:0.06376\ttest-error:0.12954                              \n",
      "\n",
      "[39]\ttrain-error:0.06259\ttest-error:0.13028                              \n",
      "\n",
      "[40]\ttrain-error:0.06173\ttest-error:0.13028                              \n",
      "\n",
      "[41]\ttrain-error:0.06035\ttest-error:0.12985                              \n",
      "\n",
      "[42]\ttrain-error:0.05869\ttest-error:0.12979                              \n",
      "\n",
      "[43]\ttrain-error:0.05799\ttest-error:0.12985                              \n",
      "\n",
      "[44]\ttrain-error:0.05660\ttest-error:0.13022                              \n",
      "\n",
      "[45]\ttrain-error:0.05470\ttest-error:0.12985                              \n",
      "\n",
      "[46]\ttrain-error:0.05326\ttest-error:0.12991                              \n",
      "\n",
      "[47]\ttrain-error:0.05187\ttest-error:0.13065                              \n",
      "\n",
      "[48]\ttrain-error:0.05058\ttest-error:0.13108                              \n",
      "\n",
      "[49]\ttrain-error:0.04917\ttest-error:0.13151                              \n",
      "\n",
      "[50]\ttrain-error:0.04819\ttest-error:0.13114                              \n",
      "\n",
      "[51]\ttrain-error:0.04724\ttest-error:0.13206                              \n",
      "\n",
      "[52]\ttrain-error:0.04671\ttest-error:0.13206                              \n",
      "\n",
      "[53]\ttrain-error:0.04567\ttest-error:0.13225                              \n",
      "\n",
      "[54]\ttrain-error:0.04419\ttest-error:0.13292                              \n",
      "\n",
      "[55]\ttrain-error:0.04333\ttest-error:0.13366                              \n",
      "\n",
      "[56]\ttrain-error:0.04220\ttest-error:0.13434                              \n",
      "\n",
      "[57]\ttrain-error:0.04060\ttest-error:0.13464                              \n",
      "\n",
      "[58]\ttrain-error:0.03980\ttest-error:0.13446                              \n",
      "\n",
      "[59]\ttrain-error:0.03870\ttest-error:0.13464                              \n",
      "\n",
      "[60]\ttrain-error:0.03750\ttest-error:0.13452                              \n",
      "\n",
      "[61]\ttrain-error:0.03612\ttest-error:0.13470                              \n",
      "\n",
      "[62]\ttrain-error:0.03547\ttest-error:0.13483                              \n",
      "\n",
      "[63]\ttrain-error:0.03388\ttest-error:0.13477                              \n",
      "\n",
      "[64]\ttrain-error:0.03351\ttest-error:0.13538                              \n",
      "\n",
      "[65]\ttrain-error:0.03286\ttest-error:0.13495                              \n",
      "\n",
      "[66]\ttrain-error:0.03231\ttest-error:0.13569                              \n",
      "\n",
      "[67]\ttrain-error:0.03111\ttest-error:0.13544                              \n",
      "\n",
      "[68]\ttrain-error:0.03019\ttest-error:0.13569                              \n",
      "\n",
      "[69]\ttrain-error:0.02921\ttest-error:0.13606                              \n",
      "\n",
      "[70]\ttrain-error:0.02832\ttest-error:0.13550                              \n",
      "\n",
      "[71]\ttrain-error:0.02709\ttest-error:0.13563                              \n",
      "\n",
      "[72]\ttrain-error:0.02635\ttest-error:0.13507                              \n",
      "\n",
      "[73]\ttrain-error:0.02528\ttest-error:0.13563                              \n",
      "\n",
      "[74]\ttrain-error:0.02485\ttest-error:0.13538                              \n",
      "\n",
      "[75]\ttrain-error:0.02469\ttest-error:0.13532                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76]\ttrain-error:0.02365\ttest-error:0.13538                              \n",
      "\n",
      "[77]\ttrain-error:0.02263\ttest-error:0.13520                              \n",
      "\n",
      "[78]\ttrain-error:0.02190\ttest-error:0.13587                              \n",
      "\n",
      "[79]\ttrain-error:0.02122\ttest-error:0.13636                              \n",
      "\n",
      "[80]\ttrain-error:0.02061\ttest-error:0.13569                              \n",
      "\n",
      "[81]\ttrain-error:0.01963\ttest-error:0.13612                              \n",
      "\n",
      "[82]\ttrain-error:0.01880\ttest-error:0.13710                              \n",
      "\n",
      "[83]\ttrain-error:0.01815\ttest-error:0.13704                              \n",
      "\n",
      "[84]\ttrain-error:0.01787\ttest-error:0.13716                              \n",
      "\n",
      "[85]\ttrain-error:0.01714\ttest-error:0.13704                              \n",
      "\n",
      "[86]\ttrain-error:0.01622\ttest-error:0.13679                              \n",
      "\n",
      "[87]\ttrain-error:0.01572\ttest-error:0.13728                              \n",
      "\n",
      "[88]\ttrain-error:0.01526\ttest-error:0.13673                              \n",
      "\n",
      "[89]\ttrain-error:0.01499\ttest-error:0.13692                              \n",
      "\n",
      "[90]\ttrain-error:0.01443\ttest-error:0.13728                              \n",
      "\n",
      "[91]\ttrain-error:0.01434\ttest-error:0.13784                              \n",
      "\n",
      "[92]\ttrain-error:0.01401\ttest-error:0.13728                              \n",
      "\n",
      "[93]\ttrain-error:0.01376\ttest-error:0.13686                              \n",
      "\n",
      "[94]\ttrain-error:0.01327\ttest-error:0.13741                              \n",
      "\n",
      "[95]\ttrain-error:0.01268\ttest-error:0.13741                              \n",
      "\n",
      "[96]\ttrain-error:0.01219\ttest-error:0.13821                              \n",
      "\n",
      "[97]\ttrain-error:0.01189\ttest-error:0.13765                              \n",
      "\n",
      "[98]\ttrain-error:0.01146\ttest-error:0.13778                              \n",
      "\n",
      "[99]\ttrain-error:0.01106\ttest-error:0.13765                              \n",
      "\n",
      "{'alpha': 0, 'btype': 'In', 'colsample_bylevel': 0.9835167806067702, 'colsample_bytree': 0.7478380791810084, 'eta': 0.6510076077507987, 'eval_metric': ('error',), 'extra_dims': 6, 'gamma': 0, 'lambda': 0, 'max_depth': 1, 'min_child_weight': 2.0013210692728694e-06, 'objective': 'binary:logistic', 'subsample': 0.6390809008090306}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:18:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[1]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[2]\ttrain-error:0.35654\ttest-error:0.35369                               \n",
      "\n",
      "[3]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[4]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[5]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[6]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[7]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[8]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[9]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[10]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[11]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[12]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[13]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[14]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[15]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[16]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[17]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[18]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[19]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[20]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[21]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[22]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[23]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[24]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[25]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[26]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[27]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[28]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[29]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[30]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[31]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[32]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[33]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[34]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[35]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[36]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[37]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[38]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[39]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[40]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[41]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[42]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[43]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[44]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[45]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[46]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[47]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[48]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[49]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[50]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[51]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[52]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[53]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[54]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[55]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[56]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[57]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[58]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[59]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[60]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[61]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[62]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[63]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[64]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[65]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[66]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[67]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[68]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[69]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[71]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[72]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[73]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[74]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[75]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[76]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[77]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[78]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[79]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[80]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[81]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[82]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[83]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[84]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[85]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[86]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[87]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[88]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[89]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[90]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[91]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[92]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[93]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[94]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[95]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[96]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[97]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[98]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[99]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "{'alpha': 0.003545362941147879, 'btype': 'I', 'colsample_bylevel': 0.7507597570800806, 'colsample_bytree': 0.866416021094226, 'eta': 0.038031996822319704, 'eval_metric': ('error',), 'extra_dims': 10, 'gamma': 5.734134823416919e-07, 'lambda': 0, 'max_depth': 2, 'min_child_weight': 1.2917196221584, 'objective': 'binary:logistic', 'subsample': 0.9078110272223198}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:19:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.16023\ttest-error:0.16081                               \n",
      "\n",
      "[1]\ttrain-error:0.16013\ttest-error:0.16069                               \n",
      "\n",
      "[2]\ttrain-error:0.15971\ttest-error:0.16032                               \n",
      "\n",
      "[3]\ttrain-error:0.15823\ttest-error:0.15872                               \n",
      "\n",
      "[4]\ttrain-error:0.15666\ttest-error:0.15670                               \n",
      "\n",
      "[5]\ttrain-error:0.15344\ttest-error:0.15369                               \n",
      "\n",
      "[6]\ttrain-error:0.15178\ttest-error:0.15074                               \n",
      "\n",
      "[7]\ttrain-error:0.15218\ttest-error:0.15240                               \n",
      "\n",
      "[8]\ttrain-error:0.15163\ttest-error:0.15098                               \n",
      "\n",
      "[9]\ttrain-error:0.15071\ttest-error:0.14939                               \n",
      "\n",
      "[10]\ttrain-error:0.14859\ttest-error:0.14711                              \n",
      "\n",
      "[11]\ttrain-error:0.14653\ttest-error:0.14564                              \n",
      "\n",
      "[12]\ttrain-error:0.14641\ttest-error:0.14447                              \n",
      "\n",
      "[13]\ttrain-error:0.14628\ttest-error:0.14453                              \n",
      "\n",
      "[14]\ttrain-error:0.14595\ttest-error:0.14404                              \n",
      "\n",
      "[15]\ttrain-error:0.14546\ttest-error:0.14374                              \n",
      "\n",
      "[16]\ttrain-error:0.14490\ttest-error:0.14330                              \n",
      "\n",
      "[17]\ttrain-error:0.14505\ttest-error:0.14318                              \n",
      "\n",
      "[18]\ttrain-error:0.14407\ttest-error:0.14275                              \n",
      "\n",
      "[19]\ttrain-error:0.14438\ttest-error:0.14257                              \n",
      "\n",
      "[20]\ttrain-error:0.14389\ttest-error:0.14232                              \n",
      "\n",
      "[21]\ttrain-error:0.14352\ttest-error:0.14202                              \n",
      "\n",
      "[22]\ttrain-error:0.14297\ttest-error:0.14152                              \n",
      "\n",
      "[23]\ttrain-error:0.14288\ttest-error:0.14109                              \n",
      "\n",
      "[24]\ttrain-error:0.14272\ttest-error:0.14097                              \n",
      "\n",
      "[25]\ttrain-error:0.14214\ttest-error:0.14023                              \n",
      "\n",
      "[26]\ttrain-error:0.14165\ttest-error:0.14023                              \n",
      "\n",
      "[27]\ttrain-error:0.14146\ttest-error:0.13974                              \n",
      "\n",
      "[28]\ttrain-error:0.14116\ttest-error:0.13956                              \n",
      "\n",
      "[29]\ttrain-error:0.14088\ttest-error:0.13913                              \n",
      "\n",
      "[30]\ttrain-error:0.14030\ttest-error:0.13851                              \n",
      "\n",
      "[31]\ttrain-error:0.14023\ttest-error:0.13845                              \n",
      "\n",
      "[32]\ttrain-error:0.14017\ttest-error:0.13864                              \n",
      "\n",
      "[33]\ttrain-error:0.13974\ttest-error:0.13802                              \n",
      "\n",
      "[34]\ttrain-error:0.13974\ttest-error:0.13765                              \n",
      "\n",
      "[35]\ttrain-error:0.13947\ttest-error:0.13716                              \n",
      "\n",
      "[36]\ttrain-error:0.13916\ttest-error:0.13741                              \n",
      "\n",
      "[37]\ttrain-error:0.13904\ttest-error:0.13655                              \n",
      "\n",
      "[38]\ttrain-error:0.13873\ttest-error:0.13667                              \n",
      "\n",
      "[39]\ttrain-error:0.13864\ttest-error:0.13618                              \n",
      "\n",
      "[40]\ttrain-error:0.13818\ttest-error:0.13618                              \n",
      "\n",
      "[41]\ttrain-error:0.13784\ttest-error:0.13538                              \n",
      "\n",
      "[42]\ttrain-error:0.13719\ttest-error:0.13507                              \n",
      "\n",
      "[43]\ttrain-error:0.13686\ttest-error:0.13495                              \n",
      "\n",
      "[44]\ttrain-error:0.13642\ttest-error:0.13483                              \n",
      "\n",
      "[45]\ttrain-error:0.13621\ttest-error:0.13483                              \n",
      "\n",
      "[46]\ttrain-error:0.13593\ttest-error:0.13409                              \n",
      "\n",
      "[47]\ttrain-error:0.13578\ttest-error:0.13384                              \n",
      "\n",
      "[48]\ttrain-error:0.13541\ttest-error:0.13360                              \n",
      "\n",
      "[49]\ttrain-error:0.13514\ttest-error:0.13317                              \n",
      "\n",
      "[50]\ttrain-error:0.13467\ttest-error:0.13317                              \n",
      "\n",
      "[51]\ttrain-error:0.13446\ttest-error:0.13292                              \n",
      "\n",
      "[52]\ttrain-error:0.13397\ttest-error:0.13256                              \n",
      "\n",
      "[53]\ttrain-error:0.13369\ttest-error:0.13268                              \n",
      "\n",
      "[54]\ttrain-error:0.13369\ttest-error:0.13298                              \n",
      "\n",
      "[55]\ttrain-error:0.13351\ttest-error:0.13286                              \n",
      "\n",
      "[56]\ttrain-error:0.13345\ttest-error:0.13256                              \n",
      "\n",
      "[57]\ttrain-error:0.13314\ttest-error:0.13274                              \n",
      "\n",
      "[58]\ttrain-error:0.13305\ttest-error:0.13274                              \n",
      "\n",
      "[59]\ttrain-error:0.13305\ttest-error:0.13256                              \n",
      "\n",
      "[60]\ttrain-error:0.13302\ttest-error:0.13237                              \n",
      "\n",
      "[61]\ttrain-error:0.13292\ttest-error:0.13274                              \n",
      "\n",
      "[62]\ttrain-error:0.13289\ttest-error:0.13249                              \n",
      "\n",
      "[63]\ttrain-error:0.13243\ttest-error:0.13206                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64]\ttrain-error:0.13182\ttest-error:0.13231                              \n",
      "\n",
      "[65]\ttrain-error:0.13185\ttest-error:0.13188                              \n",
      "\n",
      "[66]\ttrain-error:0.13176\ttest-error:0.13151                              \n",
      "\n",
      "[67]\ttrain-error:0.13157\ttest-error:0.13139                              \n",
      "\n",
      "[68]\ttrain-error:0.13170\ttest-error:0.13170                              \n",
      "\n",
      "[69]\ttrain-error:0.13154\ttest-error:0.13151                              \n",
      "\n",
      "[70]\ttrain-error:0.13139\ttest-error:0.13139                              \n",
      "\n",
      "[71]\ttrain-error:0.13108\ttest-error:0.13151                              \n",
      "\n",
      "[72]\ttrain-error:0.13099\ttest-error:0.13126                              \n",
      "\n",
      "[73]\ttrain-error:0.13090\ttest-error:0.13139                              \n",
      "\n",
      "[74]\ttrain-error:0.13071\ttest-error:0.13139                              \n",
      "\n",
      "[75]\ttrain-error:0.13062\ttest-error:0.13126                              \n",
      "\n",
      "[76]\ttrain-error:0.13068\ttest-error:0.13126                              \n",
      "\n",
      "[77]\ttrain-error:0.13037\ttest-error:0.13102                              \n",
      "\n",
      "[78]\ttrain-error:0.13028\ttest-error:0.13102                              \n",
      "\n",
      "[79]\ttrain-error:0.13031\ttest-error:0.13126                              \n",
      "\n",
      "[80]\ttrain-error:0.13031\ttest-error:0.13120                              \n",
      "\n",
      "[81]\ttrain-error:0.12988\ttest-error:0.13096                              \n",
      "\n",
      "[82]\ttrain-error:0.12991\ttest-error:0.13102                              \n",
      "\n",
      "[83]\ttrain-error:0.12985\ttest-error:0.13120                              \n",
      "\n",
      "[84]\ttrain-error:0.12967\ttest-error:0.13108                              \n",
      "\n",
      "[85]\ttrain-error:0.12942\ttest-error:0.13126                              \n",
      "\n",
      "[86]\ttrain-error:0.12924\ttest-error:0.13126                              \n",
      "\n",
      "[87]\ttrain-error:0.12924\ttest-error:0.13133                              \n",
      "\n",
      "[88]\ttrain-error:0.12918\ttest-error:0.13139                              \n",
      "\n",
      "[89]\ttrain-error:0.12902\ttest-error:0.13120                              \n",
      "\n",
      "[90]\ttrain-error:0.12902\ttest-error:0.13133                              \n",
      "\n",
      "[91]\ttrain-error:0.12899\ttest-error:0.13126                              \n",
      "\n",
      "[92]\ttrain-error:0.12887\ttest-error:0.13108                              \n",
      "\n",
      "[93]\ttrain-error:0.12878\ttest-error:0.13102                              \n",
      "\n",
      "[94]\ttrain-error:0.12862\ttest-error:0.13090                              \n",
      "\n",
      "[95]\ttrain-error:0.12859\ttest-error:0.13108                              \n",
      "\n",
      "[96]\ttrain-error:0.12869\ttest-error:0.13096                              \n",
      "\n",
      "[97]\ttrain-error:0.12853\ttest-error:0.13090                              \n",
      "\n",
      "[98]\ttrain-error:0.12841\ttest-error:0.13077                              \n",
      "\n",
      "[99]\ttrain-error:0.12823\ttest-error:0.13071                              \n",
      "\n",
      "{'alpha': 6.77988757726024e-05, 'btype': 'Rn', 'colsample_bylevel': 0.9516765515524339, 'colsample_bytree': 0.5237568469342535, 'eta': 0.0019900213062150063, 'eval_metric': ('error',), 'extra_dims': 3, 'gamma': 0, 'lambda': 0, 'max_depth': 9, 'min_child_weight': 0.0010454008457031591, 'objective': 'binary:logistic', 'subsample': 0.82100720588702}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:20:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13363\ttest-error:0.14097                               \n",
      "\n",
      "[1]\ttrain-error:0.13185\ttest-error:0.14066                               \n",
      "\n",
      "[2]\ttrain-error:0.12872\ttest-error:0.13483                               \n",
      "\n",
      "[3]\ttrain-error:0.12832\ttest-error:0.13403                               \n",
      "\n",
      "[4]\ttrain-error:0.12893\ttest-error:0.13348                               \n",
      "\n",
      "[5]\ttrain-error:0.12884\ttest-error:0.13378                               \n",
      "\n",
      "[6]\ttrain-error:0.13040\ttest-error:0.13587                               \n",
      "\n",
      "[7]\ttrain-error:0.12902\ttest-error:0.13391                               \n",
      "\n",
      "[8]\ttrain-error:0.12832\ttest-error:0.13440                               \n",
      "\n",
      "[9]\ttrain-error:0.12982\ttest-error:0.13489                               \n",
      "\n",
      "[10]\ttrain-error:0.12967\ttest-error:0.13550                              \n",
      "\n",
      "[11]\ttrain-error:0.12924\ttest-error:0.13526                              \n",
      "\n",
      "[12]\ttrain-error:0.12942\ttest-error:0.13526                              \n",
      "\n",
      "[13]\ttrain-error:0.12939\ttest-error:0.13569                              \n",
      "\n",
      "[14]\ttrain-error:0.12924\ttest-error:0.13593                              \n",
      "\n",
      "[15]\ttrain-error:0.12961\ttest-error:0.13587                              \n",
      "\n",
      "[16]\ttrain-error:0.12927\ttest-error:0.13526                              \n",
      "\n",
      "[17]\ttrain-error:0.12912\ttest-error:0.13544                              \n",
      "\n",
      "[18]\ttrain-error:0.12921\ttest-error:0.13569                              \n",
      "\n",
      "[19]\ttrain-error:0.12899\ttest-error:0.13600                              \n",
      "\n",
      "[20]\ttrain-error:0.12884\ttest-error:0.13538                              \n",
      "\n",
      "[21]\ttrain-error:0.12887\ttest-error:0.13526                              \n",
      "\n",
      "[22]\ttrain-error:0.12915\ttest-error:0.13563                              \n",
      "\n",
      "[23]\ttrain-error:0.12878\ttest-error:0.13569                              \n",
      "\n",
      "[24]\ttrain-error:0.12899\ttest-error:0.13575                              \n",
      "\n",
      "[25]\ttrain-error:0.12847\ttest-error:0.13526                              \n",
      "\n",
      "[26]\ttrain-error:0.12810\ttest-error:0.13526                              \n",
      "\n",
      "[27]\ttrain-error:0.12807\ttest-error:0.13520                              \n",
      "\n",
      "[28]\ttrain-error:0.12807\ttest-error:0.13556                              \n",
      "\n",
      "[29]\ttrain-error:0.12804\ttest-error:0.13556                              \n",
      "\n",
      "[30]\ttrain-error:0.12795\ttest-error:0.13520                              \n",
      "\n",
      "[31]\ttrain-error:0.12798\ttest-error:0.13514                              \n",
      "\n",
      "[32]\ttrain-error:0.12773\ttest-error:0.13489                              \n",
      "\n",
      "[33]\ttrain-error:0.12773\ttest-error:0.13470                              \n",
      "\n",
      "[34]\ttrain-error:0.12755\ttest-error:0.13470                              \n",
      "\n",
      "[35]\ttrain-error:0.12776\ttest-error:0.13495                              \n",
      "\n",
      "[36]\ttrain-error:0.12758\ttest-error:0.13501                              \n",
      "\n",
      "[37]\ttrain-error:0.12789\ttest-error:0.13507                              \n",
      "\n",
      "[38]\ttrain-error:0.12776\ttest-error:0.13520                              \n",
      "\n",
      "[39]\ttrain-error:0.12798\ttest-error:0.13526                              \n",
      "\n",
      "[40]\ttrain-error:0.12798\ttest-error:0.13556                              \n",
      "\n",
      "[41]\ttrain-error:0.12789\ttest-error:0.13520                              \n",
      "\n",
      "[42]\ttrain-error:0.12773\ttest-error:0.13501                              \n",
      "\n",
      "[43]\ttrain-error:0.12779\ttest-error:0.13470                              \n",
      "\n",
      "[44]\ttrain-error:0.12776\ttest-error:0.13501                              \n",
      "\n",
      "[45]\ttrain-error:0.12758\ttest-error:0.13514                              \n",
      "\n",
      "[46]\ttrain-error:0.12770\ttest-error:0.13526                              \n",
      "\n",
      "[47]\ttrain-error:0.12764\ttest-error:0.13464                              \n",
      "\n",
      "[48]\ttrain-error:0.12743\ttest-error:0.13458                              \n",
      "\n",
      "[49]\ttrain-error:0.12746\ttest-error:0.13415                              \n",
      "\n",
      "[50]\ttrain-error:0.12743\ttest-error:0.13415                              \n",
      "\n",
      "[51]\ttrain-error:0.12743\ttest-error:0.13384                              \n",
      "\n",
      "[52]\ttrain-error:0.12740\ttest-error:0.13415                              \n",
      "\n",
      "[53]\ttrain-error:0.12733\ttest-error:0.13421                              \n",
      "\n",
      "[54]\ttrain-error:0.12740\ttest-error:0.13428                              \n",
      "\n",
      "[55]\ttrain-error:0.12724\ttest-error:0.13428                              \n",
      "\n",
      "[56]\ttrain-error:0.12730\ttest-error:0.13421                              \n",
      "\n",
      "[57]\ttrain-error:0.12706\ttest-error:0.13428                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58]\ttrain-error:0.12700\ttest-error:0.13421                              \n",
      "\n",
      "[59]\ttrain-error:0.12700\ttest-error:0.13397                              \n",
      "\n",
      "[60]\ttrain-error:0.12684\ttest-error:0.13372                              \n",
      "\n",
      "[61]\ttrain-error:0.12700\ttest-error:0.13409                              \n",
      "\n",
      "[62]\ttrain-error:0.12684\ttest-error:0.13384                              \n",
      "\n",
      "[63]\ttrain-error:0.12693\ttest-error:0.13403                              \n",
      "\n",
      "[64]\ttrain-error:0.12681\ttest-error:0.13415                              \n",
      "\n",
      "[65]\ttrain-error:0.12660\ttest-error:0.13434                              \n",
      "\n",
      "[66]\ttrain-error:0.12663\ttest-error:0.13434                              \n",
      "\n",
      "[67]\ttrain-error:0.12675\ttest-error:0.13440                              \n",
      "\n",
      "[68]\ttrain-error:0.12666\ttest-error:0.13464                              \n",
      "\n",
      "[69]\ttrain-error:0.12669\ttest-error:0.13434                              \n",
      "\n",
      "[70]\ttrain-error:0.12641\ttest-error:0.13440                              \n",
      "\n",
      "[71]\ttrain-error:0.12644\ttest-error:0.13440                              \n",
      "\n",
      "[72]\ttrain-error:0.12647\ttest-error:0.13428                              \n",
      "\n",
      "[73]\ttrain-error:0.12651\ttest-error:0.13409                              \n",
      "\n",
      "[74]\ttrain-error:0.12654\ttest-error:0.13421                              \n",
      "\n",
      "[75]\ttrain-error:0.12660\ttest-error:0.13391                              \n",
      "\n",
      "[76]\ttrain-error:0.12644\ttest-error:0.13384                              \n",
      "\n",
      "[77]\ttrain-error:0.12663\ttest-error:0.13391                              \n",
      "\n",
      "[78]\ttrain-error:0.12638\ttest-error:0.13403                              \n",
      "\n",
      "[79]\ttrain-error:0.12635\ttest-error:0.13384                              \n",
      "\n",
      "[80]\ttrain-error:0.12623\ttest-error:0.13384                              \n",
      "\n",
      "[81]\ttrain-error:0.12598\ttest-error:0.13384                              \n",
      "\n",
      "[82]\ttrain-error:0.12592\ttest-error:0.13391                              \n",
      "\n",
      "[83]\ttrain-error:0.12586\ttest-error:0.13384                              \n",
      "\n",
      "[84]\ttrain-error:0.12571\ttest-error:0.13360                              \n",
      "\n",
      "[85]\ttrain-error:0.12577\ttest-error:0.13366                              \n",
      "\n",
      "[86]\ttrain-error:0.12568\ttest-error:0.13360                              \n",
      "\n",
      "[87]\ttrain-error:0.12580\ttest-error:0.13348                              \n",
      "\n",
      "[88]\ttrain-error:0.12592\ttest-error:0.13354                              \n",
      "\n",
      "[89]\ttrain-error:0.12595\ttest-error:0.13378                              \n",
      "\n",
      "[90]\ttrain-error:0.12580\ttest-error:0.13360                              \n",
      "\n",
      "[91]\ttrain-error:0.12598\ttest-error:0.13384                              \n",
      "\n",
      "[92]\ttrain-error:0.12586\ttest-error:0.13360                              \n",
      "\n",
      "[93]\ttrain-error:0.12586\ttest-error:0.13348                              \n",
      "\n",
      "[94]\ttrain-error:0.12574\ttest-error:0.13342                              \n",
      "\n",
      "[95]\ttrain-error:0.12574\ttest-error:0.13342                              \n",
      "\n",
      "[96]\ttrain-error:0.12577\ttest-error:0.13329                              \n",
      "\n",
      "[97]\ttrain-error:0.12568\ttest-error:0.13348                              \n",
      "\n",
      "[98]\ttrain-error:0.12571\ttest-error:0.13354                              \n",
      "\n",
      "[99]\ttrain-error:0.12568\ttest-error:0.13329                              \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.8075593207162193, 'colsample_bytree': 0.8789772832231175, 'eta': 0.08304683842002579, 'eval_metric': ('error',), 'extra_dims': 9, 'gamma': 0, 'lambda': 5.685913664181764e-06, 'max_depth': 4, 'min_child_weight': 3.328725677186256e-05, 'objective': 'binary:logistic', 'subsample': 0.5057328092118428}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:21:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14896\ttest-error:0.14846                               \n",
      "\n",
      "[1]\ttrain-error:0.14484\ttest-error:0.14453                               \n",
      "\n",
      "[2]\ttrain-error:0.14125\ttest-error:0.13944                               \n",
      "\n",
      "[3]\ttrain-error:0.13971\ttest-error:0.13808                               \n",
      "\n",
      "[4]\ttrain-error:0.13781\ttest-error:0.13673                               \n",
      "\n",
      "[5]\ttrain-error:0.13655\ttest-error:0.13446                               \n",
      "\n",
      "[6]\ttrain-error:0.13415\ttest-error:0.13256                               \n",
      "\n",
      "[7]\ttrain-error:0.13249\ttest-error:0.13133                               \n",
      "\n",
      "[8]\ttrain-error:0.13120\ttest-error:0.13004                               \n",
      "\n",
      "[9]\ttrain-error:0.12985\ttest-error:0.12948                               \n",
      "\n",
      "[10]\ttrain-error:0.12856\ttest-error:0.12826                              \n",
      "\n",
      "[11]\ttrain-error:0.12638\ttest-error:0.12844                              \n",
      "\n",
      "[12]\ttrain-error:0.12515\ttest-error:0.12893                              \n",
      "\n",
      "[13]\ttrain-error:0.12482\ttest-error:0.12967                              \n",
      "\n",
      "[14]\ttrain-error:0.12411\ttest-error:0.12948                              \n",
      "\n",
      "[15]\ttrain-error:0.12313\ttest-error:0.12899                              \n",
      "\n",
      "[16]\ttrain-error:0.12260\ttest-error:0.12832                              \n",
      "\n",
      "[17]\ttrain-error:0.12150\ttest-error:0.12862                              \n",
      "\n",
      "[18]\ttrain-error:0.12039\ttest-error:0.12875                              \n",
      "\n",
      "[19]\ttrain-error:0.11953\ttest-error:0.12856                              \n",
      "\n",
      "[20]\ttrain-error:0.11913\ttest-error:0.12746                              \n",
      "\n",
      "[21]\ttrain-error:0.11889\ttest-error:0.12746                              \n",
      "\n",
      "[22]\ttrain-error:0.11830\ttest-error:0.12666                              \n",
      "\n",
      "[23]\ttrain-error:0.11784\ttest-error:0.12709                              \n",
      "\n",
      "[24]\ttrain-error:0.11751\ttest-error:0.12746                              \n",
      "\n",
      "[25]\ttrain-error:0.11674\ttest-error:0.12758                              \n",
      "\n",
      "[26]\ttrain-error:0.11579\ttest-error:0.12764                              \n",
      "\n",
      "[27]\ttrain-error:0.11554\ttest-error:0.12783                              \n",
      "\n",
      "[28]\ttrain-error:0.11480\ttest-error:0.12776                              \n",
      "\n",
      "[29]\ttrain-error:0.11465\ttest-error:0.12727                              \n",
      "\n",
      "[30]\ttrain-error:0.11379\ttest-error:0.12758                              \n",
      "\n",
      "[31]\ttrain-error:0.11348\ttest-error:0.12721                              \n",
      "\n",
      "[32]\ttrain-error:0.11268\ttest-error:0.12715                              \n",
      "\n",
      "[33]\ttrain-error:0.11225\ttest-error:0.12678                              \n",
      "\n",
      "[34]\ttrain-error:0.11182\ttest-error:0.12758                              \n",
      "\n",
      "[35]\ttrain-error:0.11155\ttest-error:0.12752                              \n",
      "\n",
      "[36]\ttrain-error:0.11164\ttest-error:0.12838                              \n",
      "\n",
      "[37]\ttrain-error:0.11072\ttest-error:0.12746                              \n",
      "\n",
      "[38]\ttrain-error:0.11007\ttest-error:0.12746                              \n",
      "\n",
      "[39]\ttrain-error:0.11010\ttest-error:0.12770                              \n",
      "\n",
      "[40]\ttrain-error:0.10943\ttest-error:0.12715                              \n",
      "\n",
      "[41]\ttrain-error:0.10869\ttest-error:0.12715                              \n",
      "\n",
      "[42]\ttrain-error:0.10878\ttest-error:0.12697                              \n",
      "\n",
      "[43]\ttrain-error:0.10798\ttest-error:0.12752                              \n",
      "\n",
      "[44]\ttrain-error:0.10765\ttest-error:0.12629                              \n",
      "\n",
      "[45]\ttrain-error:0.10719\ttest-error:0.12690                              \n",
      "\n",
      "[46]\ttrain-error:0.10706\ttest-error:0.12641                              \n",
      "\n",
      "[47]\ttrain-error:0.10645\ttest-error:0.12697                              \n",
      "\n",
      "[48]\ttrain-error:0.10630\ttest-error:0.12758                              \n",
      "\n",
      "[49]\ttrain-error:0.10565\ttest-error:0.12758                              \n",
      "\n",
      "[50]\ttrain-error:0.10556\ttest-error:0.12795                              \n",
      "\n",
      "[51]\ttrain-error:0.10479\ttest-error:0.12819                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52]\ttrain-error:0.10497\ttest-error:0.12795                              \n",
      "\n",
      "[53]\ttrain-error:0.10501\ttest-error:0.12770                              \n",
      "\n",
      "[54]\ttrain-error:0.10504\ttest-error:0.12807                              \n",
      "\n",
      "[55]\ttrain-error:0.10464\ttest-error:0.12826                              \n",
      "\n",
      "[56]\ttrain-error:0.10405\ttest-error:0.12813                              \n",
      "\n",
      "[57]\ttrain-error:0.10353\ttest-error:0.12838                              \n",
      "\n",
      "[58]\ttrain-error:0.10362\ttest-error:0.12899                              \n",
      "\n",
      "[59]\ttrain-error:0.10304\ttest-error:0.12875                              \n",
      "\n",
      "[60]\ttrain-error:0.10227\ttest-error:0.12899                              \n",
      "\n",
      "[61]\ttrain-error:0.10200\ttest-error:0.12899                              \n",
      "\n",
      "[62]\ttrain-error:0.10163\ttest-error:0.12887                              \n",
      "\n",
      "[63]\ttrain-error:0.10166\ttest-error:0.12869                              \n",
      "\n",
      "[64]\ttrain-error:0.10080\ttest-error:0.12862                              \n",
      "\n",
      "[65]\ttrain-error:0.10071\ttest-error:0.12985                              \n",
      "\n",
      "[66]\ttrain-error:0.09991\ttest-error:0.12942                              \n",
      "\n",
      "[67]\ttrain-error:0.10028\ttest-error:0.12918                              \n",
      "\n",
      "[68]\ttrain-error:0.09985\ttest-error:0.12930                              \n",
      "\n",
      "[69]\ttrain-error:0.09991\ttest-error:0.13004                              \n",
      "\n",
      "[70]\ttrain-error:0.09960\ttest-error:0.13022                              \n",
      "\n",
      "[71]\ttrain-error:0.09920\ttest-error:0.12942                              \n",
      "\n",
      "[72]\ttrain-error:0.09880\ttest-error:0.12887                              \n",
      "\n",
      "[73]\ttrain-error:0.09859\ttest-error:0.12887                              \n",
      "\n",
      "[74]\ttrain-error:0.09773\ttest-error:0.12954                              \n",
      "\n",
      "[75]\ttrain-error:0.09767\ttest-error:0.13004                              \n",
      "\n",
      "[76]\ttrain-error:0.09739\ttest-error:0.12942                              \n",
      "\n",
      "[77]\ttrain-error:0.09724\ttest-error:0.12918                              \n",
      "\n",
      "[78]\ttrain-error:0.09687\ttest-error:0.12948                              \n",
      "\n",
      "[79]\ttrain-error:0.09622\ttest-error:0.12998                              \n",
      "\n",
      "[80]\ttrain-error:0.09585\ttest-error:0.12954                              \n",
      "\n",
      "[81]\ttrain-error:0.09558\ttest-error:0.12961                              \n",
      "\n",
      "[82]\ttrain-error:0.09527\ttest-error:0.12991                              \n",
      "\n",
      "[83]\ttrain-error:0.09555\ttest-error:0.13034                              \n",
      "\n",
      "[84]\ttrain-error:0.09524\ttest-error:0.12973                              \n",
      "\n",
      "[85]\ttrain-error:0.09499\ttest-error:0.12967                              \n",
      "\n",
      "[86]\ttrain-error:0.09432\ttest-error:0.13047                              \n",
      "\n",
      "[87]\ttrain-error:0.09453\ttest-error:0.13077                              \n",
      "\n",
      "[88]\ttrain-error:0.09398\ttest-error:0.12991                              \n",
      "\n",
      "[89]\ttrain-error:0.09389\ttest-error:0.13034                              \n",
      "\n",
      "[90]\ttrain-error:0.09318\ttest-error:0.13071                              \n",
      "\n",
      "[91]\ttrain-error:0.09315\ttest-error:0.13065                              \n",
      "\n",
      "[92]\ttrain-error:0.09275\ttest-error:0.13047                              \n",
      "\n",
      "[93]\ttrain-error:0.09269\ttest-error:0.13053                              \n",
      "\n",
      "[94]\ttrain-error:0.09263\ttest-error:0.13040                              \n",
      "\n",
      "[95]\ttrain-error:0.09235\ttest-error:0.12973                              \n",
      "\n",
      "[96]\ttrain-error:0.09235\ttest-error:0.13016                              \n",
      "\n",
      "[97]\ttrain-error:0.09183\ttest-error:0.13004                              \n",
      "\n",
      "[98]\ttrain-error:0.09115\ttest-error:0.12985                              \n",
      "\n",
      "[99]\ttrain-error:0.09115\ttest-error:0.13010                              \n",
      "\n",
      "{'alpha': 6.276267147947394e-06, 'btype': 'In', 'colsample_bylevel': 0.5732402049646198, 'colsample_bytree': 0.5096333169806044, 'eta': 0.014503017830968868, 'eval_metric': ('error',), 'extra_dims': 12, 'gamma': 0, 'lambda': 0, 'max_depth': 7, 'min_child_weight': 0.0023114852539441668, 'objective': 'binary:logistic', 'subsample': 0.7816176471195234}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:23:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14085\ttest-error:0.14441                               \n",
      "\n",
      "[1]\ttrain-error:0.13814\ttest-error:0.14109                               \n",
      "\n",
      "[2]\ttrain-error:0.13664\ttest-error:0.13870                               \n",
      "\n",
      "[3]\ttrain-error:0.13596\ttest-error:0.13790                               \n",
      "\n",
      "[4]\ttrain-error:0.13517\ttest-error:0.13765                               \n",
      "\n",
      "[5]\ttrain-error:0.13483\ttest-error:0.13765                               \n",
      "\n",
      "[6]\ttrain-error:0.13418\ttest-error:0.13600                               \n",
      "\n",
      "[7]\ttrain-error:0.13391\ttest-error:0.13477                               \n",
      "\n",
      "[8]\ttrain-error:0.13286\ttest-error:0.13434                               \n",
      "\n",
      "[9]\ttrain-error:0.13249\ttest-error:0.13342                               \n",
      "\n",
      "[10]\ttrain-error:0.13188\ttest-error:0.13329                              \n",
      "\n",
      "[11]\ttrain-error:0.13148\ttest-error:0.13311                              \n",
      "\n",
      "[12]\ttrain-error:0.13093\ttest-error:0.13225                              \n",
      "\n",
      "[13]\ttrain-error:0.13040\ttest-error:0.13194                              \n",
      "\n",
      "[14]\ttrain-error:0.12970\ttest-error:0.13126                              \n",
      "\n",
      "[15]\ttrain-error:0.12905\ttest-error:0.13040                              \n",
      "\n",
      "[16]\ttrain-error:0.12832\ttest-error:0.12954                              \n",
      "\n",
      "[17]\ttrain-error:0.12767\ttest-error:0.12881                              \n",
      "\n",
      "[18]\ttrain-error:0.12712\ttest-error:0.12899                              \n",
      "\n",
      "[19]\ttrain-error:0.12647\ttest-error:0.12881                              \n",
      "\n",
      "[20]\ttrain-error:0.12614\ttest-error:0.12819                              \n",
      "\n",
      "[21]\ttrain-error:0.12543\ttest-error:0.12801                              \n",
      "\n",
      "[22]\ttrain-error:0.12482\ttest-error:0.12752                              \n",
      "\n",
      "[23]\ttrain-error:0.12414\ttest-error:0.12721                              \n",
      "\n",
      "[24]\ttrain-error:0.12356\ttest-error:0.12703                              \n",
      "\n",
      "[25]\ttrain-error:0.12297\ttest-error:0.12678                              \n",
      "\n",
      "[26]\ttrain-error:0.12214\ttest-error:0.12647                              \n",
      "\n",
      "[27]\ttrain-error:0.12162\ttest-error:0.12672                              \n",
      "\n",
      "[28]\ttrain-error:0.12098\ttest-error:0.12635                              \n",
      "\n",
      "[29]\ttrain-error:0.11981\ttest-error:0.12629                              \n",
      "\n",
      "[30]\ttrain-error:0.11923\ttest-error:0.12586                              \n",
      "\n",
      "[31]\ttrain-error:0.11867\ttest-error:0.12574                              \n",
      "\n",
      "[32]\ttrain-error:0.11830\ttest-error:0.12555                              \n",
      "\n",
      "[33]\ttrain-error:0.11809\ttest-error:0.12518                              \n",
      "\n",
      "[34]\ttrain-error:0.11769\ttest-error:0.12500                              \n",
      "\n",
      "[35]\ttrain-error:0.11735\ttest-error:0.12525                              \n",
      "\n",
      "[36]\ttrain-error:0.11689\ttest-error:0.12506                              \n",
      "\n",
      "[37]\ttrain-error:0.11661\ttest-error:0.12506                              \n",
      "\n",
      "[38]\ttrain-error:0.11615\ttest-error:0.12482                              \n",
      "\n",
      "[39]\ttrain-error:0.11591\ttest-error:0.12488                              \n",
      "\n",
      "[40]\ttrain-error:0.11572\ttest-error:0.12482                              \n",
      "\n",
      "[41]\ttrain-error:0.11526\ttest-error:0.12463                              \n",
      "\n",
      "[42]\ttrain-error:0.11508\ttest-error:0.12482                              \n",
      "\n",
      "[43]\ttrain-error:0.11480\ttest-error:0.12475                              \n",
      "\n",
      "[44]\ttrain-error:0.11471\ttest-error:0.12482                              \n",
      "\n",
      "[45]\ttrain-error:0.11379\ttest-error:0.12482                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46]\ttrain-error:0.11376\ttest-error:0.12469                              \n",
      "\n",
      "[47]\ttrain-error:0.11345\ttest-error:0.12506                              \n",
      "\n",
      "[48]\ttrain-error:0.11305\ttest-error:0.12506                              \n",
      "\n",
      "[49]\ttrain-error:0.11275\ttest-error:0.12506                              \n",
      "\n",
      "[50]\ttrain-error:0.11271\ttest-error:0.12506                              \n",
      "\n",
      "[51]\ttrain-error:0.11253\ttest-error:0.12512                              \n",
      "\n",
      "[52]\ttrain-error:0.11232\ttest-error:0.12475                              \n",
      "\n",
      "[53]\ttrain-error:0.11210\ttest-error:0.12506                              \n",
      "\n",
      "[54]\ttrain-error:0.11173\ttest-error:0.12531                              \n",
      "\n",
      "[55]\ttrain-error:0.11142\ttest-error:0.12568                              \n",
      "\n",
      "[56]\ttrain-error:0.11124\ttest-error:0.12586                              \n",
      "\n",
      "[57]\ttrain-error:0.11093\ttest-error:0.12568                              \n",
      "\n",
      "[58]\ttrain-error:0.11066\ttest-error:0.12568                              \n",
      "\n",
      "[59]\ttrain-error:0.11072\ttest-error:0.12568                              \n",
      "\n",
      "[60]\ttrain-error:0.11023\ttest-error:0.12568                              \n",
      "\n",
      "[61]\ttrain-error:0.11007\ttest-error:0.12561                              \n",
      "\n",
      "[62]\ttrain-error:0.10992\ttest-error:0.12537                              \n",
      "\n",
      "[63]\ttrain-error:0.10967\ttest-error:0.12531                              \n",
      "\n",
      "[64]\ttrain-error:0.10937\ttest-error:0.12500                              \n",
      "\n",
      "[65]\ttrain-error:0.10931\ttest-error:0.12512                              \n",
      "\n",
      "[66]\ttrain-error:0.10884\ttest-error:0.12506                              \n",
      "\n",
      "[67]\ttrain-error:0.10866\ttest-error:0.12512                              \n",
      "\n",
      "[68]\ttrain-error:0.10848\ttest-error:0.12500                              \n",
      "\n",
      "[69]\ttrain-error:0.10795\ttest-error:0.12506                              \n",
      "\n",
      "[70]\ttrain-error:0.10774\ttest-error:0.12525                              \n",
      "\n",
      "[71]\ttrain-error:0.10777\ttest-error:0.12525                              \n",
      "\n",
      "[72]\ttrain-error:0.10780\ttest-error:0.12537                              \n",
      "\n",
      "[73]\ttrain-error:0.10774\ttest-error:0.12525                              \n",
      "\n",
      "[74]\ttrain-error:0.10731\ttest-error:0.12525                              \n",
      "\n",
      "[75]\ttrain-error:0.10719\ttest-error:0.12537                              \n",
      "\n",
      "[76]\ttrain-error:0.10700\ttest-error:0.12543                              \n",
      "\n",
      "[77]\ttrain-error:0.10679\ttest-error:0.12525                              \n",
      "\n",
      "[78]\ttrain-error:0.10663\ttest-error:0.12537                              \n",
      "\n",
      "[79]\ttrain-error:0.10666\ttest-error:0.12531                              \n",
      "\n",
      "[80]\ttrain-error:0.10633\ttest-error:0.12549                              \n",
      "\n",
      "[81]\ttrain-error:0.10590\ttest-error:0.12525                              \n",
      "\n",
      "[82]\ttrain-error:0.10571\ttest-error:0.12525                              \n",
      "\n",
      "[83]\ttrain-error:0.10525\ttest-error:0.12549                              \n",
      "\n",
      "[84]\ttrain-error:0.10534\ttest-error:0.12555                              \n",
      "\n",
      "[85]\ttrain-error:0.10510\ttest-error:0.12555                              \n",
      "\n",
      "[86]\ttrain-error:0.10494\ttest-error:0.12568                              \n",
      "\n",
      "[87]\ttrain-error:0.10461\ttest-error:0.12568                              \n",
      "\n",
      "[88]\ttrain-error:0.10448\ttest-error:0.12531                              \n",
      "\n",
      "[89]\ttrain-error:0.10421\ttest-error:0.12543                              \n",
      "\n",
      "[90]\ttrain-error:0.10408\ttest-error:0.12525                              \n",
      "\n",
      "[91]\ttrain-error:0.10411\ttest-error:0.12537                              \n",
      "\n",
      "[92]\ttrain-error:0.10372\ttest-error:0.12561                              \n",
      "\n",
      "[93]\ttrain-error:0.10347\ttest-error:0.12525                              \n",
      "\n",
      "[94]\ttrain-error:0.10329\ttest-error:0.12531                              \n",
      "\n",
      "[95]\ttrain-error:0.10286\ttest-error:0.12512                              \n",
      "\n",
      "[96]\ttrain-error:0.10261\ttest-error:0.12537                              \n",
      "\n",
      "[97]\ttrain-error:0.10224\ttest-error:0.12531                              \n",
      "\n",
      "[98]\ttrain-error:0.10197\ttest-error:0.12537                              \n",
      "\n",
      "[99]\ttrain-error:0.10187\ttest-error:0.12543                              \n",
      "\n",
      "{'alpha': 0, 'btype': 'In', 'colsample_bylevel': 0.9972026978445254, 'colsample_bytree': 0.7914096443956073, 'eta': 0.006021800268670084, 'eval_metric': ('error',), 'extra_dims': 8, 'gamma': 0.12806060575295797, 'lambda': 0, 'max_depth': 1, 'min_child_weight': 9.472104896971971e-05, 'objective': 'binary:logistic', 'subsample': 0.8513860725219512}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:24:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[1]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[2]\ttrain-error:0.20863\ttest-error:0.20565                               \n",
      "\n",
      "[3]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[4]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[5]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[6]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[7]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[8]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[9]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[10]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[11]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[12]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[13]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[14]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[15]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[16]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[17]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[18]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[19]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[20]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[21]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[22]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[23]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[24]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[25]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[26]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[27]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[28]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[29]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[30]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[31]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[32]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[33]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[34]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[35]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[36]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[37]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[38]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[39]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[41]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[42]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[43]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[44]\ttrain-error:0.20455\ttest-error:0.20190                              \n",
      "\n",
      "[45]\ttrain-error:0.20452\ttest-error:0.20190                              \n",
      "\n",
      "[46]\ttrain-error:0.20181\ttest-error:0.19932                              \n",
      "\n",
      "[47]\ttrain-error:0.20181\ttest-error:0.19932                              \n",
      "\n",
      "[48]\ttrain-error:0.19960\ttest-error:0.19705                              \n",
      "\n",
      "[49]\ttrain-error:0.19948\ttest-error:0.19699                              \n",
      "\n",
      "[50]\ttrain-error:0.19966\ttest-error:0.19705                              \n",
      "\n",
      "[51]\ttrain-error:0.19966\ttest-error:0.19705                              \n",
      "\n",
      "[52]\ttrain-error:0.17666\ttest-error:0.17580                              \n",
      "\n",
      "[53]\ttrain-error:0.17632\ttest-error:0.17561                              \n",
      "\n",
      "[54]\ttrain-error:0.17153\ttest-error:0.17064                              \n",
      "\n",
      "[55]\ttrain-error:0.17153\ttest-error:0.17058                              \n",
      "\n",
      "[56]\ttrain-error:0.17141\ttest-error:0.17045                              \n",
      "\n",
      "[57]\ttrain-error:0.17070\ttest-error:0.16953                              \n",
      "\n",
      "[58]\ttrain-error:0.16990\ttest-error:0.16886                              \n",
      "\n",
      "[59]\ttrain-error:0.16966\ttest-error:0.16855                              \n",
      "\n",
      "[60]\ttrain-error:0.16953\ttest-error:0.16855                              \n",
      "\n",
      "[61]\ttrain-error:0.16944\ttest-error:0.16843                              \n",
      "\n",
      "[62]\ttrain-error:0.16935\ttest-error:0.16837                              \n",
      "\n",
      "[63]\ttrain-error:0.16929\ttest-error:0.16831                              \n",
      "\n",
      "[64]\ttrain-error:0.16929\ttest-error:0.16824                              \n",
      "\n",
      "[65]\ttrain-error:0.16926\ttest-error:0.16818                              \n",
      "\n",
      "[66]\ttrain-error:0.16923\ttest-error:0.16818                              \n",
      "\n",
      "[67]\ttrain-error:0.16554\ttest-error:0.16591                              \n",
      "\n",
      "[68]\ttrain-error:0.16087\ttest-error:0.15940                              \n",
      "\n",
      "[69]\ttrain-error:0.16539\ttest-error:0.16579                              \n",
      "\n",
      "[70]\ttrain-error:0.16511\ttest-error:0.16542                              \n",
      "\n",
      "[71]\ttrain-error:0.16511\ttest-error:0.16542                              \n",
      "\n",
      "[72]\ttrain-error:0.16496\ttest-error:0.16517                              \n",
      "\n",
      "[73]\ttrain-error:0.16087\ttest-error:0.15934                              \n",
      "\n",
      "[74]\ttrain-error:0.16066\ttest-error:0.15909                              \n",
      "\n",
      "[75]\ttrain-error:0.16066\ttest-error:0.15903                              \n",
      "\n",
      "[76]\ttrain-error:0.16453\ttest-error:0.16523                              \n",
      "\n",
      "[77]\ttrain-error:0.16004\ttest-error:0.15903                              \n",
      "\n",
      "[78]\ttrain-error:0.16004\ttest-error:0.15891                              \n",
      "\n",
      "[79]\ttrain-error:0.15934\ttest-error:0.15786                              \n",
      "\n",
      "[80]\ttrain-error:0.15931\ttest-error:0.15780                              \n",
      "\n",
      "[81]\ttrain-error:0.15872\ttest-error:0.15633                              \n",
      "\n",
      "[82]\ttrain-error:0.15854\ttest-error:0.15620                              \n",
      "\n",
      "[83]\ttrain-error:0.15848\ttest-error:0.15602                              \n",
      "\n",
      "[84]\ttrain-error:0.15891\ttest-error:0.15725                              \n",
      "\n",
      "[85]\ttrain-error:0.15894\ttest-error:0.15706                              \n",
      "\n",
      "[86]\ttrain-error:0.15875\ttest-error:0.15706                              \n",
      "\n",
      "[87]\ttrain-error:0.15768\ttest-error:0.15522                              \n",
      "\n",
      "[88]\ttrain-error:0.15746\ttest-error:0.15559                              \n",
      "\n",
      "[89]\ttrain-error:0.15796\ttest-error:0.15565                              \n",
      "\n",
      "[90]\ttrain-error:0.15780\ttest-error:0.15565                              \n",
      "\n",
      "[91]\ttrain-error:0.15556\ttest-error:0.15454                              \n",
      "\n",
      "[92]\ttrain-error:0.15538\ttest-error:0.15430                              \n",
      "\n",
      "[93]\ttrain-error:0.15519\ttest-error:0.15424                              \n",
      "\n",
      "[94]\ttrain-error:0.15510\ttest-error:0.15418                              \n",
      "\n",
      "[95]\ttrain-error:0.15666\ttest-error:0.15448                              \n",
      "\n",
      "[96]\ttrain-error:0.15510\ttest-error:0.15369                              \n",
      "\n",
      "[97]\ttrain-error:0.15498\ttest-error:0.15369                              \n",
      "\n",
      "[98]\ttrain-error:0.15501\ttest-error:0.15375                              \n",
      "\n",
      "[99]\ttrain-error:0.15498\ttest-error:0.15356                              \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.6915553005948871, 'colsample_bytree': 0.5964443720904835, 'eta': 0.011328565431718863, 'eval_metric': ('error',), 'extra_dims': 13, 'gamma': 0, 'lambda': 0, 'max_depth': 3, 'min_child_weight': 3.739497752906063e-06, 'objective': 'binary:logistic', 'subsample': 0.5147179706725337}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:26:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.16404\ttest-error:0.16235                               \n",
      "\n",
      "[1]\ttrain-error:0.15341\ttest-error:0.15319                               \n",
      "\n",
      "[2]\ttrain-error:0.15482\ttest-error:0.15510                               \n",
      "\n",
      "[3]\ttrain-error:0.15507\ttest-error:0.15387                               \n",
      "\n",
      "[4]\ttrain-error:0.15473\ttest-error:0.15387                               \n",
      "\n",
      "[5]\ttrain-error:0.15412\ttest-error:0.15381                               \n",
      "\n",
      "[6]\ttrain-error:0.15295\ttest-error:0.15240                               \n",
      "\n",
      "[7]\ttrain-error:0.15301\ttest-error:0.15184                               \n",
      "\n",
      "[8]\ttrain-error:0.15200\ttest-error:0.15061                               \n",
      "\n",
      "[9]\ttrain-error:0.15083\ttest-error:0.14994                               \n",
      "\n",
      "[10]\ttrain-error:0.15080\ttest-error:0.14975                              \n",
      "\n",
      "[11]\ttrain-error:0.15000\ttest-error:0.14871                              \n",
      "\n",
      "[12]\ttrain-error:0.14985\ttest-error:0.14834                              \n",
      "\n",
      "[13]\ttrain-error:0.14889\ttest-error:0.14760                              \n",
      "\n",
      "[14]\ttrain-error:0.14727\ttest-error:0.14631                              \n",
      "\n",
      "[15]\ttrain-error:0.14733\ttest-error:0.14607                              \n",
      "\n",
      "[16]\ttrain-error:0.14693\ttest-error:0.14595                              \n",
      "\n",
      "[17]\ttrain-error:0.14460\ttest-error:0.14355                              \n",
      "\n",
      "[18]\ttrain-error:0.14419\ttest-error:0.14312                              \n",
      "\n",
      "[19]\ttrain-error:0.14404\ttest-error:0.14281                              \n",
      "\n",
      "[20]\ttrain-error:0.14352\ttest-error:0.14251                              \n",
      "\n",
      "[21]\ttrain-error:0.14340\ttest-error:0.14232                              \n",
      "\n",
      "[22]\ttrain-error:0.14321\ttest-error:0.14202                              \n",
      "\n",
      "[23]\ttrain-error:0.14288\ttest-error:0.14202                              \n",
      "\n",
      "[24]\ttrain-error:0.14275\ttest-error:0.14171                              \n",
      "\n",
      "[25]\ttrain-error:0.14291\ttest-error:0.14202                              \n",
      "\n",
      "[26]\ttrain-error:0.14260\ttest-error:0.14208                              \n",
      "\n",
      "[27]\ttrain-error:0.14226\ttest-error:0.14177                              \n",
      "\n",
      "[28]\ttrain-error:0.14198\ttest-error:0.14171                              \n",
      "\n",
      "[29]\ttrain-error:0.14208\ttest-error:0.14103                              \n",
      "\n",
      "[30]\ttrain-error:0.14183\ttest-error:0.14066                              \n",
      "\n",
      "[31]\ttrain-error:0.14183\ttest-error:0.14048                              \n",
      "\n",
      "[32]\ttrain-error:0.14158\ttest-error:0.13980                              \n",
      "\n",
      "[33]\ttrain-error:0.14103\ttest-error:0.13980                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34]\ttrain-error:0.14088\ttest-error:0.13913                              \n",
      "\n",
      "[35]\ttrain-error:0.14060\ttest-error:0.13876                              \n",
      "\n",
      "[36]\ttrain-error:0.14045\ttest-error:0.13858                              \n",
      "\n",
      "[37]\ttrain-error:0.14030\ttest-error:0.13808                              \n",
      "\n",
      "[38]\ttrain-error:0.14020\ttest-error:0.13821                              \n",
      "\n",
      "[39]\ttrain-error:0.14011\ttest-error:0.13796                              \n",
      "\n",
      "[40]\ttrain-error:0.13983\ttest-error:0.13753                              \n",
      "\n",
      "[41]\ttrain-error:0.13956\ttest-error:0.13716                              \n",
      "\n",
      "[42]\ttrain-error:0.13947\ttest-error:0.13698                              \n",
      "\n",
      "[43]\ttrain-error:0.13916\ttest-error:0.13636                              \n",
      "\n",
      "[44]\ttrain-error:0.13916\ttest-error:0.13649                              \n",
      "\n",
      "[45]\ttrain-error:0.13894\ttest-error:0.13624                              \n",
      "\n",
      "[46]\ttrain-error:0.13854\ttest-error:0.13575                              \n",
      "\n",
      "[47]\ttrain-error:0.13830\ttest-error:0.13550                              \n",
      "\n",
      "[48]\ttrain-error:0.13793\ttest-error:0.13501                              \n",
      "\n",
      "[49]\ttrain-error:0.13790\ttest-error:0.13507                              \n",
      "\n",
      "[50]\ttrain-error:0.13762\ttest-error:0.13520                              \n",
      "\n",
      "[51]\ttrain-error:0.13725\ttest-error:0.13501                              \n",
      "\n",
      "[52]\ttrain-error:0.13713\ttest-error:0.13464                              \n",
      "\n",
      "[53]\ttrain-error:0.13682\ttest-error:0.13458                              \n",
      "\n",
      "[54]\ttrain-error:0.13664\ttest-error:0.13421                              \n",
      "\n",
      "[55]\ttrain-error:0.13618\ttest-error:0.13409                              \n",
      "\n",
      "[56]\ttrain-error:0.13603\ttest-error:0.13384                              \n",
      "\n",
      "[57]\ttrain-error:0.13572\ttest-error:0.13348                              \n",
      "\n",
      "[58]\ttrain-error:0.13547\ttest-error:0.13366                              \n",
      "\n",
      "[59]\ttrain-error:0.13529\ttest-error:0.13354                              \n",
      "\n",
      "[60]\ttrain-error:0.13514\ttest-error:0.13323                              \n",
      "\n",
      "[61]\ttrain-error:0.13504\ttest-error:0.13256                              \n",
      "\n",
      "[62]\ttrain-error:0.13461\ttest-error:0.13243                              \n",
      "\n",
      "[63]\ttrain-error:0.13449\ttest-error:0.13231                              \n",
      "\n",
      "[64]\ttrain-error:0.13449\ttest-error:0.13200                              \n",
      "\n",
      "[65]\ttrain-error:0.13443\ttest-error:0.13176                              \n",
      "\n",
      "[66]\ttrain-error:0.13415\ttest-error:0.13151                              \n",
      "\n",
      "[67]\ttrain-error:0.13394\ttest-error:0.13126                              \n",
      "\n",
      "[68]\ttrain-error:0.13384\ttest-error:0.13133                              \n",
      "\n",
      "[69]\ttrain-error:0.13360\ttest-error:0.13090                              \n",
      "\n",
      "[70]\ttrain-error:0.13351\ttest-error:0.13071                              \n",
      "\n",
      "[71]\ttrain-error:0.13339\ttest-error:0.13047                              \n",
      "\n",
      "[72]\ttrain-error:0.13289\ttest-error:0.13047                              \n",
      "\n",
      "[73]\ttrain-error:0.13249\ttest-error:0.13071                              \n",
      "\n",
      "[74]\ttrain-error:0.13206\ttest-error:0.13084                              \n",
      "\n",
      "[75]\ttrain-error:0.13188\ttest-error:0.13053                              \n",
      "\n",
      "[76]\ttrain-error:0.13188\ttest-error:0.13059                              \n",
      "\n",
      "[77]\ttrain-error:0.13167\ttest-error:0.13028                              \n",
      "\n",
      "[78]\ttrain-error:0.13151\ttest-error:0.13022                              \n",
      "\n",
      "[79]\ttrain-error:0.13133\ttest-error:0.13016                              \n",
      "\n",
      "[80]\ttrain-error:0.13114\ttest-error:0.13016                              \n",
      "\n",
      "[81]\ttrain-error:0.13096\ttest-error:0.13010                              \n",
      "\n",
      "[82]\ttrain-error:0.13077\ttest-error:0.12998                              \n",
      "\n",
      "[83]\ttrain-error:0.13068\ttest-error:0.12991                              \n",
      "\n",
      "[84]\ttrain-error:0.13056\ttest-error:0.12985                              \n",
      "\n",
      "[85]\ttrain-error:0.13022\ttest-error:0.12973                              \n",
      "\n",
      "[86]\ttrain-error:0.13007\ttest-error:0.12961                              \n",
      "\n",
      "[87]\ttrain-error:0.12995\ttest-error:0.12954                              \n",
      "\n",
      "[88]\ttrain-error:0.13001\ttest-error:0.12967                              \n",
      "\n",
      "[89]\ttrain-error:0.12973\ttest-error:0.12924                              \n",
      "\n",
      "[90]\ttrain-error:0.12954\ttest-error:0.12936                              \n",
      "\n",
      "[91]\ttrain-error:0.12948\ttest-error:0.12936                              \n",
      "\n",
      "[92]\ttrain-error:0.12945\ttest-error:0.12942                              \n",
      "\n",
      "[93]\ttrain-error:0.12954\ttest-error:0.12930                              \n",
      "\n",
      "[94]\ttrain-error:0.12921\ttest-error:0.12942                              \n",
      "\n",
      "[95]\ttrain-error:0.12890\ttest-error:0.12905                              \n",
      "\n",
      "[96]\ttrain-error:0.12890\ttest-error:0.12899                              \n",
      "\n",
      "[97]\ttrain-error:0.12884\ttest-error:0.12875                              \n",
      "\n",
      "[98]\ttrain-error:0.12865\ttest-error:0.12887                              \n",
      "\n",
      "[99]\ttrain-error:0.12862\ttest-error:0.12869                              \n",
      "\n",
      "{'alpha': 9.302039092966166e-06, 'btype': 'R', 'colsample_bylevel': 0.7789103983943955, 'colsample_bytree': 0.8190821446937828, 'eta': 0.18104536928560785, 'eval_metric': ('error',), 'extra_dims': 15, 'gamma': 0, 'lambda': 4.141325252286392, 'max_depth': 7, 'min_child_weight': 1.677728151607064, 'objective': 'binary:logistic', 'subsample': 0.5836282972391584}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:27:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14392\ttest-error:0.14410                               \n",
      "\n",
      "[1]\ttrain-error:0.34447\ttest-error:0.35283                               \n",
      "\n",
      "[2]\ttrain-error:0.17064\ttest-error:0.17089                               \n",
      "\n",
      "[3]\ttrain-error:0.75375\ttest-error:0.75964                               \n",
      "\n",
      "[4]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[5]\ttrain-error:0.24840\ttest-error:0.24975                               \n",
      "\n",
      "[6]\ttrain-error:0.24843\ttest-error:0.24982                               \n",
      "\n",
      "[7]\ttrain-error:0.24843\ttest-error:0.24982                               \n",
      "\n",
      "[8]\ttrain-error:0.24843\ttest-error:0.24982                               \n",
      "\n",
      "[9]\ttrain-error:0.24754\ttest-error:0.24896                               \n",
      "\n",
      "[10]\ttrain-error:0.24721\ttest-error:0.24816                              \n",
      "\n",
      "[11]\ttrain-error:0.24011\ttest-error:0.24146                              \n",
      "\n",
      "[12]\ttrain-error:0.24097\ttest-error:0.24208                              \n",
      "\n",
      "[13]\ttrain-error:0.24122\ttest-error:0.24257                              \n",
      "\n",
      "[14]\ttrain-error:0.24161\ttest-error:0.24263                              \n",
      "\n",
      "[15]\ttrain-error:0.24214\ttest-error:0.24312                              \n",
      "\n",
      "[16]\ttrain-error:0.24205\ttest-error:0.24312                              \n",
      "\n",
      "[17]\ttrain-error:0.24226\ttest-error:0.24312                              \n",
      "\n",
      "[18]\ttrain-error:0.24294\ttest-error:0.24398                              \n",
      "\n",
      "[19]\ttrain-error:0.24333\ttest-error:0.24410                              \n",
      "\n",
      "[20]\ttrain-error:0.24291\ttest-error:0.24423                              \n",
      "\n",
      "[21]\ttrain-error:0.24244\ttest-error:0.24410                              \n",
      "\n",
      "[22]\ttrain-error:0.24177\ttest-error:0.24337                              \n",
      "\n",
      "[23]\ttrain-error:0.24180\ttest-error:0.24330                              \n",
      "\n",
      "[24]\ttrain-error:0.24192\ttest-error:0.24349                              \n",
      "\n",
      "[25]\ttrain-error:0.24214\ttest-error:0.24380                              \n",
      "\n",
      "[26]\ttrain-error:0.24229\ttest-error:0.24398                              \n",
      "\n",
      "[27]\ttrain-error:0.24192\ttest-error:0.24355                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28]\ttrain-error:0.24189\ttest-error:0.24355                              \n",
      "\n",
      "[29]\ttrain-error:0.24186\ttest-error:0.24355                              \n",
      "\n",
      "[30]\ttrain-error:0.24189\ttest-error:0.24355                              \n",
      "\n",
      "[31]\ttrain-error:0.24186\ttest-error:0.24355                              \n",
      "\n",
      "[32]\ttrain-error:0.24192\ttest-error:0.24349                              \n",
      "\n",
      "[33]\ttrain-error:0.24183\ttest-error:0.24337                              \n",
      "\n",
      "[34]\ttrain-error:0.24180\ttest-error:0.24343                              \n",
      "\n",
      "[35]\ttrain-error:0.24174\ttest-error:0.24312                              \n",
      "\n",
      "[36]\ttrain-error:0.24171\ttest-error:0.24312                              \n",
      "\n",
      "[37]\ttrain-error:0.24155\ttest-error:0.24294                              \n",
      "\n",
      "[38]\ttrain-error:0.23805\ttest-error:0.23925                              \n",
      "\n",
      "[39]\ttrain-error:0.23197\ttest-error:0.23378                              \n",
      "\n",
      "[40]\ttrain-error:0.22629\ttest-error:0.22666                              \n",
      "\n",
      "[41]\ttrain-error:0.20574\ttest-error:0.20633                              \n",
      "\n",
      "[42]\ttrain-error:0.20971\ttest-error:0.20983                              \n",
      "\n",
      "[43]\ttrain-error:0.21345\ttest-error:0.21751                              \n",
      "\n",
      "[44]\ttrain-error:0.18041\ttest-error:0.18108                              \n",
      "\n",
      "[45]\ttrain-error:0.23753\ttest-error:0.24023                              \n",
      "\n",
      "[46]\ttrain-error:0.18028\ttest-error:0.17795                              \n",
      "\n",
      "[47]\ttrain-error:0.29226\ttest-error:0.28839                              \n",
      "\n",
      "[48]\ttrain-error:0.21450\ttest-error:0.20977                              \n",
      "\n",
      "[49]\ttrain-error:0.22737\ttest-error:0.22611                              \n",
      "\n",
      "[50]\ttrain-error:0.22442\ttest-error:0.22672                              \n",
      "\n",
      "[51]\ttrain-error:0.19290\ttest-error:0.19134                              \n",
      "\n",
      "[52]\ttrain-error:0.25338\ttest-error:0.25547                              \n",
      "\n",
      "[53]\ttrain-error:0.19782\ttest-error:0.19810                              \n",
      "\n",
      "[54]\ttrain-error:0.35676\ttest-error:0.35897                              \n",
      "\n",
      "[55]\ttrain-error:0.23188\ttest-error:0.22592                              \n",
      "\n",
      "[56]\ttrain-error:0.71063\ttest-error:0.71216                              \n",
      "\n",
      "[57]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[58]\ttrain-error:0.66744\ttest-error:0.67310                              \n",
      "\n",
      "[59]\ttrain-error:0.24214\ttest-error:0.23845                              \n",
      "\n",
      "[60]\ttrain-error:0.61278\ttest-error:0.61892                              \n",
      "\n",
      "[61]\ttrain-error:0.24051\ttest-error:0.23581                              \n",
      "\n",
      "[62]\ttrain-error:0.70126\ttest-error:0.70369                              \n",
      "\n",
      "[63]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[64]\ttrain-error:0.27070\ttest-error:0.27199                              \n",
      "\n",
      "[65]\ttrain-error:0.37131\ttest-error:0.36929                              \n",
      "\n",
      "[66]\ttrain-error:0.24588\ttest-error:0.24097                              \n",
      "\n",
      "[67]\ttrain-error:0.70599\ttest-error:0.70971                              \n",
      "\n",
      "[68]\ttrain-error:0.24794\ttest-error:0.24386                              \n",
      "\n",
      "[69]\ttrain-error:0.39745\ttest-error:0.40252                              \n",
      "\n",
      "[70]\ttrain-error:0.37310\ttest-error:0.37242                              \n",
      "\n",
      "[71]\ttrain-error:0.25547\ttest-error:0.25018                              \n",
      "\n",
      "[72]\ttrain-error:0.58240\ttest-error:0.58667                              \n",
      "\n",
      "[73]\ttrain-error:0.24085\ttest-error:0.23630                              \n",
      "\n",
      "[74]\ttrain-error:0.27869\ttest-error:0.27647                              \n",
      "\n",
      "[75]\ttrain-error:0.47436\ttest-error:0.47586                              \n",
      "\n",
      "[76]\ttrain-error:0.26520\ttest-error:0.26014                              \n",
      "\n",
      "[77]\ttrain-error:0.43538\ttest-error:0.43440                              \n",
      "\n",
      "[78]\ttrain-error:0.23154\ttest-error:0.23120                              \n",
      "\n",
      "[79]\ttrain-error:0.25562\ttest-error:0.25608                              \n",
      "\n",
      "[80]\ttrain-error:0.21950\ttest-error:0.21830                              \n",
      "\n",
      "[81]\ttrain-error:0.32162\ttest-error:0.31966                              \n",
      "\n",
      "[82]\ttrain-error:0.24082\ttest-error:0.23655                              \n",
      "\n",
      "[83]\ttrain-error:0.48799\ttest-error:0.48974                              \n",
      "\n",
      "[84]\ttrain-error:0.24487\ttest-error:0.24036                              \n",
      "\n",
      "[85]\ttrain-error:0.54748\ttest-error:0.54902                              \n",
      "\n",
      "[86]\ttrain-error:0.25335\ttest-error:0.24914                              \n",
      "\n",
      "[87]\ttrain-error:0.62568\ttest-error:0.62961                              \n",
      "\n",
      "[88]\ttrain-error:0.24085\ttest-error:0.23624                              \n",
      "\n",
      "[89]\ttrain-error:0.31517\ttest-error:0.30977                              \n",
      "\n",
      "[90]\ttrain-error:0.49800\ttest-error:0.50086                              \n",
      "\n",
      "[91]\ttrain-error:0.25381\ttest-error:0.24963                              \n",
      "\n",
      "[92]\ttrain-error:0.64561\ttest-error:0.65283                              \n",
      "\n",
      "[93]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[94]\ttrain-error:0.25636\ttest-error:0.25295                              \n",
      "\n",
      "[95]\ttrain-error:0.64502\ttest-error:0.65160                              \n",
      "\n",
      "[96]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[97]\ttrain-error:0.25617\ttest-error:0.25307                              \n",
      "\n",
      "[98]\ttrain-error:0.63891\ttest-error:0.64576                              \n",
      "\n",
      "[99]\ttrain-error:0.24085\ttest-error:0.23624                              \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.5746186766011021, 'colsample_bytree': 0.6006771406668292, 'eta': 0.019556328604250668, 'eval_metric': ('error',), 'extra_dims': 15, 'gamma': 0.0001960112447438232, 'lambda': 0.39304297405436917, 'max_depth': 1, 'min_child_weight': 3.127311000067921e-07, 'objective': 'binary:logistic', 'subsample': 0.5480561977904441}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:29:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.22221\ttest-error:0.21806                               \n",
      "\n",
      "[1]\ttrain-error:0.20924\ttest-error:0.20602                               \n",
      "\n",
      "[2]\ttrain-error:0.20663\ttest-error:0.20362                               \n",
      "\n",
      "[3]\ttrain-error:0.20679\ttest-error:0.20362                               \n",
      "\n",
      "[4]\ttrain-error:0.20820\ttest-error:0.20541                               \n",
      "\n",
      "[5]\ttrain-error:0.20510\ttest-error:0.20240                               \n",
      "\n",
      "[6]\ttrain-error:0.20497\ttest-error:0.20227                               \n",
      "\n",
      "[7]\ttrain-error:0.20424\ttest-error:0.20141                               \n",
      "\n",
      "[8]\ttrain-error:0.18016\ttest-error:0.17911                               \n",
      "\n",
      "[9]\ttrain-error:0.17650\ttest-error:0.17543                               \n",
      "\n",
      "[10]\ttrain-error:0.17399\ttest-error:0.17291                              \n",
      "\n",
      "[11]\ttrain-error:0.17104\ttest-error:0.17021                              \n",
      "\n",
      "[12]\ttrain-error:0.16603\ttest-error:0.16763                              \n",
      "\n",
      "[13]\ttrain-error:0.16533\ttest-error:0.16585                              \n",
      "\n",
      "[14]\ttrain-error:0.16007\ttest-error:0.15927                              \n",
      "\n",
      "[15]\ttrain-error:0.15940\ttest-error:0.15897                              \n",
      "\n",
      "[16]\ttrain-error:0.15842\ttest-error:0.15762                              \n",
      "\n",
      "[17]\ttrain-error:0.15725\ttest-error:0.15645                              \n",
      "\n",
      "[18]\ttrain-error:0.15571\ttest-error:0.15540                              \n",
      "\n",
      "[19]\ttrain-error:0.15531\ttest-error:0.15491                              \n",
      "\n",
      "[20]\ttrain-error:0.15347\ttest-error:0.15289                              \n",
      "\n",
      "[21]\ttrain-error:0.15132\ttest-error:0.15123                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\ttrain-error:0.15080\ttest-error:0.15111                              \n",
      "\n",
      "[23]\ttrain-error:0.15040\ttest-error:0.15086                              \n",
      "\n",
      "[24]\ttrain-error:0.15046\ttest-error:0.15055                              \n",
      "\n",
      "[25]\ttrain-error:0.15018\ttest-error:0.15061                              \n",
      "\n",
      "[26]\ttrain-error:0.14957\ttest-error:0.14926                              \n",
      "\n",
      "[27]\ttrain-error:0.14920\ttest-error:0.14883                              \n",
      "\n",
      "[28]\ttrain-error:0.14899\ttest-error:0.14859                              \n",
      "\n",
      "[29]\ttrain-error:0.14865\ttest-error:0.14803                              \n",
      "\n",
      "[30]\ttrain-error:0.14828\ttest-error:0.14803                              \n",
      "\n",
      "[31]\ttrain-error:0.14791\ttest-error:0.14736                              \n",
      "\n",
      "[32]\ttrain-error:0.14785\ttest-error:0.14724                              \n",
      "\n",
      "[33]\ttrain-error:0.14767\ttest-error:0.14724                              \n",
      "\n",
      "[34]\ttrain-error:0.14665\ttest-error:0.14533                              \n",
      "\n",
      "[35]\ttrain-error:0.14622\ttest-error:0.14472                              \n",
      "\n",
      "[36]\ttrain-error:0.14622\ttest-error:0.14521                              \n",
      "\n",
      "[37]\ttrain-error:0.14613\ttest-error:0.14466                              \n",
      "\n",
      "[38]\ttrain-error:0.14573\ttest-error:0.14447                              \n",
      "\n",
      "[39]\ttrain-error:0.14555\ttest-error:0.14447                              \n",
      "\n",
      "[40]\ttrain-error:0.14524\ttest-error:0.14392                              \n",
      "\n",
      "[41]\ttrain-error:0.14502\ttest-error:0.14410                              \n",
      "\n",
      "[42]\ttrain-error:0.14496\ttest-error:0.14374                              \n",
      "\n",
      "[43]\ttrain-error:0.14509\ttest-error:0.14392                              \n",
      "\n",
      "[44]\ttrain-error:0.14499\ttest-error:0.14367                              \n",
      "\n",
      "[45]\ttrain-error:0.14493\ttest-error:0.14330                              \n",
      "\n",
      "[46]\ttrain-error:0.14490\ttest-error:0.14343                              \n",
      "\n",
      "[47]\ttrain-error:0.14487\ttest-error:0.14324                              \n",
      "\n",
      "[48]\ttrain-error:0.14484\ttest-error:0.14288                              \n",
      "\n",
      "[49]\ttrain-error:0.14466\ttest-error:0.14312                              \n",
      "\n",
      "[50]\ttrain-error:0.14490\ttest-error:0.14275                              \n",
      "\n",
      "[51]\ttrain-error:0.14475\ttest-error:0.14263                              \n",
      "\n",
      "[52]\ttrain-error:0.14450\ttest-error:0.14226                              \n",
      "\n",
      "[53]\ttrain-error:0.14450\ttest-error:0.14238                              \n",
      "\n",
      "[54]\ttrain-error:0.14429\ttest-error:0.14238                              \n",
      "\n",
      "[55]\ttrain-error:0.14438\ttest-error:0.14251                              \n",
      "\n",
      "[56]\ttrain-error:0.14429\ttest-error:0.14214                              \n",
      "\n",
      "[57]\ttrain-error:0.14410\ttest-error:0.14177                              \n",
      "\n",
      "[58]\ttrain-error:0.14398\ttest-error:0.14183                              \n",
      "\n",
      "[59]\ttrain-error:0.14407\ttest-error:0.14165                              \n",
      "\n",
      "[60]\ttrain-error:0.14410\ttest-error:0.14165                              \n",
      "\n",
      "[61]\ttrain-error:0.14398\ttest-error:0.14134                              \n",
      "\n",
      "[62]\ttrain-error:0.14401\ttest-error:0.14097                              \n",
      "\n",
      "[63]\ttrain-error:0.14374\ttest-error:0.14103                              \n",
      "\n",
      "[64]\ttrain-error:0.14389\ttest-error:0.14079                              \n",
      "\n",
      "[65]\ttrain-error:0.14392\ttest-error:0.14072                              \n",
      "\n",
      "[66]\ttrain-error:0.14383\ttest-error:0.14103                              \n",
      "\n",
      "[67]\ttrain-error:0.14383\ttest-error:0.14054                              \n",
      "\n",
      "[68]\ttrain-error:0.14367\ttest-error:0.14066                              \n",
      "\n",
      "[69]\ttrain-error:0.14361\ttest-error:0.14042                              \n",
      "\n",
      "[70]\ttrain-error:0.14352\ttest-error:0.14048                              \n",
      "\n",
      "[71]\ttrain-error:0.14349\ttest-error:0.14005                              \n",
      "\n",
      "[72]\ttrain-error:0.14355\ttest-error:0.13999                              \n",
      "\n",
      "[73]\ttrain-error:0.14330\ttest-error:0.14054                              \n",
      "\n",
      "[74]\ttrain-error:0.14327\ttest-error:0.14030                              \n",
      "\n",
      "[75]\ttrain-error:0.14309\ttest-error:0.14048                              \n",
      "\n",
      "[76]\ttrain-error:0.14297\ttest-error:0.14011                              \n",
      "\n",
      "[77]\ttrain-error:0.14272\ttest-error:0.13986                              \n",
      "\n",
      "[78]\ttrain-error:0.14266\ttest-error:0.13962                              \n",
      "\n",
      "[79]\ttrain-error:0.14288\ttest-error:0.13956                              \n",
      "\n",
      "[80]\ttrain-error:0.14288\ttest-error:0.13974                              \n",
      "\n",
      "[81]\ttrain-error:0.14275\ttest-error:0.13974                              \n",
      "\n",
      "[82]\ttrain-error:0.14284\ttest-error:0.13962                              \n",
      "\n",
      "[83]\ttrain-error:0.14281\ttest-error:0.13925                              \n",
      "\n",
      "[84]\ttrain-error:0.14275\ttest-error:0.13931                              \n",
      "\n",
      "[85]\ttrain-error:0.14275\ttest-error:0.13913                              \n",
      "\n",
      "[86]\ttrain-error:0.14257\ttest-error:0.13882                              \n",
      "\n",
      "[87]\ttrain-error:0.14244\ttest-error:0.13894                              \n",
      "\n",
      "[88]\ttrain-error:0.14232\ttest-error:0.13888                              \n",
      "\n",
      "[89]\ttrain-error:0.14232\ttest-error:0.13888                              \n",
      "\n",
      "[90]\ttrain-error:0.14214\ttest-error:0.13882                              \n",
      "\n",
      "[91]\ttrain-error:0.14208\ttest-error:0.13839                              \n",
      "\n",
      "[92]\ttrain-error:0.14186\ttest-error:0.13827                              \n",
      "\n",
      "[93]\ttrain-error:0.14183\ttest-error:0.13821                              \n",
      "\n",
      "[94]\ttrain-error:0.14180\ttest-error:0.13802                              \n",
      "\n",
      "[95]\ttrain-error:0.14180\ttest-error:0.13778                              \n",
      "\n",
      "[96]\ttrain-error:0.14183\ttest-error:0.13802                              \n",
      "\n",
      "[97]\ttrain-error:0.14183\ttest-error:0.13808                              \n",
      "\n",
      "[98]\ttrain-error:0.14161\ttest-error:0.13796                              \n",
      "\n",
      "[99]\ttrain-error:0.14131\ttest-error:0.13765                              \n",
      "\n",
      "{'alpha': 1.4759557247722424, 'btype': 'In', 'colsample_bylevel': 0.8515109898508662, 'colsample_bytree': 0.6688964157774572, 'eta': 0.023613766610546837, 'eval_metric': ('error',), 'extra_dims': 12, 'gamma': 3.7380197952595906, 'lambda': 2.3405084270460816e-07, 'max_depth': 7, 'min_child_weight': 0.025648268977702605, 'objective': 'binary:logistic', 'subsample': 0.9881968648022366}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:31:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14155\ttest-error:0.13876                               \n",
      "\n",
      "[1]\ttrain-error:0.14226\ttest-error:0.13937                               \n",
      "\n",
      "[2]\ttrain-error:0.14100\ttest-error:0.13980                               \n",
      "\n",
      "[3]\ttrain-error:0.14076\ttest-error:0.13833                               \n",
      "\n",
      "[4]\ttrain-error:0.14036\ttest-error:0.13808                               \n",
      "\n",
      "[5]\ttrain-error:0.13983\ttest-error:0.13728                               \n",
      "\n",
      "[6]\ttrain-error:0.13956\ttest-error:0.13618                               \n",
      "\n",
      "[7]\ttrain-error:0.13858\ttest-error:0.13587                               \n",
      "\n",
      "[8]\ttrain-error:0.13818\ttest-error:0.13483                               \n",
      "\n",
      "[9]\ttrain-error:0.13768\ttest-error:0.13470                               \n",
      "\n",
      "[10]\ttrain-error:0.13732\ttest-error:0.13378                              \n",
      "\n",
      "[11]\ttrain-error:0.13646\ttest-error:0.13342                              \n",
      "\n",
      "[12]\ttrain-error:0.13609\ttest-error:0.13292                              \n",
      "\n",
      "[13]\ttrain-error:0.13544\ttest-error:0.13249                              \n",
      "\n",
      "[14]\ttrain-error:0.13489\ttest-error:0.13170                              \n",
      "\n",
      "[15]\ttrain-error:0.13428\ttest-error:0.13176                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\ttrain-error:0.13384\ttest-error:0.13151                              \n",
      "\n",
      "[17]\ttrain-error:0.13329\ttest-error:0.13176                              \n",
      "\n",
      "[18]\ttrain-error:0.13271\ttest-error:0.13108                              \n",
      "\n",
      "[19]\ttrain-error:0.13265\ttest-error:0.13114                              \n",
      "\n",
      "[20]\ttrain-error:0.13216\ttest-error:0.13090                              \n",
      "\n",
      "[21]\ttrain-error:0.13182\ttest-error:0.13053                              \n",
      "\n",
      "[22]\ttrain-error:0.13117\ttest-error:0.13028                              \n",
      "\n",
      "[23]\ttrain-error:0.13087\ttest-error:0.13022                              \n",
      "\n",
      "[24]\ttrain-error:0.13047\ttest-error:0.12985                              \n",
      "\n",
      "[25]\ttrain-error:0.13034\ttest-error:0.12967                              \n",
      "\n",
      "[26]\ttrain-error:0.13016\ttest-error:0.12961                              \n",
      "\n",
      "[27]\ttrain-error:0.13013\ttest-error:0.12998                              \n",
      "\n",
      "[28]\ttrain-error:0.12976\ttest-error:0.12973                              \n",
      "\n",
      "[29]\ttrain-error:0.12958\ttest-error:0.12954                              \n",
      "\n",
      "[30]\ttrain-error:0.12921\ttest-error:0.12924                              \n",
      "\n",
      "[31]\ttrain-error:0.12927\ttest-error:0.12905                              \n",
      "\n",
      "[32]\ttrain-error:0.12884\ttest-error:0.12893                              \n",
      "\n",
      "[33]\ttrain-error:0.12875\ttest-error:0.12862                              \n",
      "\n",
      "[34]\ttrain-error:0.12869\ttest-error:0.12819                              \n",
      "\n",
      "[35]\ttrain-error:0.12826\ttest-error:0.12807                              \n",
      "\n",
      "[36]\ttrain-error:0.12832\ttest-error:0.12807                              \n",
      "\n",
      "[37]\ttrain-error:0.12813\ttest-error:0.12795                              \n",
      "\n",
      "[38]\ttrain-error:0.12816\ttest-error:0.12789                              \n",
      "\n",
      "[39]\ttrain-error:0.12789\ttest-error:0.12776                              \n",
      "\n",
      "[40]\ttrain-error:0.12795\ttest-error:0.12783                              \n",
      "\n",
      "[41]\ttrain-error:0.12783\ttest-error:0.12776                              \n",
      "\n",
      "[42]\ttrain-error:0.12779\ttest-error:0.12770                              \n",
      "\n",
      "[43]\ttrain-error:0.12767\ttest-error:0.12764                              \n",
      "\n",
      "[44]\ttrain-error:0.12764\ttest-error:0.12770                              \n",
      "\n",
      "[45]\ttrain-error:0.12737\ttest-error:0.12752                              \n",
      "\n",
      "[46]\ttrain-error:0.12730\ttest-error:0.12776                              \n",
      "\n",
      "[47]\ttrain-error:0.12743\ttest-error:0.12758                              \n",
      "\n",
      "[48]\ttrain-error:0.12743\ttest-error:0.12764                              \n",
      "\n",
      "[49]\ttrain-error:0.12715\ttest-error:0.12758                              \n",
      "\n",
      "[50]\ttrain-error:0.12706\ttest-error:0.12776                              \n",
      "\n",
      "[51]\ttrain-error:0.12709\ttest-error:0.12783                              \n",
      "\n",
      "[52]\ttrain-error:0.12700\ttest-error:0.12770                              \n",
      "\n",
      "[53]\ttrain-error:0.12690\ttest-error:0.12764                              \n",
      "\n",
      "[54]\ttrain-error:0.12678\ttest-error:0.12770                              \n",
      "\n",
      "[55]\ttrain-error:0.12681\ttest-error:0.12758                              \n",
      "\n",
      "[56]\ttrain-error:0.12687\ttest-error:0.12758                              \n",
      "\n",
      "[57]\ttrain-error:0.12681\ttest-error:0.12764                              \n",
      "\n",
      "[58]\ttrain-error:0.12663\ttest-error:0.12764                              \n",
      "\n",
      "[59]\ttrain-error:0.12669\ttest-error:0.12770                              \n",
      "\n",
      "[60]\ttrain-error:0.12675\ttest-error:0.12758                              \n",
      "\n",
      "[61]\ttrain-error:0.12672\ttest-error:0.12746                              \n",
      "\n",
      "[62]\ttrain-error:0.12660\ttest-error:0.12746                              \n",
      "\n",
      "[63]\ttrain-error:0.12651\ttest-error:0.12740                              \n",
      "\n",
      "[64]\ttrain-error:0.12635\ttest-error:0.12733                              \n",
      "\n",
      "[65]\ttrain-error:0.12635\ttest-error:0.12740                              \n",
      "\n",
      "[66]\ttrain-error:0.12620\ttest-error:0.12721                              \n",
      "\n",
      "[67]\ttrain-error:0.12611\ttest-error:0.12727                              \n",
      "\n",
      "[68]\ttrain-error:0.12611\ttest-error:0.12727                              \n",
      "\n",
      "[69]\ttrain-error:0.12614\ttest-error:0.12715                              \n",
      "\n",
      "[70]\ttrain-error:0.12614\ttest-error:0.12703                              \n",
      "\n",
      "[71]\ttrain-error:0.12617\ttest-error:0.12709                              \n",
      "\n",
      "[72]\ttrain-error:0.12601\ttest-error:0.12697                              \n",
      "\n",
      "[73]\ttrain-error:0.12595\ttest-error:0.12690                              \n",
      "\n",
      "[74]\ttrain-error:0.12589\ttest-error:0.12690                              \n",
      "\n",
      "[75]\ttrain-error:0.12589\ttest-error:0.12666                              \n",
      "\n",
      "[76]\ttrain-error:0.12586\ttest-error:0.12660                              \n",
      "\n",
      "[77]\ttrain-error:0.12580\ttest-error:0.12672                              \n",
      "\n",
      "[78]\ttrain-error:0.12589\ttest-error:0.12672                              \n",
      "\n",
      "[79]\ttrain-error:0.12592\ttest-error:0.12660                              \n",
      "\n",
      "[80]\ttrain-error:0.12580\ttest-error:0.12654                              \n",
      "\n",
      "[81]\ttrain-error:0.12574\ttest-error:0.12654                              \n",
      "\n",
      "[82]\ttrain-error:0.12580\ttest-error:0.12654                              \n",
      "\n",
      "[83]\ttrain-error:0.12577\ttest-error:0.12641                              \n",
      "\n",
      "[84]\ttrain-error:0.12574\ttest-error:0.12654                              \n",
      "\n",
      "[85]\ttrain-error:0.12574\ttest-error:0.12647                              \n",
      "\n",
      "[86]\ttrain-error:0.12568\ttest-error:0.12647                              \n",
      "\n",
      "[87]\ttrain-error:0.12555\ttest-error:0.12641                              \n",
      "\n",
      "[88]\ttrain-error:0.12558\ttest-error:0.12641                              \n",
      "\n",
      "[89]\ttrain-error:0.12558\ttest-error:0.12641                              \n",
      "\n",
      "[90]\ttrain-error:0.12552\ttest-error:0.12647                              \n",
      "\n",
      "[91]\ttrain-error:0.12543\ttest-error:0.12647                              \n",
      "\n",
      "[92]\ttrain-error:0.12546\ttest-error:0.12641                              \n",
      "\n",
      "[93]\ttrain-error:0.12549\ttest-error:0.12647                              \n",
      "\n",
      "[94]\ttrain-error:0.12549\ttest-error:0.12647                              \n",
      "\n",
      "[95]\ttrain-error:0.12549\ttest-error:0.12647                              \n",
      "\n",
      "[96]\ttrain-error:0.12549\ttest-error:0.12641                              \n",
      "\n",
      "[97]\ttrain-error:0.12534\ttest-error:0.12641                              \n",
      "\n",
      "[98]\ttrain-error:0.12537\ttest-error:0.12641                              \n",
      "\n",
      "[99]\ttrain-error:0.12537\ttest-error:0.12641                              \n",
      "\n",
      "{'alpha': 1.4731830550769047e-07, 'btype': 'In', 'colsample_bylevel': 0.503726866601157, 'colsample_bytree': 0.548481223319902, 'eta': 0.7107859746695228, 'eval_metric': ('error',), 'extra_dims': 12, 'gamma': 0.009326450132180157, 'lambda': 0.0023264406674389708, 'max_depth': 10, 'min_child_weight': 138.08890812916223, 'objective': 'binary:logistic', 'subsample': 0.9897785118008193}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[22:33:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[1]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[2]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[3]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[4]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[5]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[6]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[7]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[8]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[9]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[11]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[12]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[13]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[14]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[15]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[16]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[17]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[18]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[19]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[20]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[21]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[22]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[23]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[24]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[25]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[26]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[27]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[28]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[29]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[30]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[31]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[32]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[33]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[34]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[35]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[36]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[37]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[38]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[39]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[40]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[41]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[42]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[43]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[44]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[45]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[46]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[47]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[48]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[49]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[50]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[51]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[52]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[53]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[54]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[55]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[56]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[57]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[58]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[59]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[60]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[61]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[62]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[63]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[64]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[65]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[66]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[67]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[68]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[69]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[70]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[71]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[72]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[73]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[74]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[75]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[76]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[77]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[78]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[79]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[80]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[81]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[82]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[83]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[84]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[85]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[86]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[87]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[88]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[89]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[90]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[91]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[92]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[93]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[94]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[95]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[96]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[97]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[98]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[99]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.9002256687228366, 'colsample_bytree': 0.9748378481482394, 'eta': 0.28679654231918605, 'eval_metric': ('error',), 'extra_dims': 7, 'gamma': 1.1618641680062835e-07, 'lambda': 2.2981627816402113e-07, 'max_depth': 3, 'min_child_weight': 65.05225780797925, 'objective': 'binary:logistic', 'subsample': 0.9093912197034512}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[22:35:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.16680\ttest-error:0.16493                                \n",
      "\n",
      "[1]\ttrain-error:0.31748\ttest-error:0.32230                                \n",
      "\n",
      "[2]\ttrain-error:0.22122\ttest-error:0.21824                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\ttrain-error:0.70350\ttest-error:0.70762                                \n",
      "\n",
      "[4]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[5]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[6]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[7]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[8]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[9]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[10]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[11]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[12]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[13]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[14]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[15]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[16]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[17]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[18]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[19]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[20]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[21]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[22]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[23]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[24]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[25]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[26]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[27]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[28]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[29]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[30]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[31]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[32]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[33]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[34]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[35]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[36]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[37]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[38]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[39]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[40]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[41]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[42]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[43]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[44]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[45]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[46]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[47]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[48]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[49]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[50]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[51]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[52]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[53]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[54]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[55]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[56]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[57]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[58]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[59]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[60]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[61]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[62]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[63]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[64]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[65]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[66]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[67]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[68]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[69]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[70]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[71]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[72]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[73]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[74]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[75]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[76]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[77]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[78]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[79]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[80]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[81]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[82]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[83]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[84]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[85]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[86]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[87]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[88]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[89]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[90]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[91]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[92]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[93]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[94]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[95]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[96]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[97]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[98]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[99]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "{'alpha': 0.0028766226527195482, 'btype': 'In', 'colsample_bylevel': 0.830765446468874, 'colsample_bytree': 0.502079505468098, 'eta': 0.11180234515207509, 'eval_metric': ('error',), 'extra_dims': 1, 'gamma': 6.37880639202471, 'lambda': 0.0015729105666175448, 'max_depth': 7, 'min_child_weight': 0.014564256442890229, 'objective': 'binary:logistic', 'subsample': 0.7407561251178103}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:36:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.16081\ttest-error:0.16106                               \n",
      "\n",
      "[1]\ttrain-error:0.14303\ttest-error:0.14527                               \n",
      "\n",
      "[2]\ttrain-error:0.14030\ttest-error:0.14091                               \n",
      "\n",
      "[3]\ttrain-error:0.13900\ttest-error:0.13980                               \n",
      "\n",
      "[4]\ttrain-error:0.13590\ttest-error:0.13618                               \n",
      "\n",
      "[5]\ttrain-error:0.13480\ttest-error:0.13470                               \n",
      "\n",
      "[6]\ttrain-error:0.13391\ttest-error:0.13403                               \n",
      "\n",
      "[7]\ttrain-error:0.13142\ttest-error:0.13317                               \n",
      "\n",
      "[8]\ttrain-error:0.13167\ttest-error:0.13200                               \n",
      "\n",
      "[9]\ttrain-error:0.13120\ttest-error:0.13200                               \n",
      "\n",
      "[10]\ttrain-error:0.13123\ttest-error:0.13170                              \n",
      "\n",
      "[11]\ttrain-error:0.12988\ttest-error:0.13102                              \n",
      "\n",
      "[12]\ttrain-error:0.12985\ttest-error:0.13108                              \n",
      "\n",
      "[13]\ttrain-error:0.12985\ttest-error:0.13047                              \n",
      "\n",
      "[14]\ttrain-error:0.12942\ttest-error:0.13120                              \n",
      "\n",
      "[15]\ttrain-error:0.12896\ttest-error:0.13034                              \n",
      "\n",
      "[16]\ttrain-error:0.12921\ttest-error:0.13028                              \n",
      "\n",
      "[17]\ttrain-error:0.12859\ttest-error:0.12930                              \n",
      "\n",
      "[18]\ttrain-error:0.12755\ttest-error:0.12819                              \n",
      "\n",
      "[19]\ttrain-error:0.12651\ttest-error:0.12795                              \n",
      "\n",
      "[20]\ttrain-error:0.12604\ttest-error:0.12740                              \n",
      "\n",
      "[21]\ttrain-error:0.12491\ttest-error:0.12715                              \n",
      "\n",
      "[22]\ttrain-error:0.12442\ttest-error:0.12672                              \n",
      "\n",
      "[23]\ttrain-error:0.12442\ttest-error:0.12647                              \n",
      "\n",
      "[24]\ttrain-error:0.12396\ttest-error:0.12580                              \n",
      "\n",
      "[25]\ttrain-error:0.12392\ttest-error:0.12611                              \n",
      "\n",
      "[26]\ttrain-error:0.12371\ttest-error:0.12592                              \n",
      "\n",
      "[27]\ttrain-error:0.12337\ttest-error:0.12598                              \n",
      "\n",
      "[28]\ttrain-error:0.12325\ttest-error:0.12561                              \n",
      "\n",
      "[29]\ttrain-error:0.12303\ttest-error:0.12537                              \n",
      "\n",
      "[30]\ttrain-error:0.12303\ttest-error:0.12574                              \n",
      "\n",
      "[31]\ttrain-error:0.12294\ttest-error:0.12623                              \n",
      "\n",
      "[32]\ttrain-error:0.12294\ttest-error:0.12604                              \n",
      "\n",
      "[33]\ttrain-error:0.12257\ttest-error:0.12580                              \n",
      "\n",
      "[34]\ttrain-error:0.12224\ttest-error:0.12598                              \n",
      "\n",
      "[35]\ttrain-error:0.12196\ttest-error:0.12518                              \n",
      "\n",
      "[36]\ttrain-error:0.12181\ttest-error:0.12512                              \n",
      "\n",
      "[37]\ttrain-error:0.12147\ttest-error:0.12543                              \n",
      "\n",
      "[38]\ttrain-error:0.12131\ttest-error:0.12543                              \n",
      "\n",
      "[39]\ttrain-error:0.12119\ttest-error:0.12537                              \n",
      "\n",
      "[40]\ttrain-error:0.12104\ttest-error:0.12555                              \n",
      "\n",
      "[41]\ttrain-error:0.12073\ttest-error:0.12543                              \n",
      "\n",
      "[42]\ttrain-error:0.12061\ttest-error:0.12537                              \n",
      "\n",
      "[43]\ttrain-error:0.12015\ttest-error:0.12506                              \n",
      "\n",
      "[44]\ttrain-error:0.12003\ttest-error:0.12506                              \n",
      "\n",
      "[45]\ttrain-error:0.11999\ttest-error:0.12574                              \n",
      "\n",
      "[46]\ttrain-error:0.11996\ttest-error:0.12617                              \n",
      "\n",
      "[47]\ttrain-error:0.11996\ttest-error:0.12617                              \n",
      "\n",
      "[48]\ttrain-error:0.12003\ttest-error:0.12629                              \n",
      "\n",
      "[49]\ttrain-error:0.11975\ttest-error:0.12635                              \n",
      "\n",
      "[50]\ttrain-error:0.11972\ttest-error:0.12635                              \n",
      "\n",
      "[51]\ttrain-error:0.11956\ttest-error:0.12647                              \n",
      "\n",
      "[52]\ttrain-error:0.11960\ttest-error:0.12641                              \n",
      "\n",
      "[53]\ttrain-error:0.11953\ttest-error:0.12641                              \n",
      "\n",
      "[54]\ttrain-error:0.11926\ttest-error:0.12604                              \n",
      "\n",
      "[55]\ttrain-error:0.11898\ttest-error:0.12617                              \n",
      "\n",
      "[56]\ttrain-error:0.11876\ttest-error:0.12629                              \n",
      "\n",
      "[57]\ttrain-error:0.11880\ttest-error:0.12611                              \n",
      "\n",
      "[58]\ttrain-error:0.11886\ttest-error:0.12604                              \n",
      "\n",
      "[59]\ttrain-error:0.11858\ttest-error:0.12598                              \n",
      "\n",
      "[60]\ttrain-error:0.11846\ttest-error:0.12580                              \n",
      "\n",
      "[61]\ttrain-error:0.11824\ttest-error:0.12623                              \n",
      "\n",
      "[62]\ttrain-error:0.11843\ttest-error:0.12641                              \n",
      "\n",
      "[63]\ttrain-error:0.11797\ttest-error:0.12654                              \n",
      "\n",
      "[64]\ttrain-error:0.11775\ttest-error:0.12629                              \n",
      "\n",
      "[65]\ttrain-error:0.11778\ttest-error:0.12641                              \n",
      "\n",
      "[66]\ttrain-error:0.11790\ttest-error:0.12672                              \n",
      "\n",
      "[67]\ttrain-error:0.11790\ttest-error:0.12697                              \n",
      "\n",
      "[68]\ttrain-error:0.11772\ttest-error:0.12672                              \n",
      "\n",
      "[69]\ttrain-error:0.11741\ttest-error:0.12647                              \n",
      "\n",
      "[70]\ttrain-error:0.11723\ttest-error:0.12666                              \n",
      "\n",
      "[71]\ttrain-error:0.11698\ttest-error:0.12641                              \n",
      "\n",
      "[72]\ttrain-error:0.11695\ttest-error:0.12654                              \n",
      "\n",
      "[73]\ttrain-error:0.11652\ttest-error:0.12660                              \n",
      "\n",
      "[74]\ttrain-error:0.11671\ttest-error:0.12654                              \n",
      "\n",
      "[75]\ttrain-error:0.11668\ttest-error:0.12654                              \n",
      "\n",
      "[76]\ttrain-error:0.11655\ttest-error:0.12635                              \n",
      "\n",
      "[77]\ttrain-error:0.11668\ttest-error:0.12617                              \n",
      "\n",
      "[78]\ttrain-error:0.11661\ttest-error:0.12623                              \n",
      "\n",
      "[79]\ttrain-error:0.11661\ttest-error:0.12629                              \n",
      "\n",
      "[80]\ttrain-error:0.11665\ttest-error:0.12611                              \n",
      "\n",
      "[81]\ttrain-error:0.11668\ttest-error:0.12604                              \n",
      "\n",
      "[82]\ttrain-error:0.11649\ttest-error:0.12598                              \n",
      "\n",
      "[83]\ttrain-error:0.11658\ttest-error:0.12592                              \n",
      "\n",
      "[84]\ttrain-error:0.11631\ttest-error:0.12635                              \n",
      "\n",
      "[85]\ttrain-error:0.11637\ttest-error:0.12604                              \n",
      "\n",
      "[86]\ttrain-error:0.11637\ttest-error:0.12604                              \n",
      "\n",
      "[87]\ttrain-error:0.11603\ttest-error:0.12617                              \n",
      "\n",
      "[88]\ttrain-error:0.11603\ttest-error:0.12617                              \n",
      "\n",
      "[89]\ttrain-error:0.11572\ttest-error:0.12629                              \n",
      "\n",
      "[90]\ttrain-error:0.11582\ttest-error:0.12635                              \n",
      "\n",
      "[91]\ttrain-error:0.11560\ttest-error:0.12617                              \n",
      "\n",
      "[92]\ttrain-error:0.11554\ttest-error:0.12611                              \n",
      "\n",
      "[93]\ttrain-error:0.11554\ttest-error:0.12604                              \n",
      "\n",
      "[94]\ttrain-error:0.11566\ttest-error:0.12604                              \n",
      "\n",
      "[95]\ttrain-error:0.11560\ttest-error:0.12617                              \n",
      "\n",
      "[96]\ttrain-error:0.11563\ttest-error:0.12635                              \n",
      "\n",
      "[97]\ttrain-error:0.11557\ttest-error:0.12629                              \n",
      "\n",
      "[98]\ttrain-error:0.11539\ttest-error:0.12635                              \n",
      "\n",
      "[99]\ttrain-error:0.11539\ttest-error:0.12635                              \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.5185878718591106, 'colsample_bytree': 0.9326520688776099, 'eta': 0.4412691264255032, 'eval_metric': ('error',), 'extra_dims': 4, 'gamma': 0.003438182625813811, 'lambda': 3.2060321697628674e-05, 'max_depth': 9, 'min_child_weight': 21.664363521872033, 'objective': 'binary:logistic', 'subsample': 0.9467354730225441}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:36:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15089\ttest-error:0.15393                               \n",
      "\n",
      "[1]\ttrain-error:0.19226\ttest-error:0.19730                               \n",
      "\n",
      "[2]\ttrain-error:0.15940\ttest-error:0.16155                               \n",
      "\n",
      "[3]\ttrain-error:0.28569\ttest-error:0.29257                               \n",
      "\n",
      "[4]\ttrain-error:0.22177\ttest-error:0.22027                               \n",
      "\n",
      "[5]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[6]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[7]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[8]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[9]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[10]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[11]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[12]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[13]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[14]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[15]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[16]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[17]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[18]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[19]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[20]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[21]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[22]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[23]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[24]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[25]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[26]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[27]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[28]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[29]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[30]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[31]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[32]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[33]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[34]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[35]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[36]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[37]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[38]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[39]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[40]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[41]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[42]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[43]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[44]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[45]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[46]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[47]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[48]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[49]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[50]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[51]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[52]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[53]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[54]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[55]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[56]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[57]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[58]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[59]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[60]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[61]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[62]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[63]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[64]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[65]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[66]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[67]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[68]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[69]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[70]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[71]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[72]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[73]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[74]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[75]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[76]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[77]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[78]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[79]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[80]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[81]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[82]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[83]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[84]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[85]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[86]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[87]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[88]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[89]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[90]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[91]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[92]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[93]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[94]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[95]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[96]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[97]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[98]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.7290718879213356, 'colsample_bytree': 0.9947057979834075, 'eta': 0.12943843206585504, 'eval_metric': ('error',), 'extra_dims': 5, 'gamma': 0, 'lambda': 0.023985884985501006, 'max_depth': 3, 'min_child_weight': 0.15806426615757324, 'objective': 'binary:logistic', 'subsample': 0.9447169716073774}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[22:37:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15608\ttest-error:0.15528                               \n",
      "\n",
      "[1]\ttrain-error:0.14920\ttest-error:0.14889                               \n",
      "\n",
      "[2]\ttrain-error:0.14656\ttest-error:0.14509                               \n",
      "\n",
      "[3]\ttrain-error:0.14435\ttest-error:0.14300                               \n",
      "\n",
      "[4]\ttrain-error:0.14192\ttest-error:0.14128                               \n",
      "\n",
      "[5]\ttrain-error:0.14149\ttest-error:0.13974                               \n",
      "\n",
      "[6]\ttrain-error:0.14125\ttest-error:0.13993                               \n",
      "\n",
      "[7]\ttrain-error:0.13965\ttest-error:0.13759                               \n",
      "\n",
      "[8]\ttrain-error:0.13811\ttest-error:0.13686                               \n",
      "\n",
      "[9]\ttrain-error:0.13836\ttest-error:0.13624                               \n",
      "\n",
      "[10]\ttrain-error:0.13689\ttest-error:0.13520                              \n",
      "\n",
      "[11]\ttrain-error:0.13547\ttest-error:0.13452                              \n",
      "\n",
      "[12]\ttrain-error:0.13428\ttest-error:0.13342                              \n",
      "\n",
      "[13]\ttrain-error:0.13335\ttest-error:0.13280                              \n",
      "\n",
      "[14]\ttrain-error:0.13286\ttest-error:0.13219                              \n",
      "\n",
      "[15]\ttrain-error:0.13151\ttest-error:0.13084                              \n",
      "\n",
      "[16]\ttrain-error:0.13056\ttest-error:0.12973                              \n",
      "\n",
      "[17]\ttrain-error:0.12973\ttest-error:0.12918                              \n",
      "\n",
      "[18]\ttrain-error:0.12887\ttest-error:0.12850                              \n",
      "\n",
      "[19]\ttrain-error:0.12875\ttest-error:0.12899                              \n",
      "\n",
      "[20]\ttrain-error:0.12862\ttest-error:0.12875                              \n",
      "\n",
      "[21]\ttrain-error:0.12823\ttest-error:0.12856                              \n",
      "\n",
      "[22]\ttrain-error:0.12786\ttest-error:0.12869                              \n",
      "\n",
      "[23]\ttrain-error:0.12706\ttest-error:0.12826                              \n",
      "\n",
      "[24]\ttrain-error:0.12641\ttest-error:0.12838                              \n",
      "\n",
      "[25]\ttrain-error:0.12595\ttest-error:0.12795                              \n",
      "\n",
      "[26]\ttrain-error:0.12577\ttest-error:0.12795                              \n",
      "\n",
      "[27]\ttrain-error:0.12586\ttest-error:0.12770                              \n",
      "\n",
      "[28]\ttrain-error:0.12583\ttest-error:0.12733                              \n",
      "\n",
      "[29]\ttrain-error:0.12457\ttest-error:0.12770                              \n",
      "\n",
      "[30]\ttrain-error:0.12435\ttest-error:0.12715                              \n",
      "\n",
      "[31]\ttrain-error:0.12389\ttest-error:0.12641                              \n",
      "\n",
      "[32]\ttrain-error:0.12377\ttest-error:0.12574                              \n",
      "\n",
      "[33]\ttrain-error:0.12328\ttest-error:0.12531                              \n",
      "\n",
      "[34]\ttrain-error:0.12276\ttest-error:0.12525                              \n",
      "\n",
      "[35]\ttrain-error:0.12276\ttest-error:0.12525                              \n",
      "\n",
      "[36]\ttrain-error:0.12279\ttest-error:0.12494                              \n",
      "\n",
      "[37]\ttrain-error:0.12251\ttest-error:0.12494                              \n",
      "\n",
      "[38]\ttrain-error:0.12248\ttest-error:0.12506                              \n",
      "\n",
      "[39]\ttrain-error:0.12205\ttest-error:0.12463                              \n",
      "\n",
      "[40]\ttrain-error:0.12199\ttest-error:0.12457                              \n",
      "\n",
      "[41]\ttrain-error:0.12181\ttest-error:0.12432                              \n",
      "\n",
      "[42]\ttrain-error:0.12104\ttest-error:0.12469                              \n",
      "\n",
      "[43]\ttrain-error:0.12091\ttest-error:0.12469                              \n",
      "\n",
      "[44]\ttrain-error:0.12058\ttest-error:0.12457                              \n",
      "\n",
      "[45]\ttrain-error:0.12046\ttest-error:0.12475                              \n",
      "\n",
      "[46]\ttrain-error:0.11990\ttest-error:0.12469                              \n",
      "\n",
      "[47]\ttrain-error:0.11969\ttest-error:0.12475                              \n",
      "\n",
      "[48]\ttrain-error:0.11956\ttest-error:0.12451                              \n",
      "\n",
      "[49]\ttrain-error:0.11944\ttest-error:0.12451                              \n",
      "\n",
      "[50]\ttrain-error:0.11950\ttest-error:0.12445                              \n",
      "\n",
      "[51]\ttrain-error:0.11898\ttest-error:0.12451                              \n",
      "\n",
      "[52]\ttrain-error:0.11861\ttest-error:0.12420                              \n",
      "\n",
      "[53]\ttrain-error:0.11840\ttest-error:0.12408                              \n",
      "\n",
      "[54]\ttrain-error:0.11806\ttest-error:0.12432                              \n",
      "\n",
      "[55]\ttrain-error:0.11797\ttest-error:0.12426                              \n",
      "\n",
      "[56]\ttrain-error:0.11806\ttest-error:0.12457                              \n",
      "\n",
      "[57]\ttrain-error:0.11794\ttest-error:0.12451                              \n",
      "\n",
      "[58]\ttrain-error:0.11747\ttest-error:0.12426                              \n",
      "\n",
      "[59]\ttrain-error:0.11704\ttest-error:0.12396                              \n",
      "\n",
      "[60]\ttrain-error:0.11683\ttest-error:0.12426                              \n",
      "\n",
      "[61]\ttrain-error:0.11643\ttest-error:0.12408                              \n",
      "\n",
      "[62]\ttrain-error:0.11634\ttest-error:0.12383                              \n",
      "\n",
      "[63]\ttrain-error:0.11603\ttest-error:0.12426                              \n",
      "\n",
      "[64]\ttrain-error:0.11597\ttest-error:0.12402                              \n",
      "\n",
      "[65]\ttrain-error:0.11582\ttest-error:0.12396                              \n",
      "\n",
      "[66]\ttrain-error:0.11588\ttest-error:0.12408                              \n",
      "\n",
      "[67]\ttrain-error:0.11554\ttest-error:0.12402                              \n",
      "\n",
      "[68]\ttrain-error:0.11566\ttest-error:0.12377                              \n",
      "\n",
      "[69]\ttrain-error:0.11548\ttest-error:0.12383                              \n",
      "\n",
      "[70]\ttrain-error:0.11539\ttest-error:0.12365                              \n",
      "\n",
      "[71]\ttrain-error:0.11480\ttest-error:0.12353                              \n",
      "\n",
      "[72]\ttrain-error:0.11474\ttest-error:0.12359                              \n",
      "\n",
      "[73]\ttrain-error:0.11462\ttest-error:0.12383                              \n",
      "\n",
      "[74]\ttrain-error:0.11486\ttest-error:0.12396                              \n",
      "\n",
      "[75]\ttrain-error:0.11437\ttest-error:0.12365                              \n",
      "\n",
      "[76]\ttrain-error:0.11391\ttest-error:0.12340                              \n",
      "\n",
      "[77]\ttrain-error:0.11379\ttest-error:0.12389                              \n",
      "\n",
      "[78]\ttrain-error:0.11388\ttest-error:0.12426                              \n",
      "\n",
      "[79]\ttrain-error:0.11364\ttest-error:0.12389                              \n",
      "\n",
      "[80]\ttrain-error:0.11348\ttest-error:0.12414                              \n",
      "\n",
      "[81]\ttrain-error:0.11367\ttest-error:0.12432                              \n",
      "\n",
      "[82]\ttrain-error:0.11333\ttest-error:0.12426                              \n",
      "\n",
      "[83]\ttrain-error:0.11348\ttest-error:0.12432                              \n",
      "\n",
      "[84]\ttrain-error:0.11345\ttest-error:0.12396                              \n",
      "\n",
      "[85]\ttrain-error:0.11302\ttest-error:0.12439                              \n",
      "\n",
      "[86]\ttrain-error:0.11247\ttest-error:0.12457                              \n",
      "\n",
      "[87]\ttrain-error:0.11241\ttest-error:0.12457                              \n",
      "\n",
      "[88]\ttrain-error:0.11232\ttest-error:0.12420                              \n",
      "\n",
      "[89]\ttrain-error:0.11228\ttest-error:0.12432                              \n",
      "\n",
      "[90]\ttrain-error:0.11201\ttest-error:0.12402                              \n",
      "\n",
      "[91]\ttrain-error:0.11204\ttest-error:0.12408                              \n",
      "\n",
      "[92]\ttrain-error:0.11204\ttest-error:0.12420                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[93]\ttrain-error:0.11198\ttest-error:0.12414                              \n",
      "\n",
      "[94]\ttrain-error:0.11155\ttest-error:0.12402                              \n",
      "\n",
      "[95]\ttrain-error:0.11170\ttest-error:0.12414                              \n",
      "\n",
      "[96]\ttrain-error:0.11146\ttest-error:0.12432                              \n",
      "\n",
      "[97]\ttrain-error:0.11106\ttest-error:0.12426                              \n",
      "\n",
      "[98]\ttrain-error:0.11078\ttest-error:0.12432                              \n",
      "\n",
      "[99]\ttrain-error:0.11087\ttest-error:0.12445                              \n",
      "\n",
      "NEW BEST VALUE!                                                          \n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.7204203061799728, 'colsample_bytree': 0.6507504321634177, 'eta': 0.03962949435931849, 'eval_metric': ('error',), 'extra_dims': 5, 'gamma': 0, 'lambda': 0.03242064983465272, 'max_depth': 2, 'min_child_weight': 0.11234896882121148, 'objective': 'binary:logistic', 'subsample': 0.9540354909944775}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[22:38:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.19567\ttest-error:0.19318                                \n",
      "\n",
      "[1]\ttrain-error:0.15924\ttest-error:0.15891                                \n",
      "\n",
      "[2]\ttrain-error:0.17478\ttest-error:0.17254                                \n",
      "\n",
      "[3]\ttrain-error:0.15934\ttest-error:0.15940                                \n",
      "\n",
      "[4]\ttrain-error:0.15544\ttest-error:0.15479                                \n",
      "\n",
      "[5]\ttrain-error:0.15494\ttest-error:0.15356                                \n",
      "\n",
      "[6]\ttrain-error:0.15467\ttest-error:0.15356                                \n",
      "\n",
      "[7]\ttrain-error:0.15454\ttest-error:0.15344                                \n",
      "\n",
      "[8]\ttrain-error:0.15341\ttest-error:0.15203                                \n",
      "\n",
      "[9]\ttrain-error:0.15375\ttest-error:0.15203                                \n",
      "\n",
      "[10]\ttrain-error:0.15307\ttest-error:0.15147                               \n",
      "\n",
      "[11]\ttrain-error:0.15095\ttest-error:0.14975                               \n",
      "\n",
      "[12]\ttrain-error:0.15209\ttest-error:0.15061                               \n",
      "\n",
      "[13]\ttrain-error:0.15021\ttest-error:0.14810                               \n",
      "\n",
      "[14]\ttrain-error:0.14923\ttest-error:0.14748                               \n",
      "\n",
      "[15]\ttrain-error:0.14822\ttest-error:0.14607                               \n",
      "\n",
      "[16]\ttrain-error:0.14708\ttest-error:0.14539                               \n",
      "\n",
      "[17]\ttrain-error:0.14696\ttest-error:0.14490                               \n",
      "\n",
      "[18]\ttrain-error:0.14708\ttest-error:0.14509                               \n",
      "\n",
      "[19]\ttrain-error:0.14601\ttest-error:0.14367                               \n",
      "\n",
      "[20]\ttrain-error:0.14588\ttest-error:0.14349                               \n",
      "\n",
      "[21]\ttrain-error:0.14515\ttest-error:0.14294                               \n",
      "\n",
      "[22]\ttrain-error:0.14472\ttest-error:0.14294                               \n",
      "\n",
      "[23]\ttrain-error:0.14478\ttest-error:0.14275                               \n",
      "\n",
      "[24]\ttrain-error:0.14441\ttest-error:0.14288                               \n",
      "\n",
      "[25]\ttrain-error:0.14413\ttest-error:0.14214                               \n",
      "\n",
      "[26]\ttrain-error:0.14383\ttest-error:0.14183                               \n",
      "\n",
      "[27]\ttrain-error:0.14386\ttest-error:0.14208                               \n",
      "\n",
      "[28]\ttrain-error:0.14377\ttest-error:0.14171                               \n",
      "\n",
      "[29]\ttrain-error:0.14349\ttest-error:0.14195                               \n",
      "\n",
      "[30]\ttrain-error:0.14352\ttest-error:0.14202                               \n",
      "\n",
      "[31]\ttrain-error:0.14367\ttest-error:0.14177                               \n",
      "\n",
      "[32]\ttrain-error:0.14294\ttest-error:0.14152                               \n",
      "\n",
      "[33]\ttrain-error:0.14291\ttest-error:0.14066                               \n",
      "\n",
      "[34]\ttrain-error:0.14284\ttest-error:0.14128                               \n",
      "\n",
      "[35]\ttrain-error:0.14251\ttest-error:0.14030                               \n",
      "\n",
      "[36]\ttrain-error:0.14198\ttest-error:0.14030                               \n",
      "\n",
      "[37]\ttrain-error:0.14198\ttest-error:0.13937                               \n",
      "\n",
      "[38]\ttrain-error:0.14149\ttest-error:0.13894                               \n",
      "\n",
      "[39]\ttrain-error:0.14137\ttest-error:0.13907                               \n",
      "\n",
      "[40]\ttrain-error:0.14137\ttest-error:0.13864                               \n",
      "\n",
      "[41]\ttrain-error:0.14109\ttest-error:0.13839                               \n",
      "\n",
      "[42]\ttrain-error:0.14128\ttest-error:0.13808                               \n",
      "\n",
      "[43]\ttrain-error:0.14109\ttest-error:0.13802                               \n",
      "\n",
      "[44]\ttrain-error:0.14094\ttest-error:0.13765                               \n",
      "\n",
      "[45]\ttrain-error:0.14048\ttest-error:0.13716                               \n",
      "\n",
      "[46]\ttrain-error:0.14030\ttest-error:0.13673                               \n",
      "\n",
      "[47]\ttrain-error:0.14017\ttest-error:0.13698                               \n",
      "\n",
      "[48]\ttrain-error:0.14002\ttest-error:0.13661                               \n",
      "\n",
      "[49]\ttrain-error:0.13971\ttest-error:0.13661                               \n",
      "\n",
      "[50]\ttrain-error:0.13956\ttest-error:0.13581                               \n",
      "\n",
      "[51]\ttrain-error:0.13950\ttest-error:0.13581                               \n",
      "\n",
      "[52]\ttrain-error:0.13944\ttest-error:0.13612                               \n",
      "\n",
      "[53]\ttrain-error:0.13913\ttest-error:0.13593                               \n",
      "\n",
      "[54]\ttrain-error:0.13885\ttest-error:0.13514                               \n",
      "\n",
      "[55]\ttrain-error:0.13870\ttest-error:0.13514                               \n",
      "\n",
      "[56]\ttrain-error:0.13848\ttest-error:0.13544                               \n",
      "\n",
      "[57]\ttrain-error:0.13821\ttest-error:0.13532                               \n",
      "\n",
      "[58]\ttrain-error:0.13818\ttest-error:0.13520                               \n",
      "\n",
      "[59]\ttrain-error:0.13796\ttest-error:0.13501                               \n",
      "\n",
      "[60]\ttrain-error:0.13772\ttest-error:0.13520                               \n",
      "\n",
      "[61]\ttrain-error:0.13747\ttest-error:0.13495                               \n",
      "\n",
      "[62]\ttrain-error:0.13725\ttest-error:0.13507                               \n",
      "\n",
      "[63]\ttrain-error:0.13728\ttest-error:0.13470                               \n",
      "\n",
      "[64]\ttrain-error:0.13695\ttest-error:0.13440                               \n",
      "\n",
      "[65]\ttrain-error:0.13682\ttest-error:0.13440                               \n",
      "\n",
      "[66]\ttrain-error:0.13679\ttest-error:0.13397                               \n",
      "\n",
      "[67]\ttrain-error:0.13655\ttest-error:0.13372                               \n",
      "\n",
      "[68]\ttrain-error:0.13624\ttest-error:0.13348                               \n",
      "\n",
      "[69]\ttrain-error:0.13624\ttest-error:0.13342                               \n",
      "\n",
      "[70]\ttrain-error:0.13600\ttest-error:0.13348                               \n",
      "\n",
      "[71]\ttrain-error:0.13590\ttest-error:0.13298                               \n",
      "\n",
      "[72]\ttrain-error:0.13584\ttest-error:0.13262                               \n",
      "\n",
      "[73]\ttrain-error:0.13563\ttest-error:0.13256                               \n",
      "\n",
      "[74]\ttrain-error:0.13563\ttest-error:0.13206                               \n",
      "\n",
      "[75]\ttrain-error:0.13532\ttest-error:0.13212                               \n",
      "\n",
      "[76]\ttrain-error:0.13514\ttest-error:0.13212                               \n",
      "\n",
      "[77]\ttrain-error:0.13486\ttest-error:0.13219                               \n",
      "\n",
      "[78]\ttrain-error:0.13489\ttest-error:0.13219                               \n",
      "\n",
      "[79]\ttrain-error:0.13461\ttest-error:0.13237                               \n",
      "\n",
      "[80]\ttrain-error:0.13474\ttest-error:0.13176                               \n",
      "\n",
      "[81]\ttrain-error:0.13464\ttest-error:0.13200                               \n",
      "\n",
      "[82]\ttrain-error:0.13449\ttest-error:0.13182                               \n",
      "\n",
      "[83]\ttrain-error:0.13424\ttest-error:0.13176                               \n",
      "\n",
      "[84]\ttrain-error:0.13412\ttest-error:0.13170                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85]\ttrain-error:0.13403\ttest-error:0.13151                               \n",
      "\n",
      "[86]\ttrain-error:0.13397\ttest-error:0.13145                               \n",
      "\n",
      "[87]\ttrain-error:0.13403\ttest-error:0.13133                               \n",
      "\n",
      "[88]\ttrain-error:0.13384\ttest-error:0.13145                               \n",
      "\n",
      "[89]\ttrain-error:0.13369\ttest-error:0.13114                               \n",
      "\n",
      "[90]\ttrain-error:0.13372\ttest-error:0.13090                               \n",
      "\n",
      "[91]\ttrain-error:0.13345\ttest-error:0.13090                               \n",
      "\n",
      "[92]\ttrain-error:0.13311\ttest-error:0.13090                               \n",
      "\n",
      "[93]\ttrain-error:0.13295\ttest-error:0.13065                               \n",
      "\n",
      "[94]\ttrain-error:0.13274\ttest-error:0.13114                               \n",
      "\n",
      "[95]\ttrain-error:0.13262\ttest-error:0.13108                               \n",
      "\n",
      "[96]\ttrain-error:0.13256\ttest-error:0.13084                               \n",
      "\n",
      "[97]\ttrain-error:0.13222\ttest-error:0.13028                               \n",
      "\n",
      "[98]\ttrain-error:0.13194\ttest-error:0.13028                               \n",
      "\n",
      "[99]\ttrain-error:0.13170\ttest-error:0.13004                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'In', 'colsample_bylevel': 0.9099711748598821, 'colsample_bytree': 0.709248694046891, 'eta': 0.1305130935134191, 'eval_metric': ('error',), 'extra_dims': 5, 'gamma': 1.2110814127002058e-06, 'lambda': 7.714193390682054e-06, 'max_depth': 10, 'min_child_weight': 6.700333546378421, 'objective': 'binary:logistic', 'subsample': 0.9524383893427251}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[22:38:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.16370\ttest-error:0.16548                                \n",
      "\n",
      "[1]\ttrain-error:0.15270\ttest-error:0.15283                                \n",
      "\n",
      "[2]\ttrain-error:0.14644\ttest-error:0.14306                                \n",
      "\n",
      "[3]\ttrain-error:0.14343\ttest-error:0.13956                                \n",
      "\n",
      "[4]\ttrain-error:0.14094\ttest-error:0.13827                                \n",
      "\n",
      "[5]\ttrain-error:0.14023\ttest-error:0.13728                                \n",
      "\n",
      "[6]\ttrain-error:0.13999\ttest-error:0.13796                                \n",
      "\n",
      "[7]\ttrain-error:0.13947\ttest-error:0.13765                                \n",
      "\n",
      "[8]\ttrain-error:0.13839\ttest-error:0.13802                                \n",
      "\n",
      "[9]\ttrain-error:0.13811\ttest-error:0.13753                                \n",
      "\n",
      "[10]\ttrain-error:0.13790\ttest-error:0.13722                               \n",
      "\n",
      "[11]\ttrain-error:0.13695\ttest-error:0.13796                               \n",
      "\n",
      "[12]\ttrain-error:0.13695\ttest-error:0.13772                               \n",
      "\n",
      "[13]\ttrain-error:0.13600\ttest-error:0.13796                               \n",
      "\n",
      "[14]\ttrain-error:0.13600\ttest-error:0.13814                               \n",
      "\n",
      "[15]\ttrain-error:0.13556\ttest-error:0.13876                               \n",
      "\n",
      "[16]\ttrain-error:0.13563\ttest-error:0.13821                               \n",
      "\n",
      "[17]\ttrain-error:0.13572\ttest-error:0.13839                               \n",
      "\n",
      "[18]\ttrain-error:0.13520\ttest-error:0.13784                               \n",
      "\n",
      "[19]\ttrain-error:0.13467\ttest-error:0.13839                               \n",
      "\n",
      "[20]\ttrain-error:0.13480\ttest-error:0.13833                               \n",
      "\n",
      "[21]\ttrain-error:0.13452\ttest-error:0.13913                               \n",
      "\n",
      "[22]\ttrain-error:0.13455\ttest-error:0.13845                               \n",
      "\n",
      "[23]\ttrain-error:0.13434\ttest-error:0.13833                               \n",
      "\n",
      "[24]\ttrain-error:0.13369\ttest-error:0.13814                               \n",
      "\n",
      "[25]\ttrain-error:0.13351\ttest-error:0.13802                               \n",
      "\n",
      "[26]\ttrain-error:0.13335\ttest-error:0.13765                               \n",
      "\n",
      "[27]\ttrain-error:0.13308\ttest-error:0.13827                               \n",
      "\n",
      "[28]\ttrain-error:0.13302\ttest-error:0.13845                               \n",
      "\n",
      "[29]\ttrain-error:0.13256\ttest-error:0.13851                               \n",
      "\n",
      "[30]\ttrain-error:0.13253\ttest-error:0.13772                               \n",
      "\n",
      "[31]\ttrain-error:0.13265\ttest-error:0.13821                               \n",
      "\n",
      "[32]\ttrain-error:0.13259\ttest-error:0.13814                               \n",
      "\n",
      "[33]\ttrain-error:0.13188\ttest-error:0.13772                               \n",
      "\n",
      "[34]\ttrain-error:0.13182\ttest-error:0.13698                               \n",
      "\n",
      "[35]\ttrain-error:0.13182\ttest-error:0.13778                               \n",
      "\n",
      "[36]\ttrain-error:0.13191\ttest-error:0.13759                               \n",
      "\n",
      "[37]\ttrain-error:0.13170\ttest-error:0.13796                               \n",
      "\n",
      "[38]\ttrain-error:0.13130\ttest-error:0.13814                               \n",
      "\n",
      "[39]\ttrain-error:0.13151\ttest-error:0.13814                               \n",
      "\n",
      "[40]\ttrain-error:0.13157\ttest-error:0.13753                               \n",
      "\n",
      "[41]\ttrain-error:0.13130\ttest-error:0.13784                               \n",
      "\n",
      "[42]\ttrain-error:0.13114\ttest-error:0.13772                               \n",
      "\n",
      "[43]\ttrain-error:0.13108\ttest-error:0.13778                               \n",
      "\n",
      "[44]\ttrain-error:0.13102\ttest-error:0.13753                               \n",
      "\n",
      "[45]\ttrain-error:0.13090\ttest-error:0.13784                               \n",
      "\n",
      "[46]\ttrain-error:0.13034\ttest-error:0.13778                               \n",
      "\n",
      "[47]\ttrain-error:0.13050\ttest-error:0.13784                               \n",
      "\n",
      "[48]\ttrain-error:0.13019\ttest-error:0.13796                               \n",
      "\n",
      "[49]\ttrain-error:0.13016\ttest-error:0.13778                               \n",
      "\n",
      "[50]\ttrain-error:0.13007\ttest-error:0.13808                               \n",
      "\n",
      "[51]\ttrain-error:0.13022\ttest-error:0.13784                               \n",
      "\n",
      "[52]\ttrain-error:0.13022\ttest-error:0.13833                               \n",
      "\n",
      "[53]\ttrain-error:0.12967\ttest-error:0.13784                               \n",
      "\n",
      "[54]\ttrain-error:0.12967\ttest-error:0.13772                               \n",
      "\n",
      "[55]\ttrain-error:0.12915\ttest-error:0.13784                               \n",
      "\n",
      "[56]\ttrain-error:0.12909\ttest-error:0.13704                               \n",
      "\n",
      "[57]\ttrain-error:0.12887\ttest-error:0.13790                               \n",
      "\n",
      "[58]\ttrain-error:0.12899\ttest-error:0.13778                               \n",
      "\n",
      "[59]\ttrain-error:0.12881\ttest-error:0.13814                               \n",
      "\n",
      "[60]\ttrain-error:0.12862\ttest-error:0.13784                               \n",
      "\n",
      "[61]\ttrain-error:0.12862\ttest-error:0.13814                               \n",
      "\n",
      "[62]\ttrain-error:0.12850\ttest-error:0.13845                               \n",
      "\n",
      "[63]\ttrain-error:0.12847\ttest-error:0.13802                               \n",
      "\n",
      "[64]\ttrain-error:0.12819\ttest-error:0.13784                               \n",
      "\n",
      "[65]\ttrain-error:0.12841\ttest-error:0.13790                               \n",
      "\n",
      "[66]\ttrain-error:0.12801\ttest-error:0.13784                               \n",
      "\n",
      "[67]\ttrain-error:0.12810\ttest-error:0.13753                               \n",
      "\n",
      "[68]\ttrain-error:0.12801\ttest-error:0.13796                               \n",
      "\n",
      "[69]\ttrain-error:0.12792\ttest-error:0.13753                               \n",
      "\n",
      "[70]\ttrain-error:0.12792\ttest-error:0.13790                               \n",
      "\n",
      "[71]\ttrain-error:0.12764\ttest-error:0.13772                               \n",
      "\n",
      "[72]\ttrain-error:0.12779\ttest-error:0.13735                               \n",
      "\n",
      "[73]\ttrain-error:0.12783\ttest-error:0.13704                               \n",
      "\n",
      "[74]\ttrain-error:0.12783\ttest-error:0.13784                               \n",
      "\n",
      "[75]\ttrain-error:0.12767\ttest-error:0.13753                               \n",
      "\n",
      "[76]\ttrain-error:0.12783\ttest-error:0.13741                               \n",
      "\n",
      "[77]\ttrain-error:0.12789\ttest-error:0.13747                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78]\ttrain-error:0.12721\ttest-error:0.13796                               \n",
      "\n",
      "[79]\ttrain-error:0.12709\ttest-error:0.13784                               \n",
      "\n",
      "[80]\ttrain-error:0.12712\ttest-error:0.13753                               \n",
      "\n",
      "[81]\ttrain-error:0.12684\ttest-error:0.13741                               \n",
      "\n",
      "[82]\ttrain-error:0.12715\ttest-error:0.13741                               \n",
      "\n",
      "[83]\ttrain-error:0.12660\ttest-error:0.13747                               \n",
      "\n",
      "[84]\ttrain-error:0.12614\ttest-error:0.13759                               \n",
      "\n",
      "[85]\ttrain-error:0.12632\ttest-error:0.13735                               \n",
      "\n",
      "[86]\ttrain-error:0.12607\ttest-error:0.13759                               \n",
      "\n",
      "[87]\ttrain-error:0.12574\ttest-error:0.13735                               \n",
      "\n",
      "[88]\ttrain-error:0.12558\ttest-error:0.13728                               \n",
      "\n",
      "[89]\ttrain-error:0.12525\ttest-error:0.13790                               \n",
      "\n",
      "[90]\ttrain-error:0.12546\ttest-error:0.13759                               \n",
      "\n",
      "[91]\ttrain-error:0.12534\ttest-error:0.13765                               \n",
      "\n",
      "[92]\ttrain-error:0.12512\ttest-error:0.13784                               \n",
      "\n",
      "[93]\ttrain-error:0.12540\ttest-error:0.13790                               \n",
      "\n",
      "[94]\ttrain-error:0.12528\ttest-error:0.13765                               \n",
      "\n",
      "[95]\ttrain-error:0.12503\ttest-error:0.13759                               \n",
      "\n",
      "[96]\ttrain-error:0.12512\ttest-error:0.13796                               \n",
      "\n",
      "[97]\ttrain-error:0.12512\ttest-error:0.13753                               \n",
      "\n",
      "[98]\ttrain-error:0.12482\ttest-error:0.13759                               \n",
      "\n",
      "[99]\ttrain-error:0.12454\ttest-error:0.13692                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.8043575385197138, 'colsample_bytree': 0.9884855544173237, 'eta': 0.40002670773727966, 'eval_metric': ('error',), 'extra_dims': 0, 'gamma': 0.0004326676661218565, 'lambda': 0.014156422742361308, 'max_depth': 6, 'min_child_weight': 0.13849055344302025, 'objective': 'binary:logistic', 'subsample': 0.9955053721442284}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[22:40:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14604\ttest-error:0.14908                                \n",
      "\n",
      "[1]\ttrain-error:0.14214\ttest-error:0.14189                                \n",
      "\n",
      "[2]\ttrain-error:0.14002\ttest-error:0.13993                                \n",
      "\n",
      "[3]\ttrain-error:0.13842\ttest-error:0.13845                                \n",
      "\n",
      "[4]\ttrain-error:0.13609\ttest-error:0.13735                                \n",
      "\n",
      "[5]\ttrain-error:0.13305\ttest-error:0.13477                                \n",
      "\n",
      "[6]\ttrain-error:0.13292\ttest-error:0.13403                                \n",
      "\n",
      "[7]\ttrain-error:0.12976\ttest-error:0.13170                                \n",
      "\n",
      "[8]\ttrain-error:0.12737\ttest-error:0.13102                                \n",
      "\n",
      "[9]\ttrain-error:0.12687\ttest-error:0.13126                                \n",
      "\n",
      "[10]\ttrain-error:0.12469\ttest-error:0.13090                               \n",
      "\n",
      "[11]\ttrain-error:0.12371\ttest-error:0.12930                               \n",
      "\n",
      "[12]\ttrain-error:0.12322\ttest-error:0.12905                               \n",
      "\n",
      "[13]\ttrain-error:0.12257\ttest-error:0.12893                               \n",
      "\n",
      "[14]\ttrain-error:0.12134\ttest-error:0.12899                               \n",
      "\n",
      "[15]\ttrain-error:0.12024\ttest-error:0.12770                               \n",
      "\n",
      "[16]\ttrain-error:0.11864\ttest-error:0.12733                               \n",
      "\n",
      "[17]\ttrain-error:0.11754\ttest-error:0.12709                               \n",
      "\n",
      "[18]\ttrain-error:0.11643\ttest-error:0.12709                               \n",
      "\n",
      "[19]\ttrain-error:0.11548\ttest-error:0.12697                               \n",
      "\n",
      "[20]\ttrain-error:0.11514\ttest-error:0.12770                               \n",
      "\n",
      "[21]\ttrain-error:0.11456\ttest-error:0.12813                               \n",
      "\n",
      "[22]\ttrain-error:0.11397\ttest-error:0.12807                               \n",
      "\n",
      "[23]\ttrain-error:0.11250\ttest-error:0.12832                               \n",
      "\n",
      "[24]\ttrain-error:0.11219\ttest-error:0.12899                               \n",
      "\n",
      "[25]\ttrain-error:0.11182\ttest-error:0.12881                               \n",
      "\n",
      "[26]\ttrain-error:0.11146\ttest-error:0.12887                               \n",
      "\n",
      "[27]\ttrain-error:0.11106\ttest-error:0.12899                               \n",
      "\n",
      "[28]\ttrain-error:0.11090\ttest-error:0.12893                               \n",
      "\n",
      "[29]\ttrain-error:0.11066\ttest-error:0.12893                               \n",
      "\n",
      "[30]\ttrain-error:0.11078\ttest-error:0.12844                               \n",
      "\n",
      "[31]\ttrain-error:0.11026\ttest-error:0.12801                               \n",
      "\n",
      "[32]\ttrain-error:0.11038\ttest-error:0.12776                               \n",
      "\n",
      "[33]\ttrain-error:0.10931\ttest-error:0.12783                               \n",
      "\n",
      "[34]\ttrain-error:0.10924\ttest-error:0.12709                               \n",
      "\n",
      "[35]\ttrain-error:0.10857\ttest-error:0.12844                               \n",
      "\n",
      "[36]\ttrain-error:0.10814\ttest-error:0.12899                               \n",
      "\n",
      "[37]\ttrain-error:0.10746\ttest-error:0.12881                               \n",
      "\n",
      "[38]\ttrain-error:0.10611\ttest-error:0.12881                               \n",
      "\n",
      "[39]\ttrain-error:0.10577\ttest-error:0.12899                               \n",
      "\n",
      "[40]\ttrain-error:0.10522\ttest-error:0.12881                               \n",
      "\n",
      "[41]\ttrain-error:0.10497\ttest-error:0.12899                               \n",
      "\n",
      "[42]\ttrain-error:0.10491\ttest-error:0.12930                               \n",
      "\n",
      "[43]\ttrain-error:0.10402\ttest-error:0.12924                               \n",
      "\n",
      "[44]\ttrain-error:0.10418\ttest-error:0.12899                               \n",
      "\n",
      "[45]\ttrain-error:0.10344\ttest-error:0.12918                               \n",
      "\n",
      "[46]\ttrain-error:0.10273\ttest-error:0.12924                               \n",
      "\n",
      "[47]\ttrain-error:0.10249\ttest-error:0.12905                               \n",
      "\n",
      "[48]\ttrain-error:0.10178\ttest-error:0.12918                               \n",
      "\n",
      "[49]\ttrain-error:0.10157\ttest-error:0.12918                               \n",
      "\n",
      "[50]\ttrain-error:0.10129\ttest-error:0.12918                               \n",
      "\n",
      "[51]\ttrain-error:0.10083\ttest-error:0.12912                               \n",
      "\n",
      "[52]\ttrain-error:0.10080\ttest-error:0.12918                               \n",
      "\n",
      "[53]\ttrain-error:0.10021\ttest-error:0.12905                               \n",
      "\n",
      "[54]\ttrain-error:0.09954\ttest-error:0.12899                               \n",
      "\n",
      "[55]\ttrain-error:0.09929\ttest-error:0.12973                               \n",
      "\n",
      "[56]\ttrain-error:0.09883\ttest-error:0.12954                               \n",
      "\n",
      "[57]\ttrain-error:0.09868\ttest-error:0.12991                               \n",
      "\n",
      "[58]\ttrain-error:0.09862\ttest-error:0.12961                               \n",
      "\n",
      "[59]\ttrain-error:0.09816\ttest-error:0.13102                               \n",
      "\n",
      "[60]\ttrain-error:0.09745\ttest-error:0.13114                               \n",
      "\n",
      "[61]\ttrain-error:0.09696\ttest-error:0.13151                               \n",
      "\n",
      "[62]\ttrain-error:0.09665\ttest-error:0.13151                               \n",
      "\n",
      "[63]\ttrain-error:0.09674\ttest-error:0.13163                               \n",
      "\n",
      "[64]\ttrain-error:0.09693\ttest-error:0.13151                               \n",
      "\n",
      "[65]\ttrain-error:0.09684\ttest-error:0.13120                               \n",
      "\n",
      "[66]\ttrain-error:0.09638\ttest-error:0.13096                               \n",
      "\n",
      "[67]\ttrain-error:0.09628\ttest-error:0.13151                               \n",
      "\n",
      "[68]\ttrain-error:0.09588\ttest-error:0.13145                               \n",
      "\n",
      "[69]\ttrain-error:0.09521\ttest-error:0.13133                               \n",
      "\n",
      "[70]\ttrain-error:0.09506\ttest-error:0.13151                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71]\ttrain-error:0.09496\ttest-error:0.13170                               \n",
      "\n",
      "[72]\ttrain-error:0.09496\ttest-error:0.13170                               \n",
      "\n",
      "[73]\ttrain-error:0.09490\ttest-error:0.13182                               \n",
      "\n",
      "[74]\ttrain-error:0.09481\ttest-error:0.13206                               \n",
      "\n",
      "[75]\ttrain-error:0.09423\ttest-error:0.13206                               \n",
      "\n",
      "[76]\ttrain-error:0.09358\ttest-error:0.13305                               \n",
      "\n",
      "[77]\ttrain-error:0.09300\ttest-error:0.13305                               \n",
      "\n",
      "[78]\ttrain-error:0.09272\ttest-error:0.13243                               \n",
      "\n",
      "[79]\ttrain-error:0.09238\ttest-error:0.13200                               \n",
      "\n",
      "[80]\ttrain-error:0.09183\ttest-error:0.13280                               \n",
      "\n",
      "[81]\ttrain-error:0.09171\ttest-error:0.13317                               \n",
      "\n",
      "[82]\ttrain-error:0.09140\ttest-error:0.13298                               \n",
      "\n",
      "[83]\ttrain-error:0.09115\ttest-error:0.13286                               \n",
      "\n",
      "[84]\ttrain-error:0.09082\ttest-error:0.13311                               \n",
      "\n",
      "[85]\ttrain-error:0.08980\ttest-error:0.13298                               \n",
      "\n",
      "[86]\ttrain-error:0.08956\ttest-error:0.13298                               \n",
      "\n",
      "[87]\ttrain-error:0.08873\ttest-error:0.13292                               \n",
      "\n",
      "[88]\ttrain-error:0.08873\ttest-error:0.13311                               \n",
      "\n",
      "[89]\ttrain-error:0.08879\ttest-error:0.13311                               \n",
      "\n",
      "[90]\ttrain-error:0.08864\ttest-error:0.13311                               \n",
      "\n",
      "[91]\ttrain-error:0.08793\ttest-error:0.13354                               \n",
      "\n",
      "[92]\ttrain-error:0.08738\ttest-error:0.13384                               \n",
      "\n",
      "[93]\ttrain-error:0.08698\ttest-error:0.13452                               \n",
      "\n",
      "[94]\ttrain-error:0.08636\ttest-error:0.13428                               \n",
      "\n",
      "[95]\ttrain-error:0.08517\ttest-error:0.13366                               \n",
      "\n",
      "[96]\ttrain-error:0.08461\ttest-error:0.13311                               \n",
      "\n",
      "[97]\ttrain-error:0.08409\ttest-error:0.13298                               \n",
      "\n",
      "[98]\ttrain-error:0.08391\ttest-error:0.13298                               \n",
      "\n",
      "[99]\ttrain-error:0.08339\ttest-error:0.13305                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'In', 'colsample_bylevel': 0.7211147770010453, 'colsample_bytree': 0.7778965682322676, 'eta': 0.13661496448902408, 'eval_metric': ('error',), 'extra_dims': 5, 'gamma': 0, 'lambda': 0.00012845179129524642, 'max_depth': 3, 'min_child_weight': 0.0002520273170115792, 'objective': 'binary:logistic', 'subsample': 0.7395814833262049}\n",
      "Overwriting param `num_class`                                           \n",
      "Overwriting param `objective` while setting `obj` in train.             \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                 \n",
      "Setting param `disable_default_eval_metric` to 1.                       \n",
      "[22:40:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15611\ttest-error:0.15670                              \n",
      "\n",
      "[1]\ttrain-error:0.14724\ttest-error:0.14797                              \n",
      "\n",
      "[2]\ttrain-error:0.14671\ttest-error:0.14644                              \n",
      "\n",
      "[3]\ttrain-error:0.14330\ttest-error:0.14330                              \n",
      "\n",
      "[4]\ttrain-error:0.14174\ttest-error:0.14128                              \n",
      "\n",
      "[5]\ttrain-error:0.14048\ttest-error:0.13950                              \n",
      "\n",
      "[6]\ttrain-error:0.13910\ttest-error:0.13839                              \n",
      "\n",
      "[7]\ttrain-error:0.13845\ttest-error:0.13587                              \n",
      "\n",
      "[8]\ttrain-error:0.13719\ttest-error:0.13575                              \n",
      "\n",
      "[9]\ttrain-error:0.13578\ttest-error:0.13348                              \n",
      "\n",
      "[10]\ttrain-error:0.13504\ttest-error:0.13372                             \n",
      "\n",
      "[11]\ttrain-error:0.13335\ttest-error:0.13323                             \n",
      "\n",
      "[12]\ttrain-error:0.13179\ttest-error:0.13182                             \n",
      "\n",
      "[13]\ttrain-error:0.13151\ttest-error:0.13212                             \n",
      "\n",
      "[14]\ttrain-error:0.13068\ttest-error:0.13047                             \n",
      "\n",
      "[15]\ttrain-error:0.12979\ttest-error:0.13071                             \n",
      "\n",
      "[16]\ttrain-error:0.12890\ttest-error:0.13047                             \n",
      "\n",
      "[17]\ttrain-error:0.12829\ttest-error:0.12948                             \n",
      "\n",
      "[18]\ttrain-error:0.12746\ttest-error:0.12832                             \n",
      "\n",
      "[19]\ttrain-error:0.12715\ttest-error:0.12862                             \n",
      "\n",
      "[20]\ttrain-error:0.12623\ttest-error:0.12832                             \n",
      "\n",
      "[21]\ttrain-error:0.12534\ttest-error:0.12789                             \n",
      "\n",
      "[22]\ttrain-error:0.12454\ttest-error:0.12721                             \n",
      "\n",
      "[23]\ttrain-error:0.12405\ttest-error:0.12764                             \n",
      "\n",
      "[24]\ttrain-error:0.12349\ttest-error:0.12752                             \n",
      "\n",
      "[25]\ttrain-error:0.12322\ttest-error:0.12727                             \n",
      "\n",
      "[26]\ttrain-error:0.12273\ttest-error:0.12709                             \n",
      "\n",
      "[27]\ttrain-error:0.12303\ttest-error:0.12684                             \n",
      "\n",
      "[28]\ttrain-error:0.12248\ttest-error:0.12666                             \n",
      "\n",
      "[29]\ttrain-error:0.12220\ttest-error:0.12697                             \n",
      "\n",
      "[30]\ttrain-error:0.12162\ttest-error:0.12690                             \n",
      "\n",
      "[31]\ttrain-error:0.12079\ttest-error:0.12617                             \n",
      "\n",
      "[32]\ttrain-error:0.12052\ttest-error:0.12580                             \n",
      "\n",
      "[33]\ttrain-error:0.11999\ttest-error:0.12604                             \n",
      "\n",
      "[34]\ttrain-error:0.12033\ttest-error:0.12568                             \n",
      "\n",
      "[35]\ttrain-error:0.11962\ttest-error:0.12555                             \n",
      "\n",
      "[36]\ttrain-error:0.11916\ttest-error:0.12549                             \n",
      "\n",
      "[37]\ttrain-error:0.11861\ttest-error:0.12525                             \n",
      "\n",
      "[38]\ttrain-error:0.11864\ttest-error:0.12531                             \n",
      "\n",
      "[39]\ttrain-error:0.11797\ttest-error:0.12580                             \n",
      "\n",
      "[40]\ttrain-error:0.11741\ttest-error:0.12549                             \n",
      "\n",
      "[41]\ttrain-error:0.11738\ttest-error:0.12531                             \n",
      "\n",
      "[42]\ttrain-error:0.11661\ttest-error:0.12494                             \n",
      "\n",
      "[43]\ttrain-error:0.11649\ttest-error:0.12475                             \n",
      "\n",
      "[44]\ttrain-error:0.11668\ttest-error:0.12463                             \n",
      "\n",
      "[45]\ttrain-error:0.11655\ttest-error:0.12445                             \n",
      "\n",
      "[46]\ttrain-error:0.11631\ttest-error:0.12475                             \n",
      "\n",
      "[47]\ttrain-error:0.11609\ttest-error:0.12475                             \n",
      "\n",
      "[48]\ttrain-error:0.11612\ttest-error:0.12463                             \n",
      "\n",
      "[49]\ttrain-error:0.11597\ttest-error:0.12451                             \n",
      "\n",
      "[50]\ttrain-error:0.11551\ttest-error:0.12561                             \n",
      "\n",
      "[51]\ttrain-error:0.11526\ttest-error:0.12543                             \n",
      "\n",
      "[52]\ttrain-error:0.11493\ttest-error:0.12561                             \n",
      "\n",
      "[53]\ttrain-error:0.11496\ttest-error:0.12537                             \n",
      "\n",
      "[54]\ttrain-error:0.11480\ttest-error:0.12555                             \n",
      "\n",
      "[55]\ttrain-error:0.11462\ttest-error:0.12561                             \n",
      "\n",
      "[56]\ttrain-error:0.11419\ttest-error:0.12506                             \n",
      "\n",
      "[57]\ttrain-error:0.11413\ttest-error:0.12506                             \n",
      "\n",
      "[58]\ttrain-error:0.11394\ttest-error:0.12543                             \n",
      "\n",
      "[59]\ttrain-error:0.11364\ttest-error:0.12555                             \n",
      "\n",
      "[60]\ttrain-error:0.11345\ttest-error:0.12525                             \n",
      "\n",
      "[61]\ttrain-error:0.11290\ttest-error:0.12537                             \n",
      "\n",
      "[62]\ttrain-error:0.11262\ttest-error:0.12555                             \n",
      "\n",
      "[63]\ttrain-error:0.11278\ttest-error:0.12561                             \n",
      "\n",
      "[64]\ttrain-error:0.11308\ttest-error:0.12598                             \n",
      "\n",
      "[65]\ttrain-error:0.11253\ttest-error:0.12623                             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66]\ttrain-error:0.11228\ttest-error:0.12598                             \n",
      "\n",
      "[67]\ttrain-error:0.11235\ttest-error:0.12586                             \n",
      "\n",
      "[68]\ttrain-error:0.11210\ttest-error:0.12555                             \n",
      "\n",
      "[69]\ttrain-error:0.11238\ttest-error:0.12525                             \n",
      "\n",
      "[70]\ttrain-error:0.11173\ttest-error:0.12574                             \n",
      "\n",
      "[71]\ttrain-error:0.11146\ttest-error:0.12537                             \n",
      "\n",
      "[72]\ttrain-error:0.11142\ttest-error:0.12568                             \n",
      "\n",
      "[73]\ttrain-error:0.11121\ttest-error:0.12574                             \n",
      "\n",
      "[74]\ttrain-error:0.11124\ttest-error:0.12592                             \n",
      "\n",
      "[75]\ttrain-error:0.11112\ttest-error:0.12598                             \n",
      "\n",
      "[76]\ttrain-error:0.11087\ttest-error:0.12617                             \n",
      "\n",
      "[77]\ttrain-error:0.11063\ttest-error:0.12611                             \n",
      "\n",
      "[78]\ttrain-error:0.11056\ttest-error:0.12647                             \n",
      "\n",
      "[79]\ttrain-error:0.11056\ttest-error:0.12629                             \n",
      "\n",
      "[80]\ttrain-error:0.10998\ttest-error:0.12647                             \n",
      "\n",
      "[81]\ttrain-error:0.11013\ttest-error:0.12604                             \n",
      "\n",
      "[82]\ttrain-error:0.10995\ttest-error:0.12611                             \n",
      "\n",
      "[83]\ttrain-error:0.10998\ttest-error:0.12580                             \n",
      "\n",
      "[84]\ttrain-error:0.10955\ttest-error:0.12611                             \n",
      "\n",
      "[85]\ttrain-error:0.10958\ttest-error:0.12580                             \n",
      "\n",
      "[86]\ttrain-error:0.10992\ttest-error:0.12629                             \n",
      "\n",
      "[87]\ttrain-error:0.10995\ttest-error:0.12617                             \n",
      "\n",
      "[88]\ttrain-error:0.10955\ttest-error:0.12611                             \n",
      "\n",
      "[89]\ttrain-error:0.10897\ttest-error:0.12709                             \n",
      "\n",
      "[90]\ttrain-error:0.10903\ttest-error:0.12684                             \n",
      "\n",
      "[91]\ttrain-error:0.10924\ttest-error:0.12690                             \n",
      "\n",
      "[92]\ttrain-error:0.10866\ttest-error:0.12672                             \n",
      "\n",
      "[93]\ttrain-error:0.10878\ttest-error:0.12727                             \n",
      "\n",
      "[94]\ttrain-error:0.10878\ttest-error:0.12684                             \n",
      "\n",
      "[95]\ttrain-error:0.10832\ttest-error:0.12715                             \n",
      "\n",
      "[96]\ttrain-error:0.10820\ttest-error:0.12660                             \n",
      "\n",
      "[97]\ttrain-error:0.10808\ttest-error:0.12684                             \n",
      "\n",
      "[98]\ttrain-error:0.10780\ttest-error:0.12654                             \n",
      "\n",
      "[99]\ttrain-error:0.10771\ttest-error:0.12660                             \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.8699156782132219, 'colsample_bytree': 0.6805580863279227, 'eta': 0.9249694869281545, 'eval_metric': ('error',), 'extra_dims': 11, 'gamma': 0.3030829194917927, 'lambda': 0.016641409570238488, 'max_depth': 8, 'min_child_weight': 0.006673493984277853, 'objective': 'binary:logistic', 'subsample': 0.8903866864367262}\n",
      "Overwriting param `num_class`                                           \n",
      "Overwriting param `objective` while setting `obj` in train.             \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                 \n",
      "Setting param `disable_default_eval_metric` to 1.                       \n",
      "[22:40:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13148\ttest-error:0.13458                              \n",
      "\n",
      "[1]\ttrain-error:0.81634\ttest-error:0.81830                              \n",
      "\n",
      "[2]\ttrain-error:0.18480\ttest-error:0.18274                              \n",
      "\n",
      "[3]\ttrain-error:0.27795\ttest-error:0.27721                              \n",
      "\n",
      "[4]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[5]\ttrain-error:0.27684\ttest-error:0.28133                              \n",
      "\n",
      "[6]\ttrain-error:0.28385\ttest-error:0.28581                              \n",
      "\n",
      "[7]\ttrain-error:0.24487\ttest-error:0.24460                              \n",
      "\n",
      "[8]\ttrain-error:0.20620\ttest-error:0.20620                              \n",
      "\n",
      "[9]\ttrain-error:0.28452\ttest-error:0.28612                              \n",
      "\n",
      "[10]\ttrain-error:0.19245\ttest-error:0.19331                             \n",
      "\n",
      "[11]\ttrain-error:0.28065\ttest-error:0.28256                             \n",
      "\n",
      "[12]\ttrain-error:0.27015\ttest-error:0.26929                             \n",
      "\n",
      "[13]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[14]\ttrain-error:0.28262\ttest-error:0.28753                             \n",
      "\n",
      "[15]\ttrain-error:0.28440\ttest-error:0.28587                             \n",
      "\n",
      "[16]\ttrain-error:0.23618\ttest-error:0.23679                             \n",
      "\n",
      "[17]\ttrain-error:0.25289\ttest-error:0.25252                             \n",
      "\n",
      "[18]\ttrain-error:0.19119\ttest-error:0.18931                             \n",
      "\n",
      "[19]\ttrain-error:0.28065\ttest-error:0.28274                             \n",
      "\n",
      "[20]\ttrain-error:0.25559\ttest-error:0.25547                             \n",
      "\n",
      "[21]\ttrain-error:0.19929\ttest-error:0.19865                             \n",
      "\n",
      "[22]\ttrain-error:0.28065\ttest-error:0.28280                             \n",
      "\n",
      "[23]\ttrain-error:0.25295\ttest-error:0.25252                             \n",
      "\n",
      "[24]\ttrain-error:0.19125\ttest-error:0.18931                             \n",
      "\n",
      "[25]\ttrain-error:0.28065\ttest-error:0.28274                             \n",
      "\n",
      "[26]\ttrain-error:0.25863\ttest-error:0.25774                             \n",
      "\n",
      "[27]\ttrain-error:0.21302\ttest-error:0.21179                             \n",
      "\n",
      "[28]\ttrain-error:0.27257\ttest-error:0.27580                             \n",
      "\n",
      "[29]\ttrain-error:0.28452\ttest-error:0.28618                             \n",
      "\n",
      "[30]\ttrain-error:0.19057\ttest-error:0.18913                             \n",
      "\n",
      "[31]\ttrain-error:0.28065\ttest-error:0.28274                             \n",
      "\n",
      "[32]\ttrain-error:0.25900\ttest-error:0.25829                             \n",
      "\n",
      "[33]\ttrain-error:0.21410\ttest-error:0.21296                             \n",
      "\n",
      "[34]\ttrain-error:0.28228\ttest-error:0.28274                             \n",
      "\n",
      "[35]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[36]\ttrain-error:0.28338\ttest-error:0.28814                             \n",
      "\n",
      "[37]\ttrain-error:0.28437\ttest-error:0.28587                             \n",
      "\n",
      "[38]\ttrain-error:0.23925\ttest-error:0.23980                             \n",
      "\n",
      "[39]\ttrain-error:0.24917\ttest-error:0.24963                             \n",
      "\n",
      "[40]\ttrain-error:0.20144\ttest-error:0.19957                             \n",
      "\n",
      "[41]\ttrain-error:0.28256\ttest-error:0.28470                             \n",
      "\n",
      "[42]\ttrain-error:0.24914\ttest-error:0.24969                             \n",
      "\n",
      "[43]\ttrain-error:0.20126\ttest-error:0.19932                             \n",
      "\n",
      "[44]\ttrain-error:0.28163\ttest-error:0.28403                             \n",
      "\n",
      "[45]\ttrain-error:0.24920\ttest-error:0.24975                             \n",
      "\n",
      "[46]\ttrain-error:0.20141\ttest-error:0.19969                             \n",
      "\n",
      "[47]\ttrain-error:0.28338\ttest-error:0.28550                             \n",
      "\n",
      "[48]\ttrain-error:0.24975\ttest-error:0.25055                             \n",
      "\n",
      "[49]\ttrain-error:0.20144\ttest-error:0.19957                             \n",
      "\n",
      "[50]\ttrain-error:0.28253\ttest-error:0.28470                             \n",
      "\n",
      "[51]\ttrain-error:0.24914\ttest-error:0.24969                             \n",
      "\n",
      "[52]\ttrain-error:0.20141\ttest-error:0.19957                             \n",
      "\n",
      "[53]\ttrain-error:0.28259\ttest-error:0.28470                             \n",
      "\n",
      "[54]\ttrain-error:0.24923\ttest-error:0.24982                             \n",
      "\n",
      "[55]\ttrain-error:0.20135\ttest-error:0.20006                             \n",
      "\n",
      "[56]\ttrain-error:0.28341\ttest-error:0.28569                             \n",
      "\n",
      "[57]\ttrain-error:0.24920\ttest-error:0.24975                             \n",
      "\n",
      "[58]\ttrain-error:0.20126\ttest-error:0.19932                             \n",
      "\n",
      "[59]\ttrain-error:0.28308\ttest-error:0.28483                             \n",
      "\n",
      "[60]\ttrain-error:0.24920\ttest-error:0.24975                             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61]\ttrain-error:0.20135\ttest-error:0.20012                             \n",
      "\n",
      "[62]\ttrain-error:0.28308\ttest-error:0.28483                             \n",
      "\n",
      "[63]\ttrain-error:0.24932\ttest-error:0.24988                             \n",
      "\n",
      "[64]\ttrain-error:0.20132\ttest-error:0.19969                             \n",
      "\n",
      "[65]\ttrain-error:0.28253\ttest-error:0.28477                             \n",
      "\n",
      "[66]\ttrain-error:0.24920\ttest-error:0.24975                             \n",
      "\n",
      "[67]\ttrain-error:0.20132\ttest-error:0.20000                             \n",
      "\n",
      "[68]\ttrain-error:0.28341\ttest-error:0.28557                             \n",
      "\n",
      "[69]\ttrain-error:0.24975\ttest-error:0.25068                             \n",
      "\n",
      "[70]\ttrain-error:0.20132\ttest-error:0.19951                             \n",
      "\n",
      "[71]\ttrain-error:0.28151\ttest-error:0.28391                             \n",
      "\n",
      "[72]\ttrain-error:0.24920\ttest-error:0.24975                             \n",
      "\n",
      "[73]\ttrain-error:0.20126\ttest-error:0.19932                             \n",
      "\n",
      "[74]\ttrain-error:0.28329\ttest-error:0.28526                             \n",
      "\n",
      "[75]\ttrain-error:0.24948\ttest-error:0.25031                             \n",
      "\n",
      "[76]\ttrain-error:0.20141\ttest-error:0.19951                             \n",
      "\n",
      "[77]\ttrain-error:0.28163\ttest-error:0.28403                             \n",
      "\n",
      "[78]\ttrain-error:0.24920\ttest-error:0.24975                             \n",
      "\n",
      "[79]\ttrain-error:0.20138\ttest-error:0.19963                             \n",
      "\n",
      "[80]\ttrain-error:0.28345\ttest-error:0.28569                             \n",
      "\n",
      "[81]\ttrain-error:0.24911\ttest-error:0.24957                             \n",
      "\n",
      "[82]\ttrain-error:0.20126\ttest-error:0.19939                             \n",
      "\n",
      "[83]\ttrain-error:0.28163\ttest-error:0.28403                             \n",
      "\n",
      "[84]\ttrain-error:0.24920\ttest-error:0.24975                             \n",
      "\n",
      "[85]\ttrain-error:0.20141\ttest-error:0.19969                             \n",
      "\n",
      "[86]\ttrain-error:0.28298\ttest-error:0.28477                             \n",
      "\n",
      "[87]\ttrain-error:0.24920\ttest-error:0.24982                             \n",
      "\n",
      "[88]\ttrain-error:0.20141\ttest-error:0.20006                             \n",
      "\n",
      "[89]\ttrain-error:0.28311\ttest-error:0.28501                             \n",
      "\n",
      "[90]\ttrain-error:0.24945\ttest-error:0.25018                             \n",
      "\n",
      "[91]\ttrain-error:0.20141\ttest-error:0.19957                             \n",
      "\n",
      "[92]\ttrain-error:0.28253\ttest-error:0.28464                             \n",
      "\n",
      "[93]\ttrain-error:0.24932\ttest-error:0.24994                             \n",
      "\n",
      "[94]\ttrain-error:0.20138\ttest-error:0.19963                             \n",
      "\n",
      "[95]\ttrain-error:0.28259\ttest-error:0.28470                             \n",
      "\n",
      "[96]\ttrain-error:0.24923\ttest-error:0.24988                             \n",
      "\n",
      "[97]\ttrain-error:0.20135\ttest-error:0.19957                             \n",
      "\n",
      "[98]\ttrain-error:0.28256\ttest-error:0.28470                             \n",
      "\n",
      "[99]\ttrain-error:0.24920\ttest-error:0.24969                             \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.6408921323365495, 'colsample_bytree': 0.8438506566743287, 'eta': 0.05597994446501395, 'eval_metric': ('error',), 'extra_dims': 4, 'gamma': 0, 'lambda': 1.597084702040103e-06, 'max_depth': 7, 'min_child_weight': 0.09669320741500273, 'objective': 'binary:logistic', 'subsample': 0.9406211662332149}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[22:42:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13661\ttest-error:0.13728                                \n",
      "\n",
      "[1]\ttrain-error:0.13618\ttest-error:0.13845                                \n",
      "\n",
      "[2]\ttrain-error:0.13547\ttest-error:0.13784                                \n",
      "\n",
      "[3]\ttrain-error:0.13375\ttest-error:0.13661                                \n",
      "\n",
      "[4]\ttrain-error:0.13262\ttest-error:0.13600                                \n",
      "\n",
      "[5]\ttrain-error:0.13176\ttest-error:0.13397                                \n",
      "\n",
      "[6]\ttrain-error:0.13087\ttest-error:0.13354                                \n",
      "\n",
      "[7]\ttrain-error:0.13047\ttest-error:0.13274                                \n",
      "\n",
      "[8]\ttrain-error:0.12918\ttest-error:0.13176                                \n",
      "\n",
      "[9]\ttrain-error:0.12807\ttest-error:0.13157                                \n",
      "\n",
      "[10]\ttrain-error:0.12635\ttest-error:0.13034                               \n",
      "\n",
      "[11]\ttrain-error:0.12534\ttest-error:0.12869                               \n",
      "\n",
      "[12]\ttrain-error:0.12521\ttest-error:0.12826                               \n",
      "\n",
      "[13]\ttrain-error:0.12408\ttest-error:0.12807                               \n",
      "\n",
      "[14]\ttrain-error:0.12389\ttest-error:0.12789                               \n",
      "\n",
      "[15]\ttrain-error:0.12282\ttest-error:0.12783                               \n",
      "\n",
      "[16]\ttrain-error:0.12144\ttest-error:0.12709                               \n",
      "\n",
      "[17]\ttrain-error:0.11990\ttest-error:0.12647                               \n",
      "\n",
      "[18]\ttrain-error:0.11913\ttest-error:0.12617                               \n",
      "\n",
      "[19]\ttrain-error:0.11837\ttest-error:0.12568                               \n",
      "\n",
      "[20]\ttrain-error:0.11689\ttest-error:0.12598                               \n",
      "\n",
      "[21]\ttrain-error:0.11640\ttest-error:0.12586                               \n",
      "\n",
      "[22]\ttrain-error:0.11545\ttest-error:0.12549                               \n",
      "\n",
      "[23]\ttrain-error:0.11477\ttest-error:0.12580                               \n",
      "\n",
      "[24]\ttrain-error:0.11407\ttest-error:0.12525                               \n",
      "\n",
      "[25]\ttrain-error:0.11311\ttest-error:0.12543                               \n",
      "\n",
      "[26]\ttrain-error:0.11241\ttest-error:0.12549                               \n",
      "\n",
      "[27]\ttrain-error:0.11195\ttest-error:0.12580                               \n",
      "\n",
      "[28]\ttrain-error:0.11167\ttest-error:0.12592                               \n",
      "\n",
      "[29]\ttrain-error:0.11078\ttest-error:0.12549                               \n",
      "\n",
      "[30]\ttrain-error:0.11066\ttest-error:0.12549                               \n",
      "\n",
      "[31]\ttrain-error:0.11029\ttest-error:0.12604                               \n",
      "\n",
      "[32]\ttrain-error:0.10943\ttest-error:0.12617                               \n",
      "\n",
      "[33]\ttrain-error:0.10891\ttest-error:0.12684                               \n",
      "\n",
      "[34]\ttrain-error:0.10863\ttest-error:0.12697                               \n",
      "\n",
      "[35]\ttrain-error:0.10817\ttest-error:0.12697                               \n",
      "\n",
      "[36]\ttrain-error:0.10777\ttest-error:0.12709                               \n",
      "\n",
      "[37]\ttrain-error:0.10722\ttest-error:0.12709                               \n",
      "\n",
      "[38]\ttrain-error:0.10697\ttest-error:0.12690                               \n",
      "\n",
      "[39]\ttrain-error:0.10666\ttest-error:0.12641                               \n",
      "\n",
      "[40]\ttrain-error:0.10623\ttest-error:0.12623                               \n",
      "\n",
      "[41]\ttrain-error:0.10531\ttest-error:0.12635                               \n",
      "\n",
      "[42]\ttrain-error:0.10497\ttest-error:0.12617                               \n",
      "\n",
      "[43]\ttrain-error:0.10464\ttest-error:0.12604                               \n",
      "\n",
      "[44]\ttrain-error:0.10430\ttest-error:0.12611                               \n",
      "\n",
      "[45]\ttrain-error:0.10396\ttest-error:0.12574                               \n",
      "\n",
      "[46]\ttrain-error:0.10335\ttest-error:0.12598                               \n",
      "\n",
      "[47]\ttrain-error:0.10286\ttest-error:0.12604                               \n",
      "\n",
      "[48]\ttrain-error:0.10212\ttest-error:0.12555                               \n",
      "\n",
      "[49]\ttrain-error:0.10209\ttest-error:0.12611                               \n",
      "\n",
      "[50]\ttrain-error:0.10187\ttest-error:0.12586                               \n",
      "\n",
      "[51]\ttrain-error:0.10154\ttest-error:0.12574                               \n",
      "\n",
      "[52]\ttrain-error:0.10154\ttest-error:0.12543                               \n",
      "\n",
      "[53]\ttrain-error:0.10114\ttest-error:0.12549                               \n",
      "\n",
      "[54]\ttrain-error:0.10086\ttest-error:0.12518                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55]\ttrain-error:0.10009\ttest-error:0.12555                               \n",
      "\n",
      "[56]\ttrain-error:0.09948\ttest-error:0.12531                               \n",
      "\n",
      "[57]\ttrain-error:0.09929\ttest-error:0.12549                               \n",
      "\n",
      "[58]\ttrain-error:0.09886\ttest-error:0.12580                               \n",
      "\n",
      "[59]\ttrain-error:0.09856\ttest-error:0.12555                               \n",
      "\n",
      "[60]\ttrain-error:0.09828\ttest-error:0.12561                               \n",
      "\n",
      "[61]\ttrain-error:0.09800\ttest-error:0.12617                               \n",
      "\n",
      "[62]\ttrain-error:0.09745\ttest-error:0.12604                               \n",
      "\n",
      "[63]\ttrain-error:0.09696\ttest-error:0.12611                               \n",
      "\n",
      "[64]\ttrain-error:0.09653\ttest-error:0.12629                               \n",
      "\n",
      "[65]\ttrain-error:0.09610\ttest-error:0.12635                               \n",
      "\n",
      "[66]\ttrain-error:0.09592\ttest-error:0.12629                               \n",
      "\n",
      "[67]\ttrain-error:0.09570\ttest-error:0.12660                               \n",
      "\n",
      "[68]\ttrain-error:0.09530\ttest-error:0.12635                               \n",
      "\n",
      "[69]\ttrain-error:0.09481\ttest-error:0.12623                               \n",
      "\n",
      "[70]\ttrain-error:0.09456\ttest-error:0.12611                               \n",
      "\n",
      "[71]\ttrain-error:0.09404\ttest-error:0.12666                               \n",
      "\n",
      "[72]\ttrain-error:0.09383\ttest-error:0.12660                               \n",
      "\n",
      "[73]\ttrain-error:0.09337\ttest-error:0.12666                               \n",
      "\n",
      "[74]\ttrain-error:0.09346\ttest-error:0.12660                               \n",
      "\n",
      "[75]\ttrain-error:0.09306\ttest-error:0.12629                               \n",
      "\n",
      "[76]\ttrain-error:0.09275\ttest-error:0.12635                               \n",
      "\n",
      "[77]\ttrain-error:0.09254\ttest-error:0.12660                               \n",
      "\n",
      "[78]\ttrain-error:0.09229\ttest-error:0.12654                               \n",
      "\n",
      "[79]\ttrain-error:0.09198\ttest-error:0.12641                               \n",
      "\n",
      "[80]\ttrain-error:0.09158\ttest-error:0.12641                               \n",
      "\n",
      "[81]\ttrain-error:0.09125\ttest-error:0.12660                               \n",
      "\n",
      "[82]\ttrain-error:0.09079\ttest-error:0.12684                               \n",
      "\n",
      "[83]\ttrain-error:0.09048\ttest-error:0.12703                               \n",
      "\n",
      "[84]\ttrain-error:0.09014\ttest-error:0.12678                               \n",
      "\n",
      "[85]\ttrain-error:0.08968\ttest-error:0.12703                               \n",
      "\n",
      "[86]\ttrain-error:0.08934\ttest-error:0.12678                               \n",
      "\n",
      "[87]\ttrain-error:0.08910\ttest-error:0.12672                               \n",
      "\n",
      "[88]\ttrain-error:0.08861\ttest-error:0.12709                               \n",
      "\n",
      "[89]\ttrain-error:0.08805\ttest-error:0.12684                               \n",
      "\n",
      "[90]\ttrain-error:0.08747\ttest-error:0.12672                               \n",
      "\n",
      "[91]\ttrain-error:0.08686\ttest-error:0.12666                               \n",
      "\n",
      "[92]\ttrain-error:0.08646\ttest-error:0.12678                               \n",
      "\n",
      "[93]\ttrain-error:0.08615\ttest-error:0.12690                               \n",
      "\n",
      "[94]\ttrain-error:0.08557\ttest-error:0.12690                               \n",
      "\n",
      "[95]\ttrain-error:0.08514\ttest-error:0.12709                               \n",
      "\n",
      "[96]\ttrain-error:0.08461\ttest-error:0.12733                               \n",
      "\n",
      "[97]\ttrain-error:0.08400\ttest-error:0.12752                               \n",
      "\n",
      "[98]\ttrain-error:0.08372\ttest-error:0.12752                               \n",
      "\n",
      "[99]\ttrain-error:0.08326\ttest-error:0.12746                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'In', 'colsample_bylevel': 0.7929678541888858, 'colsample_bytree': 0.633321169257873, 'eta': 0.32021494307810544, 'eval_metric': ('error',), 'extra_dims': 14, 'gamma': 1.9706167984164115e-07, 'lambda': 0.676731756127599, 'max_depth': 6, 'min_child_weight': 0.00041648330219982364, 'objective': 'binary:logistic', 'subsample': 0.8705494245500998}\n",
      "Overwriting param `num_class`                                           \n",
      "Overwriting param `objective` while setting `obj` in train.             \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                 \n",
      "Setting param `disable_default_eval_metric` to 1.                       \n",
      "[22:43:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14853\ttest-error:0.14797                              \n",
      "\n",
      "[1]\ttrain-error:0.66892\ttest-error:0.67211                              \n",
      "\n",
      "[2]\ttrain-error:0.22423\ttest-error:0.22009                              \n",
      "\n",
      "[3]\ttrain-error:0.55697\ttest-error:0.56284                              \n",
      "\n",
      "[4]\ttrain-error:0.23618\ttest-error:0.23931                              \n",
      "\n",
      "[5]\ttrain-error:0.23627\ttest-error:0.23667                              \n",
      "\n",
      "[6]\ttrain-error:0.22488\ttest-error:0.22518                              \n",
      "\n",
      "[7]\ttrain-error:0.23074\ttest-error:0.23237                              \n",
      "\n",
      "[8]\ttrain-error:0.31950\ttest-error:0.31609                              \n",
      "\n",
      "[9]\ttrain-error:0.21895\ttest-error:0.21579                              \n",
      "\n",
      "[10]\ttrain-error:0.34159\ttest-error:0.34441                             \n",
      "\n",
      "[11]\ttrain-error:0.23262\ttest-error:0.22801                             \n",
      "\n",
      "[12]\ttrain-error:0.73679\ttest-error:0.74134                             \n",
      "\n",
      "[13]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[14]\ttrain-error:0.24146\ttest-error:0.23704                             \n",
      "\n",
      "[15]\ttrain-error:0.26849\ttest-error:0.26536                             \n",
      "\n",
      "[16]\ttrain-error:0.40190\ttest-error:0.40608                             \n",
      "\n",
      "[17]\ttrain-error:0.24539\ttest-error:0.24146                             \n",
      "\n",
      "[18]\ttrain-error:0.64724\ttest-error:0.64828                             \n",
      "\n",
      "[19]\ttrain-error:0.24011\ttest-error:0.23581                             \n",
      "\n",
      "[20]\ttrain-error:0.45835\ttest-error:0.45854                             \n",
      "\n",
      "[21]\ttrain-error:0.24972\ttest-error:0.24386                             \n",
      "\n",
      "[22]\ttrain-error:0.22488\ttest-error:0.22125                             \n",
      "\n",
      "[23]\ttrain-error:0.50126\ttest-error:0.50381                             \n",
      "\n",
      "[24]\ttrain-error:0.23483\ttest-error:0.23071                             \n",
      "\n",
      "[25]\ttrain-error:0.30931\ttest-error:0.31609                             \n",
      "\n",
      "[26]\ttrain-error:0.22082\ttest-error:0.22316                             \n",
      "\n",
      "[27]\ttrain-error:0.18916\ttest-error:0.19029                             \n",
      "\n",
      "[28]\ttrain-error:0.24742\ttest-error:0.24638                             \n",
      "\n",
      "[29]\ttrain-error:0.21238\ttest-error:0.21143                             \n",
      "\n",
      "[30]\ttrain-error:0.51290\ttest-error:0.51585                             \n",
      "\n",
      "[31]\ttrain-error:0.23176\ttest-error:0.22826                             \n",
      "\n",
      "[32]\ttrain-error:0.29530\ttest-error:0.29822                             \n",
      "\n",
      "[33]\ttrain-error:0.28243\ttest-error:0.28022                             \n",
      "\n",
      "[34]\ttrain-error:0.20777\ttest-error:0.20559                             \n",
      "\n",
      "[35]\ttrain-error:0.53744\ttest-error:0.53833                             \n",
      "\n",
      "[36]\ttrain-error:0.23762\ttest-error:0.23360                             \n",
      "\n",
      "[37]\ttrain-error:0.27819\ttest-error:0.27819                             \n",
      "\n",
      "[38]\ttrain-error:0.28452\ttest-error:0.28163                             \n",
      "\n",
      "[39]\ttrain-error:0.21176\ttest-error:0.20983                             \n",
      "\n",
      "[40]\ttrain-error:0.48080\ttest-error:0.47967                             \n",
      "\n",
      "[41]\ttrain-error:0.21843\ttest-error:0.21505                             \n",
      "\n",
      "[42]\ttrain-error:0.29272\ttest-error:0.29730                             \n",
      "\n",
      "[43]\ttrain-error:0.26708\ttest-error:0.26714                             \n",
      "\n",
      "[44]\ttrain-error:0.20845\ttest-error:0.20817                             \n",
      "\n",
      "[45]\ttrain-error:0.29622\ttest-error:0.29865                             \n",
      "\n",
      "[46]\ttrain-error:0.22617\ttest-error:0.22439                             \n",
      "\n",
      "[47]\ttrain-error:0.39837\ttest-error:0.39865                             \n",
      "\n",
      "[48]\ttrain-error:0.22033\ttest-error:0.21683                             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49]\ttrain-error:0.50135\ttest-error:0.49914                             \n",
      "\n",
      "[50]\ttrain-error:0.23483\ttest-error:0.23040                             \n",
      "\n",
      "[51]\ttrain-error:0.36293\ttest-error:0.37002                             \n",
      "\n",
      "[52]\ttrain-error:0.19462\ttest-error:0.19373                             \n",
      "\n",
      "[53]\ttrain-error:0.21889\ttest-error:0.21996                             \n",
      "\n",
      "[54]\ttrain-error:0.18821\ttest-error:0.18999                             \n",
      "\n",
      "[55]\ttrain-error:0.45531\ttest-error:0.45454                             \n",
      "\n",
      "[56]\ttrain-error:0.23873\ttest-error:0.23397                             \n",
      "\n",
      "[57]\ttrain-error:0.46284\ttest-error:0.46401                             \n",
      "\n",
      "[58]\ttrain-error:0.20691\ttest-error:0.20436                             \n",
      "\n",
      "[59]\ttrain-error:0.40854\ttest-error:0.40559                             \n",
      "\n",
      "[60]\ttrain-error:0.21348\ttest-error:0.20940                             \n",
      "\n",
      "[61]\ttrain-error:0.44493\ttest-error:0.44367                             \n",
      "\n",
      "[62]\ttrain-error:0.23265\ttest-error:0.22776                             \n",
      "\n",
      "[63]\ttrain-error:0.51272\ttest-error:0.51069                             \n",
      "\n",
      "[64]\ttrain-error:0.23765\ttest-error:0.23274                             \n",
      "\n",
      "[65]\ttrain-error:0.38808\ttest-error:0.38999                             \n",
      "\n",
      "[66]\ttrain-error:0.21265\ttest-error:0.21013                             \n",
      "\n",
      "[67]\ttrain-error:0.44843\ttest-error:0.44779                             \n",
      "\n",
      "[68]\ttrain-error:0.22340\ttest-error:0.21953                             \n",
      "\n",
      "[69]\ttrain-error:0.29696\ttest-error:0.29791                             \n",
      "\n",
      "[70]\ttrain-error:0.20642\ttest-error:0.20436                             \n",
      "\n",
      "[71]\ttrain-error:0.30663\ttest-error:0.30657                             \n",
      "\n",
      "[72]\ttrain-error:0.19902\ttest-error:0.19681                             \n",
      "\n",
      "[73]\ttrain-error:0.40258\ttest-error:0.40381                             \n",
      "\n",
      "[74]\ttrain-error:0.22064\ttest-error:0.21775                             \n",
      "\n",
      "[75]\ttrain-error:0.41858\ttest-error:0.41745                             \n",
      "\n",
      "[76]\ttrain-error:0.20476\ttest-error:0.20258                             \n",
      "\n",
      "[77]\ttrain-error:0.46907\ttest-error:0.46358                             \n",
      "\n",
      "[78]\ttrain-error:0.23397\ttest-error:0.22954                             \n",
      "\n",
      "[79]\ttrain-error:0.29042\ttest-error:0.29361                             \n",
      "\n",
      "[80]\ttrain-error:0.22601\ttest-error:0.22660                             \n",
      "\n",
      "[81]\ttrain-error:0.19822\ttest-error:0.19951                             \n",
      "\n",
      "[82]\ttrain-error:0.26483\ttest-error:0.26063                             \n",
      "\n",
      "[83]\ttrain-error:0.21050\ttest-error:0.20971                             \n",
      "\n",
      "[84]\ttrain-error:0.27328\ttest-error:0.27297                             \n",
      "\n",
      "[85]\ttrain-error:0.21529\ttest-error:0.21443                             \n",
      "\n",
      "[86]\ttrain-error:0.42571\ttest-error:0.42420                             \n",
      "\n",
      "[87]\ttrain-error:0.23197\ttest-error:0.22807                             \n",
      "\n",
      "[88]\ttrain-error:0.39410\ttest-error:0.40154                             \n",
      "\n",
      "[89]\ttrain-error:0.22110\ttest-error:0.22297                             \n",
      "\n",
      "[90]\ttrain-error:0.31551\ttest-error:0.32088                             \n",
      "\n",
      "[91]\ttrain-error:0.21354\ttest-error:0.21099                             \n",
      "\n",
      "[92]\ttrain-error:0.39076\ttest-error:0.38821                             \n",
      "\n",
      "[93]\ttrain-error:0.20642\ttest-error:0.20479                             \n",
      "\n",
      "[94]\ttrain-error:0.47190\ttest-error:0.47371                             \n",
      "\n",
      "[95]\ttrain-error:0.20688\ttest-error:0.20467                             \n",
      "\n",
      "[96]\ttrain-error:0.41238\ttest-error:0.41394                             \n",
      "\n",
      "[97]\ttrain-error:0.16606\ttest-error:0.16566                             \n",
      "\n",
      "[98]\ttrain-error:0.25768\ttest-error:0.25774                             \n",
      "\n",
      "[99]\ttrain-error:0.18857\ttest-error:0.18771                             \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.7282038187114673, 'colsample_bytree': 0.554173742883725, 'eta': 0.0933257556293938, 'eval_metric': ('error',), 'extra_dims': 2, 'gamma': 0, 'lambda': 0.05970397913363311, 'max_depth': 10, 'min_child_weight': 4.8835453288534, 'objective': 'binary:logistic', 'subsample': 0.6784003056386674}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[22:44:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.16745\ttest-error:0.16775                                \n",
      "\n",
      "[1]\ttrain-error:0.14911\ttest-error:0.15129                                \n",
      "\n",
      "[2]\ttrain-error:0.14435\ttest-error:0.14638                                \n",
      "\n",
      "[3]\ttrain-error:0.14131\ttest-error:0.14386                                \n",
      "\n",
      "[4]\ttrain-error:0.13913\ttest-error:0.13968                                \n",
      "\n",
      "[5]\ttrain-error:0.14008\ttest-error:0.14116                                \n",
      "\n",
      "[6]\ttrain-error:0.13986\ttest-error:0.14011                                \n",
      "\n",
      "[7]\ttrain-error:0.14026\ttest-error:0.14017                                \n",
      "\n",
      "[8]\ttrain-error:0.14011\ttest-error:0.13944                                \n",
      "\n",
      "[9]\ttrain-error:0.13851\ttest-error:0.13913                                \n",
      "\n",
      "[10]\ttrain-error:0.13719\ttest-error:0.13839                               \n",
      "\n",
      "[11]\ttrain-error:0.13655\ttest-error:0.13735                               \n",
      "\n",
      "[12]\ttrain-error:0.13566\ttest-error:0.13642                               \n",
      "\n",
      "[13]\ttrain-error:0.13538\ttest-error:0.13655                               \n",
      "\n",
      "[14]\ttrain-error:0.13455\ttest-error:0.13593                               \n",
      "\n",
      "[15]\ttrain-error:0.13345\ttest-error:0.13495                               \n",
      "\n",
      "[16]\ttrain-error:0.13302\ttest-error:0.13434                               \n",
      "\n",
      "[17]\ttrain-error:0.13222\ttest-error:0.13348                               \n",
      "\n",
      "[18]\ttrain-error:0.13197\ttest-error:0.13354                               \n",
      "\n",
      "[19]\ttrain-error:0.13160\ttest-error:0.13256                               \n",
      "\n",
      "[20]\ttrain-error:0.13081\ttest-error:0.13268                               \n",
      "\n",
      "[21]\ttrain-error:0.13050\ttest-error:0.13219                               \n",
      "\n",
      "[22]\ttrain-error:0.12973\ttest-error:0.13182                               \n",
      "\n",
      "[23]\ttrain-error:0.12967\ttest-error:0.13145                               \n",
      "\n",
      "[24]\ttrain-error:0.12921\ttest-error:0.13133                               \n",
      "\n",
      "[25]\ttrain-error:0.12829\ttest-error:0.13077                               \n",
      "\n",
      "[26]\ttrain-error:0.12819\ttest-error:0.13071                               \n",
      "\n",
      "[27]\ttrain-error:0.12773\ttest-error:0.13139                               \n",
      "\n",
      "[28]\ttrain-error:0.12752\ttest-error:0.13090                               \n",
      "\n",
      "[29]\ttrain-error:0.12706\ttest-error:0.13071                               \n",
      "\n",
      "[30]\ttrain-error:0.12712\ttest-error:0.13084                               \n",
      "\n",
      "[31]\ttrain-error:0.12693\ttest-error:0.13022                               \n",
      "\n",
      "[32]\ttrain-error:0.12614\ttest-error:0.13040                               \n",
      "\n",
      "[33]\ttrain-error:0.12620\ttest-error:0.13028                               \n",
      "\n",
      "[34]\ttrain-error:0.12586\ttest-error:0.13022                               \n",
      "\n",
      "[35]\ttrain-error:0.12580\ttest-error:0.13028                               \n",
      "\n",
      "[36]\ttrain-error:0.12515\ttest-error:0.13016                               \n",
      "\n",
      "[37]\ttrain-error:0.12540\ttest-error:0.12985                               \n",
      "\n",
      "[38]\ttrain-error:0.12506\ttest-error:0.13034                               \n",
      "\n",
      "[39]\ttrain-error:0.12488\ttest-error:0.13016                               \n",
      "\n",
      "[40]\ttrain-error:0.12460\ttest-error:0.13053                               \n",
      "\n",
      "[41]\ttrain-error:0.12442\ttest-error:0.13059                               \n",
      "\n",
      "[42]\ttrain-error:0.12386\ttest-error:0.13022                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43]\ttrain-error:0.12383\ttest-error:0.12961                               \n",
      "\n",
      "[44]\ttrain-error:0.12340\ttest-error:0.13059                               \n",
      "\n",
      "[45]\ttrain-error:0.12279\ttest-error:0.13010                               \n",
      "\n",
      "[46]\ttrain-error:0.12267\ttest-error:0.12991                               \n",
      "\n",
      "[47]\ttrain-error:0.12285\ttest-error:0.12985                               \n",
      "\n",
      "[48]\ttrain-error:0.12263\ttest-error:0.12979                               \n",
      "\n",
      "[49]\ttrain-error:0.12267\ttest-error:0.12973                               \n",
      "\n",
      "[50]\ttrain-error:0.12233\ttest-error:0.12912                               \n",
      "\n",
      "[51]\ttrain-error:0.12230\ttest-error:0.12942                               \n",
      "\n",
      "[52]\ttrain-error:0.12184\ttest-error:0.12918                               \n",
      "\n",
      "[53]\ttrain-error:0.12174\ttest-error:0.12967                               \n",
      "\n",
      "[54]\ttrain-error:0.12193\ttest-error:0.12961                               \n",
      "\n",
      "[55]\ttrain-error:0.12128\ttest-error:0.12961                               \n",
      "\n",
      "[56]\ttrain-error:0.12076\ttest-error:0.12948                               \n",
      "\n",
      "[57]\ttrain-error:0.12058\ttest-error:0.12967                               \n",
      "\n",
      "[58]\ttrain-error:0.12042\ttest-error:0.12961                               \n",
      "\n",
      "[59]\ttrain-error:0.12052\ttest-error:0.12991                               \n",
      "\n",
      "[60]\ttrain-error:0.12009\ttest-error:0.12973                               \n",
      "\n",
      "[61]\ttrain-error:0.11996\ttest-error:0.12936                               \n",
      "\n",
      "[62]\ttrain-error:0.12048\ttest-error:0.12924                               \n",
      "\n",
      "[63]\ttrain-error:0.11987\ttest-error:0.12893                               \n",
      "\n",
      "[64]\ttrain-error:0.11969\ttest-error:0.12893                               \n",
      "\n",
      "[65]\ttrain-error:0.11962\ttest-error:0.12936                               \n",
      "\n",
      "[66]\ttrain-error:0.11923\ttest-error:0.12924                               \n",
      "\n",
      "[67]\ttrain-error:0.11923\ttest-error:0.12887                               \n",
      "\n",
      "[68]\ttrain-error:0.11858\ttest-error:0.12930                               \n",
      "\n",
      "[69]\ttrain-error:0.11861\ttest-error:0.12918                               \n",
      "\n",
      "[70]\ttrain-error:0.11864\ttest-error:0.12948                               \n",
      "\n",
      "[71]\ttrain-error:0.11812\ttest-error:0.12869                               \n",
      "\n",
      "[72]\ttrain-error:0.11852\ttest-error:0.12856                               \n",
      "\n",
      "[73]\ttrain-error:0.11846\ttest-error:0.12832                               \n",
      "\n",
      "[74]\ttrain-error:0.11837\ttest-error:0.12881                               \n",
      "\n",
      "[75]\ttrain-error:0.11781\ttest-error:0.12905                               \n",
      "\n",
      "[76]\ttrain-error:0.11781\ttest-error:0.12893                               \n",
      "\n",
      "[77]\ttrain-error:0.11744\ttest-error:0.12893                               \n",
      "\n",
      "[78]\ttrain-error:0.11723\ttest-error:0.12899                               \n",
      "\n",
      "[79]\ttrain-error:0.11729\ttest-error:0.12881                               \n",
      "\n",
      "[80]\ttrain-error:0.11717\ttest-error:0.12856                               \n",
      "\n",
      "[81]\ttrain-error:0.11701\ttest-error:0.12875                               \n",
      "\n",
      "[82]\ttrain-error:0.11726\ttest-error:0.12887                               \n",
      "\n",
      "[83]\ttrain-error:0.11695\ttest-error:0.12881                               \n",
      "\n",
      "[84]\ttrain-error:0.11704\ttest-error:0.12967                               \n",
      "\n",
      "[85]\ttrain-error:0.11711\ttest-error:0.12979                               \n",
      "\n",
      "[86]\ttrain-error:0.11680\ttest-error:0.12942                               \n",
      "\n",
      "[87]\ttrain-error:0.11661\ttest-error:0.12918                               \n",
      "\n",
      "[88]\ttrain-error:0.11649\ttest-error:0.12918                               \n",
      "\n",
      "[89]\ttrain-error:0.11668\ttest-error:0.12893                               \n",
      "\n",
      "[90]\ttrain-error:0.11640\ttest-error:0.12887                               \n",
      "\n",
      "[91]\ttrain-error:0.11643\ttest-error:0.12899                               \n",
      "\n",
      "[92]\ttrain-error:0.11655\ttest-error:0.12924                               \n",
      "\n",
      "[93]\ttrain-error:0.11658\ttest-error:0.12887                               \n",
      "\n",
      "[94]\ttrain-error:0.11649\ttest-error:0.12862                               \n",
      "\n",
      "[95]\ttrain-error:0.11600\ttest-error:0.12893                               \n",
      "\n",
      "[96]\ttrain-error:0.11619\ttest-error:0.12887                               \n",
      "\n",
      "[97]\ttrain-error:0.11619\ttest-error:0.12899                               \n",
      "\n",
      "[98]\ttrain-error:0.11569\ttest-error:0.12924                               \n",
      "\n",
      "[99]\ttrain-error:0.11533\ttest-error:0.12862                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'I', 'colsample_bylevel': 0.6071774780828779, 'colsample_bytree': 0.5870957473556949, 'eta': 0.18779869215731376, 'eval_metric': ('error',), 'extra_dims': 5, 'gamma': 0.5030473654386771, 'lambda': 0.00032953853322229606, 'max_depth': 3, 'min_child_weight': 0.004185848815899322, 'objective': 'binary:logistic', 'subsample': 0.7133131911135115}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[22:45:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.17660\ttest-error:0.17518                                \n",
      "\n",
      "[1]\ttrain-error:0.15166\ttest-error:0.15154                                \n",
      "\n",
      "[2]\ttrain-error:0.14247\ttest-error:0.13999                                \n",
      "\n",
      "[3]\ttrain-error:0.14116\ttest-error:0.13864                                \n",
      "\n",
      "[4]\ttrain-error:0.14088\ttest-error:0.13845                                \n",
      "\n",
      "[5]\ttrain-error:0.13919\ttest-error:0.13772                                \n",
      "\n",
      "[6]\ttrain-error:0.13689\ttest-error:0.13520                                \n",
      "\n",
      "[7]\ttrain-error:0.13553\ttest-error:0.13317                                \n",
      "\n",
      "[8]\ttrain-error:0.13428\ttest-error:0.13231                                \n",
      "\n",
      "[9]\ttrain-error:0.13305\ttest-error:0.13219                                \n",
      "\n",
      "[10]\ttrain-error:0.13200\ttest-error:0.13243                               \n",
      "\n",
      "[11]\ttrain-error:0.12973\ttest-error:0.13010                               \n",
      "\n",
      "[12]\ttrain-error:0.12933\ttest-error:0.12973                               \n",
      "\n",
      "[13]\ttrain-error:0.12776\ttest-error:0.12979                               \n",
      "\n",
      "[14]\ttrain-error:0.12733\ttest-error:0.13022                               \n",
      "\n",
      "[15]\ttrain-error:0.12647\ttest-error:0.13034                               \n",
      "\n",
      "[16]\ttrain-error:0.12589\ttest-error:0.12991                               \n",
      "\n",
      "[17]\ttrain-error:0.12595\ttest-error:0.12991                               \n",
      "\n",
      "[18]\ttrain-error:0.12497\ttest-error:0.12961                               \n",
      "\n",
      "[19]\ttrain-error:0.12491\ttest-error:0.12991                               \n",
      "\n",
      "[20]\ttrain-error:0.12316\ttest-error:0.12936                               \n",
      "\n",
      "[21]\ttrain-error:0.12291\ttest-error:0.12887                               \n",
      "\n",
      "[22]\ttrain-error:0.12230\ttest-error:0.12924                               \n",
      "\n",
      "[23]\ttrain-error:0.12239\ttest-error:0.12948                               \n",
      "\n",
      "[24]\ttrain-error:0.12165\ttest-error:0.12924                               \n",
      "\n",
      "[25]\ttrain-error:0.12162\ttest-error:0.12942                               \n",
      "\n",
      "[26]\ttrain-error:0.12119\ttest-error:0.12881                               \n",
      "\n",
      "[27]\ttrain-error:0.12076\ttest-error:0.12856                               \n",
      "\n",
      "[28]\ttrain-error:0.12058\ttest-error:0.12875                               \n",
      "\n",
      "[29]\ttrain-error:0.12067\ttest-error:0.12856                               \n",
      "\n",
      "[30]\ttrain-error:0.11966\ttest-error:0.12912                               \n",
      "\n",
      "[31]\ttrain-error:0.11941\ttest-error:0.12869                               \n",
      "\n",
      "[32]\ttrain-error:0.11895\ttest-error:0.12905                               \n",
      "\n",
      "[33]\ttrain-error:0.11861\ttest-error:0.12875                               \n",
      "\n",
      "[34]\ttrain-error:0.11880\ttest-error:0.12783                               \n",
      "\n",
      "[35]\ttrain-error:0.11824\ttest-error:0.12758                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36]\ttrain-error:0.11775\ttest-error:0.12764                               \n",
      "\n",
      "[37]\ttrain-error:0.11775\ttest-error:0.12764                               \n",
      "\n",
      "[38]\ttrain-error:0.11751\ttest-error:0.12826                               \n",
      "\n",
      "[39]\ttrain-error:0.11747\ttest-error:0.12875                               \n",
      "\n",
      "[40]\ttrain-error:0.11711\ttest-error:0.12875                               \n",
      "\n",
      "[41]\ttrain-error:0.11686\ttest-error:0.12875                               \n",
      "\n",
      "[42]\ttrain-error:0.11637\ttest-error:0.12819                               \n",
      "\n",
      "[43]\ttrain-error:0.11619\ttest-error:0.12881                               \n",
      "\n",
      "[44]\ttrain-error:0.11612\ttest-error:0.12924                               \n",
      "\n",
      "[45]\ttrain-error:0.11603\ttest-error:0.12954                               \n",
      "\n",
      "[46]\ttrain-error:0.11554\ttest-error:0.12961                               \n",
      "\n",
      "[47]\ttrain-error:0.11539\ttest-error:0.12856                               \n",
      "\n",
      "[48]\ttrain-error:0.11502\ttest-error:0.12856                               \n",
      "\n",
      "[49]\ttrain-error:0.11468\ttest-error:0.12862                               \n",
      "\n",
      "[50]\ttrain-error:0.11440\ttest-error:0.12856                               \n",
      "\n",
      "[51]\ttrain-error:0.11410\ttest-error:0.12881                               \n",
      "\n",
      "[52]\ttrain-error:0.11354\ttest-error:0.12838                               \n",
      "\n",
      "[53]\ttrain-error:0.11382\ttest-error:0.12776                               \n",
      "\n",
      "[54]\ttrain-error:0.11345\ttest-error:0.12875                               \n",
      "\n",
      "[55]\ttrain-error:0.11342\ttest-error:0.12850                               \n",
      "\n",
      "[56]\ttrain-error:0.11345\ttest-error:0.12838                               \n",
      "\n",
      "[57]\ttrain-error:0.11354\ttest-error:0.12838                               \n",
      "\n",
      "[58]\ttrain-error:0.11339\ttest-error:0.12813                               \n",
      "\n",
      "[59]\ttrain-error:0.11296\ttest-error:0.12789                               \n",
      "\n",
      "[60]\ttrain-error:0.11213\ttest-error:0.12758                               \n",
      "\n",
      "[61]\ttrain-error:0.11201\ttest-error:0.12764                               \n",
      "\n",
      "[62]\ttrain-error:0.11241\ttest-error:0.12764                               \n",
      "\n",
      "[63]\ttrain-error:0.11173\ttest-error:0.12807                               \n",
      "\n",
      "[64]\ttrain-error:0.11195\ttest-error:0.12856                               \n",
      "\n",
      "[65]\ttrain-error:0.11179\ttest-error:0.12832                               \n",
      "\n",
      "[66]\ttrain-error:0.11152\ttest-error:0.12770                               \n",
      "\n",
      "[67]\ttrain-error:0.11106\ttest-error:0.12807                               \n",
      "\n",
      "[68]\ttrain-error:0.11096\ttest-error:0.12832                               \n",
      "\n",
      "[69]\ttrain-error:0.11090\ttest-error:0.12826                               \n",
      "\n",
      "[70]\ttrain-error:0.11072\ttest-error:0.12801                               \n",
      "\n",
      "[71]\ttrain-error:0.11035\ttest-error:0.12783                               \n",
      "\n",
      "[72]\ttrain-error:0.11032\ttest-error:0.12826                               \n",
      "\n",
      "[73]\ttrain-error:0.10992\ttest-error:0.12783                               \n",
      "\n",
      "[74]\ttrain-error:0.10977\ttest-error:0.12844                               \n",
      "\n",
      "[75]\ttrain-error:0.10964\ttest-error:0.12807                               \n",
      "\n",
      "[76]\ttrain-error:0.10952\ttest-error:0.12807                               \n",
      "\n",
      "[77]\ttrain-error:0.10940\ttest-error:0.12795                               \n",
      "\n",
      "[78]\ttrain-error:0.10915\ttest-error:0.12789                               \n",
      "\n",
      "[79]\ttrain-error:0.10872\ttest-error:0.12801                               \n",
      "\n",
      "[80]\ttrain-error:0.10845\ttest-error:0.12844                               \n",
      "\n",
      "[81]\ttrain-error:0.10832\ttest-error:0.12795                               \n",
      "\n",
      "[82]\ttrain-error:0.10817\ttest-error:0.12826                               \n",
      "\n",
      "[83]\ttrain-error:0.10792\ttest-error:0.12942                               \n",
      "\n",
      "[84]\ttrain-error:0.10783\ttest-error:0.12862                               \n",
      "\n",
      "[85]\ttrain-error:0.10808\ttest-error:0.12893                               \n",
      "\n",
      "[86]\ttrain-error:0.10802\ttest-error:0.12954                               \n",
      "\n",
      "[87]\ttrain-error:0.10762\ttest-error:0.12893                               \n",
      "\n",
      "[88]\ttrain-error:0.10746\ttest-error:0.12942                               \n",
      "\n",
      "[89]\ttrain-error:0.10737\ttest-error:0.12930                               \n",
      "\n",
      "[90]\ttrain-error:0.10700\ttest-error:0.12912                               \n",
      "\n",
      "[91]\ttrain-error:0.10697\ttest-error:0.12942                               \n",
      "\n",
      "[92]\ttrain-error:0.10679\ttest-error:0.12905                               \n",
      "\n",
      "[93]\ttrain-error:0.10620\ttest-error:0.12869                               \n",
      "\n",
      "[94]\ttrain-error:0.10596\ttest-error:0.12844                               \n",
      "\n",
      "[95]\ttrain-error:0.10605\ttest-error:0.12844                               \n",
      "\n",
      "[96]\ttrain-error:0.10587\ttest-error:0.12813                               \n",
      "\n",
      "[97]\ttrain-error:0.10593\ttest-error:0.12893                               \n",
      "\n",
      "[98]\ttrain-error:0.10534\ttest-error:0.12918                               \n",
      "\n",
      "[99]\ttrain-error:0.10531\ttest-error:0.12954                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.9060480671052291, 'colsample_bytree': 0.6975691985780887, 'eta': 0.030602509369852485, 'eval_metric': ('error',), 'extra_dims': 3, 'gamma': 0, 'lambda': 0.004548240155123054, 'max_depth': 4, 'min_child_weight': 5.3861235867675704e-05, 'objective': 'binary:logistic', 'subsample': 0.9245316343964811}\n",
      "Overwriting param `num_class`                                           \n",
      "Overwriting param `objective` while setting `obj` in train.             \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                 \n",
      "Setting param `disable_default_eval_metric` to 1.                       \n",
      "[22:46:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15138\ttest-error:0.15147                              \n",
      "\n",
      "[1]\ttrain-error:0.14681\ttest-error:0.14730                              \n",
      "\n",
      "[2]\ttrain-error:0.14665\ttest-error:0.14754                              \n",
      "\n",
      "[3]\ttrain-error:0.14681\ttest-error:0.14644                              \n",
      "\n",
      "[4]\ttrain-error:0.14610\ttest-error:0.14472                              \n",
      "\n",
      "[5]\ttrain-error:0.14622\ttest-error:0.14484                              \n",
      "\n",
      "[6]\ttrain-error:0.14625\ttest-error:0.14496                              \n",
      "\n",
      "[7]\ttrain-error:0.14585\ttest-error:0.14496                              \n",
      "\n",
      "[8]\ttrain-error:0.14530\ttest-error:0.14453                              \n",
      "\n",
      "[9]\ttrain-error:0.14456\ttest-error:0.14441                              \n",
      "\n",
      "[10]\ttrain-error:0.14432\ttest-error:0.14404                             \n",
      "\n",
      "[11]\ttrain-error:0.14413\ttest-error:0.14361                             \n",
      "\n",
      "[12]\ttrain-error:0.14383\ttest-error:0.14367                             \n",
      "\n",
      "[13]\ttrain-error:0.14358\ttest-error:0.14361                             \n",
      "\n",
      "[14]\ttrain-error:0.14346\ttest-error:0.14330                             \n",
      "\n",
      "[15]\ttrain-error:0.14349\ttest-error:0.14330                             \n",
      "\n",
      "[16]\ttrain-error:0.14186\ttest-error:0.14171                             \n",
      "\n",
      "[17]\ttrain-error:0.14165\ttest-error:0.14140                             \n",
      "\n",
      "[18]\ttrain-error:0.14183\ttest-error:0.14128                             \n",
      "\n",
      "[19]\ttrain-error:0.14168\ttest-error:0.14134                             \n",
      "\n",
      "[20]\ttrain-error:0.14171\ttest-error:0.14140                             \n",
      "\n",
      "[21]\ttrain-error:0.14155\ttest-error:0.14091                             \n",
      "\n",
      "[22]\ttrain-error:0.14116\ttest-error:0.13937                             \n",
      "\n",
      "[23]\ttrain-error:0.14116\ttest-error:0.14023                             \n",
      "\n",
      "[24]\ttrain-error:0.14097\ttest-error:0.13931                             \n",
      "\n",
      "[25]\ttrain-error:0.14076\ttest-error:0.13876                             \n",
      "\n",
      "[26]\ttrain-error:0.14048\ttest-error:0.13894                             \n",
      "\n",
      "[27]\ttrain-error:0.13990\ttest-error:0.13814                             \n",
      "\n",
      "[28]\ttrain-error:0.13953\ttest-error:0.13851                             \n",
      "\n",
      "[29]\ttrain-error:0.13904\ttest-error:0.13821                             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\ttrain-error:0.13870\ttest-error:0.13796                             \n",
      "\n",
      "[31]\ttrain-error:0.13867\ttest-error:0.13759                             \n",
      "\n",
      "[32]\ttrain-error:0.13845\ttest-error:0.13784                             \n",
      "\n",
      "[33]\ttrain-error:0.13827\ttest-error:0.13710                             \n",
      "\n",
      "[34]\ttrain-error:0.13799\ttest-error:0.13710                             \n",
      "\n",
      "[35]\ttrain-error:0.13778\ttest-error:0.13667                             \n",
      "\n",
      "[36]\ttrain-error:0.13747\ttest-error:0.13575                             \n",
      "\n",
      "[37]\ttrain-error:0.13713\ttest-error:0.13563                             \n",
      "\n",
      "[38]\ttrain-error:0.13679\ttest-error:0.13556                             \n",
      "\n",
      "[39]\ttrain-error:0.13639\ttest-error:0.13575                             \n",
      "\n",
      "[40]\ttrain-error:0.13600\ttest-error:0.13544                             \n",
      "\n",
      "[41]\ttrain-error:0.13593\ttest-error:0.13464                             \n",
      "\n",
      "[42]\ttrain-error:0.13569\ttest-error:0.13483                             \n",
      "\n",
      "[43]\ttrain-error:0.13572\ttest-error:0.13409                             \n",
      "\n",
      "[44]\ttrain-error:0.13560\ttest-error:0.13335                             \n",
      "\n",
      "[45]\ttrain-error:0.13544\ttest-error:0.13292                             \n",
      "\n",
      "[46]\ttrain-error:0.13504\ttest-error:0.13268                             \n",
      "\n",
      "[47]\ttrain-error:0.13514\ttest-error:0.13225                             \n",
      "\n",
      "[48]\ttrain-error:0.13443\ttest-error:0.13194                             \n",
      "\n",
      "[49]\ttrain-error:0.13428\ttest-error:0.13188                             \n",
      "\n",
      "[50]\ttrain-error:0.13357\ttest-error:0.13157                             \n",
      "\n",
      "[51]\ttrain-error:0.13292\ttest-error:0.13090                             \n",
      "\n",
      "[52]\ttrain-error:0.13262\ttest-error:0.13077                             \n",
      "\n",
      "[53]\ttrain-error:0.13249\ttest-error:0.13059                             \n",
      "\n",
      "[54]\ttrain-error:0.13249\ttest-error:0.13059                             \n",
      "\n",
      "[55]\ttrain-error:0.13231\ttest-error:0.13059                             \n",
      "\n",
      "[56]\ttrain-error:0.13170\ttest-error:0.13016                             \n",
      "\n",
      "[57]\ttrain-error:0.13151\ttest-error:0.12985                             \n",
      "\n",
      "[58]\ttrain-error:0.13120\ttest-error:0.12973                             \n",
      "\n",
      "[59]\ttrain-error:0.13117\ttest-error:0.12998                             \n",
      "\n",
      "[60]\ttrain-error:0.13093\ttest-error:0.12967                             \n",
      "\n",
      "[61]\ttrain-error:0.13093\ttest-error:0.12973                             \n",
      "\n",
      "[62]\ttrain-error:0.13068\ttest-error:0.12930                             \n",
      "\n",
      "[63]\ttrain-error:0.13028\ttest-error:0.12918                             \n",
      "\n",
      "[64]\ttrain-error:0.12995\ttest-error:0.12893                             \n",
      "\n",
      "[65]\ttrain-error:0.12976\ttest-error:0.12905                             \n",
      "\n",
      "[66]\ttrain-error:0.12958\ttest-error:0.12881                             \n",
      "\n",
      "[67]\ttrain-error:0.12912\ttest-error:0.12856                             \n",
      "\n",
      "[68]\ttrain-error:0.12921\ttest-error:0.12826                             \n",
      "\n",
      "[69]\ttrain-error:0.12869\ttest-error:0.12789                             \n",
      "\n",
      "[70]\ttrain-error:0.12850\ttest-error:0.12770                             \n",
      "\n",
      "[71]\ttrain-error:0.12835\ttest-error:0.12789                             \n",
      "\n",
      "[72]\ttrain-error:0.12807\ttest-error:0.12752                             \n",
      "\n",
      "[73]\ttrain-error:0.12807\ttest-error:0.12740                             \n",
      "\n",
      "[74]\ttrain-error:0.12789\ttest-error:0.12715                             \n",
      "\n",
      "[75]\ttrain-error:0.12776\ttest-error:0.12709                             \n",
      "\n",
      "[76]\ttrain-error:0.12752\ttest-error:0.12690                             \n",
      "\n",
      "[77]\ttrain-error:0.12727\ttest-error:0.12660                             \n",
      "\n",
      "[78]\ttrain-error:0.12703\ttest-error:0.12660                             \n",
      "\n",
      "[79]\ttrain-error:0.12654\ttest-error:0.12623                             \n",
      "\n",
      "[80]\ttrain-error:0.12641\ttest-error:0.12623                             \n",
      "\n",
      "[81]\ttrain-error:0.12623\ttest-error:0.12617                             \n",
      "\n",
      "[82]\ttrain-error:0.12626\ttest-error:0.12604                             \n",
      "\n",
      "[83]\ttrain-error:0.12614\ttest-error:0.12598                             \n",
      "\n",
      "[84]\ttrain-error:0.12601\ttest-error:0.12574                             \n",
      "\n",
      "[85]\ttrain-error:0.12571\ttest-error:0.12568                             \n",
      "\n",
      "[86]\ttrain-error:0.12543\ttest-error:0.12568                             \n",
      "\n",
      "[87]\ttrain-error:0.12531\ttest-error:0.12574                             \n",
      "\n",
      "[88]\ttrain-error:0.12525\ttest-error:0.12586                             \n",
      "\n",
      "[89]\ttrain-error:0.12491\ttest-error:0.12604                             \n",
      "\n",
      "[90]\ttrain-error:0.12494\ttest-error:0.12611                             \n",
      "\n",
      "[91]\ttrain-error:0.12457\ttest-error:0.12592                             \n",
      "\n",
      "[92]\ttrain-error:0.12448\ttest-error:0.12568                             \n",
      "\n",
      "[93]\ttrain-error:0.12426\ttest-error:0.12604                             \n",
      "\n",
      "[94]\ttrain-error:0.12402\ttest-error:0.12598                             \n",
      "\n",
      "[95]\ttrain-error:0.12392\ttest-error:0.12586                             \n",
      "\n",
      "[96]\ttrain-error:0.12353\ttest-error:0.12592                             \n",
      "\n",
      "[97]\ttrain-error:0.12356\ttest-error:0.12592                             \n",
      "\n",
      "[98]\ttrain-error:0.12340\ttest-error:0.12574                             \n",
      "\n",
      "[99]\ttrain-error:0.12349\ttest-error:0.12580                             \n",
      "\n",
      "{'alpha': 0, 'btype': 'In', 'colsample_bylevel': 0.7515827254157815, 'colsample_bytree': 0.7575101586617471, 'eta': 0.5498185527127569, 'eval_metric': ('error',), 'extra_dims': 0, 'gamma': 0, 'lambda': 3.2707063709368615e-05, 'max_depth': 5, 'min_child_weight': 4.354088205708483e-07, 'objective': 'binary:logistic', 'subsample': 0.8268040154048721}\n",
      "Overwriting param `num_class`                                           \n",
      "Overwriting param `objective` while setting `obj` in train.             \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                 \n",
      "Setting param `disable_default_eval_metric` to 1.                       \n",
      "[22:46:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15319\ttest-error:0.15338                              \n",
      "\n",
      "[1]\ttrain-error:0.14456\ttest-error:0.14324                              \n",
      "\n",
      "[2]\ttrain-error:0.13759\ttest-error:0.13514                              \n",
      "\n",
      "[3]\ttrain-error:0.13738\ttest-error:0.13556                              \n",
      "\n",
      "[4]\ttrain-error:0.13550\ttest-error:0.13428                              \n",
      "\n",
      "[5]\ttrain-error:0.13477\ttest-error:0.13550                              \n",
      "\n",
      "[6]\ttrain-error:0.13409\ttest-error:0.13495                              \n",
      "\n",
      "[7]\ttrain-error:0.13283\ttest-error:0.13428                              \n",
      "\n",
      "[8]\ttrain-error:0.13167\ttest-error:0.13268                              \n",
      "\n",
      "[9]\ttrain-error:0.13065\ttest-error:0.13170                              \n",
      "\n",
      "[10]\ttrain-error:0.12826\ttest-error:0.13335                             \n",
      "\n",
      "[11]\ttrain-error:0.12500\ttest-error:0.12985                             \n",
      "\n",
      "[12]\ttrain-error:0.12294\ttest-error:0.12979                             \n",
      "\n",
      "[13]\ttrain-error:0.12184\ttest-error:0.12936                             \n",
      "\n",
      "[14]\ttrain-error:0.12131\ttest-error:0.12924                             \n",
      "\n",
      "[15]\ttrain-error:0.12039\ttest-error:0.12967                             \n",
      "\n",
      "[16]\ttrain-error:0.11953\ttest-error:0.12954                             \n",
      "\n",
      "[17]\ttrain-error:0.11923\ttest-error:0.13016                             \n",
      "\n",
      "[18]\ttrain-error:0.11861\ttest-error:0.13010                             \n",
      "\n",
      "[19]\ttrain-error:0.11827\ttest-error:0.13022                             \n",
      "\n",
      "[20]\ttrain-error:0.11787\ttest-error:0.13028                             \n",
      "\n",
      "[21]\ttrain-error:0.11698\ttest-error:0.13077                             \n",
      "\n",
      "[22]\ttrain-error:0.11668\ttest-error:0.13151                             \n",
      "\n",
      "[23]\ttrain-error:0.11576\ttest-error:0.13108                             \n",
      "\n",
      "[24]\ttrain-error:0.11514\ttest-error:0.13096                             \n",
      "\n",
      "[25]\ttrain-error:0.11490\ttest-error:0.13120                             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26]\ttrain-error:0.11437\ttest-error:0.13139                             \n",
      "\n",
      "[27]\ttrain-error:0.11400\ttest-error:0.13071                             \n",
      "\n",
      "[28]\ttrain-error:0.11348\ttest-error:0.13145                             \n",
      "\n",
      "[29]\ttrain-error:0.11336\ttest-error:0.13182                             \n",
      "\n",
      "[30]\ttrain-error:0.11290\ttest-error:0.13182                             \n",
      "\n",
      "[31]\ttrain-error:0.11201\ttest-error:0.13212                             \n",
      "\n",
      "[32]\ttrain-error:0.11176\ttest-error:0.13212                             \n",
      "\n",
      "[33]\ttrain-error:0.11124\ttest-error:0.13249                             \n",
      "\n",
      "[34]\ttrain-error:0.11103\ttest-error:0.13182                             \n",
      "\n",
      "[35]\ttrain-error:0.11063\ttest-error:0.13212                             \n",
      "\n",
      "[36]\ttrain-error:0.11075\ttest-error:0.13256                             \n",
      "\n",
      "[37]\ttrain-error:0.11072\ttest-error:0.13237                             \n",
      "\n",
      "[38]\ttrain-error:0.11029\ttest-error:0.13262                             \n",
      "\n",
      "[39]\ttrain-error:0.11035\ttest-error:0.13249                             \n",
      "\n",
      "[40]\ttrain-error:0.11010\ttest-error:0.13268                             \n",
      "\n",
      "[41]\ttrain-error:0.10998\ttest-error:0.13194                             \n",
      "\n",
      "[42]\ttrain-error:0.10986\ttest-error:0.13163                             \n",
      "\n",
      "[43]\ttrain-error:0.10952\ttest-error:0.13126                             \n",
      "\n",
      "[44]\ttrain-error:0.10937\ttest-error:0.13108                             \n",
      "\n",
      "[45]\ttrain-error:0.10875\ttest-error:0.13120                             \n",
      "\n",
      "[46]\ttrain-error:0.10854\ttest-error:0.13163                             \n",
      "\n",
      "[47]\ttrain-error:0.10792\ttest-error:0.13219                             \n",
      "\n",
      "[48]\ttrain-error:0.10682\ttest-error:0.13256                             \n",
      "\n",
      "[49]\ttrain-error:0.10645\ttest-error:0.13262                             \n",
      "\n",
      "[50]\ttrain-error:0.10565\ttest-error:0.13225                             \n",
      "\n",
      "[51]\ttrain-error:0.10534\ttest-error:0.13212                             \n",
      "\n",
      "[52]\ttrain-error:0.10513\ttest-error:0.13237                             \n",
      "\n",
      "[53]\ttrain-error:0.10473\ttest-error:0.13231                             \n",
      "\n",
      "[54]\ttrain-error:0.10479\ttest-error:0.13262                             \n",
      "\n",
      "[55]\ttrain-error:0.10418\ttest-error:0.13262                             \n",
      "\n",
      "[56]\ttrain-error:0.10384\ttest-error:0.13256                             \n",
      "\n",
      "[57]\ttrain-error:0.10393\ttest-error:0.13237                             \n",
      "\n",
      "[58]\ttrain-error:0.10384\ttest-error:0.13243                             \n",
      "\n",
      "[59]\ttrain-error:0.10442\ttest-error:0.13378                             \n",
      "\n",
      "[60]\ttrain-error:0.10418\ttest-error:0.13298                             \n",
      "\n",
      "[61]\ttrain-error:0.10369\ttest-error:0.13342                             \n",
      "\n",
      "[62]\ttrain-error:0.10316\ttest-error:0.13397                             \n",
      "\n",
      "[63]\ttrain-error:0.10267\ttest-error:0.13409                             \n",
      "\n",
      "[64]\ttrain-error:0.11981\ttest-error:0.14951                             \n",
      "\n",
      "[65]\ttrain-error:0.10712\ttest-error:0.13784                             \n",
      "\n",
      "[66]\ttrain-error:0.10338\ttest-error:0.13606                             \n",
      "\n",
      "[67]\ttrain-error:0.10304\ttest-error:0.13544                             \n",
      "\n",
      "[68]\ttrain-error:0.10286\ttest-error:0.13526                             \n",
      "\n",
      "[69]\ttrain-error:0.10273\ttest-error:0.13556                             \n",
      "\n",
      "[70]\ttrain-error:0.10255\ttest-error:0.13526                             \n",
      "\n",
      "[71]\ttrain-error:0.10267\ttest-error:0.13550                             \n",
      "\n",
      "[72]\ttrain-error:0.10224\ttest-error:0.13446                             \n",
      "\n",
      "[73]\ttrain-error:0.10261\ttest-error:0.13624                             \n",
      "\n",
      "[74]\ttrain-error:0.10289\ttest-error:0.13606                             \n",
      "\n",
      "[75]\ttrain-error:0.10255\ttest-error:0.13642                             \n",
      "\n",
      "[76]\ttrain-error:0.10209\ttest-error:0.13593                             \n",
      "\n",
      "[77]\ttrain-error:0.10206\ttest-error:0.13630                             \n",
      "\n",
      "[78]\ttrain-error:0.10212\ttest-error:0.13630                             \n",
      "\n",
      "[79]\ttrain-error:0.10203\ttest-error:0.13593                             \n",
      "\n",
      "[80]\ttrain-error:0.10163\ttest-error:0.13606                             \n",
      "\n",
      "[81]\ttrain-error:0.10190\ttest-error:0.13581                             \n",
      "\n",
      "[82]\ttrain-error:0.10169\ttest-error:0.13600                             \n",
      "\n",
      "[83]\ttrain-error:0.10150\ttest-error:0.13563                             \n",
      "\n",
      "[84]\ttrain-error:0.10086\ttest-error:0.13581                             \n",
      "\n",
      "[85]\ttrain-error:0.10080\ttest-error:0.13593                             \n",
      "\n",
      "[86]\ttrain-error:0.10055\ttest-error:0.13612                             \n",
      "\n",
      "[87]\ttrain-error:0.10049\ttest-error:0.13606                             \n",
      "\n",
      "[88]\ttrain-error:0.10132\ttest-error:0.13747                             \n",
      "\n",
      "[89]\ttrain-error:0.10021\ttest-error:0.13642                             \n",
      "\n",
      "[90]\ttrain-error:0.10009\ttest-error:0.13636                             \n",
      "\n",
      "[91]\ttrain-error:0.10021\ttest-error:0.13642                             \n",
      "\n",
      "[92]\ttrain-error:0.10365\ttest-error:0.13986                             \n",
      "\n",
      "[93]\ttrain-error:0.10058\ttest-error:0.13655                             \n",
      "\n",
      "[94]\ttrain-error:0.10031\ttest-error:0.13710                             \n",
      "\n",
      "[95]\ttrain-error:0.10240\ttest-error:0.13950                             \n",
      "\n",
      "[96]\ttrain-error:0.10200\ttest-error:0.13882                             \n",
      "\n",
      "[97]\ttrain-error:0.10175\ttest-error:0.13864                             \n",
      "\n",
      "[98]\ttrain-error:0.10083\ttest-error:0.13722                             \n",
      "\n",
      "[99]\ttrain-error:0.11296\ttest-error:0.14908                             \n",
      "\n",
      "{'alpha': 0, 'btype': 'I', 'colsample_bylevel': 0.8338922418373309, 'colsample_bytree': 0.9358293550947975, 'eta': 0.04684879202472014, 'eval_metric': ('error',), 'extra_dims': 8, 'gamma': 4.26610317867463e-05, 'lambda': 1.0326944657539483e-06, 'max_depth': 8, 'min_child_weight': 0.052262211119832404, 'objective': 'binary:logistic', 'subsample': 0.8761145942660464}\n",
      "Overwriting param `num_class`                                           \n",
      "Overwriting param `objective` while setting `obj` in train.             \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                 \n",
      "Setting param `disable_default_eval_metric` to 1.                       \n",
      "[22:46:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13477\ttest-error:0.13753                              \n",
      "\n",
      "[1]\ttrain-error:0.13384\ttest-error:0.13759                              \n",
      "\n",
      "[2]\ttrain-error:0.13096\ttest-error:0.13464                              \n",
      "\n",
      "[3]\ttrain-error:0.12693\ttest-error:0.13286                              \n",
      "\n",
      "[4]\ttrain-error:0.12546\ttest-error:0.13182                              \n",
      "\n",
      "[5]\ttrain-error:0.12402\ttest-error:0.13084                              \n",
      "\n",
      "[6]\ttrain-error:0.12214\ttest-error:0.12985                              \n",
      "\n",
      "[7]\ttrain-error:0.12039\ttest-error:0.12770                              \n",
      "\n",
      "[8]\ttrain-error:0.11960\ttest-error:0.12801                              \n",
      "\n",
      "[9]\ttrain-error:0.11803\ttest-error:0.12715                              \n",
      "\n",
      "[10]\ttrain-error:0.11548\ttest-error:0.12721                             \n",
      "\n",
      "[11]\ttrain-error:0.11397\ttest-error:0.12598                             \n",
      "\n",
      "[12]\ttrain-error:0.11241\ttest-error:0.12531                             \n",
      "\n",
      "[13]\ttrain-error:0.11136\ttest-error:0.12500                             \n",
      "\n",
      "[14]\ttrain-error:0.11026\ttest-error:0.12537                             \n",
      "\n",
      "[15]\ttrain-error:0.10900\ttest-error:0.12574                             \n",
      "\n",
      "[16]\ttrain-error:0.10771\ttest-error:0.12549                             \n",
      "\n",
      "[17]\ttrain-error:0.10620\ttest-error:0.12586                             \n",
      "\n",
      "[18]\ttrain-error:0.10534\ttest-error:0.12580                             \n",
      "\n",
      "[19]\ttrain-error:0.10473\ttest-error:0.12568                             \n",
      "\n",
      "[20]\ttrain-error:0.10326\ttest-error:0.12604                             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21]\ttrain-error:0.10240\ttest-error:0.12617                             \n",
      "\n",
      "[22]\ttrain-error:0.10147\ttest-error:0.12580                             \n",
      "\n",
      "[23]\ttrain-error:0.10034\ttest-error:0.12574                             \n",
      "\n",
      "[24]\ttrain-error:0.09939\ttest-error:0.12586                             \n",
      "\n",
      "[25]\ttrain-error:0.09828\ttest-error:0.12543                             \n",
      "\n",
      "[26]\ttrain-error:0.09730\ttest-error:0.12641                             \n",
      "\n",
      "[27]\ttrain-error:0.09650\ttest-error:0.12641                             \n",
      "\n",
      "[28]\ttrain-error:0.09582\ttest-error:0.12592                             \n",
      "\n",
      "[29]\ttrain-error:0.09496\ttest-error:0.12611                             \n",
      "\n",
      "[30]\ttrain-error:0.09410\ttest-error:0.12604                             \n",
      "\n",
      "[31]\ttrain-error:0.09306\ttest-error:0.12678                             \n",
      "\n",
      "[32]\ttrain-error:0.09235\ttest-error:0.12654                             \n",
      "\n",
      "[33]\ttrain-error:0.09168\ttest-error:0.12617                             \n",
      "\n",
      "[34]\ttrain-error:0.09066\ttest-error:0.12660                             \n",
      "\n",
      "[35]\ttrain-error:0.08983\ttest-error:0.12629                             \n",
      "\n",
      "[36]\ttrain-error:0.08965\ttest-error:0.12617                             \n",
      "\n",
      "[37]\ttrain-error:0.08799\ttest-error:0.12647                             \n",
      "\n",
      "[38]\ttrain-error:0.08750\ttest-error:0.12598                             \n",
      "\n",
      "[39]\ttrain-error:0.08667\ttest-error:0.12635                             \n",
      "\n",
      "[40]\ttrain-error:0.08590\ttest-error:0.12629                             \n",
      "\n",
      "[41]\ttrain-error:0.08504\ttest-error:0.12660                             \n",
      "\n",
      "[42]\ttrain-error:0.08464\ttest-error:0.12660                             \n",
      "\n",
      "[43]\ttrain-error:0.08391\ttest-error:0.12697                             \n",
      "\n",
      "[44]\ttrain-error:0.08363\ttest-error:0.12697                             \n",
      "\n",
      "[45]\ttrain-error:0.08302\ttest-error:0.12647                             \n",
      "\n",
      "[46]\ttrain-error:0.08265\ttest-error:0.12733                             \n",
      "\n",
      "[47]\ttrain-error:0.08182\ttest-error:0.12715                             \n",
      "\n",
      "[48]\ttrain-error:0.08053\ttest-error:0.12672                             \n",
      "\n",
      "[49]\ttrain-error:0.07967\ttest-error:0.12709                             \n",
      "\n",
      "[50]\ttrain-error:0.07893\ttest-error:0.12740                             \n",
      "\n",
      "[51]\ttrain-error:0.07780\ttest-error:0.12752                             \n",
      "\n",
      "[52]\ttrain-error:0.07724\ttest-error:0.12758                             \n",
      "\n",
      "[53]\ttrain-error:0.07647\ttest-error:0.12733                             \n",
      "\n",
      "[54]\ttrain-error:0.07531\ttest-error:0.12764                             \n",
      "\n",
      "[55]\ttrain-error:0.07436\ttest-error:0.12819                             \n",
      "\n",
      "[56]\ttrain-error:0.07356\ttest-error:0.12869                             \n",
      "\n",
      "[57]\ttrain-error:0.07288\ttest-error:0.12862                             \n",
      "\n",
      "[58]\ttrain-error:0.07233\ttest-error:0.12875                             \n",
      "\n",
      "[59]\ttrain-error:0.07159\ttest-error:0.12899                             \n",
      "\n",
      "[60]\ttrain-error:0.07113\ttest-error:0.12930                             \n",
      "\n",
      "[61]\ttrain-error:0.07030\ttest-error:0.12979                             \n",
      "\n",
      "[62]\ttrain-error:0.06960\ttest-error:0.12948                             \n",
      "\n",
      "[63]\ttrain-error:0.06907\ttest-error:0.12942                             \n",
      "\n",
      "[64]\ttrain-error:0.06843\ttest-error:0.12924                             \n",
      "\n",
      "[65]\ttrain-error:0.06720\ttest-error:0.12930                             \n",
      "\n",
      "[66]\ttrain-error:0.06665\ttest-error:0.12991                             \n",
      "\n",
      "[67]\ttrain-error:0.06612\ttest-error:0.12912                             \n",
      "\n",
      "[68]\ttrain-error:0.06560\ttest-error:0.12918                             \n",
      "\n",
      "[69]\ttrain-error:0.06523\ttest-error:0.12948                             \n",
      "\n",
      "[70]\ttrain-error:0.06440\ttest-error:0.12961                             \n",
      "\n",
      "[71]\ttrain-error:0.06425\ttest-error:0.12985                             \n",
      "\n",
      "[72]\ttrain-error:0.06364\ttest-error:0.12973                             \n",
      "\n",
      "[73]\ttrain-error:0.06268\ttest-error:0.13034                             \n",
      "\n",
      "[74]\ttrain-error:0.06216\ttest-error:0.13016                             \n",
      "\n",
      "[75]\ttrain-error:0.06124\ttest-error:0.12991                             \n",
      "\n",
      "[76]\ttrain-error:0.06090\ttest-error:0.13022                             \n",
      "\n",
      "[77]\ttrain-error:0.06032\ttest-error:0.13053                             \n",
      "\n",
      "[78]\ttrain-error:0.05949\ttest-error:0.13065                             \n",
      "\n",
      "[79]\ttrain-error:0.05863\ttest-error:0.13096                             \n",
      "\n",
      "[80]\ttrain-error:0.05814\ttest-error:0.13053                             \n",
      "\n",
      "[81]\ttrain-error:0.05749\ttest-error:0.12979                             \n",
      "\n",
      "[82]\ttrain-error:0.05639\ttest-error:0.13028                             \n",
      "\n",
      "[83]\ttrain-error:0.05541\ttest-error:0.13047                             \n",
      "\n",
      "[84]\ttrain-error:0.05498\ttest-error:0.13053                             \n",
      "\n",
      "[85]\ttrain-error:0.05442\ttest-error:0.13065                             \n",
      "\n",
      "[86]\ttrain-error:0.05390\ttest-error:0.13077                             \n",
      "\n",
      "[87]\ttrain-error:0.05344\ttest-error:0.13126                             \n",
      "\n",
      "[88]\ttrain-error:0.05273\ttest-error:0.13090                             \n",
      "\n",
      "[89]\ttrain-error:0.05221\ttest-error:0.13108                             \n",
      "\n",
      "[90]\ttrain-error:0.05175\ttest-error:0.13151                             \n",
      "\n",
      "[91]\ttrain-error:0.05111\ttest-error:0.13188                             \n",
      "\n",
      "[92]\ttrain-error:0.05034\ttest-error:0.13145                             \n",
      "\n",
      "[93]\ttrain-error:0.04982\ttest-error:0.13114                             \n",
      "\n",
      "[94]\ttrain-error:0.04899\ttest-error:0.13102                             \n",
      "\n",
      "[95]\ttrain-error:0.04776\ttest-error:0.13096                             \n",
      "\n",
      "[96]\ttrain-error:0.04720\ttest-error:0.13176                             \n",
      "\n",
      "[97]\ttrain-error:0.04674\ttest-error:0.13182                             \n",
      "\n",
      "[98]\ttrain-error:0.04598\ttest-error:0.13182                             \n",
      "\n",
      "[99]\ttrain-error:0.04539\ttest-error:0.13280                             \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.6965880756550744, 'colsample_bytree': 0.7288065148595675, 'eta': 0.08455772738520137, 'eval_metric': ('error',), 'extra_dims': 1, 'gamma': 0, 'lambda': 6.228730619073351, 'max_depth': 9, 'min_child_weight': 0.0009820549035399122, 'objective': 'binary:logistic', 'subsample': 0.7722745400408453}\n",
      "Overwriting param `num_class`                                           \n",
      "Overwriting param `objective` while setting `obj` in train.             \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                 \n",
      "Setting param `disable_default_eval_metric` to 1.                       \n",
      "[22:48:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13980\ttest-error:0.14244                              \n",
      "\n",
      "[1]\ttrain-error:0.13894\ttest-error:0.14060                              \n",
      "\n",
      "[2]\ttrain-error:0.13695\ttest-error:0.13814                              \n",
      "\n",
      "[3]\ttrain-error:0.13658\ttest-error:0.13753                              \n",
      "\n",
      "[4]\ttrain-error:0.13563\ttest-error:0.13655                              \n",
      "\n",
      "[5]\ttrain-error:0.13526\ttest-error:0.13550                              \n",
      "\n",
      "[6]\ttrain-error:0.13339\ttest-error:0.13483                              \n",
      "\n",
      "[7]\ttrain-error:0.13388\ttest-error:0.13464                              \n",
      "\n",
      "[8]\ttrain-error:0.13314\ttest-error:0.13403                              \n",
      "\n",
      "[9]\ttrain-error:0.13292\ttest-error:0.13409                              \n",
      "\n",
      "[10]\ttrain-error:0.13219\ttest-error:0.13354                             \n",
      "\n",
      "[11]\ttrain-error:0.13139\ttest-error:0.13323                             \n",
      "\n",
      "[12]\ttrain-error:0.13093\ttest-error:0.13311                             \n",
      "\n",
      "[13]\ttrain-error:0.13105\ttest-error:0.13317                             \n",
      "\n",
      "[14]\ttrain-error:0.13090\ttest-error:0.13305                             \n",
      "\n",
      "[15]\ttrain-error:0.13040\ttest-error:0.13176                             \n",
      "\n",
      "[16]\ttrain-error:0.12985\ttest-error:0.13225                             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17]\ttrain-error:0.12958\ttest-error:0.13157                             \n",
      "\n",
      "[18]\ttrain-error:0.12869\ttest-error:0.13170                             \n",
      "\n",
      "[19]\ttrain-error:0.12826\ttest-error:0.13176                             \n",
      "\n",
      "[20]\ttrain-error:0.12813\ttest-error:0.13145                             \n",
      "\n",
      "[21]\ttrain-error:0.12773\ttest-error:0.13120                             \n",
      "\n",
      "[22]\ttrain-error:0.12724\ttest-error:0.13084                             \n",
      "\n",
      "[23]\ttrain-error:0.12690\ttest-error:0.13047                             \n",
      "\n",
      "[24]\ttrain-error:0.12675\ttest-error:0.13065                             \n",
      "\n",
      "[25]\ttrain-error:0.12651\ttest-error:0.13047                             \n",
      "\n",
      "[26]\ttrain-error:0.12623\ttest-error:0.13010                             \n",
      "\n",
      "[27]\ttrain-error:0.12565\ttest-error:0.12991                             \n",
      "\n",
      "[28]\ttrain-error:0.12525\ttest-error:0.13016                             \n",
      "\n",
      "[29]\ttrain-error:0.12457\ttest-error:0.12998                             \n",
      "\n",
      "[30]\ttrain-error:0.12399\ttest-error:0.12942                             \n",
      "\n",
      "[31]\ttrain-error:0.12371\ttest-error:0.12942                             \n",
      "\n",
      "[32]\ttrain-error:0.12356\ttest-error:0.12942                             \n",
      "\n",
      "[33]\ttrain-error:0.12328\ttest-error:0.12924                             \n",
      "\n",
      "[34]\ttrain-error:0.12285\ttest-error:0.12856                             \n",
      "\n",
      "[35]\ttrain-error:0.12251\ttest-error:0.12832                             \n",
      "\n",
      "[36]\ttrain-error:0.12230\ttest-error:0.12819                             \n",
      "\n",
      "[37]\ttrain-error:0.12242\ttest-error:0.12813                             \n",
      "\n",
      "[38]\ttrain-error:0.12217\ttest-error:0.12832                             \n",
      "\n",
      "[39]\ttrain-error:0.12187\ttest-error:0.12813                             \n",
      "\n",
      "[40]\ttrain-error:0.12107\ttest-error:0.12838                             \n",
      "\n",
      "[41]\ttrain-error:0.12079\ttest-error:0.12875                             \n",
      "\n",
      "[42]\ttrain-error:0.12076\ttest-error:0.12856                             \n",
      "\n",
      "[43]\ttrain-error:0.12046\ttest-error:0.12838                             \n",
      "\n",
      "[44]\ttrain-error:0.12046\ttest-error:0.12813                             \n",
      "\n",
      "[45]\ttrain-error:0.12036\ttest-error:0.12801                             \n",
      "\n",
      "[46]\ttrain-error:0.12003\ttest-error:0.12783                             \n",
      "\n",
      "[47]\ttrain-error:0.11966\ttest-error:0.12770                             \n",
      "\n",
      "[48]\ttrain-error:0.11962\ttest-error:0.12776                             \n",
      "\n",
      "[49]\ttrain-error:0.11962\ttest-error:0.12783                             \n",
      "\n",
      "[50]\ttrain-error:0.11947\ttest-error:0.12758                             \n",
      "\n",
      "[51]\ttrain-error:0.11929\ttest-error:0.12740                             \n",
      "\n",
      "[52]\ttrain-error:0.11895\ttest-error:0.12789                             \n",
      "\n",
      "[53]\ttrain-error:0.11870\ttest-error:0.12826                             \n",
      "\n",
      "[54]\ttrain-error:0.11861\ttest-error:0.12813                             \n",
      "\n",
      "[55]\ttrain-error:0.11815\ttest-error:0.12746                             \n",
      "\n",
      "[56]\ttrain-error:0.11818\ttest-error:0.12770                             \n",
      "\n",
      "[57]\ttrain-error:0.11800\ttest-error:0.12764                             \n",
      "\n",
      "[58]\ttrain-error:0.11787\ttest-error:0.12770                             \n",
      "\n",
      "[59]\ttrain-error:0.11769\ttest-error:0.12740                             \n",
      "\n",
      "[60]\ttrain-error:0.11741\ttest-error:0.12770                             \n",
      "\n",
      "[61]\ttrain-error:0.11726\ttest-error:0.12801                             \n",
      "\n",
      "[62]\ttrain-error:0.11720\ttest-error:0.12764                             \n",
      "\n",
      "[63]\ttrain-error:0.11714\ttest-error:0.12758                             \n",
      "\n",
      "[64]\ttrain-error:0.11665\ttest-error:0.12795                             \n",
      "\n",
      "[65]\ttrain-error:0.11625\ttest-error:0.12770                             \n",
      "\n",
      "[66]\ttrain-error:0.11628\ttest-error:0.12770                             \n",
      "\n",
      "[67]\ttrain-error:0.11615\ttest-error:0.12807                             \n",
      "\n",
      "[68]\ttrain-error:0.11585\ttest-error:0.12776                             \n",
      "\n",
      "[69]\ttrain-error:0.11600\ttest-error:0.12758                             \n",
      "\n",
      "[70]\ttrain-error:0.11600\ttest-error:0.12783                             \n",
      "\n",
      "[71]\ttrain-error:0.11557\ttest-error:0.12770                             \n",
      "\n",
      "[72]\ttrain-error:0.11563\ttest-error:0.12764                             \n",
      "\n",
      "[73]\ttrain-error:0.11545\ttest-error:0.12740                             \n",
      "\n",
      "[74]\ttrain-error:0.11508\ttest-error:0.12733                             \n",
      "\n",
      "[75]\ttrain-error:0.11493\ttest-error:0.12733                             \n",
      "\n",
      "[76]\ttrain-error:0.11508\ttest-error:0.12752                             \n",
      "\n",
      "[77]\ttrain-error:0.11496\ttest-error:0.12770                             \n",
      "\n",
      "[78]\ttrain-error:0.11480\ttest-error:0.12795                             \n",
      "\n",
      "[79]\ttrain-error:0.11456\ttest-error:0.12764                             \n",
      "\n",
      "[80]\ttrain-error:0.11434\ttest-error:0.12807                             \n",
      "\n",
      "[81]\ttrain-error:0.11416\ttest-error:0.12770                             \n",
      "\n",
      "[82]\ttrain-error:0.11404\ttest-error:0.12740                             \n",
      "\n",
      "[83]\ttrain-error:0.11407\ttest-error:0.12740                             \n",
      "\n",
      "[84]\ttrain-error:0.11397\ttest-error:0.12752                             \n",
      "\n",
      "[85]\ttrain-error:0.11361\ttest-error:0.12703                             \n",
      "\n",
      "[86]\ttrain-error:0.11330\ttest-error:0.12678                             \n",
      "\n",
      "[87]\ttrain-error:0.11336\ttest-error:0.12697                             \n",
      "\n",
      "[88]\ttrain-error:0.11308\ttest-error:0.12684                             \n",
      "\n",
      "[89]\ttrain-error:0.11287\ttest-error:0.12709                             \n",
      "\n",
      "[90]\ttrain-error:0.11275\ttest-error:0.12709                             \n",
      "\n",
      "[91]\ttrain-error:0.11275\ttest-error:0.12697                             \n",
      "\n",
      "[92]\ttrain-error:0.11265\ttest-error:0.12690                             \n",
      "\n",
      "[93]\ttrain-error:0.11247\ttest-error:0.12678                             \n",
      "\n",
      "[94]\ttrain-error:0.11235\ttest-error:0.12733                             \n",
      "\n",
      "[95]\ttrain-error:0.11241\ttest-error:0.12740                             \n",
      "\n",
      "[96]\ttrain-error:0.11232\ttest-error:0.12746                             \n",
      "\n",
      "[97]\ttrain-error:0.11216\ttest-error:0.12740                             \n",
      "\n",
      "[98]\ttrain-error:0.11195\ttest-error:0.12758                             \n",
      "\n",
      "[99]\ttrain-error:0.11195\ttest-error:0.12758                             \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.9426086199411045, 'colsample_bytree': 0.6394428062401094, 'eta': 0.9047612196961812, 'eval_metric': ('error',), 'extra_dims': 10, 'gamma': 0.0020812533223371977, 'lambda': 0.10307145471500108, 'max_depth': 2, 'min_child_weight': 1.610259949233978e-05, 'objective': 'binary:logistic', 'subsample': 0.9715286544570794}\n",
      "Overwriting param `num_class`                                           \n",
      "Overwriting param `objective` while setting `obj` in train.             \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                 \n",
      "Setting param `disable_default_eval_metric` to 1.                       \n",
      "[22:49:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15710\ttest-error:0.15743                              \n",
      "\n",
      "[1]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[2]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[3]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[4]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[5]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[6]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[7]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[8]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[9]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[10]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[11]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[13]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[14]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[15]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[16]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[17]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[18]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[19]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[20]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[21]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[22]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[23]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[24]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[25]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[26]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[27]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[28]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[29]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[30]\ttrain-error:0.25384\ttest-error:0.25154                             \n",
      "\n",
      "[31]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[32]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[33]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[34]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[35]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[36]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[37]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[38]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[39]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[40]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[41]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[42]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[43]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[44]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[45]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[46]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[47]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[48]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[49]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[50]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[51]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[52]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[53]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[54]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[55]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[56]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[57]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[58]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[59]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[60]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[61]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[62]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[63]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[64]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[65]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[66]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[67]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[68]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[69]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[70]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[71]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[72]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[73]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[74]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[75]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[76]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[77]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[78]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[79]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[80]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[81]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[82]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[83]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[84]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[85]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[86]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[87]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[88]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[89]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[90]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[91]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[92]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[93]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[94]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[95]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[96]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[97]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[98]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[99]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "{'alpha': 0, 'btype': 'I', 'colsample_bylevel': 0.6667451872018769, 'colsample_bytree': 0.571270630266237, 'eta': 0.022787885700040054, 'eval_metric': ('error',), 'extra_dims': 11, 'gamma': 0, 'lambda': 0.0007546978780310646, 'max_depth': 3, 'min_child_weight': 0.008830117091130029, 'objective': 'binary:logistic', 'subsample': 0.8319140474534461}\n",
      "Overwriting param `num_class`                                           \n",
      "Overwriting param `objective` while setting `obj` in train.             \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                 \n",
      "Setting param `disable_default_eval_metric` to 1.                       \n",
      "[22:50:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15464\ttest-error:0.15430                              \n",
      "\n",
      "[1]\ttrain-error:0.16179\ttest-error:0.16050                              \n",
      "\n",
      "[2]\ttrain-error:0.15421\ttest-error:0.15399                              \n",
      "\n",
      "[3]\ttrain-error:0.15132\ttest-error:0.15092                              \n",
      "\n",
      "[4]\ttrain-error:0.15227\ttest-error:0.15135                              \n",
      "\n",
      "[5]\ttrain-error:0.15138\ttest-error:0.15031                              \n",
      "\n",
      "[6]\ttrain-error:0.14948\ttest-error:0.14865                              \n",
      "\n",
      "[7]\ttrain-error:0.14819\ttest-error:0.14767                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain-error:0.14748\ttest-error:0.14687                              \n",
      "\n",
      "[9]\ttrain-error:0.14588\ttest-error:0.14429                              \n",
      "\n",
      "[10]\ttrain-error:0.14466\ttest-error:0.14355                             \n",
      "\n",
      "[11]\ttrain-error:0.14426\ttest-error:0.14294                             \n",
      "\n",
      "[12]\ttrain-error:0.14429\ttest-error:0.14275                             \n",
      "\n",
      "[13]\ttrain-error:0.14404\ttest-error:0.14281                             \n",
      "\n",
      "[14]\ttrain-error:0.14383\ttest-error:0.14244                             \n",
      "\n",
      "[15]\ttrain-error:0.14278\ttest-error:0.14165                             \n",
      "\n",
      "[16]\ttrain-error:0.14278\ttest-error:0.14146                             \n",
      "\n",
      "[17]\ttrain-error:0.14226\ttest-error:0.14079                             \n",
      "\n",
      "[18]\ttrain-error:0.14208\ttest-error:0.14066                             \n",
      "\n",
      "[19]\ttrain-error:0.14189\ttest-error:0.13999                             \n",
      "\n",
      "[20]\ttrain-error:0.14122\ttest-error:0.13974                             \n",
      "\n",
      "[21]\ttrain-error:0.14100\ttest-error:0.13919                             \n",
      "\n",
      "[22]\ttrain-error:0.14085\ttest-error:0.13876                             \n",
      "\n",
      "[23]\ttrain-error:0.14036\ttest-error:0.13814                             \n",
      "\n",
      "[24]\ttrain-error:0.13959\ttest-error:0.13728                             \n",
      "\n",
      "[25]\ttrain-error:0.13959\ttest-error:0.13630                             \n",
      "\n",
      "[26]\ttrain-error:0.13928\ttest-error:0.13556                             \n",
      "\n",
      "[27]\ttrain-error:0.13900\ttest-error:0.13514                             \n",
      "\n",
      "[28]\ttrain-error:0.13870\ttest-error:0.13526                             \n",
      "\n",
      "[29]\ttrain-error:0.13845\ttest-error:0.13495                             \n",
      "\n",
      "[30]\ttrain-error:0.13778\ttest-error:0.13458                             \n",
      "\n",
      "[31]\ttrain-error:0.13713\ttest-error:0.13348                             \n",
      "\n",
      "[32]\ttrain-error:0.13682\ttest-error:0.13348                             \n",
      "\n",
      "[33]\ttrain-error:0.13630\ttest-error:0.13286                             \n",
      "\n",
      "[34]\ttrain-error:0.13590\ttest-error:0.13274                             \n",
      "\n",
      "[35]\ttrain-error:0.13550\ttest-error:0.13274                             \n",
      "\n",
      "[36]\ttrain-error:0.13495\ttest-error:0.13280                             \n",
      "\n",
      "[37]\ttrain-error:0.13440\ttest-error:0.13274                             \n",
      "\n",
      "[38]\ttrain-error:0.13403\ttest-error:0.13200                             \n",
      "\n",
      "[39]\ttrain-error:0.13369\ttest-error:0.13188                             \n",
      "\n",
      "[40]\ttrain-error:0.13314\ttest-error:0.13170                             \n",
      "\n",
      "[41]\ttrain-error:0.13289\ttest-error:0.13163                             \n",
      "\n",
      "[42]\ttrain-error:0.13259\ttest-error:0.13126                             \n",
      "\n",
      "[43]\ttrain-error:0.13231\ttest-error:0.13108                             \n",
      "\n",
      "[44]\ttrain-error:0.13209\ttest-error:0.13108                             \n",
      "\n",
      "[45]\ttrain-error:0.13151\ttest-error:0.13084                             \n",
      "\n",
      "[46]\ttrain-error:0.13130\ttest-error:0.13071                             \n",
      "\n",
      "[47]\ttrain-error:0.13117\ttest-error:0.13071                             \n",
      "\n",
      "[48]\ttrain-error:0.13077\ttest-error:0.13028                             \n",
      "\n",
      "[49]\ttrain-error:0.13065\ttest-error:0.12979                             \n",
      "\n",
      "[50]\ttrain-error:0.13031\ttest-error:0.12973                             \n",
      "\n",
      "[51]\ttrain-error:0.13034\ttest-error:0.12998                             \n",
      "\n",
      "[52]\ttrain-error:0.12998\ttest-error:0.12954                             \n",
      "\n",
      "[53]\ttrain-error:0.12998\ttest-error:0.12961                             \n",
      "\n",
      "[54]\ttrain-error:0.12967\ttest-error:0.12948                             \n",
      "\n",
      "[55]\ttrain-error:0.12930\ttest-error:0.12967                             \n",
      "\n",
      "[56]\ttrain-error:0.12909\ttest-error:0.12930                             \n",
      "\n",
      "[57]\ttrain-error:0.12856\ttest-error:0.12930                             \n",
      "\n",
      "[58]\ttrain-error:0.12859\ttest-error:0.12875                             \n",
      "\n",
      "[59]\ttrain-error:0.12841\ttest-error:0.12881                             \n",
      "\n",
      "[60]\ttrain-error:0.12816\ttest-error:0.12869                             \n",
      "\n",
      "[61]\ttrain-error:0.12798\ttest-error:0.12862                             \n",
      "\n",
      "[62]\ttrain-error:0.12783\ttest-error:0.12887                             \n",
      "\n",
      "[63]\ttrain-error:0.12789\ttest-error:0.12826                             \n",
      "\n",
      "[64]\ttrain-error:0.12783\ttest-error:0.12832                             \n",
      "\n",
      "[65]\ttrain-error:0.12764\ttest-error:0.12850                             \n",
      "\n",
      "[66]\ttrain-error:0.12743\ttest-error:0.12856                             \n",
      "\n",
      "[67]\ttrain-error:0.12703\ttest-error:0.12832                             \n",
      "\n",
      "[68]\ttrain-error:0.12693\ttest-error:0.12832                             \n",
      "\n",
      "[69]\ttrain-error:0.12700\ttest-error:0.12856                             \n",
      "\n",
      "[70]\ttrain-error:0.12669\ttest-error:0.12826                             \n",
      "\n",
      "[71]\ttrain-error:0.12651\ttest-error:0.12807                             \n",
      "\n",
      "[72]\ttrain-error:0.12644\ttest-error:0.12813                             \n",
      "\n",
      "[73]\ttrain-error:0.12632\ttest-error:0.12819                             \n",
      "\n",
      "[74]\ttrain-error:0.12632\ttest-error:0.12813                             \n",
      "\n",
      "[75]\ttrain-error:0.12611\ttest-error:0.12813                             \n",
      "\n",
      "[76]\ttrain-error:0.12589\ttest-error:0.12807                             \n",
      "\n",
      "[77]\ttrain-error:0.12574\ttest-error:0.12813                             \n",
      "\n",
      "[78]\ttrain-error:0.12552\ttest-error:0.12801                             \n",
      "\n",
      "[79]\ttrain-error:0.12521\ttest-error:0.12826                             \n",
      "\n",
      "[80]\ttrain-error:0.12509\ttest-error:0.12807                             \n",
      "\n",
      "[81]\ttrain-error:0.12506\ttest-error:0.12819                             \n",
      "\n",
      "[82]\ttrain-error:0.12503\ttest-error:0.12807                             \n",
      "\n",
      "[83]\ttrain-error:0.12475\ttest-error:0.12807                             \n",
      "\n",
      "[84]\ttrain-error:0.12478\ttest-error:0.12789                             \n",
      "\n",
      "[85]\ttrain-error:0.12460\ttest-error:0.12764                             \n",
      "\n",
      "[86]\ttrain-error:0.12469\ttest-error:0.12776                             \n",
      "\n",
      "[87]\ttrain-error:0.12442\ttest-error:0.12783                             \n",
      "\n",
      "[88]\ttrain-error:0.12435\ttest-error:0.12746                             \n",
      "\n",
      "[89]\ttrain-error:0.12417\ttest-error:0.12746                             \n",
      "\n",
      "[90]\ttrain-error:0.12411\ttest-error:0.12703                             \n",
      "\n",
      "[91]\ttrain-error:0.12405\ttest-error:0.12690                             \n",
      "\n",
      "[92]\ttrain-error:0.12386\ttest-error:0.12672                             \n",
      "\n",
      "[93]\ttrain-error:0.12377\ttest-error:0.12684                             \n",
      "\n",
      "[94]\ttrain-error:0.12377\ttest-error:0.12666                             \n",
      "\n",
      "[95]\ttrain-error:0.12377\ttest-error:0.12654                             \n",
      "\n",
      "[96]\ttrain-error:0.12386\ttest-error:0.12666                             \n",
      "\n",
      "[97]\ttrain-error:0.12371\ttest-error:0.12629                             \n",
      "\n",
      "[98]\ttrain-error:0.12353\ttest-error:0.12617                             \n",
      "\n",
      "[99]\ttrain-error:0.12343\ttest-error:0.12647                             \n",
      "\n",
      "{'alpha': 0, 'btype': 'In', 'colsample_bylevel': 0.8751288346700629, 'colsample_bytree': 0.9000694080950027, 'eta': 0.2092639503761344, 'eval_metric': ('error',), 'extra_dims': 13, 'gamma': 2.8695177423433465e-06, 'lambda': 0.005300219421148002, 'max_depth': 7, 'min_child_weight': 0.5638652697851314, 'objective': 'binary:logistic', 'subsample': 0.8108755488625266}\n",
      "Overwriting param `num_class`                                           \n",
      "Overwriting param `objective` while setting `obj` in train.             \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                 \n",
      "Setting param `disable_default_eval_metric` to 1.                       \n",
      "[22:51:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15605\ttest-error:0.15602                              \n",
      "\n",
      "[1]\ttrain-error:0.75169\ttest-error:0.75626                              \n",
      "\n",
      "[2]\ttrain-error:0.18526\ttest-error:0.18206                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\ttrain-error:0.62657\ttest-error:0.62832                              \n",
      "\n",
      "[4]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[5]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[6]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[7]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[8]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[9]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[10]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[11]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[12]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[13]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[14]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[15]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[16]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[17]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[18]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[19]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[20]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[21]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[22]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[23]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[24]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[25]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[26]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[27]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[28]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[29]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[30]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[31]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[32]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[33]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[34]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[35]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[36]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[37]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[38]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[39]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[40]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[41]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[42]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[43]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[44]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[45]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[46]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[47]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[48]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[49]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[50]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[51]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[52]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[53]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[54]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[55]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[56]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[57]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[58]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[59]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[60]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[61]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[62]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[63]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[64]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[65]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[66]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[67]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[68]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[69]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[70]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[71]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[72]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[73]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[74]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[75]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[76]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[77]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[78]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[79]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[80]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[81]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[82]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[83]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[84]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[85]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[86]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[87]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[88]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[89]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[90]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[91]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[92]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[93]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[94]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[95]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[96]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[97]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[98]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[99]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.778618829431884, 'colsample_bytree': 0.8378336894966871, 'eta': 0.006356582663278299, 'eval_metric': ('error',), 'extra_dims': 9, 'gamma': 0, 'lambda': 4.4562389336758164e-05, 'max_depth': 6, 'min_child_weight': 0.2039627478637734, 'objective': 'binary:logistic', 'subsample': 0.9714671436701058}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[22:52:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.14247\ttest-error:0.14300                                \n",
      "\n",
      "[1]\ttrain-error:0.14244\ttest-error:0.14306                                \n",
      "\n",
      "[2]\ttrain-error:0.14241\ttest-error:0.14312                                \n",
      "\n",
      "[3]\ttrain-error:0.14208\ttest-error:0.14238                                \n",
      "\n",
      "[4]\ttrain-error:0.14174\ttest-error:0.14238                                \n",
      "\n",
      "[5]\ttrain-error:0.14183\ttest-error:0.14214                                \n",
      "\n",
      "[6]\ttrain-error:0.14171\ttest-error:0.14232                                \n",
      "\n",
      "[7]\ttrain-error:0.14109\ttest-error:0.14165                                \n",
      "\n",
      "[8]\ttrain-error:0.14103\ttest-error:0.14171                                \n",
      "\n",
      "[9]\ttrain-error:0.14082\ttest-error:0.14152                                \n",
      "\n",
      "[10]\ttrain-error:0.14072\ttest-error:0.14122                               \n",
      "\n",
      "[11]\ttrain-error:0.14042\ttest-error:0.14146                               \n",
      "\n",
      "[12]\ttrain-error:0.13996\ttest-error:0.14122                               \n",
      "\n",
      "[13]\ttrain-error:0.13947\ttest-error:0.14066                               \n",
      "\n",
      "[14]\ttrain-error:0.13867\ttest-error:0.13993                               \n",
      "\n",
      "[15]\ttrain-error:0.13799\ttest-error:0.13864                               \n",
      "\n",
      "[16]\ttrain-error:0.13765\ttest-error:0.13772                               \n",
      "\n",
      "[17]\ttrain-error:0.13744\ttest-error:0.13784                               \n",
      "\n",
      "[18]\ttrain-error:0.13741\ttest-error:0.13765                               \n",
      "\n",
      "[19]\ttrain-error:0.13735\ttest-error:0.13692                               \n",
      "\n",
      "[20]\ttrain-error:0.13710\ttest-error:0.13698                               \n",
      "\n",
      "[21]\ttrain-error:0.13701\ttest-error:0.13710                               \n",
      "\n",
      "[22]\ttrain-error:0.13661\ttest-error:0.13728                               \n",
      "\n",
      "[23]\ttrain-error:0.13596\ttest-error:0.13655                               \n",
      "\n",
      "[24]\ttrain-error:0.13603\ttest-error:0.13655                               \n",
      "\n",
      "[25]\ttrain-error:0.13590\ttest-error:0.13606                               \n",
      "\n",
      "[26]\ttrain-error:0.13566\ttest-error:0.13581                               \n",
      "\n",
      "[27]\ttrain-error:0.13544\ttest-error:0.13563                               \n",
      "\n",
      "[28]\ttrain-error:0.13526\ttest-error:0.13507                               \n",
      "\n",
      "[29]\ttrain-error:0.13507\ttest-error:0.13458                               \n",
      "\n",
      "[30]\ttrain-error:0.13510\ttest-error:0.13446                               \n",
      "\n",
      "[31]\ttrain-error:0.13474\ttest-error:0.13403                               \n",
      "\n",
      "[32]\ttrain-error:0.13440\ttest-error:0.13409                               \n",
      "\n",
      "[33]\ttrain-error:0.13397\ttest-error:0.13397                               \n",
      "\n",
      "[34]\ttrain-error:0.13360\ttest-error:0.13366                               \n",
      "\n",
      "[35]\ttrain-error:0.13345\ttest-error:0.13335                               \n",
      "\n",
      "[36]\ttrain-error:0.13314\ttest-error:0.13311                               \n",
      "\n",
      "[37]\ttrain-error:0.13295\ttest-error:0.13317                               \n",
      "\n",
      "[38]\ttrain-error:0.13308\ttest-error:0.13298                               \n",
      "\n",
      "[39]\ttrain-error:0.13305\ttest-error:0.13280                               \n",
      "\n",
      "[40]\ttrain-error:0.13292\ttest-error:0.13286                               \n",
      "\n",
      "[41]\ttrain-error:0.13292\ttest-error:0.13268                               \n",
      "\n",
      "[42]\ttrain-error:0.13271\ttest-error:0.13225                               \n",
      "\n",
      "[43]\ttrain-error:0.13253\ttest-error:0.13243                               \n",
      "\n",
      "[44]\ttrain-error:0.13249\ttest-error:0.13231                               \n",
      "\n",
      "[45]\ttrain-error:0.13216\ttest-error:0.13249                               \n",
      "\n",
      "[46]\ttrain-error:0.13200\ttest-error:0.13225                               \n",
      "\n",
      "[47]\ttrain-error:0.13148\ttest-error:0.13176                               \n",
      "\n",
      "[48]\ttrain-error:0.13154\ttest-error:0.13108                               \n",
      "\n",
      "[49]\ttrain-error:0.13160\ttest-error:0.13114                               \n",
      "\n",
      "[50]\ttrain-error:0.13120\ttest-error:0.13090                               \n",
      "\n",
      "[51]\ttrain-error:0.13090\ttest-error:0.13102                               \n",
      "\n",
      "[52]\ttrain-error:0.13093\ttest-error:0.13071                               \n",
      "\n",
      "[53]\ttrain-error:0.13081\ttest-error:0.13077                               \n",
      "\n",
      "[54]\ttrain-error:0.13090\ttest-error:0.13077                               \n",
      "\n",
      "[55]\ttrain-error:0.13081\ttest-error:0.13077                               \n",
      "\n",
      "[56]\ttrain-error:0.13044\ttest-error:0.13071                               \n",
      "\n",
      "[57]\ttrain-error:0.13004\ttest-error:0.13047                               \n",
      "\n",
      "[58]\ttrain-error:0.13001\ttest-error:0.12998                               \n",
      "\n",
      "[59]\ttrain-error:0.12991\ttest-error:0.12973                               \n",
      "\n",
      "[60]\ttrain-error:0.12958\ttest-error:0.12961                               \n",
      "\n",
      "[61]\ttrain-error:0.12958\ttest-error:0.12948                               \n",
      "\n",
      "[62]\ttrain-error:0.12954\ttest-error:0.12942                               \n",
      "\n",
      "[63]\ttrain-error:0.12924\ttest-error:0.12924                               \n",
      "\n",
      "[64]\ttrain-error:0.12918\ttest-error:0.12912                               \n",
      "\n",
      "[65]\ttrain-error:0.12887\ttest-error:0.12875                               \n",
      "\n",
      "[66]\ttrain-error:0.12878\ttest-error:0.12881                               \n",
      "\n",
      "[67]\ttrain-error:0.12869\ttest-error:0.12875                               \n",
      "\n",
      "[68]\ttrain-error:0.12847\ttest-error:0.12869                               \n",
      "\n",
      "[69]\ttrain-error:0.12853\ttest-error:0.12875                               \n",
      "\n",
      "[70]\ttrain-error:0.12813\ttest-error:0.12838                               \n",
      "\n",
      "[71]\ttrain-error:0.12801\ttest-error:0.12813                               \n",
      "\n",
      "[72]\ttrain-error:0.12776\ttest-error:0.12838                               \n",
      "\n",
      "[73]\ttrain-error:0.12743\ttest-error:0.12807                               \n",
      "\n",
      "[74]\ttrain-error:0.12724\ttest-error:0.12764                               \n",
      "\n",
      "[75]\ttrain-error:0.12697\ttest-error:0.12746                               \n",
      "\n",
      "[76]\ttrain-error:0.12681\ttest-error:0.12752                               \n",
      "\n",
      "[77]\ttrain-error:0.12663\ttest-error:0.12740                               \n",
      "\n",
      "[78]\ttrain-error:0.12638\ttest-error:0.12727                               \n",
      "\n",
      "[79]\ttrain-error:0.12620\ttest-error:0.12709                               \n",
      "\n",
      "[80]\ttrain-error:0.12598\ttest-error:0.12684                               \n",
      "\n",
      "[81]\ttrain-error:0.12558\ttest-error:0.12635                               \n",
      "\n",
      "[82]\ttrain-error:0.12518\ttest-error:0.12672                               \n",
      "\n",
      "[83]\ttrain-error:0.12494\ttest-error:0.12666                               \n",
      "\n",
      "[84]\ttrain-error:0.12469\ttest-error:0.12654                               \n",
      "\n",
      "[85]\ttrain-error:0.12417\ttest-error:0.12641                               \n",
      "\n",
      "[86]\ttrain-error:0.12371\ttest-error:0.12647                               \n",
      "\n",
      "[87]\ttrain-error:0.12334\ttest-error:0.12635                               \n",
      "\n",
      "[88]\ttrain-error:0.12310\ttest-error:0.12611                               \n",
      "\n",
      "[89]\ttrain-error:0.12276\ttest-error:0.12611                               \n",
      "\n",
      "[90]\ttrain-error:0.12260\ttest-error:0.12574                               \n",
      "\n",
      "[91]\ttrain-error:0.12233\ttest-error:0.12574                               \n",
      "\n",
      "[92]\ttrain-error:0.12214\ttest-error:0.12549                               \n",
      "\n",
      "[93]\ttrain-error:0.12224\ttest-error:0.12549                               \n",
      "\n",
      "[94]\ttrain-error:0.12196\ttest-error:0.12561                               \n",
      "\n",
      "[95]\ttrain-error:0.12187\ttest-error:0.12525                               \n",
      "\n",
      "[96]\ttrain-error:0.12159\ttest-error:0.12531                               \n",
      "\n",
      "[97]\ttrain-error:0.12141\ttest-error:0.12531                               \n",
      "\n",
      "[98]\ttrain-error:0.12128\ttest-error:0.12506                               \n",
      "\n",
      "[99]\ttrain-error:0.12122\ttest-error:0.12525                               \n",
      "\n",
      "{'alpha': 2.2878023974065878, 'btype': 'Rn', 'colsample_bylevel': 0.6144591724963042, 'colsample_bytree': 0.6163605466486257, 'eta': 0.06743973510028023, 'eval_metric': ('error',), 'extra_dims': 8, 'gamma': 0, 'lambda': 0, 'max_depth': 5, 'min_child_weight': 0.00013171309721044848, 'objective': 'binary:logistic', 'subsample': 0.9215314705245914}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[22:54:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14524\ttest-error:0.14404                                \n",
      "\n",
      "[1]\ttrain-error:0.14076\ttest-error:0.14140                                \n",
      "\n",
      "[2]\ttrain-error:0.13947\ttest-error:0.13999                                \n",
      "\n",
      "[3]\ttrain-error:0.13990\ttest-error:0.13882                                \n",
      "\n",
      "[4]\ttrain-error:0.13851\ttest-error:0.13679                                \n",
      "\n",
      "[5]\ttrain-error:0.13722\ttest-error:0.13563                                \n",
      "\n",
      "[6]\ttrain-error:0.13603\ttest-error:0.13477                                \n",
      "\n",
      "[7]\ttrain-error:0.13523\ttest-error:0.13298                                \n",
      "\n",
      "[8]\ttrain-error:0.13363\ttest-error:0.13200                                \n",
      "\n",
      "[9]\ttrain-error:0.13145\ttest-error:0.13034                                \n",
      "\n",
      "[10]\ttrain-error:0.13010\ttest-error:0.12881                               \n",
      "\n",
      "[11]\ttrain-error:0.12869\ttest-error:0.12826                               \n",
      "\n",
      "[12]\ttrain-error:0.12752\ttest-error:0.12789                               \n",
      "\n",
      "[13]\ttrain-error:0.12657\ttest-error:0.12746                               \n",
      "\n",
      "[14]\ttrain-error:0.12580\ttest-error:0.12709                               \n",
      "\n",
      "[15]\ttrain-error:0.12488\ttest-error:0.12721                               \n",
      "\n",
      "[16]\ttrain-error:0.12423\ttest-error:0.12660                               \n",
      "\n",
      "[17]\ttrain-error:0.12346\ttest-error:0.12641                               \n",
      "\n",
      "[18]\ttrain-error:0.12294\ttest-error:0.12561                               \n",
      "\n",
      "[19]\ttrain-error:0.12205\ttest-error:0.12494                               \n",
      "\n",
      "[20]\ttrain-error:0.12205\ttest-error:0.12512                               \n",
      "\n",
      "[21]\ttrain-error:0.12150\ttest-error:0.12500                               \n",
      "\n",
      "[22]\ttrain-error:0.12125\ttest-error:0.12506                               \n",
      "\n",
      "[23]\ttrain-error:0.12095\ttest-error:0.12549                               \n",
      "\n",
      "[24]\ttrain-error:0.11981\ttest-error:0.12623                               \n",
      "\n",
      "[25]\ttrain-error:0.11962\ttest-error:0.12617                               \n",
      "\n",
      "[26]\ttrain-error:0.11876\ttest-error:0.12617                               \n",
      "\n",
      "[27]\ttrain-error:0.11858\ttest-error:0.12592                               \n",
      "\n",
      "[28]\ttrain-error:0.11827\ttest-error:0.12604                               \n",
      "\n",
      "[29]\ttrain-error:0.11806\ttest-error:0.12598                               \n",
      "\n",
      "[30]\ttrain-error:0.11818\ttest-error:0.12598                               \n",
      "\n",
      "[31]\ttrain-error:0.11797\ttest-error:0.12568                               \n",
      "\n",
      "[32]\ttrain-error:0.11760\ttest-error:0.12555                               \n",
      "\n",
      "[33]\ttrain-error:0.11726\ttest-error:0.12592                               \n",
      "\n",
      "[34]\ttrain-error:0.11689\ttest-error:0.12549                               \n",
      "\n",
      "[35]\ttrain-error:0.11643\ttest-error:0.12506                               \n",
      "\n",
      "[36]\ttrain-error:0.11588\ttest-error:0.12537                               \n",
      "\n",
      "[37]\ttrain-error:0.11588\ttest-error:0.12580                               \n",
      "\n",
      "[38]\ttrain-error:0.11569\ttest-error:0.12574                               \n",
      "\n",
      "[39]\ttrain-error:0.11539\ttest-error:0.12611                               \n",
      "\n",
      "[40]\ttrain-error:0.11548\ttest-error:0.12611                               \n",
      "\n",
      "[41]\ttrain-error:0.11523\ttest-error:0.12580                               \n",
      "\n",
      "[42]\ttrain-error:0.11480\ttest-error:0.12586                               \n",
      "\n",
      "[43]\ttrain-error:0.11447\ttest-error:0.12592                               \n",
      "\n",
      "[44]\ttrain-error:0.11388\ttest-error:0.12574                               \n",
      "\n",
      "[45]\ttrain-error:0.11339\ttest-error:0.12592                               \n",
      "\n",
      "[46]\ttrain-error:0.11318\ttest-error:0.12586                               \n",
      "\n",
      "[47]\ttrain-error:0.11284\ttest-error:0.12574                               \n",
      "\n",
      "[48]\ttrain-error:0.11268\ttest-error:0.12549                               \n",
      "\n",
      "[49]\ttrain-error:0.11247\ttest-error:0.12537                               \n",
      "\n",
      "[50]\ttrain-error:0.11213\ttest-error:0.12561                               \n",
      "\n",
      "[51]\ttrain-error:0.11204\ttest-error:0.12568                               \n",
      "\n",
      "[52]\ttrain-error:0.11167\ttest-error:0.12598                               \n",
      "\n",
      "[53]\ttrain-error:0.11133\ttest-error:0.12561                               \n",
      "\n",
      "[54]\ttrain-error:0.11103\ttest-error:0.12586                               \n",
      "\n",
      "[55]\ttrain-error:0.11103\ttest-error:0.12586                               \n",
      "\n",
      "[56]\ttrain-error:0.11103\ttest-error:0.12611                               \n",
      "\n",
      "[57]\ttrain-error:0.11053\ttest-error:0.12635                               \n",
      "\n",
      "[58]\ttrain-error:0.11050\ttest-error:0.12666                               \n",
      "\n",
      "[59]\ttrain-error:0.11041\ttest-error:0.12635                               \n",
      "\n",
      "[60]\ttrain-error:0.11013\ttest-error:0.12586                               \n",
      "\n",
      "[61]\ttrain-error:0.11001\ttest-error:0.12611                               \n",
      "\n",
      "[62]\ttrain-error:0.10998\ttest-error:0.12598                               \n",
      "\n",
      "[63]\ttrain-error:0.10983\ttest-error:0.12635                               \n",
      "\n",
      "[64]\ttrain-error:0.10977\ttest-error:0.12580                               \n",
      "\n",
      "[65]\ttrain-error:0.10946\ttest-error:0.12611                               \n",
      "\n",
      "[66]\ttrain-error:0.10943\ttest-error:0.12592                               \n",
      "\n",
      "[67]\ttrain-error:0.10909\ttest-error:0.12604                               \n",
      "\n",
      "[68]\ttrain-error:0.10894\ttest-error:0.12580                               \n",
      "\n",
      "[69]\ttrain-error:0.10857\ttest-error:0.12561                               \n",
      "\n",
      "[70]\ttrain-error:0.10863\ttest-error:0.12586                               \n",
      "\n",
      "[71]\ttrain-error:0.10845\ttest-error:0.12611                               \n",
      "\n",
      "[72]\ttrain-error:0.10832\ttest-error:0.12604                               \n",
      "\n",
      "[73]\ttrain-error:0.10808\ttest-error:0.12617                               \n",
      "\n",
      "[74]\ttrain-error:0.10795\ttest-error:0.12580                               \n",
      "\n",
      "[75]\ttrain-error:0.10737\ttest-error:0.12568                               \n",
      "\n",
      "[76]\ttrain-error:0.10728\ttest-error:0.12561                               \n",
      "\n",
      "[77]\ttrain-error:0.10731\ttest-error:0.12586                               \n",
      "\n",
      "[78]\ttrain-error:0.10700\ttest-error:0.12568                               \n",
      "\n",
      "[79]\ttrain-error:0.10694\ttest-error:0.12561                               \n",
      "\n",
      "[80]\ttrain-error:0.10666\ttest-error:0.12512                               \n",
      "\n",
      "[81]\ttrain-error:0.10651\ttest-error:0.12555                               \n",
      "\n",
      "[82]\ttrain-error:0.10666\ttest-error:0.12586                               \n",
      "\n",
      "[83]\ttrain-error:0.10636\ttest-error:0.12598                               \n",
      "\n",
      "[84]\ttrain-error:0.10608\ttest-error:0.12574                               \n",
      "\n",
      "[85]\ttrain-error:0.10608\ttest-error:0.12623                               \n",
      "\n",
      "[86]\ttrain-error:0.10602\ttest-error:0.12604                               \n",
      "\n",
      "[87]\ttrain-error:0.10577\ttest-error:0.12623                               \n",
      "\n",
      "[88]\ttrain-error:0.10544\ttest-error:0.12666                               \n",
      "\n",
      "[89]\ttrain-error:0.10516\ttest-error:0.12660                               \n",
      "\n",
      "[90]\ttrain-error:0.10476\ttest-error:0.12654                               \n",
      "\n",
      "[91]\ttrain-error:0.10476\ttest-error:0.12684                               \n",
      "\n",
      "[92]\ttrain-error:0.10470\ttest-error:0.12678                               \n",
      "\n",
      "[93]\ttrain-error:0.10467\ttest-error:0.12647                               \n",
      "\n",
      "[94]\ttrain-error:0.10451\ttest-error:0.12690                               \n",
      "\n",
      "[95]\ttrain-error:0.10415\ttest-error:0.12666                               \n",
      "\n",
      "[96]\ttrain-error:0.10424\ttest-error:0.12672                               \n",
      "\n",
      "[97]\ttrain-error:0.10396\ttest-error:0.12672                               \n",
      "\n",
      "[98]\ttrain-error:0.10387\ttest-error:0.12709                               \n",
      "\n",
      "[99]\ttrain-error:0.10344\ttest-error:0.12684                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'In', 'colsample_bylevel': 0.8167398581421182, 'colsample_bytree': 0.7607054587668658, 'eta': 0.000944897496528179, 'eval_metric': ('error',), 'extra_dims': 14, 'gamma': 0.023215801072715887, 'lambda': 0.2705109195763764, 'max_depth': 4, 'min_child_weight': 0.002525251902080359, 'objective': 'binary:logistic', 'subsample': 0.8891980852204241}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[22:55:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14598\ttest-error:0.14736                                \n",
      "\n",
      "[1]\ttrain-error:0.15006\ttest-error:0.14865                                \n",
      "\n",
      "[2]\ttrain-error:0.15071\ttest-error:0.14994                                \n",
      "\n",
      "[3]\ttrain-error:0.15009\ttest-error:0.14969                                \n",
      "\n",
      "[4]\ttrain-error:0.15283\ttest-error:0.15221                                \n",
      "\n",
      "[5]\ttrain-error:0.15341\ttest-error:0.15313                                \n",
      "\n",
      "[6]\ttrain-error:0.15295\ttest-error:0.15240                                \n",
      "\n",
      "[7]\ttrain-error:0.15381\ttest-error:0.15295                                \n",
      "\n",
      "[8]\ttrain-error:0.15347\ttest-error:0.15276                                \n",
      "\n",
      "[9]\ttrain-error:0.15344\ttest-error:0.15221                                \n",
      "\n",
      "[10]\ttrain-error:0.15323\ttest-error:0.15197                               \n",
      "\n",
      "[11]\ttrain-error:0.15246\ttest-error:0.15166                               \n",
      "\n",
      "[12]\ttrain-error:0.15243\ttest-error:0.15172                               \n",
      "\n",
      "[13]\ttrain-error:0.15233\ttest-error:0.15166                               \n",
      "\n",
      "[14]\ttrain-error:0.15246\ttest-error:0.15160                               \n",
      "\n",
      "[15]\ttrain-error:0.15240\ttest-error:0.15154                               \n",
      "\n",
      "[16]\ttrain-error:0.15233\ttest-error:0.15154                               \n",
      "\n",
      "[17]\ttrain-error:0.15243\ttest-error:0.15160                               \n",
      "\n",
      "[18]\ttrain-error:0.15255\ttest-error:0.15154                               \n",
      "\n",
      "[19]\ttrain-error:0.15286\ttest-error:0.15184                               \n",
      "\n",
      "[20]\ttrain-error:0.15243\ttest-error:0.15190                               \n",
      "\n",
      "[21]\ttrain-error:0.15215\ttest-error:0.15160                               \n",
      "\n",
      "[22]\ttrain-error:0.15227\ttest-error:0.15147                               \n",
      "\n",
      "[23]\ttrain-error:0.15206\ttest-error:0.15123                               \n",
      "\n",
      "[24]\ttrain-error:0.15209\ttest-error:0.15086                               \n",
      "\n",
      "[25]\ttrain-error:0.15209\ttest-error:0.15092                               \n",
      "\n",
      "[26]\ttrain-error:0.15209\ttest-error:0.15104                               \n",
      "\n",
      "[27]\ttrain-error:0.15203\ttest-error:0.15080                               \n",
      "\n",
      "[28]\ttrain-error:0.15193\ttest-error:0.15080                               \n",
      "\n",
      "[29]\ttrain-error:0.15190\ttest-error:0.15080                               \n",
      "\n",
      "[30]\ttrain-error:0.15181\ttest-error:0.15086                               \n",
      "\n",
      "[31]\ttrain-error:0.15175\ttest-error:0.15086                               \n",
      "\n",
      "[32]\ttrain-error:0.15169\ttest-error:0.15086                               \n",
      "\n",
      "[33]\ttrain-error:0.15166\ttest-error:0.15086                               \n",
      "\n",
      "[34]\ttrain-error:0.15163\ttest-error:0.15086                               \n",
      "\n",
      "[35]\ttrain-error:0.15157\ttest-error:0.15086                               \n",
      "\n",
      "[36]\ttrain-error:0.15160\ttest-error:0.15086                               \n",
      "\n",
      "[37]\ttrain-error:0.15154\ttest-error:0.15086                               \n",
      "\n",
      "[38]\ttrain-error:0.15138\ttest-error:0.15068                               \n",
      "\n",
      "[39]\ttrain-error:0.15151\ttest-error:0.15049                               \n",
      "\n",
      "[40]\ttrain-error:0.15135\ttest-error:0.15049                               \n",
      "\n",
      "[41]\ttrain-error:0.15120\ttest-error:0.15031                               \n",
      "\n",
      "[42]\ttrain-error:0.15074\ttest-error:0.14975                               \n",
      "\n",
      "[43]\ttrain-error:0.15068\ttest-error:0.14963                               \n",
      "\n",
      "[44]\ttrain-error:0.15058\ttest-error:0.14975                               \n",
      "\n",
      "[45]\ttrain-error:0.15055\ttest-error:0.14982                               \n",
      "\n",
      "[46]\ttrain-error:0.15049\ttest-error:0.14975                               \n",
      "\n",
      "[47]\ttrain-error:0.15031\ttest-error:0.14963                               \n",
      "\n",
      "[48]\ttrain-error:0.14969\ttest-error:0.14945                               \n",
      "\n",
      "[49]\ttrain-error:0.14966\ttest-error:0.14932                               \n",
      "\n",
      "[50]\ttrain-error:0.14966\ttest-error:0.14932                               \n",
      "\n",
      "[51]\ttrain-error:0.14969\ttest-error:0.14926                               \n",
      "\n",
      "[52]\ttrain-error:0.14951\ttest-error:0.14920                               \n",
      "\n",
      "[53]\ttrain-error:0.14942\ttest-error:0.14920                               \n",
      "\n",
      "[54]\ttrain-error:0.14932\ttest-error:0.14926                               \n",
      "\n",
      "[55]\ttrain-error:0.14929\ttest-error:0.14926                               \n",
      "\n",
      "[56]\ttrain-error:0.14929\ttest-error:0.14939                               \n",
      "\n",
      "[57]\ttrain-error:0.14929\ttest-error:0.14939                               \n",
      "\n",
      "[58]\ttrain-error:0.14926\ttest-error:0.14932                               \n",
      "\n",
      "[59]\ttrain-error:0.14932\ttest-error:0.14932                               \n",
      "\n",
      "[60]\ttrain-error:0.14926\ttest-error:0.14939                               \n",
      "\n",
      "[61]\ttrain-error:0.14914\ttest-error:0.14920                               \n",
      "\n",
      "[62]\ttrain-error:0.14911\ttest-error:0.14914                               \n",
      "\n",
      "[63]\ttrain-error:0.14911\ttest-error:0.14914                               \n",
      "\n",
      "[64]\ttrain-error:0.14917\ttest-error:0.14926                               \n",
      "\n",
      "[65]\ttrain-error:0.14920\ttest-error:0.14939                               \n",
      "\n",
      "[66]\ttrain-error:0.14920\ttest-error:0.14932                               \n",
      "\n",
      "[67]\ttrain-error:0.14880\ttest-error:0.14914                               \n",
      "\n",
      "[68]\ttrain-error:0.14880\ttest-error:0.14908                               \n",
      "\n",
      "[69]\ttrain-error:0.14874\ttest-error:0.14889                               \n",
      "\n",
      "[70]\ttrain-error:0.14865\ttest-error:0.14889                               \n",
      "\n",
      "[71]\ttrain-error:0.14853\ttest-error:0.14902                               \n",
      "\n",
      "[72]\ttrain-error:0.14853\ttest-error:0.14889                               \n",
      "\n",
      "[73]\ttrain-error:0.14856\ttest-error:0.14902                               \n",
      "\n",
      "[74]\ttrain-error:0.14853\ttest-error:0.14889                               \n",
      "\n",
      "[75]\ttrain-error:0.14853\ttest-error:0.14883                               \n",
      "\n",
      "[76]\ttrain-error:0.14846\ttest-error:0.14877                               \n",
      "\n",
      "[77]\ttrain-error:0.14856\ttest-error:0.14865                               \n",
      "\n",
      "[78]\ttrain-error:0.14843\ttest-error:0.14840                               \n",
      "\n",
      "[79]\ttrain-error:0.14825\ttest-error:0.14816                               \n",
      "\n",
      "[80]\ttrain-error:0.14825\ttest-error:0.14791                               \n",
      "\n",
      "[81]\ttrain-error:0.14828\ttest-error:0.14822                               \n",
      "\n",
      "[82]\ttrain-error:0.14813\ttest-error:0.14828                               \n",
      "\n",
      "[83]\ttrain-error:0.14797\ttest-error:0.14803                               \n",
      "\n",
      "[84]\ttrain-error:0.14791\ttest-error:0.14797                               \n",
      "\n",
      "[85]\ttrain-error:0.14794\ttest-error:0.14803                               \n",
      "\n",
      "[86]\ttrain-error:0.14797\ttest-error:0.14803                               \n",
      "\n",
      "[87]\ttrain-error:0.14797\ttest-error:0.14797                               \n",
      "\n",
      "[88]\ttrain-error:0.14797\ttest-error:0.14803                               \n",
      "\n",
      "[89]\ttrain-error:0.14794\ttest-error:0.14797                               \n",
      "\n",
      "[90]\ttrain-error:0.14785\ttest-error:0.14797                               \n",
      "\n",
      "[91]\ttrain-error:0.14791\ttest-error:0.14791                               \n",
      "\n",
      "[92]\ttrain-error:0.14788\ttest-error:0.14785                               \n",
      "\n",
      "[93]\ttrain-error:0.14782\ttest-error:0.14785                               \n",
      "\n",
      "[94]\ttrain-error:0.14785\ttest-error:0.14791                               \n",
      "\n",
      "[95]\ttrain-error:0.14788\ttest-error:0.14779                               \n",
      "\n",
      "[96]\ttrain-error:0.14779\ttest-error:0.14779                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97]\ttrain-error:0.14788\ttest-error:0.14779                               \n",
      "\n",
      "[98]\ttrain-error:0.14782\ttest-error:0.14779                               \n",
      "\n",
      "[99]\ttrain-error:0.14773\ttest-error:0.14785                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'I', 'colsample_bylevel': 0.6506180275884217, 'colsample_bytree': 0.7260872114805785, 'eta': 0.0019148028046859973, 'eval_metric': ('error',), 'extra_dims': 2, 'gamma': 0, 'lambda': 0, 'max_depth': 3, 'min_child_weight': 6.271696857031619e-06, 'objective': 'binary:logistic', 'subsample': 0.7078494483467541}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[22:57:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.16311\ttest-error:0.16198                                \n",
      "\n",
      "[1]\ttrain-error:0.16118\ttest-error:0.16118                                \n",
      "\n",
      "[2]\ttrain-error:0.15522\ttest-error:0.15424                                \n",
      "\n",
      "[3]\ttrain-error:0.15516\ttest-error:0.15430                                \n",
      "\n",
      "[4]\ttrain-error:0.15430\ttest-error:0.15418                                \n",
      "\n",
      "[5]\ttrain-error:0.15369\ttest-error:0.15344                                \n",
      "\n",
      "[6]\ttrain-error:0.15574\ttest-error:0.15510                                \n",
      "\n",
      "[7]\ttrain-error:0.15547\ttest-error:0.15534                                \n",
      "\n",
      "[8]\ttrain-error:0.15519\ttest-error:0.15504                                \n",
      "\n",
      "[9]\ttrain-error:0.15522\ttest-error:0.15540                                \n",
      "\n",
      "[10]\ttrain-error:0.15531\ttest-error:0.15540                               \n",
      "\n",
      "[11]\ttrain-error:0.15522\ttest-error:0.15547                               \n",
      "\n",
      "[12]\ttrain-error:0.15528\ttest-error:0.15553                               \n",
      "\n",
      "[13]\ttrain-error:0.15531\ttest-error:0.15553                               \n",
      "\n",
      "[14]\ttrain-error:0.15531\ttest-error:0.15534                               \n",
      "\n",
      "[15]\ttrain-error:0.15522\ttest-error:0.15577                               \n",
      "\n",
      "[16]\ttrain-error:0.15513\ttest-error:0.15553                               \n",
      "\n",
      "[17]\ttrain-error:0.15522\ttest-error:0.15534                               \n",
      "\n",
      "[18]\ttrain-error:0.15528\ttest-error:0.15547                               \n",
      "\n",
      "[19]\ttrain-error:0.15540\ttest-error:0.15540                               \n",
      "\n",
      "[20]\ttrain-error:0.15538\ttest-error:0.15534                               \n",
      "\n",
      "[21]\ttrain-error:0.15540\ttest-error:0.15547                               \n",
      "\n",
      "[22]\ttrain-error:0.15540\ttest-error:0.15534                               \n",
      "\n",
      "[23]\ttrain-error:0.15540\ttest-error:0.15547                               \n",
      "\n",
      "[24]\ttrain-error:0.15540\ttest-error:0.15547                               \n",
      "\n",
      "[25]\ttrain-error:0.15540\ttest-error:0.15547                               \n",
      "\n",
      "[26]\ttrain-error:0.15540\ttest-error:0.15534                               \n",
      "\n",
      "[27]\ttrain-error:0.15540\ttest-error:0.15540                               \n",
      "\n",
      "[28]\ttrain-error:0.15538\ttest-error:0.15540                               \n",
      "\n",
      "[29]\ttrain-error:0.15540\ttest-error:0.15534                               \n",
      "\n",
      "[30]\ttrain-error:0.15540\ttest-error:0.15534                               \n",
      "\n",
      "[31]\ttrain-error:0.15540\ttest-error:0.15540                               \n",
      "\n",
      "[32]\ttrain-error:0.15540\ttest-error:0.15540                               \n",
      "\n",
      "[33]\ttrain-error:0.15540\ttest-error:0.15540                               \n",
      "\n",
      "[34]\ttrain-error:0.15538\ttest-error:0.15540                               \n",
      "\n",
      "[35]\ttrain-error:0.15538\ttest-error:0.15540                               \n",
      "\n",
      "[36]\ttrain-error:0.15538\ttest-error:0.15540                               \n",
      "\n",
      "[37]\ttrain-error:0.15540\ttest-error:0.15540                               \n",
      "\n",
      "[38]\ttrain-error:0.15540\ttest-error:0.15540                               \n",
      "\n",
      "[39]\ttrain-error:0.15538\ttest-error:0.15540                               \n",
      "\n",
      "[40]\ttrain-error:0.15538\ttest-error:0.15540                               \n",
      "\n",
      "[41]\ttrain-error:0.15538\ttest-error:0.15540                               \n",
      "\n",
      "[42]\ttrain-error:0.15538\ttest-error:0.15540                               \n",
      "\n",
      "[43]\ttrain-error:0.15538\ttest-error:0.15540                               \n",
      "\n",
      "[44]\ttrain-error:0.15538\ttest-error:0.15540                               \n",
      "\n",
      "[45]\ttrain-error:0.15538\ttest-error:0.15540                               \n",
      "\n",
      "[46]\ttrain-error:0.15538\ttest-error:0.15540                               \n",
      "\n",
      "[47]\ttrain-error:0.15538\ttest-error:0.15540                               \n",
      "\n",
      "[48]\ttrain-error:0.15538\ttest-error:0.15540                               \n",
      "\n",
      "[49]\ttrain-error:0.15538\ttest-error:0.15540                               \n",
      "\n",
      "[50]\ttrain-error:0.15538\ttest-error:0.15540                               \n",
      "\n",
      "[51]\ttrain-error:0.15534\ttest-error:0.15534                               \n",
      "\n",
      "[52]\ttrain-error:0.15534\ttest-error:0.15534                               \n",
      "\n",
      "[53]\ttrain-error:0.15534\ttest-error:0.15540                               \n",
      "\n",
      "[54]\ttrain-error:0.15534\ttest-error:0.15534                               \n",
      "\n",
      "[55]\ttrain-error:0.15534\ttest-error:0.15540                               \n",
      "\n",
      "[56]\ttrain-error:0.15525\ttest-error:0.15522                               \n",
      "\n",
      "[57]\ttrain-error:0.15525\ttest-error:0.15522                               \n",
      "\n",
      "[58]\ttrain-error:0.15525\ttest-error:0.15522                               \n",
      "\n",
      "[59]\ttrain-error:0.15528\ttest-error:0.15522                               \n",
      "\n",
      "[60]\ttrain-error:0.15528\ttest-error:0.15522                               \n",
      "\n",
      "[61]\ttrain-error:0.15525\ttest-error:0.15522                               \n",
      "\n",
      "[62]\ttrain-error:0.15522\ttest-error:0.15504                               \n",
      "\n",
      "[63]\ttrain-error:0.15522\ttest-error:0.15504                               \n",
      "\n",
      "[64]\ttrain-error:0.15522\ttest-error:0.15504                               \n",
      "\n",
      "[65]\ttrain-error:0.15525\ttest-error:0.15522                               \n",
      "\n",
      "[66]\ttrain-error:0.15522\ttest-error:0.15522                               \n",
      "\n",
      "[67]\ttrain-error:0.15522\ttest-error:0.15522                               \n",
      "\n",
      "[68]\ttrain-error:0.15519\ttest-error:0.15498                               \n",
      "\n",
      "[69]\ttrain-error:0.15519\ttest-error:0.15504                               \n",
      "\n",
      "[70]\ttrain-error:0.15516\ttest-error:0.15498                               \n",
      "\n",
      "[71]\ttrain-error:0.15516\ttest-error:0.15504                               \n",
      "\n",
      "[72]\ttrain-error:0.15519\ttest-error:0.15498                               \n",
      "\n",
      "[73]\ttrain-error:0.15528\ttest-error:0.15491                               \n",
      "\n",
      "[74]\ttrain-error:0.15528\ttest-error:0.15485                               \n",
      "\n",
      "[75]\ttrain-error:0.15519\ttest-error:0.15491                               \n",
      "\n",
      "[76]\ttrain-error:0.15522\ttest-error:0.15491                               \n",
      "\n",
      "[77]\ttrain-error:0.15522\ttest-error:0.15491                               \n",
      "\n",
      "[78]\ttrain-error:0.15528\ttest-error:0.15485                               \n",
      "\n",
      "[79]\ttrain-error:0.15528\ttest-error:0.15485                               \n",
      "\n",
      "[80]\ttrain-error:0.15528\ttest-error:0.15485                               \n",
      "\n",
      "[81]\ttrain-error:0.15531\ttest-error:0.15485                               \n",
      "\n",
      "[82]\ttrain-error:0.15516\ttest-error:0.15485                               \n",
      "\n",
      "[83]\ttrain-error:0.15528\ttest-error:0.15485                               \n",
      "\n",
      "[84]\ttrain-error:0.15528\ttest-error:0.15485                               \n",
      "\n",
      "[85]\ttrain-error:0.15528\ttest-error:0.15485                               \n",
      "\n",
      "[86]\ttrain-error:0.15525\ttest-error:0.15485                               \n",
      "\n",
      "[87]\ttrain-error:0.15516\ttest-error:0.15491                               \n",
      "\n",
      "[88]\ttrain-error:0.15501\ttest-error:0.15498                               \n",
      "\n",
      "[89]\ttrain-error:0.15507\ttest-error:0.15504                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90]\ttrain-error:0.15531\ttest-error:0.15491                               \n",
      "\n",
      "[91]\ttrain-error:0.15510\ttest-error:0.15504                               \n",
      "\n",
      "[92]\ttrain-error:0.15510\ttest-error:0.15504                               \n",
      "\n",
      "[93]\ttrain-error:0.15534\ttest-error:0.15491                               \n",
      "\n",
      "[94]\ttrain-error:0.15510\ttest-error:0.15504                               \n",
      "\n",
      "[95]\ttrain-error:0.15510\ttest-error:0.15504                               \n",
      "\n",
      "[96]\ttrain-error:0.15510\ttest-error:0.15504                               \n",
      "\n",
      "[97]\ttrain-error:0.15510\ttest-error:0.15504                               \n",
      "\n",
      "[98]\ttrain-error:0.15504\ttest-error:0.15461                               \n",
      "\n",
      "[99]\ttrain-error:0.15482\ttest-error:0.15473                               \n",
      "\n",
      "{'alpha': 0.10494631594164275, 'btype': 'R', 'colsample_bylevel': 0.9300687277679391, 'colsample_bytree': 0.5387430647908488, 'eta': 0.014826705304607071, 'eval_metric': ('error',), 'extra_dims': 8, 'gamma': 0, 'lambda': 1.673842480299815, 'max_depth': 7, 'min_child_weight': 0.39375379196649496, 'objective': 'binary:logistic', 'subsample': 0.8408995452431361}\n",
      "Overwriting param `num_class`                                           \n",
      "Overwriting param `objective` while setting `obj` in train.             \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                 \n",
      "Setting param `disable_default_eval_metric` to 1.                       \n",
      "[22:57:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14294\ttest-error:0.14195                              \n",
      "\n",
      "[1]\ttrain-error:0.14103\ttest-error:0.13999                              \n",
      "\n",
      "[2]\ttrain-error:0.14346\ttest-error:0.14453                              \n",
      "\n",
      "[3]\ttrain-error:0.14205\ttest-error:0.14263                              \n",
      "\n",
      "[4]\ttrain-error:0.13937\ttest-error:0.13980                              \n",
      "\n",
      "[5]\ttrain-error:0.13931\ttest-error:0.13962                              \n",
      "\n",
      "[6]\ttrain-error:0.13937\ttest-error:0.13968                              \n",
      "\n",
      "[7]\ttrain-error:0.13910\ttest-error:0.13950                              \n",
      "\n",
      "[8]\ttrain-error:0.13833\ttest-error:0.13882                              \n",
      "\n",
      "[9]\ttrain-error:0.13772\ttest-error:0.13747                              \n",
      "\n",
      "[10]\ttrain-error:0.13750\ttest-error:0.13661                             \n",
      "\n",
      "[11]\ttrain-error:0.13698\ttest-error:0.13655                             \n",
      "\n",
      "[12]\ttrain-error:0.13673\ttest-error:0.13624                             \n",
      "\n",
      "[13]\ttrain-error:0.13630\ttest-error:0.13532                             \n",
      "\n",
      "[14]\ttrain-error:0.13603\ttest-error:0.13470                             \n",
      "\n",
      "[15]\ttrain-error:0.13578\ttest-error:0.13452                             \n",
      "\n",
      "[16]\ttrain-error:0.13535\ttest-error:0.13446                             \n",
      "\n",
      "[17]\ttrain-error:0.13486\ttest-error:0.13372                             \n",
      "\n",
      "[18]\ttrain-error:0.13440\ttest-error:0.13323                             \n",
      "\n",
      "[19]\ttrain-error:0.13384\ttest-error:0.13292                             \n",
      "\n",
      "[20]\ttrain-error:0.13357\ttest-error:0.13206                             \n",
      "\n",
      "[21]\ttrain-error:0.13314\ttest-error:0.13176                             \n",
      "\n",
      "[22]\ttrain-error:0.13286\ttest-error:0.13096                             \n",
      "\n",
      "[23]\ttrain-error:0.13249\ttest-error:0.13090                             \n",
      "\n",
      "[24]\ttrain-error:0.13203\ttest-error:0.13139                             \n",
      "\n",
      "[25]\ttrain-error:0.13173\ttest-error:0.13114                             \n",
      "\n",
      "[26]\ttrain-error:0.13133\ttest-error:0.13133                             \n",
      "\n",
      "[27]\ttrain-error:0.13126\ttest-error:0.13102                             \n",
      "\n",
      "[28]\ttrain-error:0.13111\ttest-error:0.13059                             \n",
      "\n",
      "[29]\ttrain-error:0.13096\ttest-error:0.13071                             \n",
      "\n",
      "[30]\ttrain-error:0.13093\ttest-error:0.13096                             \n",
      "\n",
      "[31]\ttrain-error:0.13071\ttest-error:0.13077                             \n",
      "\n",
      "[32]\ttrain-error:0.13004\ttest-error:0.13047                             \n",
      "\n",
      "[33]\ttrain-error:0.12961\ttest-error:0.13016                             \n",
      "\n",
      "[34]\ttrain-error:0.12942\ttest-error:0.13034                             \n",
      "\n",
      "[35]\ttrain-error:0.12881\ttest-error:0.12985                             \n",
      "\n",
      "[36]\ttrain-error:0.12875\ttest-error:0.12967                             \n",
      "\n",
      "[37]\ttrain-error:0.12859\ttest-error:0.12973                             \n",
      "\n",
      "[38]\ttrain-error:0.12847\ttest-error:0.12979                             \n",
      "\n",
      "[39]\ttrain-error:0.12826\ttest-error:0.12973                             \n",
      "\n",
      "[40]\ttrain-error:0.12816\ttest-error:0.12930                             \n",
      "\n",
      "[41]\ttrain-error:0.12798\ttest-error:0.12918                             \n",
      "\n",
      "[42]\ttrain-error:0.12770\ttest-error:0.12912                             \n",
      "\n",
      "[43]\ttrain-error:0.12737\ttest-error:0.12899                             \n",
      "\n",
      "[44]\ttrain-error:0.12690\ttest-error:0.12869                             \n",
      "\n",
      "[45]\ttrain-error:0.12647\ttest-error:0.12850                             \n",
      "\n",
      "[46]\ttrain-error:0.12614\ttest-error:0.12819                             \n",
      "\n",
      "[47]\ttrain-error:0.12577\ttest-error:0.12801                             \n",
      "\n",
      "[48]\ttrain-error:0.12543\ttest-error:0.12795                             \n",
      "\n",
      "[49]\ttrain-error:0.12509\ttest-error:0.12789                             \n",
      "\n",
      "[50]\ttrain-error:0.12469\ttest-error:0.12795                             \n",
      "\n",
      "[51]\ttrain-error:0.12426\ttest-error:0.12789                             \n",
      "\n",
      "[52]\ttrain-error:0.12408\ttest-error:0.12758                             \n",
      "\n",
      "[53]\ttrain-error:0.12377\ttest-error:0.12733                             \n",
      "\n",
      "[54]\ttrain-error:0.12371\ttest-error:0.12746                             \n",
      "\n",
      "[55]\ttrain-error:0.12349\ttest-error:0.12733                             \n",
      "\n",
      "[56]\ttrain-error:0.12340\ttest-error:0.12709                             \n",
      "\n",
      "[57]\ttrain-error:0.12306\ttest-error:0.12697                             \n",
      "\n",
      "[58]\ttrain-error:0.12294\ttest-error:0.12678                             \n",
      "\n",
      "[59]\ttrain-error:0.12276\ttest-error:0.12672                             \n",
      "\n",
      "[60]\ttrain-error:0.12276\ttest-error:0.12678                             \n",
      "\n",
      "[61]\ttrain-error:0.12248\ttest-error:0.12697                             \n",
      "\n",
      "[62]\ttrain-error:0.12227\ttest-error:0.12684                             \n",
      "\n",
      "[63]\ttrain-error:0.12199\ttest-error:0.12647                             \n",
      "\n",
      "[64]\ttrain-error:0.12187\ttest-error:0.12647                             \n",
      "\n",
      "[65]\ttrain-error:0.12162\ttest-error:0.12647                             \n",
      "\n",
      "[66]\ttrain-error:0.12147\ttest-error:0.12635                             \n",
      "\n",
      "[67]\ttrain-error:0.12110\ttest-error:0.12635                             \n",
      "\n",
      "[68]\ttrain-error:0.12101\ttest-error:0.12611                             \n",
      "\n",
      "[69]\ttrain-error:0.12085\ttest-error:0.12635                             \n",
      "\n",
      "[70]\ttrain-error:0.12052\ttest-error:0.12635                             \n",
      "\n",
      "[71]\ttrain-error:0.12042\ttest-error:0.12654                             \n",
      "\n",
      "[72]\ttrain-error:0.12021\ttest-error:0.12604                             \n",
      "\n",
      "[73]\ttrain-error:0.12009\ttest-error:0.12623                             \n",
      "\n",
      "[74]\ttrain-error:0.11990\ttest-error:0.12611                             \n",
      "\n",
      "[75]\ttrain-error:0.12009\ttest-error:0.12574                             \n",
      "\n",
      "[76]\ttrain-error:0.11972\ttest-error:0.12598                             \n",
      "\n",
      "[77]\ttrain-error:0.11972\ttest-error:0.12592                             \n",
      "\n",
      "[78]\ttrain-error:0.11956\ttest-error:0.12574                             \n",
      "\n",
      "[79]\ttrain-error:0.11960\ttest-error:0.12549                             \n",
      "\n",
      "[80]\ttrain-error:0.11923\ttest-error:0.12555                             \n",
      "\n",
      "[81]\ttrain-error:0.11901\ttest-error:0.12561                             \n",
      "\n",
      "[82]\ttrain-error:0.11895\ttest-error:0.12549                             \n",
      "\n",
      "[83]\ttrain-error:0.11870\ttest-error:0.12525                             \n",
      "\n",
      "[84]\ttrain-error:0.11861\ttest-error:0.12506                             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85]\ttrain-error:0.11858\ttest-error:0.12518                             \n",
      "\n",
      "[86]\ttrain-error:0.11858\ttest-error:0.12525                             \n",
      "\n",
      "[87]\ttrain-error:0.11843\ttest-error:0.12512                             \n",
      "\n",
      "[88]\ttrain-error:0.11815\ttest-error:0.12525                             \n",
      "\n",
      "[89]\ttrain-error:0.11781\ttest-error:0.12525                             \n",
      "\n",
      "[90]\ttrain-error:0.11784\ttest-error:0.12525                             \n",
      "\n",
      "[91]\ttrain-error:0.11781\ttest-error:0.12518                             \n",
      "\n",
      "[92]\ttrain-error:0.11781\ttest-error:0.12512                             \n",
      "\n",
      "[93]\ttrain-error:0.11778\ttest-error:0.12494                             \n",
      "\n",
      "[94]\ttrain-error:0.11760\ttest-error:0.12512                             \n",
      "\n",
      "[95]\ttrain-error:0.11766\ttest-error:0.12506                             \n",
      "\n",
      "[96]\ttrain-error:0.11738\ttest-error:0.12482                             \n",
      "\n",
      "[97]\ttrain-error:0.11717\ttest-error:0.12488                             \n",
      "\n",
      "[98]\ttrain-error:0.11692\ttest-error:0.12512                             \n",
      "\n",
      "[99]\ttrain-error:0.11698\ttest-error:0.12518                             \n",
      "\n",
      "{'alpha': 0, 'btype': 'In', 'colsample_bylevel': 0.7572299500455532, 'colsample_bytree': 0.9559560198085099, 'eta': 0.0038735957187835115, 'eval_metric': ('error',), 'extra_dims': 7, 'gamma': 1.7390328549464746, 'lambda': 0, 'max_depth': 1, 'min_child_weight': 0.0005062542886445881, 'objective': 'binary:logistic', 'subsample': 0.7642520109114282}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[22:58:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[1]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[2]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[3]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[4]\ttrain-error:0.20863\ttest-error:0.20565                                \n",
      "\n",
      "[5]\ttrain-error:0.20863\ttest-error:0.20565                                \n",
      "\n",
      "[6]\ttrain-error:0.20863\ttest-error:0.20565                                \n",
      "\n",
      "[7]\ttrain-error:0.20863\ttest-error:0.20565                                \n",
      "\n",
      "[8]\ttrain-error:0.20863\ttest-error:0.20565                                \n",
      "\n",
      "[9]\ttrain-error:0.20863\ttest-error:0.20565                                \n",
      "\n",
      "[10]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[11]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[12]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[13]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[14]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[15]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[16]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[17]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[18]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[19]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[20]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[21]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[22]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[23]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[24]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[25]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[26]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[27]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[28]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[29]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[30]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[31]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[32]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[33]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[34]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[35]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[36]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[37]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[38]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[39]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[40]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[41]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[42]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[43]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[44]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[45]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[46]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[47]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[48]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[49]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[50]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[51]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[52]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[53]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[54]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[55]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[56]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[57]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[58]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[59]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[60]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[61]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[62]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[63]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[64]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[65]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[66]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[67]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[68]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[69]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[70]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[71]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[72]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[73]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[74]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[75]\ttrain-error:0.20452\ttest-error:0.20190                               \n",
      "\n",
      "[76]\ttrain-error:0.20452\ttest-error:0.20190                               \n",
      "\n",
      "[77]\ttrain-error:0.20452\ttest-error:0.20190                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78]\ttrain-error:0.20452\ttest-error:0.20190                               \n",
      "\n",
      "[79]\ttrain-error:0.20452\ttest-error:0.20190                               \n",
      "\n",
      "[80]\ttrain-error:0.20452\ttest-error:0.20190                               \n",
      "\n",
      "[81]\ttrain-error:0.20009\ttest-error:0.19754                               \n",
      "\n",
      "[82]\ttrain-error:0.19988\ttest-error:0.19724                               \n",
      "\n",
      "[83]\ttrain-error:0.19988\ttest-error:0.19724                               \n",
      "\n",
      "[84]\ttrain-error:0.19960\ttest-error:0.19705                               \n",
      "\n",
      "[85]\ttrain-error:0.19960\ttest-error:0.19705                               \n",
      "\n",
      "[86]\ttrain-error:0.19948\ttest-error:0.19699                               \n",
      "\n",
      "[87]\ttrain-error:0.19948\ttest-error:0.19699                               \n",
      "\n",
      "[88]\ttrain-error:0.19945\ttest-error:0.19681                               \n",
      "\n",
      "[89]\ttrain-error:0.19945\ttest-error:0.19681                               \n",
      "\n",
      "[90]\ttrain-error:0.19945\ttest-error:0.19681                               \n",
      "\n",
      "[91]\ttrain-error:0.17666\ttest-error:0.17580                               \n",
      "\n",
      "[92]\ttrain-error:0.17669\ttest-error:0.17598                               \n",
      "\n",
      "[93]\ttrain-error:0.17666\ttest-error:0.17580                               \n",
      "\n",
      "[94]\ttrain-error:0.17666\ttest-error:0.17580                               \n",
      "\n",
      "[95]\ttrain-error:0.17273\ttest-error:0.17217                               \n",
      "\n",
      "[96]\ttrain-error:0.17245\ttest-error:0.17199                               \n",
      "\n",
      "[97]\ttrain-error:0.17211\ttest-error:0.17181                               \n",
      "\n",
      "[98]\ttrain-error:0.17211\ttest-error:0.17181                               \n",
      "\n",
      "[99]\ttrain-error:0.17168\ttest-error:0.17138                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.9705522085989342, 'colsample_bytree': 0.9145874007324325, 'eta': 0.032713849693300136, 'eval_metric': ('error',), 'extra_dims': 6, 'gamma': 0, 'lambda': 0.0004416897601503952, 'max_depth': 2, 'min_child_weight': 0.03595514298184578, 'objective': 'binary:logistic', 'subsample': 0.8016132261359206}\n",
      "Overwriting param `num_class`                                           \n",
      "Overwriting param `objective` while setting `obj` in train.             \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                 \n",
      "Setting param `disable_default_eval_metric` to 1.                       \n",
      "[22:59:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15624\ttest-error:0.15522                              \n",
      "\n",
      "[1]\ttrain-error:0.15624\ttest-error:0.15522                              \n",
      "\n",
      "[2]\ttrain-error:0.15624\ttest-error:0.15522                              \n",
      "\n",
      "[3]\ttrain-error:0.15624\ttest-error:0.15522                              \n",
      "\n",
      "[4]\ttrain-error:0.15624\ttest-error:0.15522                              \n",
      "\n",
      "[5]\ttrain-error:0.15624\ttest-error:0.15522                              \n",
      "\n",
      "[6]\ttrain-error:0.15538\ttest-error:0.15362                              \n",
      "\n",
      "[7]\ttrain-error:0.15467\ttest-error:0.15295                              \n",
      "\n",
      "[8]\ttrain-error:0.15513\ttest-error:0.15319                              \n",
      "\n",
      "[9]\ttrain-error:0.15501\ttest-error:0.15307                              \n",
      "\n",
      "[10]\ttrain-error:0.15184\ttest-error:0.14994                             \n",
      "\n",
      "[11]\ttrain-error:0.15175\ttest-error:0.15031                             \n",
      "\n",
      "[12]\ttrain-error:0.15132\ttest-error:0.14994                             \n",
      "\n",
      "[13]\ttrain-error:0.14991\ttest-error:0.14816                             \n",
      "\n",
      "[14]\ttrain-error:0.14945\ttest-error:0.14803                             \n",
      "\n",
      "[15]\ttrain-error:0.14822\ttest-error:0.14638                             \n",
      "\n",
      "[16]\ttrain-error:0.14662\ttest-error:0.14539                             \n",
      "\n",
      "[17]\ttrain-error:0.14588\ttest-error:0.14484                             \n",
      "\n",
      "[18]\ttrain-error:0.14595\ttest-error:0.14460                             \n",
      "\n",
      "[19]\ttrain-error:0.14444\ttest-error:0.14318                             \n",
      "\n",
      "[20]\ttrain-error:0.14398\ttest-error:0.14330                             \n",
      "\n",
      "[21]\ttrain-error:0.14401\ttest-error:0.14294                             \n",
      "\n",
      "[22]\ttrain-error:0.14386\ttest-error:0.14263                             \n",
      "\n",
      "[23]\ttrain-error:0.14386\ttest-error:0.14257                             \n",
      "\n",
      "[24]\ttrain-error:0.14377\ttest-error:0.14251                             \n",
      "\n",
      "[25]\ttrain-error:0.14377\ttest-error:0.14202                             \n",
      "\n",
      "[26]\ttrain-error:0.14355\ttest-error:0.14177                             \n",
      "\n",
      "[27]\ttrain-error:0.14330\ttest-error:0.14146                             \n",
      "\n",
      "[28]\ttrain-error:0.14321\ttest-error:0.14134                             \n",
      "\n",
      "[29]\ttrain-error:0.14327\ttest-error:0.14158                             \n",
      "\n",
      "[30]\ttrain-error:0.14309\ttest-error:0.14116                             \n",
      "\n",
      "[31]\ttrain-error:0.14269\ttest-error:0.14134                             \n",
      "\n",
      "[32]\ttrain-error:0.14244\ttest-error:0.14085                             \n",
      "\n",
      "[33]\ttrain-error:0.14229\ttest-error:0.14060                             \n",
      "\n",
      "[34]\ttrain-error:0.14180\ttest-error:0.14017                             \n",
      "\n",
      "[35]\ttrain-error:0.14137\ttest-error:0.14011                             \n",
      "\n",
      "[36]\ttrain-error:0.14119\ttest-error:0.13986                             \n",
      "\n",
      "[37]\ttrain-error:0.14122\ttest-error:0.13931                             \n",
      "\n",
      "[38]\ttrain-error:0.14146\ttest-error:0.13876                             \n",
      "\n",
      "[39]\ttrain-error:0.14128\ttest-error:0.13821                             \n",
      "\n",
      "[40]\ttrain-error:0.14076\ttest-error:0.13808                             \n",
      "\n",
      "[41]\ttrain-error:0.14054\ttest-error:0.13802                             \n",
      "\n",
      "[42]\ttrain-error:0.14069\ttest-error:0.13814                             \n",
      "\n",
      "[43]\ttrain-error:0.14026\ttest-error:0.13772                             \n",
      "\n",
      "[44]\ttrain-error:0.14020\ttest-error:0.13772                             \n",
      "\n",
      "[45]\ttrain-error:0.14002\ttest-error:0.13728                             \n",
      "\n",
      "[46]\ttrain-error:0.13962\ttest-error:0.13722                             \n",
      "\n",
      "[47]\ttrain-error:0.13959\ttest-error:0.13692                             \n",
      "\n",
      "[48]\ttrain-error:0.13910\ttest-error:0.13679                             \n",
      "\n",
      "[49]\ttrain-error:0.13931\ttest-error:0.13661                             \n",
      "\n",
      "[50]\ttrain-error:0.13931\ttest-error:0.13673                             \n",
      "\n",
      "[51]\ttrain-error:0.13916\ttest-error:0.13649                             \n",
      "\n",
      "[52]\ttrain-error:0.13873\ttest-error:0.13575                             \n",
      "\n",
      "[53]\ttrain-error:0.13864\ttest-error:0.13538                             \n",
      "\n",
      "[54]\ttrain-error:0.13818\ttest-error:0.13532                             \n",
      "\n",
      "[55]\ttrain-error:0.13824\ttest-error:0.13452                             \n",
      "\n",
      "[56]\ttrain-error:0.13784\ttest-error:0.13477                             \n",
      "\n",
      "[57]\ttrain-error:0.13772\ttest-error:0.13477                             \n",
      "\n",
      "[58]\ttrain-error:0.13781\ttest-error:0.13489                             \n",
      "\n",
      "[59]\ttrain-error:0.13778\ttest-error:0.13483                             \n",
      "\n",
      "[60]\ttrain-error:0.13765\ttest-error:0.13477                             \n",
      "\n",
      "[61]\ttrain-error:0.13719\ttest-error:0.13452                             \n",
      "\n",
      "[62]\ttrain-error:0.13704\ttest-error:0.13446                             \n",
      "\n",
      "[63]\ttrain-error:0.13689\ttest-error:0.13415                             \n",
      "\n",
      "[64]\ttrain-error:0.13682\ttest-error:0.13415                             \n",
      "\n",
      "[65]\ttrain-error:0.13652\ttest-error:0.13384                             \n",
      "\n",
      "[66]\ttrain-error:0.13609\ttest-error:0.13354                             \n",
      "\n",
      "[67]\ttrain-error:0.13600\ttest-error:0.13323                             \n",
      "\n",
      "[68]\ttrain-error:0.13593\ttest-error:0.13323                             \n",
      "\n",
      "[69]\ttrain-error:0.13587\ttest-error:0.13311                             \n",
      "\n",
      "[70]\ttrain-error:0.13563\ttest-error:0.13311                             \n",
      "\n",
      "[71]\ttrain-error:0.13556\ttest-error:0.13305                             \n",
      "\n",
      "[72]\ttrain-error:0.13535\ttest-error:0.13268                             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73]\ttrain-error:0.13529\ttest-error:0.13256                             \n",
      "\n",
      "[74]\ttrain-error:0.13532\ttest-error:0.13237                             \n",
      "\n",
      "[75]\ttrain-error:0.13498\ttest-error:0.13280                             \n",
      "\n",
      "[76]\ttrain-error:0.13470\ttest-error:0.13256                             \n",
      "\n",
      "[77]\ttrain-error:0.13428\ttest-error:0.13188                             \n",
      "\n",
      "[78]\ttrain-error:0.13415\ttest-error:0.13182                             \n",
      "\n",
      "[79]\ttrain-error:0.13409\ttest-error:0.13120                             \n",
      "\n",
      "[80]\ttrain-error:0.13375\ttest-error:0.13096                             \n",
      "\n",
      "[81]\ttrain-error:0.13339\ttest-error:0.13065                             \n",
      "\n",
      "[82]\ttrain-error:0.13339\ttest-error:0.13096                             \n",
      "\n",
      "[83]\ttrain-error:0.13320\ttest-error:0.13108                             \n",
      "\n",
      "[84]\ttrain-error:0.13292\ttest-error:0.13071                             \n",
      "\n",
      "[85]\ttrain-error:0.13268\ttest-error:0.13053                             \n",
      "\n",
      "[86]\ttrain-error:0.13253\ttest-error:0.13071                             \n",
      "\n",
      "[87]\ttrain-error:0.13231\ttest-error:0.13102                             \n",
      "\n",
      "[88]\ttrain-error:0.13243\ttest-error:0.13040                             \n",
      "\n",
      "[89]\ttrain-error:0.13228\ttest-error:0.13040                             \n",
      "\n",
      "[90]\ttrain-error:0.13203\ttest-error:0.13065                             \n",
      "\n",
      "[91]\ttrain-error:0.13197\ttest-error:0.13040                             \n",
      "\n",
      "[92]\ttrain-error:0.13200\ttest-error:0.13028                             \n",
      "\n",
      "[93]\ttrain-error:0.13163\ttest-error:0.13022                             \n",
      "\n",
      "[94]\ttrain-error:0.13167\ttest-error:0.13028                             \n",
      "\n",
      "[95]\ttrain-error:0.13163\ttest-error:0.13065                             \n",
      "\n",
      "[96]\ttrain-error:0.13145\ttest-error:0.13053                             \n",
      "\n",
      "[97]\ttrain-error:0.13117\ttest-error:0.13040                             \n",
      "\n",
      "[98]\ttrain-error:0.13120\ttest-error:0.13047                             \n",
      "\n",
      "[99]\ttrain-error:0.13114\ttest-error:0.13040                             \n",
      "\n",
      "{'alpha': 0.03917595407001736, 'btype': 'I', 'colsample_bylevel': 0.8638232126963521, 'colsample_bytree': 0.8123100681515015, 'eta': 0.157620123421483, 'eval_metric': ('error',), 'extra_dims': 5, 'gamma': 0.00018762754771477354, 'lambda': 0.00011386760755272913, 'max_depth': 8, 'min_child_weight': 1.8976699938963526, 'objective': 'binary:logistic', 'subsample': 0.6225345095040835}\n",
      "Overwriting param `num_class`                                           \n",
      "Overwriting param `objective` while setting `obj` in train.             \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                 \n",
      "Setting param `disable_default_eval_metric` to 1.                       \n",
      "[23:00:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14205\ttest-error:0.14220                              \n",
      "\n",
      "[1]\ttrain-error:0.13670\ttest-error:0.13784                              \n",
      "\n",
      "[2]\ttrain-error:0.13268\ttest-error:0.13360                              \n",
      "\n",
      "[3]\ttrain-error:0.13062\ttest-error:0.13225                              \n",
      "\n",
      "[4]\ttrain-error:0.12693\ttest-error:0.12936                              \n",
      "\n",
      "[5]\ttrain-error:0.12620\ttest-error:0.12899                              \n",
      "\n",
      "[6]\ttrain-error:0.12426\ttest-error:0.12770                              \n",
      "\n",
      "[7]\ttrain-error:0.12245\ttest-error:0.12733                              \n",
      "\n",
      "[8]\ttrain-error:0.12147\ttest-error:0.12740                              \n",
      "\n",
      "[9]\ttrain-error:0.11990\ttest-error:0.12733                              \n",
      "\n",
      "[10]\ttrain-error:0.11873\ttest-error:0.12660                             \n",
      "\n",
      "[11]\ttrain-error:0.11754\ttest-error:0.12666                             \n",
      "\n",
      "[12]\ttrain-error:0.11695\ttest-error:0.12690                             \n",
      "\n",
      "[13]\ttrain-error:0.11603\ttest-error:0.12783                             \n",
      "\n",
      "[14]\ttrain-error:0.11502\ttest-error:0.12641                             \n",
      "\n",
      "[15]\ttrain-error:0.11437\ttest-error:0.12647                             \n",
      "\n",
      "[16]\ttrain-error:0.11413\ttest-error:0.12666                             \n",
      "\n",
      "[17]\ttrain-error:0.11348\ttest-error:0.12586                             \n",
      "\n",
      "[18]\ttrain-error:0.11290\ttest-error:0.12715                             \n",
      "\n",
      "[19]\ttrain-error:0.11185\ttest-error:0.12721                             \n",
      "\n",
      "[20]\ttrain-error:0.11115\ttest-error:0.12684                             \n",
      "\n",
      "[21]\ttrain-error:0.11072\ttest-error:0.12740                             \n",
      "\n",
      "[22]\ttrain-error:0.11001\ttest-error:0.12776                             \n",
      "\n",
      "[23]\ttrain-error:0.11023\ttest-error:0.12740                             \n",
      "\n",
      "[24]\ttrain-error:0.10949\ttest-error:0.12758                             \n",
      "\n",
      "[25]\ttrain-error:0.10786\ttest-error:0.12678                             \n",
      "\n",
      "[26]\ttrain-error:0.10752\ttest-error:0.12770                             \n",
      "\n",
      "[27]\ttrain-error:0.10669\ttest-error:0.12832                             \n",
      "\n",
      "[28]\ttrain-error:0.10666\ttest-error:0.12844                             \n",
      "\n",
      "[29]\ttrain-error:0.10633\ttest-error:0.12850                             \n",
      "\n",
      "[30]\ttrain-error:0.10620\ttest-error:0.12832                             \n",
      "\n",
      "[31]\ttrain-error:0.10583\ttest-error:0.12862                             \n",
      "\n",
      "[32]\ttrain-error:0.10485\ttest-error:0.12783                             \n",
      "\n",
      "[33]\ttrain-error:0.10439\ttest-error:0.12776                             \n",
      "\n",
      "[34]\ttrain-error:0.10402\ttest-error:0.12862                             \n",
      "\n",
      "[35]\ttrain-error:0.10304\ttest-error:0.12905                             \n",
      "\n",
      "[36]\ttrain-error:0.10292\ttest-error:0.12850                             \n",
      "\n",
      "[37]\ttrain-error:0.10267\ttest-error:0.12795                             \n",
      "\n",
      "[38]\ttrain-error:0.10178\ttest-error:0.12813                             \n",
      "\n",
      "[39]\ttrain-error:0.10025\ttest-error:0.12844                             \n",
      "\n",
      "[40]\ttrain-error:0.09942\ttest-error:0.12801                             \n",
      "\n",
      "[41]\ttrain-error:0.09892\ttest-error:0.12912                             \n",
      "\n",
      "[42]\ttrain-error:0.09859\ttest-error:0.12905                             \n",
      "\n",
      "[43]\ttrain-error:0.09806\ttest-error:0.12918                             \n",
      "\n",
      "[44]\ttrain-error:0.09773\ttest-error:0.12887                             \n",
      "\n",
      "[45]\ttrain-error:0.09696\ttest-error:0.12936                             \n",
      "\n",
      "[46]\ttrain-error:0.09641\ttest-error:0.12905                             \n",
      "\n",
      "[47]\ttrain-error:0.09564\ttest-error:0.12942                             \n",
      "\n",
      "[48]\ttrain-error:0.09567\ttest-error:0.12967                             \n",
      "\n",
      "[49]\ttrain-error:0.09592\ttest-error:0.12948                             \n",
      "\n",
      "[50]\ttrain-error:0.09542\ttest-error:0.12954                             \n",
      "\n",
      "[51]\ttrain-error:0.09463\ttest-error:0.12985                             \n",
      "\n",
      "[52]\ttrain-error:0.09429\ttest-error:0.12991                             \n",
      "\n",
      "[53]\ttrain-error:0.09404\ttest-error:0.13065                             \n",
      "\n",
      "[54]\ttrain-error:0.09355\ttest-error:0.13071                             \n",
      "\n",
      "[55]\ttrain-error:0.09266\ttest-error:0.13096                             \n",
      "\n",
      "[56]\ttrain-error:0.09192\ttest-error:0.13034                             \n",
      "\n",
      "[57]\ttrain-error:0.09177\ttest-error:0.13108                             \n",
      "\n",
      "[58]\ttrain-error:0.09168\ttest-error:0.13176                             \n",
      "\n",
      "[59]\ttrain-error:0.09063\ttest-error:0.13126                             \n",
      "\n",
      "[60]\ttrain-error:0.09020\ttest-error:0.13145                             \n",
      "\n",
      "[61]\ttrain-error:0.09069\ttest-error:0.13157                             \n",
      "\n",
      "[62]\ttrain-error:0.09002\ttest-error:0.13034                             \n",
      "\n",
      "[63]\ttrain-error:0.08962\ttest-error:0.13065                             \n",
      "\n",
      "[64]\ttrain-error:0.08940\ttest-error:0.13065                             \n",
      "\n",
      "[65]\ttrain-error:0.08891\ttest-error:0.13084                             \n",
      "\n",
      "[66]\ttrain-error:0.08842\ttest-error:0.13090                             \n",
      "\n",
      "[67]\ttrain-error:0.08799\ttest-error:0.13163                             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68]\ttrain-error:0.08747\ttest-error:0.13071                             \n",
      "\n",
      "[69]\ttrain-error:0.08692\ttest-error:0.13157                             \n",
      "\n",
      "[70]\ttrain-error:0.08667\ttest-error:0.13182                             \n",
      "\n",
      "[71]\ttrain-error:0.08649\ttest-error:0.13219                             \n",
      "\n",
      "[72]\ttrain-error:0.08612\ttest-error:0.13243                             \n",
      "\n",
      "[73]\ttrain-error:0.08529\ttest-error:0.13280                             \n",
      "\n",
      "[74]\ttrain-error:0.08434\ttest-error:0.13262                             \n",
      "\n",
      "[75]\ttrain-error:0.08385\ttest-error:0.13256                             \n",
      "\n",
      "[76]\ttrain-error:0.08342\ttest-error:0.13378                             \n",
      "\n",
      "[77]\ttrain-error:0.08320\ttest-error:0.13354                             \n",
      "\n",
      "[78]\ttrain-error:0.08418\ttest-error:0.13342                             \n",
      "\n",
      "[79]\ttrain-error:0.08277\ttest-error:0.13348                             \n",
      "\n",
      "[80]\ttrain-error:0.08271\ttest-error:0.13378                             \n",
      "\n",
      "[81]\ttrain-error:0.08249\ttest-error:0.13464                             \n",
      "\n",
      "[82]\ttrain-error:0.08194\ttest-error:0.13489                             \n",
      "\n",
      "[83]\ttrain-error:0.08179\ttest-error:0.13520                             \n",
      "\n",
      "[84]\ttrain-error:0.08148\ttest-error:0.13532                             \n",
      "\n",
      "[85]\ttrain-error:0.08084\ttest-error:0.13507                             \n",
      "\n",
      "[86]\ttrain-error:0.08025\ttest-error:0.13489                             \n",
      "\n",
      "[87]\ttrain-error:0.08047\ttest-error:0.13452                             \n",
      "\n",
      "[88]\ttrain-error:0.07995\ttest-error:0.13428                             \n",
      "\n",
      "[89]\ttrain-error:0.07970\ttest-error:0.13501                             \n",
      "\n",
      "[90]\ttrain-error:0.07905\ttest-error:0.13532                             \n",
      "\n",
      "[91]\ttrain-error:0.07838\ttest-error:0.13550                             \n",
      "\n",
      "[92]\ttrain-error:0.07776\ttest-error:0.13575                             \n",
      "\n",
      "[93]\ttrain-error:0.07829\ttest-error:0.13544                             \n",
      "\n",
      "[94]\ttrain-error:0.07819\ttest-error:0.13538                             \n",
      "\n",
      "[95]\ttrain-error:0.07764\ttest-error:0.13593                             \n",
      "\n",
      "[96]\ttrain-error:0.07746\ttest-error:0.13538                             \n",
      "\n",
      "[97]\ttrain-error:0.07684\ttest-error:0.13575                             \n",
      "\n",
      "[98]\ttrain-error:0.07620\ttest-error:0.13581                             \n",
      "\n",
      "[99]\ttrain-error:0.07697\ttest-error:0.13587                             \n",
      "\n",
      "{'alpha': 0, 'btype': 'In', 'colsample_bylevel': 0.7045097598748906, 'colsample_bytree': 0.6741952420495041, 'eta': 0.011270158740423962, 'eval_metric': ('error',), 'extra_dims': 10, 'gamma': 0, 'lambda': 0, 'max_depth': 9, 'min_child_weight': 6.249021899417154e-07, 'objective': 'binary:logistic', 'subsample': 0.8658880768511713}\n",
      "Overwriting param `num_class`                                           \n",
      "Overwriting param `objective` while setting `obj` in train.             \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                 \n",
      "Setting param `disable_default_eval_metric` to 1.                       \n",
      "[23:01:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.12770\ttest-error:0.13550                              \n",
      "\n",
      "[1]\ttrain-error:0.12675\ttest-error:0.13397                              \n",
      "\n",
      "[2]\ttrain-error:0.12580\ttest-error:0.13378                              \n",
      "\n",
      "[3]\ttrain-error:0.12611\ttest-error:0.13378                              \n",
      "\n",
      "[4]\ttrain-error:0.12577\ttest-error:0.13348                              \n",
      "\n",
      "[5]\ttrain-error:0.12537\ttest-error:0.13384                              \n",
      "\n",
      "[6]\ttrain-error:0.12457\ttest-error:0.13305                              \n",
      "\n",
      "[7]\ttrain-error:0.12396\ttest-error:0.13243                              \n",
      "\n",
      "[8]\ttrain-error:0.12331\ttest-error:0.13200                              \n",
      "\n",
      "[9]\ttrain-error:0.12193\ttest-error:0.13206                              \n",
      "\n",
      "[10]\ttrain-error:0.12095\ttest-error:0.13133                             \n",
      "\n",
      "[11]\ttrain-error:0.12048\ttest-error:0.13145                             \n",
      "\n",
      "[12]\ttrain-error:0.11947\ttest-error:0.13053                             \n",
      "\n",
      "[13]\ttrain-error:0.11889\ttest-error:0.13010                             \n",
      "\n",
      "[14]\ttrain-error:0.11809\ttest-error:0.13034                             \n",
      "\n",
      "[15]\ttrain-error:0.11738\ttest-error:0.13022                             \n",
      "\n",
      "[16]\ttrain-error:0.11665\ttest-error:0.13010                             \n",
      "\n",
      "[17]\ttrain-error:0.11615\ttest-error:0.12967                             \n",
      "\n",
      "[18]\ttrain-error:0.11554\ttest-error:0.12893                             \n",
      "\n",
      "[19]\ttrain-error:0.11453\ttest-error:0.12844                             \n",
      "\n",
      "[20]\ttrain-error:0.11394\ttest-error:0.12869                             \n",
      "\n",
      "[21]\ttrain-error:0.11345\ttest-error:0.12838                             \n",
      "\n",
      "[22]\ttrain-error:0.11290\ttest-error:0.12776                             \n",
      "\n",
      "[23]\ttrain-error:0.11219\ttest-error:0.12758                             \n",
      "\n",
      "[24]\ttrain-error:0.11189\ttest-error:0.12690                             \n",
      "\n",
      "[25]\ttrain-error:0.11106\ttest-error:0.12697                             \n",
      "\n",
      "[26]\ttrain-error:0.11069\ttest-error:0.12709                             \n",
      "\n",
      "[27]\ttrain-error:0.11023\ttest-error:0.12721                             \n",
      "\n",
      "[28]\ttrain-error:0.10970\ttest-error:0.12678                             \n",
      "\n",
      "[29]\ttrain-error:0.10934\ttest-error:0.12703                             \n",
      "\n",
      "[30]\ttrain-error:0.10897\ttest-error:0.12672                             \n",
      "\n",
      "[31]\ttrain-error:0.10838\ttest-error:0.12629                             \n",
      "\n",
      "[32]\ttrain-error:0.10777\ttest-error:0.12647                             \n",
      "\n",
      "[33]\ttrain-error:0.10734\ttest-error:0.12611                             \n",
      "\n",
      "[34]\ttrain-error:0.10700\ttest-error:0.12660                             \n",
      "\n",
      "[35]\ttrain-error:0.10639\ttest-error:0.12697                             \n",
      "\n",
      "[36]\ttrain-error:0.10602\ttest-error:0.12647                             \n",
      "\n",
      "[37]\ttrain-error:0.10562\ttest-error:0.12623                             \n",
      "\n",
      "[38]\ttrain-error:0.10494\ttest-error:0.12647                             \n",
      "\n",
      "[39]\ttrain-error:0.10448\ttest-error:0.12690                             \n",
      "\n",
      "[40]\ttrain-error:0.10433\ttest-error:0.12672                             \n",
      "\n",
      "[41]\ttrain-error:0.10411\ttest-error:0.12684                             \n",
      "\n",
      "[42]\ttrain-error:0.10359\ttest-error:0.12690                             \n",
      "\n",
      "[43]\ttrain-error:0.10276\ttest-error:0.12690                             \n",
      "\n",
      "[44]\ttrain-error:0.10230\ttest-error:0.12666                             \n",
      "\n",
      "[45]\ttrain-error:0.10200\ttest-error:0.12660                             \n",
      "\n",
      "[46]\ttrain-error:0.10144\ttest-error:0.12647                             \n",
      "\n",
      "[47]\ttrain-error:0.10135\ttest-error:0.12635                             \n",
      "\n",
      "[48]\ttrain-error:0.10095\ttest-error:0.12684                             \n",
      "\n",
      "[49]\ttrain-error:0.10058\ttest-error:0.12697                             \n",
      "\n",
      "[50]\ttrain-error:0.10031\ttest-error:0.12697                             \n",
      "\n",
      "[51]\ttrain-error:0.10003\ttest-error:0.12678                             \n",
      "\n",
      "[52]\ttrain-error:0.09932\ttest-error:0.12703                             \n",
      "\n",
      "[53]\ttrain-error:0.09908\ttest-error:0.12697                             \n",
      "\n",
      "[54]\ttrain-error:0.09853\ttest-error:0.12703                             \n",
      "\n",
      "[55]\ttrain-error:0.09806\ttest-error:0.12678                             \n",
      "\n",
      "[56]\ttrain-error:0.09760\ttest-error:0.12666                             \n",
      "\n",
      "[57]\ttrain-error:0.09705\ttest-error:0.12666                             \n",
      "\n",
      "[58]\ttrain-error:0.09684\ttest-error:0.12641                             \n",
      "\n",
      "[59]\ttrain-error:0.09665\ttest-error:0.12629                             \n",
      "\n",
      "[60]\ttrain-error:0.09635\ttest-error:0.12654                             \n",
      "\n",
      "[61]\ttrain-error:0.09598\ttest-error:0.12654                             \n",
      "\n",
      "[62]\ttrain-error:0.09545\ttest-error:0.12654                             \n",
      "\n",
      "[63]\ttrain-error:0.09478\ttest-error:0.12647                             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64]\ttrain-error:0.09447\ttest-error:0.12647                             \n",
      "\n",
      "[65]\ttrain-error:0.09398\ttest-error:0.12654                             \n",
      "\n",
      "[66]\ttrain-error:0.09349\ttest-error:0.12666                             \n",
      "\n",
      "[67]\ttrain-error:0.09318\ttest-error:0.12641                             \n",
      "\n",
      "[68]\ttrain-error:0.09278\ttest-error:0.12654                             \n",
      "\n",
      "[69]\ttrain-error:0.09254\ttest-error:0.12623                             \n",
      "\n",
      "[70]\ttrain-error:0.09223\ttest-error:0.12617                             \n",
      "\n",
      "[71]\ttrain-error:0.09189\ttest-error:0.12604                             \n",
      "\n",
      "[72]\ttrain-error:0.09149\ttest-error:0.12598                             \n",
      "\n",
      "[73]\ttrain-error:0.09106\ttest-error:0.12598                             \n",
      "\n",
      "[74]\ttrain-error:0.09054\ttest-error:0.12568                             \n",
      "\n",
      "[75]\ttrain-error:0.09026\ttest-error:0.12580                             \n",
      "\n",
      "[76]\ttrain-error:0.08996\ttest-error:0.12586                             \n",
      "\n",
      "[77]\ttrain-error:0.08940\ttest-error:0.12586                             \n",
      "\n",
      "[78]\ttrain-error:0.08891\ttest-error:0.12586                             \n",
      "\n",
      "[79]\ttrain-error:0.08836\ttest-error:0.12574                             \n",
      "\n",
      "[80]\ttrain-error:0.08805\ttest-error:0.12531                             \n",
      "\n",
      "[81]\ttrain-error:0.08756\ttest-error:0.12543                             \n",
      "\n",
      "[82]\ttrain-error:0.08707\ttest-error:0.12543                             \n",
      "\n",
      "[83]\ttrain-error:0.08661\ttest-error:0.12543                             \n",
      "\n",
      "[84]\ttrain-error:0.08636\ttest-error:0.12580                             \n",
      "\n",
      "[85]\ttrain-error:0.08603\ttest-error:0.12586                             \n",
      "\n",
      "[86]\ttrain-error:0.08557\ttest-error:0.12580                             \n",
      "\n",
      "[87]\ttrain-error:0.08517\ttest-error:0.12568                             \n",
      "\n",
      "[88]\ttrain-error:0.08461\ttest-error:0.12574                             \n",
      "\n",
      "[89]\ttrain-error:0.08403\ttest-error:0.12580                             \n",
      "\n",
      "[90]\ttrain-error:0.08357\ttest-error:0.12555                             \n",
      "\n",
      "[91]\ttrain-error:0.08335\ttest-error:0.12574                             \n",
      "\n",
      "[92]\ttrain-error:0.08302\ttest-error:0.12580                             \n",
      "\n",
      "[93]\ttrain-error:0.08262\ttest-error:0.12604                             \n",
      "\n",
      "[94]\ttrain-error:0.08231\ttest-error:0.12604                             \n",
      "\n",
      "[95]\ttrain-error:0.08191\ttest-error:0.12617                             \n",
      "\n",
      "[96]\ttrain-error:0.08173\ttest-error:0.12592                             \n",
      "\n",
      "[97]\ttrain-error:0.08133\ttest-error:0.12611                             \n",
      "\n",
      "[98]\ttrain-error:0.08127\ttest-error:0.12611                             \n",
      "\n",
      "[99]\ttrain-error:0.08117\ttest-error:0.12598                             \n",
      "\n",
      "{'alpha': 0.00027971731851796896, 'btype': 'R', 'colsample_bylevel': 0.7353156977854195, 'colsample_bytree': 0.5281989394769192, 'eta': 0.00877250573138502, 'eval_metric': ('error',), 'extra_dims': 3, 'gamma': 0.00080556456578601, 'lambda': 1.1310492216664283e-05, 'max_depth': 3, 'min_child_weight': 3.234464196024552e-05, 'objective': 'binary:logistic', 'subsample': 0.9220979410778849}\n",
      "Overwriting param `num_class`                                           \n",
      "Overwriting param `objective` while setting `obj` in train.             \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                 \n",
      "Setting param `disable_default_eval_metric` to 1.                       \n",
      "[23:03:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.17070\ttest-error:0.16904                              \n",
      "\n",
      "[1]\ttrain-error:0.16416\ttest-error:0.16204                              \n",
      "\n",
      "[2]\ttrain-error:0.15366\ttest-error:0.15399                              \n",
      "\n",
      "[3]\ttrain-error:0.15393\ttest-error:0.15375                              \n",
      "\n",
      "[4]\ttrain-error:0.15402\ttest-error:0.15504                              \n",
      "\n",
      "[5]\ttrain-error:0.15304\ttest-error:0.15485                              \n",
      "\n",
      "[6]\ttrain-error:0.15452\ttest-error:0.15559                              \n",
      "\n",
      "[7]\ttrain-error:0.15252\ttest-error:0.15362                              \n",
      "\n",
      "[8]\ttrain-error:0.15215\ttest-error:0.15350                              \n",
      "\n",
      "[9]\ttrain-error:0.15252\ttest-error:0.15227                              \n",
      "\n",
      "[10]\ttrain-error:0.15230\ttest-error:0.15418                             \n",
      "\n",
      "[11]\ttrain-error:0.15230\ttest-error:0.15424                             \n",
      "\n",
      "[12]\ttrain-error:0.15362\ttest-error:0.15442                             \n",
      "\n",
      "[13]\ttrain-error:0.15240\ttest-error:0.15197                             \n",
      "\n",
      "[14]\ttrain-error:0.15332\ttest-error:0.15289                             \n",
      "\n",
      "[15]\ttrain-error:0.15384\ttest-error:0.15307                             \n",
      "\n",
      "[16]\ttrain-error:0.15390\ttest-error:0.15393                             \n",
      "\n",
      "[17]\ttrain-error:0.15464\ttest-error:0.15522                             \n",
      "\n",
      "[18]\ttrain-error:0.15470\ttest-error:0.15522                             \n",
      "\n",
      "[19]\ttrain-error:0.15375\ttest-error:0.15448                             \n",
      "\n",
      "[20]\ttrain-error:0.15335\ttest-error:0.15344                             \n",
      "\n",
      "[21]\ttrain-error:0.15319\ttest-error:0.15350                             \n",
      "\n",
      "[22]\ttrain-error:0.15366\ttest-error:0.15356                             \n",
      "\n",
      "[23]\ttrain-error:0.15298\ttest-error:0.15283                             \n",
      "\n",
      "[24]\ttrain-error:0.15276\ttest-error:0.15246                             \n",
      "\n",
      "[25]\ttrain-error:0.15181\ttest-error:0.15117                             \n",
      "\n",
      "[26]\ttrain-error:0.15151\ttest-error:0.15092                             \n",
      "\n",
      "[27]\ttrain-error:0.15154\ttest-error:0.15190                             \n",
      "\n",
      "[28]\ttrain-error:0.15068\ttest-error:0.15037                             \n",
      "\n",
      "[29]\ttrain-error:0.15065\ttest-error:0.15049                             \n",
      "\n",
      "[30]\ttrain-error:0.15055\ttest-error:0.15049                             \n",
      "\n",
      "[31]\ttrain-error:0.15138\ttest-error:0.15043                             \n",
      "\n",
      "[32]\ttrain-error:0.15190\ttest-error:0.15098                             \n",
      "\n",
      "[33]\ttrain-error:0.15083\ttest-error:0.15055                             \n",
      "\n",
      "[34]\ttrain-error:0.15095\ttest-error:0.15043                             \n",
      "\n",
      "[35]\ttrain-error:0.15117\ttest-error:0.15135                             \n",
      "\n",
      "[36]\ttrain-error:0.15114\ttest-error:0.15086                             \n",
      "\n",
      "[37]\ttrain-error:0.15092\ttest-error:0.15080                             \n",
      "\n",
      "[38]\ttrain-error:0.15098\ttest-error:0.15080                             \n",
      "\n",
      "[39]\ttrain-error:0.15083\ttest-error:0.15061                             \n",
      "\n",
      "[40]\ttrain-error:0.15071\ttest-error:0.15074                             \n",
      "\n",
      "[41]\ttrain-error:0.15055\ttest-error:0.15061                             \n",
      "\n",
      "[42]\ttrain-error:0.15049\ttest-error:0.15055                             \n",
      "\n",
      "[43]\ttrain-error:0.15061\ttest-error:0.15049                             \n",
      "\n",
      "[44]\ttrain-error:0.15037\ttest-error:0.15098                             \n",
      "\n",
      "[45]\ttrain-error:0.15009\ttest-error:0.15025                             \n",
      "\n",
      "[46]\ttrain-error:0.14932\ttest-error:0.14982                             \n",
      "\n",
      "[47]\ttrain-error:0.14932\ttest-error:0.14982                             \n",
      "\n",
      "[48]\ttrain-error:0.14982\ttest-error:0.15025                             \n",
      "\n",
      "[49]\ttrain-error:0.14948\ttest-error:0.14982                             \n",
      "\n",
      "[50]\ttrain-error:0.14859\ttest-error:0.14889                             \n",
      "\n",
      "[51]\ttrain-error:0.14825\ttest-error:0.14840                             \n",
      "\n",
      "[52]\ttrain-error:0.14803\ttest-error:0.14846                             \n",
      "\n",
      "[53]\ttrain-error:0.14760\ttest-error:0.14785                             \n",
      "\n",
      "[54]\ttrain-error:0.14767\ttest-error:0.14797                             \n",
      "\n",
      "[55]\ttrain-error:0.14760\ttest-error:0.14779                             \n",
      "\n",
      "[56]\ttrain-error:0.14757\ttest-error:0.14760                             \n",
      "\n",
      "[57]\ttrain-error:0.14754\ttest-error:0.14760                             \n",
      "\n",
      "[58]\ttrain-error:0.14751\ttest-error:0.14754                             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59]\ttrain-error:0.14733\ttest-error:0.14748                             \n",
      "\n",
      "[60]\ttrain-error:0.14751\ttest-error:0.14773                             \n",
      "\n",
      "[61]\ttrain-error:0.14754\ttest-error:0.14773                             \n",
      "\n",
      "[62]\ttrain-error:0.14754\ttest-error:0.14773                             \n",
      "\n",
      "[63]\ttrain-error:0.14674\ttest-error:0.14705                             \n",
      "\n",
      "[64]\ttrain-error:0.14607\ttest-error:0.14687                             \n",
      "\n",
      "[65]\ttrain-error:0.14607\ttest-error:0.14693                             \n",
      "\n",
      "[66]\ttrain-error:0.14598\ttest-error:0.14662                             \n",
      "\n",
      "[67]\ttrain-error:0.14576\ttest-error:0.14619                             \n",
      "\n",
      "[68]\ttrain-error:0.14579\ttest-error:0.14644                             \n",
      "\n",
      "[69]\ttrain-error:0.14570\ttest-error:0.14601                             \n",
      "\n",
      "[70]\ttrain-error:0.14555\ttest-error:0.14601                             \n",
      "\n",
      "[71]\ttrain-error:0.14567\ttest-error:0.14613                             \n",
      "\n",
      "[72]\ttrain-error:0.14542\ttest-error:0.14564                             \n",
      "\n",
      "[73]\ttrain-error:0.14542\ttest-error:0.14576                             \n",
      "\n",
      "[74]\ttrain-error:0.14505\ttest-error:0.14546                             \n",
      "\n",
      "[75]\ttrain-error:0.14509\ttest-error:0.14552                             \n",
      "\n",
      "[76]\ttrain-error:0.14499\ttest-error:0.14539                             \n",
      "\n",
      "[77]\ttrain-error:0.14502\ttest-error:0.14539                             \n",
      "\n",
      "[78]\ttrain-error:0.14502\ttest-error:0.14546                             \n",
      "\n",
      "[79]\ttrain-error:0.14441\ttest-error:0.14416                             \n",
      "\n",
      "[80]\ttrain-error:0.14426\ttest-error:0.14386                             \n",
      "\n",
      "[81]\ttrain-error:0.14426\ttest-error:0.14374                             \n",
      "\n",
      "[82]\ttrain-error:0.14426\ttest-error:0.14367                             \n",
      "\n",
      "[83]\ttrain-error:0.14419\ttest-error:0.14355                             \n",
      "\n",
      "[84]\ttrain-error:0.14416\ttest-error:0.14355                             \n",
      "\n",
      "[85]\ttrain-error:0.14410\ttest-error:0.14361                             \n",
      "\n",
      "[86]\ttrain-error:0.14416\ttest-error:0.14367                             \n",
      "\n",
      "[87]\ttrain-error:0.14413\ttest-error:0.14361                             \n",
      "\n",
      "[88]\ttrain-error:0.14413\ttest-error:0.14367                             \n",
      "\n",
      "[89]\ttrain-error:0.14395\ttest-error:0.14355                             \n",
      "\n",
      "[90]\ttrain-error:0.14398\ttest-error:0.14349                             \n",
      "\n",
      "[91]\ttrain-error:0.14398\ttest-error:0.14343                             \n",
      "\n",
      "[92]\ttrain-error:0.14386\ttest-error:0.14330                             \n",
      "\n",
      "[93]\ttrain-error:0.14383\ttest-error:0.14312                             \n",
      "\n",
      "[94]\ttrain-error:0.14361\ttest-error:0.14312                             \n",
      "\n",
      "[95]\ttrain-error:0.14358\ttest-error:0.14312                             \n",
      "\n",
      "[96]\ttrain-error:0.14367\ttest-error:0.14330                             \n",
      "\n",
      "[97]\ttrain-error:0.14367\ttest-error:0.14324                             \n",
      "\n",
      "[98]\ttrain-error:0.14355\ttest-error:0.14337                             \n",
      "\n",
      "[99]\ttrain-error:0.14364\ttest-error:0.14324                             \n",
      "\n",
      "{'alpha': 0, 'btype': 'In', 'colsample_bylevel': 0.590742459969314, 'colsample_bytree': 0.5792214823956328, 'eta': 0.24902913933736257, 'eval_metric': ('error',), 'extra_dims': 13, 'gamma': 0, 'lambda': 0, 'max_depth': 7, 'min_child_weight': 6.981017068116, 'objective': 'binary:logistic', 'subsample': 0.9798726586103854}\n",
      "Overwriting param `num_class`                                           \n",
      "Overwriting param `objective` while setting `obj` in train.             \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                 \n",
      "Setting param `disable_default_eval_metric` to 1.                       \n",
      "[23:03:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[1]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[2]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[3]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[4]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[5]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[6]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[7]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[8]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[9]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[10]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[11]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[12]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[13]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[14]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[15]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[16]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[17]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[18]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[19]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[20]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[21]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[22]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[23]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[24]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[25]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[26]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[27]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[28]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[29]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[30]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[31]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[32]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[33]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[34]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[35]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[36]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[37]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[38]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[39]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[40]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[41]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[42]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[43]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[44]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[45]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[46]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[47]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[48]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[49]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[50]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[51]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[52]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[53]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[54]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[56]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[57]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[58]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[59]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[60]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[61]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[62]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[63]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[64]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[65]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[66]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[67]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[68]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[69]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[70]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[71]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[72]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[73]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[74]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[75]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[76]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[77]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[78]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[79]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[80]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[81]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[82]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[83]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[84]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[85]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[86]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[87]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[88]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[89]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[90]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[91]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[92]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[93]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[94]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[95]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[96]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[97]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[98]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[99]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.5381424925523536, 'colsample_bytree': 0.9997733998934526, 'eta': 0.37996420236690936, 'eval_metric': ('error',), 'extra_dims': 9, 'gamma': 3.7106407794939143e-07, 'lambda': 1.1419901393050324e-06, 'max_depth': 5, 'min_child_weight': 24.0817473451163, 'objective': 'binary:logistic', 'subsample': 0.7914434483518111}\n",
      "Overwriting param `num_class`                                           \n",
      "Overwriting param `objective` while setting `obj` in train.             \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                 \n",
      "Setting param `disable_default_eval_metric` to 1.                       \n",
      "[23:05:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15163\ttest-error:0.15160                              \n",
      "\n",
      "[1]\ttrain-error:0.77027\ttest-error:0.77641                              \n",
      "\n",
      "[2]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[3]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[4]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[5]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[6]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[7]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[8]\ttrain-error:0.75918\ttest-error:0.76376                              \n",
      "\n",
      "[9]\ttrain-error:0.24082\ttest-error:0.23624                              \n",
      "\n",
      "[10]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[11]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[12]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[13]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[14]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[15]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[16]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[17]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[18]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[19]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[20]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[21]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[22]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[23]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[24]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[25]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[26]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[27]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[28]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[29]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[30]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[31]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[32]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[33]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[34]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[35]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[36]\ttrain-error:0.24082\ttest-error:0.23624                             \n",
      "\n",
      "[37]\ttrain-error:0.75918\ttest-error:0.76376                             \n",
      "\n",
      "[38]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[39]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[40]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[41]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[42]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[43]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[44]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[45]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[46]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[47]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[48]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[49]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[51]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[52]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[53]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[54]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[55]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[56]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[57]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[58]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[59]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[60]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[61]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[62]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[63]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[64]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[65]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[66]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[67]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[68]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[69]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[70]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[71]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[72]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[73]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[74]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[75]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[76]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[77]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[78]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[79]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[80]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[81]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[82]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[83]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[84]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[85]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[86]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[87]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[88]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[89]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[90]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[91]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[92]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[93]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[94]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[95]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[96]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[97]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[98]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[99]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "{'alpha': 1.5696082240520802e-06, 'btype': 'Rn', 'colsample_bylevel': 0.8393419232054823, 'colsample_bytree': 0.6175398502761507, 'eta': 0.051307166037374716, 'eval_metric': ('error',), 'extra_dims': 15, 'gamma': 1.0854346858627186e-05, 'lambda': 0.17193506239733405, 'max_depth': 10, 'min_child_weight': 1.2052460588313062e-06, 'objective': 'binary:logistic', 'subsample': 0.8538574237639487}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:06:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.12472\ttest-error:0.13391                                \n",
      "\n",
      "[1]\ttrain-error:0.11855\ttest-error:0.13176                                \n",
      "\n",
      "[2]\ttrain-error:0.11287\ttest-error:0.12826                                \n",
      "\n",
      "[3]\ttrain-error:0.10980\ttest-error:0.12703                                \n",
      "\n",
      "[4]\ttrain-error:0.10811\ttest-error:0.12568                                \n",
      "\n",
      "[5]\ttrain-error:0.10525\ttest-error:0.12500                                \n",
      "\n",
      "[6]\ttrain-error:0.10144\ttest-error:0.12531                                \n",
      "\n",
      "[7]\ttrain-error:0.09908\ttest-error:0.12568                                \n",
      "\n",
      "[8]\ttrain-error:0.09785\ttest-error:0.12543                                \n",
      "\n",
      "[9]\ttrain-error:0.09506\ttest-error:0.12537                                \n",
      "\n",
      "[10]\ttrain-error:0.09309\ttest-error:0.12586                               \n",
      "\n",
      "[11]\ttrain-error:0.09002\ttest-error:0.12549                               \n",
      "\n",
      "[12]\ttrain-error:0.08710\ttest-error:0.12672                               \n",
      "\n",
      "[13]\ttrain-error:0.08486\ttest-error:0.12752                               \n",
      "\n",
      "[14]\ttrain-error:0.08203\ttest-error:0.12740                               \n",
      "\n",
      "[15]\ttrain-error:0.07970\ttest-error:0.12727                               \n",
      "\n",
      "[16]\ttrain-error:0.07767\ttest-error:0.12690                               \n",
      "\n",
      "[17]\ttrain-error:0.07466\ttest-error:0.12672                               \n",
      "\n",
      "[18]\ttrain-error:0.07297\ttest-error:0.12666                               \n",
      "\n",
      "[19]\ttrain-error:0.07095\ttest-error:0.12770                               \n",
      "\n",
      "[20]\ttrain-error:0.06880\ttest-error:0.12789                               \n",
      "\n",
      "[21]\ttrain-error:0.06665\ttest-error:0.12881                               \n",
      "\n",
      "[22]\ttrain-error:0.06511\ttest-error:0.12973                               \n",
      "\n",
      "[23]\ttrain-error:0.06287\ttest-error:0.12985                               \n",
      "\n",
      "[24]\ttrain-error:0.06078\ttest-error:0.12985                               \n",
      "\n",
      "[25]\ttrain-error:0.05851\ttest-error:0.13004                               \n",
      "\n",
      "[26]\ttrain-error:0.05694\ttest-error:0.13016                               \n",
      "\n",
      "[27]\ttrain-error:0.05491\ttest-error:0.13028                               \n",
      "\n",
      "[28]\ttrain-error:0.05347\ttest-error:0.13114                               \n",
      "\n",
      "[29]\ttrain-error:0.05135\ttest-error:0.13028                               \n",
      "\n",
      "[30]\ttrain-error:0.04905\ttest-error:0.13016                               \n",
      "\n",
      "[31]\ttrain-error:0.04779\ttest-error:0.13065                               \n",
      "\n",
      "[32]\ttrain-error:0.04576\ttest-error:0.13151                               \n",
      "\n",
      "[33]\ttrain-error:0.04407\ttest-error:0.13090                               \n",
      "\n",
      "[34]\ttrain-error:0.04223\ttest-error:0.13108                               \n",
      "\n",
      "[35]\ttrain-error:0.04008\ttest-error:0.13096                               \n",
      "\n",
      "[36]\ttrain-error:0.03839\ttest-error:0.13145                               \n",
      "\n",
      "[37]\ttrain-error:0.03676\ttest-error:0.13194                               \n",
      "\n",
      "[38]\ttrain-error:0.03532\ttest-error:0.13200                               \n",
      "\n",
      "[39]\ttrain-error:0.03415\ttest-error:0.13194                               \n",
      "\n",
      "[40]\ttrain-error:0.03302\ttest-error:0.13157                               \n",
      "\n",
      "[41]\ttrain-error:0.03151\ttest-error:0.13163                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42]\ttrain-error:0.03019\ttest-error:0.13280                               \n",
      "\n",
      "[43]\ttrain-error:0.02853\ttest-error:0.13292                               \n",
      "\n",
      "[44]\ttrain-error:0.02737\ttest-error:0.13256                               \n",
      "\n",
      "[45]\ttrain-error:0.02641\ttest-error:0.13305                               \n",
      "\n",
      "[46]\ttrain-error:0.02574\ttest-error:0.13372                               \n",
      "\n",
      "[47]\ttrain-error:0.02497\ttest-error:0.13391                               \n",
      "\n",
      "[48]\ttrain-error:0.02389\ttest-error:0.13378                               \n",
      "\n",
      "[49]\ttrain-error:0.02325\ttest-error:0.13421                               \n",
      "\n",
      "[50]\ttrain-error:0.02214\ttest-error:0.13415                               \n",
      "\n",
      "[51]\ttrain-error:0.02153\ttest-error:0.13384                               \n",
      "\n",
      "[52]\ttrain-error:0.02091\ttest-error:0.13421                               \n",
      "\n",
      "[53]\ttrain-error:0.02003\ttest-error:0.13366                               \n",
      "\n",
      "[54]\ttrain-error:0.01929\ttest-error:0.13409                               \n",
      "\n",
      "[55]\ttrain-error:0.01827\ttest-error:0.13470                               \n",
      "\n",
      "[56]\ttrain-error:0.01784\ttest-error:0.13409                               \n",
      "\n",
      "[57]\ttrain-error:0.01744\ttest-error:0.13440                               \n",
      "\n",
      "[58]\ttrain-error:0.01658\ttest-error:0.13403                               \n",
      "\n",
      "[59]\ttrain-error:0.01582\ttest-error:0.13507                               \n",
      "\n",
      "[60]\ttrain-error:0.01520\ttest-error:0.13526                               \n",
      "\n",
      "[61]\ttrain-error:0.01459\ttest-error:0.13550                               \n",
      "\n",
      "[62]\ttrain-error:0.01391\ttest-error:0.13489                               \n",
      "\n",
      "[63]\ttrain-error:0.01302\ttest-error:0.13507                               \n",
      "\n",
      "[64]\ttrain-error:0.01225\ttest-error:0.13538                               \n",
      "\n",
      "[65]\ttrain-error:0.01195\ttest-error:0.13556                               \n",
      "\n",
      "[66]\ttrain-error:0.01109\ttest-error:0.13581                               \n",
      "\n",
      "[67]\ttrain-error:0.01090\ttest-error:0.13612                               \n",
      "\n",
      "[68]\ttrain-error:0.01050\ttest-error:0.13624                               \n",
      "\n",
      "[69]\ttrain-error:0.01047\ttest-error:0.13581                               \n",
      "\n",
      "[70]\ttrain-error:0.01026\ttest-error:0.13649                               \n",
      "\n",
      "[71]\ttrain-error:0.00974\ttest-error:0.13667                               \n",
      "\n",
      "[72]\ttrain-error:0.00888\ttest-error:0.13636                               \n",
      "\n",
      "[73]\ttrain-error:0.00832\ttest-error:0.13698                               \n",
      "\n",
      "[74]\ttrain-error:0.00820\ttest-error:0.13649                               \n",
      "\n",
      "[75]\ttrain-error:0.00749\ttest-error:0.13698                               \n",
      "\n",
      "[76]\ttrain-error:0.00728\ttest-error:0.13686                               \n",
      "\n",
      "[77]\ttrain-error:0.00703\ttest-error:0.13698                               \n",
      "\n",
      "[78]\ttrain-error:0.00673\ttest-error:0.13716                               \n",
      "\n",
      "[79]\ttrain-error:0.00642\ttest-error:0.13778                               \n",
      "\n",
      "[80]\ttrain-error:0.00602\ttest-error:0.13765                               \n",
      "\n",
      "[81]\ttrain-error:0.00571\ttest-error:0.13784                               \n",
      "\n",
      "[82]\ttrain-error:0.00562\ttest-error:0.13808                               \n",
      "\n",
      "[83]\ttrain-error:0.00516\ttest-error:0.13778                               \n",
      "\n",
      "[84]\ttrain-error:0.00464\ttest-error:0.13747                               \n",
      "\n",
      "[85]\ttrain-error:0.00442\ttest-error:0.13741                               \n",
      "\n",
      "[86]\ttrain-error:0.00402\ttest-error:0.13741                               \n",
      "\n",
      "[87]\ttrain-error:0.00384\ttest-error:0.13759                               \n",
      "\n",
      "[88]\ttrain-error:0.00359\ttest-error:0.13753                               \n",
      "\n",
      "[89]\ttrain-error:0.00323\ttest-error:0.13747                               \n",
      "\n",
      "[90]\ttrain-error:0.00301\ttest-error:0.13735                               \n",
      "\n",
      "[91]\ttrain-error:0.00273\ttest-error:0.13704                               \n",
      "\n",
      "[92]\ttrain-error:0.00270\ttest-error:0.13704                               \n",
      "\n",
      "[93]\ttrain-error:0.00249\ttest-error:0.13741                               \n",
      "\n",
      "[94]\ttrain-error:0.00221\ttest-error:0.13753                               \n",
      "\n",
      "[95]\ttrain-error:0.00221\ttest-error:0.13735                               \n",
      "\n",
      "[96]\ttrain-error:0.00203\ttest-error:0.13735                               \n",
      "\n",
      "[97]\ttrain-error:0.00197\ttest-error:0.13741                               \n",
      "\n",
      "[98]\ttrain-error:0.00181\ttest-error:0.13821                               \n",
      "\n",
      "[99]\ttrain-error:0.00187\ttest-error:0.13851                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'In', 'colsample_bylevel': 0.8858103283166404, 'colsample_bytree': 0.857331339691542, 'eta': 0.018141992721114934, 'eval_metric': ('error',), 'extra_dims': 8, 'gamma': 0, 'lambda': 0.006583547918218362, 'max_depth': 1, 'min_child_weight': 1.6548057759032325e-07, 'objective': 'binary:logistic', 'subsample': 0.6674698963926432}\n",
      "Overwriting param `num_class`                                               \n",
      "Overwriting param `objective` while setting `obj` in train.                 \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                     \n",
      "Setting param `disable_default_eval_metric` to 1.                           \n",
      "[23:08:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:    \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.24082\ttest-error:0.23624                                  \n",
      "\n",
      "[1]\ttrain-error:0.24082\ttest-error:0.23624                                  \n",
      "\n",
      "[2]\ttrain-error:0.20455\ttest-error:0.20190                                  \n",
      "\n",
      "[3]\ttrain-error:0.20455\ttest-error:0.20190                                  \n",
      "\n",
      "[4]\ttrain-error:0.20455\ttest-error:0.20190                                  \n",
      "\n",
      "[5]\ttrain-error:0.20455\ttest-error:0.20190                                  \n",
      "\n",
      "[6]\ttrain-error:0.20455\ttest-error:0.20190                                  \n",
      "\n",
      "[7]\ttrain-error:0.20455\ttest-error:0.20190                                  \n",
      "\n",
      "[8]\ttrain-error:0.20455\ttest-error:0.20190                                  \n",
      "\n",
      "[9]\ttrain-error:0.20455\ttest-error:0.20190                                  \n",
      "\n",
      "[10]\ttrain-error:0.20455\ttest-error:0.20190                                 \n",
      "\n",
      "[11]\ttrain-error:0.20455\ttest-error:0.20190                                 \n",
      "\n",
      "[12]\ttrain-error:0.20455\ttest-error:0.20190                                 \n",
      "\n",
      "[13]\ttrain-error:0.20455\ttest-error:0.20190                                 \n",
      "\n",
      "[14]\ttrain-error:0.20455\ttest-error:0.20190                                 \n",
      "\n",
      "[15]\ttrain-error:0.20455\ttest-error:0.20190                                 \n",
      "\n",
      "[16]\ttrain-error:0.18087\ttest-error:0.17961                                 \n",
      "\n",
      "[17]\ttrain-error:0.17629\ttest-error:0.17500                                 \n",
      "\n",
      "[18]\ttrain-error:0.16978\ttest-error:0.16873                                 \n",
      "\n",
      "[19]\ttrain-error:0.16947\ttest-error:0.16837                                 \n",
      "\n",
      "[20]\ttrain-error:0.16959\ttest-error:0.16818                                 \n",
      "\n",
      "[21]\ttrain-error:0.15995\ttest-error:0.15706                                 \n",
      "\n",
      "[22]\ttrain-error:0.15924\ttest-error:0.15706                                 \n",
      "\n",
      "[23]\ttrain-error:0.15964\ttest-error:0.15682                                 \n",
      "\n",
      "[24]\ttrain-error:0.15937\ttest-error:0.15657                                 \n",
      "\n",
      "[25]\ttrain-error:0.15918\ttest-error:0.15663                                 \n",
      "\n",
      "[26]\ttrain-error:0.15872\ttest-error:0.15639                                 \n",
      "\n",
      "[27]\ttrain-error:0.15798\ttest-error:0.15602                                 \n",
      "\n",
      "[28]\ttrain-error:0.15762\ttest-error:0.15565                                 \n",
      "\n",
      "[29]\ttrain-error:0.15626\ttest-error:0.15485                                 \n",
      "\n",
      "[30]\ttrain-error:0.15540\ttest-error:0.15424                                 \n",
      "\n",
      "[31]\ttrain-error:0.15544\ttest-error:0.15424                                 \n",
      "\n",
      "[32]\ttrain-error:0.15639\ttest-error:0.15412                                 \n",
      "\n",
      "[33]\ttrain-error:0.15657\ttest-error:0.15436                                 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34]\ttrain-error:0.15427\ttest-error:0.15240                                 \n",
      "\n",
      "[35]\ttrain-error:0.15372\ttest-error:0.15215                                 \n",
      "\n",
      "[36]\ttrain-error:0.15292\ttest-error:0.15160                                 \n",
      "\n",
      "[37]\ttrain-error:0.15283\ttest-error:0.15184                                 \n",
      "\n",
      "[38]\ttrain-error:0.15301\ttest-error:0.15184                                 \n",
      "\n",
      "[39]\ttrain-error:0.15289\ttest-error:0.15172                                 \n",
      "\n",
      "[40]\ttrain-error:0.15286\ttest-error:0.15166                                 \n",
      "\n",
      "[41]\ttrain-error:0.15206\ttest-error:0.15123                                 \n",
      "\n",
      "[42]\ttrain-error:0.15135\ttest-error:0.14994                                 \n",
      "\n",
      "[43]\ttrain-error:0.15126\ttest-error:0.15000                                 \n",
      "\n",
      "[44]\ttrain-error:0.14988\ttest-error:0.14902                                 \n",
      "\n",
      "[45]\ttrain-error:0.14942\ttest-error:0.14889                                 \n",
      "\n",
      "[46]\ttrain-error:0.14908\ttest-error:0.14883                                 \n",
      "\n",
      "[47]\ttrain-error:0.14874\ttest-error:0.14853                                 \n",
      "\n",
      "[48]\ttrain-error:0.14859\ttest-error:0.14834                                 \n",
      "\n",
      "[49]\ttrain-error:0.14843\ttest-error:0.14822                                 \n",
      "\n",
      "[50]\ttrain-error:0.14843\ttest-error:0.14797                                 \n",
      "\n",
      "[51]\ttrain-error:0.14834\ttest-error:0.14803                                 \n",
      "\n",
      "[52]\ttrain-error:0.14834\ttest-error:0.14779                                 \n",
      "\n",
      "[53]\ttrain-error:0.14840\ttest-error:0.14736                                 \n",
      "\n",
      "[54]\ttrain-error:0.14816\ttest-error:0.14711                                 \n",
      "\n",
      "[55]\ttrain-error:0.14751\ttest-error:0.14601                                 \n",
      "\n",
      "[56]\ttrain-error:0.14748\ttest-error:0.14595                                 \n",
      "\n",
      "[57]\ttrain-error:0.14754\ttest-error:0.14601                                 \n",
      "\n",
      "[58]\ttrain-error:0.14745\ttest-error:0.14558                                 \n",
      "\n",
      "[59]\ttrain-error:0.14736\ttest-error:0.14601                                 \n",
      "\n",
      "[60]\ttrain-error:0.14730\ttest-error:0.14601                                 \n",
      "\n",
      "[61]\ttrain-error:0.14717\ttest-error:0.14552                                 \n",
      "\n",
      "[62]\ttrain-error:0.14724\ttest-error:0.14546                                 \n",
      "\n",
      "[63]\ttrain-error:0.14708\ttest-error:0.14533                                 \n",
      "\n",
      "[64]\ttrain-error:0.14625\ttest-error:0.14398                                 \n",
      "\n",
      "[65]\ttrain-error:0.14616\ttest-error:0.14380                                 \n",
      "\n",
      "[66]\ttrain-error:0.14607\ttest-error:0.14374                                 \n",
      "\n",
      "[67]\ttrain-error:0.14588\ttest-error:0.14404                                 \n",
      "\n",
      "[68]\ttrain-error:0.14588\ttest-error:0.14416                                 \n",
      "\n",
      "[69]\ttrain-error:0.14579\ttest-error:0.14416                                 \n",
      "\n",
      "[70]\ttrain-error:0.14573\ttest-error:0.14398                                 \n",
      "\n",
      "[71]\ttrain-error:0.14579\ttest-error:0.14398                                 \n",
      "\n",
      "[72]\ttrain-error:0.14576\ttest-error:0.14404                                 \n",
      "\n",
      "[73]\ttrain-error:0.14549\ttest-error:0.14349                                 \n",
      "\n",
      "[74]\ttrain-error:0.14533\ttest-error:0.14367                                 \n",
      "\n",
      "[75]\ttrain-error:0.14524\ttest-error:0.14355                                 \n",
      "\n",
      "[76]\ttrain-error:0.14505\ttest-error:0.14361                                 \n",
      "\n",
      "[77]\ttrain-error:0.14509\ttest-error:0.14361                                 \n",
      "\n",
      "[78]\ttrain-error:0.14524\ttest-error:0.14349                                 \n",
      "\n",
      "[79]\ttrain-error:0.14530\ttest-error:0.14361                                 \n",
      "\n",
      "[80]\ttrain-error:0.14527\ttest-error:0.14367                                 \n",
      "\n",
      "[81]\ttrain-error:0.14521\ttest-error:0.14355                                 \n",
      "\n",
      "[82]\ttrain-error:0.14515\ttest-error:0.14361                                 \n",
      "\n",
      "[83]\ttrain-error:0.14509\ttest-error:0.14355                                 \n",
      "\n",
      "[84]\ttrain-error:0.14502\ttest-error:0.14361                                 \n",
      "\n",
      "[85]\ttrain-error:0.14515\ttest-error:0.14380                                 \n",
      "\n",
      "[86]\ttrain-error:0.14487\ttest-error:0.14318                                 \n",
      "\n",
      "[87]\ttrain-error:0.14505\ttest-error:0.14330                                 \n",
      "\n",
      "[88]\ttrain-error:0.14515\ttest-error:0.14318                                 \n",
      "\n",
      "[89]\ttrain-error:0.14512\ttest-error:0.14324                                 \n",
      "\n",
      "[90]\ttrain-error:0.14496\ttest-error:0.14300                                 \n",
      "\n",
      "[91]\ttrain-error:0.14512\ttest-error:0.14306                                 \n",
      "\n",
      "[92]\ttrain-error:0.14490\ttest-error:0.14300                                 \n",
      "\n",
      "[93]\ttrain-error:0.14484\ttest-error:0.14300                                 \n",
      "\n",
      "[94]\ttrain-error:0.14493\ttest-error:0.14318                                 \n",
      "\n",
      "[95]\ttrain-error:0.14481\ttest-error:0.14281                                 \n",
      "\n",
      "[96]\ttrain-error:0.14484\ttest-error:0.14269                                 \n",
      "\n",
      "[97]\ttrain-error:0.14472\ttest-error:0.14275                                 \n",
      "\n",
      "[98]\ttrain-error:0.14469\ttest-error:0.14275                                 \n",
      "\n",
      "[99]\ttrain-error:0.14469\ttest-error:0.14269                                 \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.7907297375681911, 'colsample_bytree': 0.6916658753695135, 'eta': 0.07744084862786957, 'eval_metric': ('error',), 'extra_dims': 1, 'gamma': 2.8385844869190435e-06, 'lambda': 0, 'max_depth': 4, 'min_child_weight': 0.001601231673922498, 'objective': 'binary:logistic', 'subsample': 0.9986135543085221}\n",
      "Overwriting param `num_class`                                               \n",
      "Overwriting param `objective` while setting `obj` in train.                 \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                     \n",
      "Setting param `disable_default_eval_metric` to 1.                           \n",
      "[23:09:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:    \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.16410\ttest-error:0.16241                                  \n",
      "\n",
      "[1]\ttrain-error:0.14951\ttest-error:0.14908                                  \n",
      "\n",
      "[2]\ttrain-error:0.14868\ttest-error:0.14975                                  \n",
      "\n",
      "[3]\ttrain-error:0.14493\ttest-error:0.14613                                  \n",
      "\n",
      "[4]\ttrain-error:0.14515\ttest-error:0.14625                                  \n",
      "\n",
      "[5]\ttrain-error:0.14447\ttest-error:0.14515                                  \n",
      "\n",
      "[6]\ttrain-error:0.14558\ttest-error:0.14564                                  \n",
      "\n",
      "[7]\ttrain-error:0.14370\ttest-error:0.14281                                  \n",
      "\n",
      "[8]\ttrain-error:0.14398\ttest-error:0.14330                                  \n",
      "\n",
      "[9]\ttrain-error:0.14327\ttest-error:0.14330                                  \n",
      "\n",
      "[10]\ttrain-error:0.14337\ttest-error:0.14263                                 \n",
      "\n",
      "[11]\ttrain-error:0.14211\ttest-error:0.14134                                 \n",
      "\n",
      "[12]\ttrain-error:0.14125\ttest-error:0.13931                                 \n",
      "\n",
      "[13]\ttrain-error:0.14097\ttest-error:0.13950                                 \n",
      "\n",
      "[14]\ttrain-error:0.14116\ttest-error:0.13974                                 \n",
      "\n",
      "[15]\ttrain-error:0.14128\ttest-error:0.14085                                 \n",
      "\n",
      "[16]\ttrain-error:0.14066\ttest-error:0.13950                                 \n",
      "\n",
      "[17]\ttrain-error:0.14005\ttest-error:0.13888                                 \n",
      "\n",
      "[18]\ttrain-error:0.14020\ttest-error:0.13870                                 \n",
      "\n",
      "[19]\ttrain-error:0.14017\ttest-error:0.13796                                 \n",
      "\n",
      "[20]\ttrain-error:0.13996\ttest-error:0.13808                                 \n",
      "\n",
      "[21]\ttrain-error:0.13980\ttest-error:0.13765                                 \n",
      "\n",
      "[22]\ttrain-error:0.13968\ttest-error:0.13673                                 \n",
      "\n",
      "[23]\ttrain-error:0.13913\ttest-error:0.13722                                 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24]\ttrain-error:0.13916\ttest-error:0.13649                                 \n",
      "\n",
      "[25]\ttrain-error:0.13864\ttest-error:0.13649                                 \n",
      "\n",
      "[26]\ttrain-error:0.13858\ttest-error:0.13630                                 \n",
      "\n",
      "[27]\ttrain-error:0.13864\ttest-error:0.13636                                 \n",
      "\n",
      "[28]\ttrain-error:0.13858\ttest-error:0.13575                                 \n",
      "\n",
      "[29]\ttrain-error:0.13719\ttest-error:0.13483                                 \n",
      "\n",
      "[30]\ttrain-error:0.13679\ttest-error:0.13452                                 \n",
      "\n",
      "[31]\ttrain-error:0.13682\ttest-error:0.13440                                 \n",
      "\n",
      "[32]\ttrain-error:0.13686\ttest-error:0.13384                                 \n",
      "\n",
      "[33]\ttrain-error:0.13627\ttest-error:0.13372                                 \n",
      "\n",
      "[34]\ttrain-error:0.13606\ttest-error:0.13360                                 \n",
      "\n",
      "[35]\ttrain-error:0.13584\ttest-error:0.13311                                 \n",
      "\n",
      "[36]\ttrain-error:0.13587\ttest-error:0.13286                                 \n",
      "\n",
      "[37]\ttrain-error:0.13517\ttest-error:0.13237                                 \n",
      "\n",
      "[38]\ttrain-error:0.13440\ttest-error:0.13206                                 \n",
      "\n",
      "[39]\ttrain-error:0.13418\ttest-error:0.13225                                 \n",
      "\n",
      "[40]\ttrain-error:0.13372\ttest-error:0.13176                                 \n",
      "\n",
      "[41]\ttrain-error:0.13345\ttest-error:0.13249                                 \n",
      "\n",
      "[42]\ttrain-error:0.13289\ttest-error:0.13170                                 \n",
      "\n",
      "[43]\ttrain-error:0.13246\ttest-error:0.13108                                 \n",
      "\n",
      "[44]\ttrain-error:0.13179\ttest-error:0.13047                                 \n",
      "\n",
      "[45]\ttrain-error:0.13203\ttest-error:0.13034                                 \n",
      "\n",
      "[46]\ttrain-error:0.13148\ttest-error:0.13010                                 \n",
      "\n",
      "[47]\ttrain-error:0.13111\ttest-error:0.12979                                 \n",
      "\n",
      "[48]\ttrain-error:0.13031\ttest-error:0.12912                                 \n",
      "\n",
      "[49]\ttrain-error:0.13004\ttest-error:0.12899                                 \n",
      "\n",
      "[50]\ttrain-error:0.12970\ttest-error:0.12850                                 \n",
      "\n",
      "[51]\ttrain-error:0.12967\ttest-error:0.12856                                 \n",
      "\n",
      "[52]\ttrain-error:0.12945\ttest-error:0.12801                                 \n",
      "\n",
      "[53]\ttrain-error:0.12948\ttest-error:0.12733                                 \n",
      "\n",
      "[54]\ttrain-error:0.12902\ttest-error:0.12746                                 \n",
      "\n",
      "[55]\ttrain-error:0.12887\ttest-error:0.12684                                 \n",
      "\n",
      "[56]\ttrain-error:0.12850\ttest-error:0.12684                                 \n",
      "\n",
      "[57]\ttrain-error:0.12829\ttest-error:0.12703                                 \n",
      "\n",
      "[58]\ttrain-error:0.12804\ttest-error:0.12684                                 \n",
      "\n",
      "[59]\ttrain-error:0.12795\ttest-error:0.12678                                 \n",
      "\n",
      "[60]\ttrain-error:0.12749\ttest-error:0.12678                                 \n",
      "\n",
      "[61]\ttrain-error:0.12743\ttest-error:0.12666                                 \n",
      "\n",
      "[62]\ttrain-error:0.12703\ttest-error:0.12660                                 \n",
      "\n",
      "[63]\ttrain-error:0.12672\ttest-error:0.12623                                 \n",
      "\n",
      "[64]\ttrain-error:0.12629\ttest-error:0.12654                                 \n",
      "\n",
      "[65]\ttrain-error:0.12598\ttest-error:0.12654                                 \n",
      "\n",
      "[66]\ttrain-error:0.12583\ttest-error:0.12709                                 \n",
      "\n",
      "[67]\ttrain-error:0.12574\ttest-error:0.12660                                 \n",
      "\n",
      "[68]\ttrain-error:0.12555\ttest-error:0.12647                                 \n",
      "\n",
      "[69]\ttrain-error:0.12506\ttest-error:0.12647                                 \n",
      "\n",
      "[70]\ttrain-error:0.12500\ttest-error:0.12623                                 \n",
      "\n",
      "[71]\ttrain-error:0.12500\ttest-error:0.12611                                 \n",
      "\n",
      "[72]\ttrain-error:0.12460\ttest-error:0.12629                                 \n",
      "\n",
      "[73]\ttrain-error:0.12469\ttest-error:0.12635                                 \n",
      "\n",
      "[74]\ttrain-error:0.12478\ttest-error:0.12635                                 \n",
      "\n",
      "[75]\ttrain-error:0.12448\ttest-error:0.12641                                 \n",
      "\n",
      "[76]\ttrain-error:0.12414\ttest-error:0.12617                                 \n",
      "\n",
      "[77]\ttrain-error:0.12420\ttest-error:0.12623                                 \n",
      "\n",
      "[78]\ttrain-error:0.12399\ttest-error:0.12568                                 \n",
      "\n",
      "[79]\ttrain-error:0.12365\ttest-error:0.12549                                 \n",
      "\n",
      "[80]\ttrain-error:0.12343\ttest-error:0.12555                                 \n",
      "\n",
      "[81]\ttrain-error:0.12300\ttest-error:0.12512                                 \n",
      "\n",
      "[82]\ttrain-error:0.12279\ttest-error:0.12531                                 \n",
      "\n",
      "[83]\ttrain-error:0.12248\ttest-error:0.12543                                 \n",
      "\n",
      "[84]\ttrain-error:0.12248\ttest-error:0.12543                                 \n",
      "\n",
      "[85]\ttrain-error:0.12233\ttest-error:0.12512                                 \n",
      "\n",
      "[86]\ttrain-error:0.12202\ttest-error:0.12512                                 \n",
      "\n",
      "[87]\ttrain-error:0.12199\ttest-error:0.12512                                 \n",
      "\n",
      "[88]\ttrain-error:0.12165\ttest-error:0.12506                                 \n",
      "\n",
      "[89]\ttrain-error:0.12159\ttest-error:0.12494                                 \n",
      "\n",
      "[90]\ttrain-error:0.12156\ttest-error:0.12512                                 \n",
      "\n",
      "[91]\ttrain-error:0.12122\ttest-error:0.12543                                 \n",
      "\n",
      "[92]\ttrain-error:0.12104\ttest-error:0.12512                                 \n",
      "\n",
      "[93]\ttrain-error:0.12079\ttest-error:0.12568                                 \n",
      "\n",
      "[94]\ttrain-error:0.12067\ttest-error:0.12580                                 \n",
      "\n",
      "[95]\ttrain-error:0.12064\ttest-error:0.12574                                 \n",
      "\n",
      "[96]\ttrain-error:0.12055\ttest-error:0.12568                                 \n",
      "\n",
      "[97]\ttrain-error:0.12042\ttest-error:0.12549                                 \n",
      "\n",
      "[98]\ttrain-error:0.12033\ttest-error:0.12531                                 \n",
      "\n",
      "[99]\ttrain-error:0.12033\ttest-error:0.12500                                 \n",
      "\n",
      "{'alpha': 0, 'btype': 'I', 'colsample_bylevel': 0.7713091496292439, 'colsample_bytree': 0.6586620600972144, 'eta': 0.10509115659984235, 'eval_metric': ('error',), 'extra_dims': 4, 'gamma': 0, 'lambda': 3.5964791682949217e-06, 'max_depth': 7, 'min_child_weight': 0.010476668007586232, 'objective': 'binary:logistic', 'subsample': 0.9022103355942781}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:10:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13772\ttest-error:0.13937                                \n",
      "\n",
      "[1]\ttrain-error:0.13458\ttest-error:0.13532                                \n",
      "\n",
      "[2]\ttrain-error:0.13212\ttest-error:0.13323                                \n",
      "\n",
      "[3]\ttrain-error:0.13037\ttest-error:0.13212                                \n",
      "\n",
      "[4]\ttrain-error:0.12663\ttest-error:0.12998                                \n",
      "\n",
      "[5]\ttrain-error:0.12515\ttest-error:0.12899                                \n",
      "\n",
      "[6]\ttrain-error:0.12343\ttest-error:0.12844                                \n",
      "\n",
      "[7]\ttrain-error:0.12199\ttest-error:0.12813                                \n",
      "\n",
      "[8]\ttrain-error:0.12005\ttest-error:0.12758                                \n",
      "\n",
      "[9]\ttrain-error:0.11760\ttest-error:0.12525                                \n",
      "\n",
      "[10]\ttrain-error:0.11643\ttest-error:0.12568                               \n",
      "\n",
      "[11]\ttrain-error:0.11379\ttest-error:0.12475                               \n",
      "\n",
      "[12]\ttrain-error:0.11210\ttest-error:0.12420                               \n",
      "\n",
      "[13]\ttrain-error:0.11142\ttest-error:0.12414                               \n",
      "\n",
      "[14]\ttrain-error:0.11010\ttest-error:0.12537                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15]\ttrain-error:0.10931\ttest-error:0.12537                               \n",
      "\n",
      "[16]\ttrain-error:0.10719\ttest-error:0.12672                               \n",
      "\n",
      "[17]\ttrain-error:0.10623\ttest-error:0.12647                               \n",
      "\n",
      "[18]\ttrain-error:0.10525\ttest-error:0.12635                               \n",
      "\n",
      "[19]\ttrain-error:0.10408\ttest-error:0.12647                               \n",
      "\n",
      "[20]\ttrain-error:0.10375\ttest-error:0.12611                               \n",
      "\n",
      "[21]\ttrain-error:0.10264\ttest-error:0.12629                               \n",
      "\n",
      "[22]\ttrain-error:0.10043\ttest-error:0.12660                               \n",
      "\n",
      "[23]\ttrain-error:0.09942\ttest-error:0.12641                               \n",
      "\n",
      "[24]\ttrain-error:0.09800\ttest-error:0.12629                               \n",
      "\n",
      "[25]\ttrain-error:0.09711\ttest-error:0.12586                               \n",
      "\n",
      "[26]\ttrain-error:0.09628\ttest-error:0.12592                               \n",
      "\n",
      "[27]\ttrain-error:0.09558\ttest-error:0.12561                               \n",
      "\n",
      "[28]\ttrain-error:0.09493\ttest-error:0.12537                               \n",
      "\n",
      "[29]\ttrain-error:0.09389\ttest-error:0.12488                               \n",
      "\n",
      "[30]\ttrain-error:0.09321\ttest-error:0.12574                               \n",
      "\n",
      "[31]\ttrain-error:0.09238\ttest-error:0.12561                               \n",
      "\n",
      "[32]\ttrain-error:0.09168\ttest-error:0.12549                               \n",
      "\n",
      "[33]\ttrain-error:0.09066\ttest-error:0.12623                               \n",
      "\n",
      "[34]\ttrain-error:0.09002\ttest-error:0.12629                               \n",
      "\n",
      "[35]\ttrain-error:0.08870\ttest-error:0.12598                               \n",
      "\n",
      "[36]\ttrain-error:0.08836\ttest-error:0.12611                               \n",
      "\n",
      "[37]\ttrain-error:0.08732\ttest-error:0.12672                               \n",
      "\n",
      "[38]\ttrain-error:0.08652\ttest-error:0.12764                               \n",
      "\n",
      "[39]\ttrain-error:0.08590\ttest-error:0.12801                               \n",
      "\n",
      "[40]\ttrain-error:0.08452\ttest-error:0.12795                               \n",
      "\n",
      "[41]\ttrain-error:0.08332\ttest-error:0.12776                               \n",
      "\n",
      "[42]\ttrain-error:0.08286\ttest-error:0.12764                               \n",
      "\n",
      "[43]\ttrain-error:0.08191\ttest-error:0.12746                               \n",
      "\n",
      "[44]\ttrain-error:0.08139\ttest-error:0.12746                               \n",
      "\n",
      "[45]\ttrain-error:0.08068\ttest-error:0.12776                               \n",
      "\n",
      "[46]\ttrain-error:0.08047\ttest-error:0.12783                               \n",
      "\n",
      "[47]\ttrain-error:0.07924\ttest-error:0.12789                               \n",
      "\n",
      "[48]\ttrain-error:0.07826\ttest-error:0.12819                               \n",
      "\n",
      "[49]\ttrain-error:0.07749\ttest-error:0.12850                               \n",
      "\n",
      "[50]\ttrain-error:0.07647\ttest-error:0.12899                               \n",
      "\n",
      "[51]\ttrain-error:0.07614\ttest-error:0.12881                               \n",
      "\n",
      "[52]\ttrain-error:0.07565\ttest-error:0.12813                               \n",
      "\n",
      "[53]\ttrain-error:0.07475\ttest-error:0.12869                               \n",
      "\n",
      "[54]\ttrain-error:0.07405\ttest-error:0.12844                               \n",
      "\n",
      "[55]\ttrain-error:0.07353\ttest-error:0.12893                               \n",
      "\n",
      "[56]\ttrain-error:0.07257\ttest-error:0.12954                               \n",
      "\n",
      "[57]\ttrain-error:0.07144\ttest-error:0.12961                               \n",
      "\n",
      "[58]\ttrain-error:0.07116\ttest-error:0.12961                               \n",
      "\n",
      "[59]\ttrain-error:0.07024\ttest-error:0.12936                               \n",
      "\n",
      "[60]\ttrain-error:0.06932\ttest-error:0.12924                               \n",
      "\n",
      "[61]\ttrain-error:0.06834\ttest-error:0.12875                               \n",
      "\n",
      "[62]\ttrain-error:0.06732\ttest-error:0.12899                               \n",
      "\n",
      "[63]\ttrain-error:0.06689\ttest-error:0.12936                               \n",
      "\n",
      "[64]\ttrain-error:0.06612\ttest-error:0.12918                               \n",
      "\n",
      "[65]\ttrain-error:0.06530\ttest-error:0.12912                               \n",
      "\n",
      "[66]\ttrain-error:0.06471\ttest-error:0.12930                               \n",
      "\n",
      "[67]\ttrain-error:0.06333\ttest-error:0.12948                               \n",
      "\n",
      "[68]\ttrain-error:0.06259\ttest-error:0.12985                               \n",
      "\n",
      "[69]\ttrain-error:0.06247\ttest-error:0.12967                               \n",
      "\n",
      "[70]\ttrain-error:0.06192\ttest-error:0.12991                               \n",
      "\n",
      "[71]\ttrain-error:0.06124\ttest-error:0.12967                               \n",
      "\n",
      "[72]\ttrain-error:0.06066\ttest-error:0.12991                               \n",
      "\n",
      "[73]\ttrain-error:0.06026\ttest-error:0.12979                               \n",
      "\n",
      "[74]\ttrain-error:0.05980\ttest-error:0.12954                               \n",
      "\n",
      "[75]\ttrain-error:0.05934\ttest-error:0.12954                               \n",
      "\n",
      "[76]\ttrain-error:0.05918\ttest-error:0.12954                               \n",
      "\n",
      "[77]\ttrain-error:0.05869\ttest-error:0.12998                               \n",
      "\n",
      "[78]\ttrain-error:0.05771\ttest-error:0.13004                               \n",
      "\n",
      "[79]\ttrain-error:0.05697\ttest-error:0.13034                               \n",
      "\n",
      "[80]\ttrain-error:0.05620\ttest-error:0.13028                               \n",
      "\n",
      "[81]\ttrain-error:0.05571\ttest-error:0.13047                               \n",
      "\n",
      "[82]\ttrain-error:0.05498\ttest-error:0.13028                               \n",
      "\n",
      "[83]\ttrain-error:0.05482\ttest-error:0.13040                               \n",
      "\n",
      "[84]\ttrain-error:0.05445\ttest-error:0.13028                               \n",
      "\n",
      "[85]\ttrain-error:0.05402\ttest-error:0.13084                               \n",
      "\n",
      "[86]\ttrain-error:0.05344\ttest-error:0.13053                               \n",
      "\n",
      "[87]\ttrain-error:0.05283\ttest-error:0.13059                               \n",
      "\n",
      "[88]\ttrain-error:0.05243\ttest-error:0.13071                               \n",
      "\n",
      "[89]\ttrain-error:0.05212\ttest-error:0.13090                               \n",
      "\n",
      "[90]\ttrain-error:0.05163\ttest-error:0.13071                               \n",
      "\n",
      "[91]\ttrain-error:0.05098\ttest-error:0.13022                               \n",
      "\n",
      "[92]\ttrain-error:0.05022\ttest-error:0.13028                               \n",
      "\n",
      "[93]\ttrain-error:0.04960\ttest-error:0.13016                               \n",
      "\n",
      "[94]\ttrain-error:0.04877\ttest-error:0.12991                               \n",
      "\n",
      "[95]\ttrain-error:0.04831\ttest-error:0.13016                               \n",
      "\n",
      "[96]\ttrain-error:0.04770\ttest-error:0.13053                               \n",
      "\n",
      "[97]\ttrain-error:0.04730\ttest-error:0.13071                               \n",
      "\n",
      "[98]\ttrain-error:0.04656\ttest-error:0.13077                               \n",
      "\n",
      "[99]\ttrain-error:0.04576\ttest-error:0.13163                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'I', 'colsample_bylevel': 0.6775971776625149, 'colsample_bytree': 0.7873202958051796, 'eta': 0.5800280622200503, 'eval_metric': ('error',), 'extra_dims': 4, 'gamma': 0, 'lambda': 1.1796476139185315, 'max_depth': 3, 'min_child_weight': 0.7268576887442736, 'objective': 'binary:logistic', 'subsample': 0.9034099686498153}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:10:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15737\ttest-error:0.15540                                \n",
      "\n",
      "[1]\ttrain-error:0.53652\ttest-error:0.54730                                \n",
      "\n",
      "[2]\ttrain-error:0.20716\ttest-error:0.20411                                \n",
      "\n",
      "[3]\ttrain-error:0.62052\ttest-error:0.61769                                \n",
      "\n",
      "[4]\ttrain-error:0.24573\ttest-error:0.24122                                \n",
      "\n",
      "[5]\ttrain-error:0.38255\ttest-error:0.37819                                \n",
      "\n",
      "[6]\ttrain-error:0.45568\ttest-error:0.45436                                \n",
      "\n",
      "[7]\ttrain-error:0.37503\ttest-error:0.36984                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain-error:0.47921\ttest-error:0.47807                                \n",
      "\n",
      "[9]\ttrain-error:0.36152\ttest-error:0.35541                                \n",
      "\n",
      "[10]\ttrain-error:0.35568\ttest-error:0.35252                               \n",
      "\n",
      "[11]\ttrain-error:0.48532\ttest-error:0.48600                               \n",
      "\n",
      "[12]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[13]\ttrain-error:0.32672\ttest-error:0.32396                               \n",
      "\n",
      "[14]\ttrain-error:0.50411\ttest-error:0.50694                               \n",
      "\n",
      "[15]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[16]\ttrain-error:0.44097\ttest-error:0.43673                               \n",
      "\n",
      "[17]\ttrain-error:0.39048\ttest-error:0.38692                               \n",
      "\n",
      "[18]\ttrain-error:0.38234\ttest-error:0.37703                               \n",
      "\n",
      "[19]\ttrain-error:0.37429\ttest-error:0.37113                               \n",
      "\n",
      "[20]\ttrain-error:0.34853\ttest-error:0.34558                               \n",
      "\n",
      "[21]\ttrain-error:0.33412\ttest-error:0.33348                               \n",
      "\n",
      "[22]\ttrain-error:0.25544\ttest-error:0.25547                               \n",
      "\n",
      "[23]\ttrain-error:0.23188\ttest-error:0.23126                               \n",
      "\n",
      "[24]\ttrain-error:0.23633\ttest-error:0.23741                               \n",
      "\n",
      "[25]\ttrain-error:0.21889\ttest-error:0.21554                               \n",
      "\n",
      "[26]\ttrain-error:0.29204\ttest-error:0.29423                               \n",
      "\n",
      "[27]\ttrain-error:0.22942\ttest-error:0.22592                               \n",
      "\n",
      "[28]\ttrain-error:0.36235\ttest-error:0.36609                               \n",
      "\n",
      "[29]\ttrain-error:0.24782\ttest-error:0.24343                               \n",
      "\n",
      "[30]\ttrain-error:0.28507\ttest-error:0.28323                               \n",
      "\n",
      "[31]\ttrain-error:0.23298\ttest-error:0.22899                               \n",
      "\n",
      "[32]\ttrain-error:0.23504\ttest-error:0.23053                               \n",
      "\n",
      "[33]\ttrain-error:0.21972\ttest-error:0.21708                               \n",
      "\n",
      "[34]\ttrain-error:0.21490\ttest-error:0.21087                               \n",
      "\n",
      "[35]\ttrain-error:0.21127\ttest-error:0.21001                               \n",
      "\n",
      "[36]\ttrain-error:0.24711\ttest-error:0.24386                               \n",
      "\n",
      "[37]\ttrain-error:0.21225\ttest-error:0.20688                               \n",
      "\n",
      "[38]\ttrain-error:0.31956\ttest-error:0.31241                               \n",
      "\n",
      "[39]\ttrain-error:0.21265\ttest-error:0.20977                               \n",
      "\n",
      "[40]\ttrain-error:0.29063\ttest-error:0.29245                               \n",
      "\n",
      "[41]\ttrain-error:0.21106\ttest-error:0.20971                               \n",
      "\n",
      "[42]\ttrain-error:0.27411\ttest-error:0.27426                               \n",
      "\n",
      "[43]\ttrain-error:0.23950\ttest-error:0.23593                               \n",
      "\n",
      "[44]\ttrain-error:0.46606\ttest-error:0.46443                               \n",
      "\n",
      "[45]\ttrain-error:0.27930\ttest-error:0.27623                               \n",
      "\n",
      "[46]\ttrain-error:0.26186\ttest-error:0.26050                               \n",
      "\n",
      "[47]\ttrain-error:0.22423\ttest-error:0.22432                               \n",
      "\n",
      "[48]\ttrain-error:0.22546\ttest-error:0.22709                               \n",
      "\n",
      "[49]\ttrain-error:0.20989\ttest-error:0.21069                               \n",
      "\n",
      "[50]\ttrain-error:0.23372\ttest-error:0.23206                               \n",
      "\n",
      "[51]\ttrain-error:0.20565\ttest-error:0.20669                               \n",
      "\n",
      "[52]\ttrain-error:0.21004\ttest-error:0.21357                               \n",
      "\n",
      "[53]\ttrain-error:0.20694\ttest-error:0.20762                               \n",
      "\n",
      "[54]\ttrain-error:0.21382\ttest-error:0.21646                               \n",
      "\n",
      "[55]\ttrain-error:0.20031\ttest-error:0.20080                               \n",
      "\n",
      "[56]\ttrain-error:0.20405\ttest-error:0.20749                               \n",
      "\n",
      "[57]\ttrain-error:0.19942\ttest-error:0.20141                               \n",
      "\n",
      "[58]\ttrain-error:0.19936\ttest-error:0.20141                               \n",
      "\n",
      "[59]\ttrain-error:0.20055\ttest-error:0.20289                               \n",
      "\n",
      "[60]\ttrain-error:0.19948\ttest-error:0.20111                               \n",
      "\n",
      "[61]\ttrain-error:0.19810\ttest-error:0.20098                               \n",
      "\n",
      "[62]\ttrain-error:0.20086\ttest-error:0.20098                               \n",
      "\n",
      "[63]\ttrain-error:0.19825\ttest-error:0.19926                               \n",
      "\n",
      "[64]\ttrain-error:0.20061\ttest-error:0.20184                               \n",
      "\n",
      "[65]\ttrain-error:0.19868\ttest-error:0.20037                               \n",
      "\n",
      "[66]\ttrain-error:0.19859\ttest-error:0.20000                               \n",
      "\n",
      "[67]\ttrain-error:0.19711\ttest-error:0.19865                               \n",
      "\n",
      "[68]\ttrain-error:0.19641\ttest-error:0.19785                               \n",
      "\n",
      "[69]\ttrain-error:0.19674\ttest-error:0.19797                               \n",
      "\n",
      "[70]\ttrain-error:0.19417\ttest-error:0.19478                               \n",
      "\n",
      "[71]\ttrain-error:0.19579\ttest-error:0.19681                               \n",
      "\n",
      "[72]\ttrain-error:0.19321\ttest-error:0.19263                               \n",
      "\n",
      "[73]\ttrain-error:0.20046\ttest-error:0.20012                               \n",
      "\n",
      "[74]\ttrain-error:0.19558\ttest-error:0.19441                               \n",
      "\n",
      "[75]\ttrain-error:0.20255\ttest-error:0.20258                               \n",
      "\n",
      "[76]\ttrain-error:0.19662\ttest-error:0.19582                               \n",
      "\n",
      "[77]\ttrain-error:0.19785\ttest-error:0.19644                               \n",
      "\n",
      "[78]\ttrain-error:0.19714\ttest-error:0.19447                               \n",
      "\n",
      "[79]\ttrain-error:0.19764\ttest-error:0.19607                               \n",
      "\n",
      "[80]\ttrain-error:0.19650\ttest-error:0.19484                               \n",
      "\n",
      "[81]\ttrain-error:0.19622\ttest-error:0.19558                               \n",
      "\n",
      "[82]\ttrain-error:0.19656\ttest-error:0.19693                               \n",
      "\n",
      "[83]\ttrain-error:0.19441\ttest-error:0.19521                               \n",
      "\n",
      "[84]\ttrain-error:0.19386\ttest-error:0.19453                               \n",
      "\n",
      "[85]\ttrain-error:0.19254\ttest-error:0.19324                               \n",
      "\n",
      "[86]\ttrain-error:0.19251\ttest-error:0.19490                               \n",
      "\n",
      "[87]\ttrain-error:0.19186\ttest-error:0.19423                               \n",
      "\n",
      "[88]\ttrain-error:0.19085\ttest-error:0.19417                               \n",
      "\n",
      "[89]\ttrain-error:0.19069\ttest-error:0.19331                               \n",
      "\n",
      "[90]\ttrain-error:0.19066\ttest-error:0.19048                               \n",
      "\n",
      "[91]\ttrain-error:0.19287\ttest-error:0.19245                               \n",
      "\n",
      "[92]\ttrain-error:0.19383\ttest-error:0.19251                               \n",
      "\n",
      "[93]\ttrain-error:0.19281\ttest-error:0.19349                               \n",
      "\n",
      "[94]\ttrain-error:0.19171\ttest-error:0.19306                               \n",
      "\n",
      "[95]\ttrain-error:0.19115\ttest-error:0.19201                               \n",
      "\n",
      "[96]\ttrain-error:0.19220\ttest-error:0.19238                               \n",
      "\n",
      "[97]\ttrain-error:0.19005\ttest-error:0.19109                               \n",
      "\n",
      "[98]\ttrain-error:0.19254\ttest-error:0.19331                               \n",
      "\n",
      "[99]\ttrain-error:0.19073\ttest-error:0.19220                               \n",
      "\n",
      "{'alpha': 0.01444034376629122, 'btype': 'I', 'colsample_bylevel': 0.6358764998769979, 'colsample_bytree': 0.7370947059491348, 'eta': 0.12590509678086323, 'eval_metric': ('error',), 'extra_dims': 4, 'gamma': 0, 'lambda': 1.570645511983137e-07, 'max_depth': 7, 'min_child_weight': 0.2730019100483141, 'objective': 'binary:logistic', 'subsample': 0.9614963011329123}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:11:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13873\ttest-error:0.13814                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-error:0.13526\ttest-error:0.13618                                \n",
      "\n",
      "[2]\ttrain-error:0.13274\ttest-error:0.13305                                \n",
      "\n",
      "[3]\ttrain-error:0.13016\ttest-error:0.13249                                \n",
      "\n",
      "[4]\ttrain-error:0.12850\ttest-error:0.13071                                \n",
      "\n",
      "[5]\ttrain-error:0.12580\ttest-error:0.12918                                \n",
      "\n",
      "[6]\ttrain-error:0.12340\ttest-error:0.12740                                \n",
      "\n",
      "[7]\ttrain-error:0.12018\ttest-error:0.12783                                \n",
      "\n",
      "[8]\ttrain-error:0.11830\ttest-error:0.12660                                \n",
      "\n",
      "[9]\ttrain-error:0.11708\ttest-error:0.12592                                \n",
      "\n",
      "[10]\ttrain-error:0.11655\ttest-error:0.12697                               \n",
      "\n",
      "[11]\ttrain-error:0.11548\ttest-error:0.12586                               \n",
      "\n",
      "[12]\ttrain-error:0.11468\ttest-error:0.12703                               \n",
      "\n",
      "[13]\ttrain-error:0.11400\ttest-error:0.12684                               \n",
      "\n",
      "[14]\ttrain-error:0.11330\ttest-error:0.12660                               \n",
      "\n",
      "[15]\ttrain-error:0.11247\ttest-error:0.12678                               \n",
      "\n",
      "[16]\ttrain-error:0.11179\ttest-error:0.12697                               \n",
      "\n",
      "[17]\ttrain-error:0.11066\ttest-error:0.12709                               \n",
      "\n",
      "[18]\ttrain-error:0.11032\ttest-error:0.12690                               \n",
      "\n",
      "[19]\ttrain-error:0.10989\ttest-error:0.12758                               \n",
      "\n",
      "[20]\ttrain-error:0.10909\ttest-error:0.12733                               \n",
      "\n",
      "[21]\ttrain-error:0.10894\ttest-error:0.12678                               \n",
      "\n",
      "[22]\ttrain-error:0.10743\ttest-error:0.12647                               \n",
      "\n",
      "[23]\ttrain-error:0.10676\ttest-error:0.12647                               \n",
      "\n",
      "[24]\ttrain-error:0.10630\ttest-error:0.12623                               \n",
      "\n",
      "[25]\ttrain-error:0.10590\ttest-error:0.12647                               \n",
      "\n",
      "[26]\ttrain-error:0.10528\ttest-error:0.12617                               \n",
      "\n",
      "[27]\ttrain-error:0.10473\ttest-error:0.12598                               \n",
      "\n",
      "[28]\ttrain-error:0.10356\ttest-error:0.12684                               \n",
      "\n",
      "[29]\ttrain-error:0.10322\ttest-error:0.12758                               \n",
      "\n",
      "[30]\ttrain-error:0.10292\ttest-error:0.12740                               \n",
      "\n",
      "[31]\ttrain-error:0.10249\ttest-error:0.12733                               \n",
      "\n",
      "[32]\ttrain-error:0.10200\ttest-error:0.12746                               \n",
      "\n",
      "[33]\ttrain-error:0.10126\ttest-error:0.12801                               \n",
      "\n",
      "[34]\ttrain-error:0.10077\ttest-error:0.12770                               \n",
      "\n",
      "[35]\ttrain-error:0.09923\ttest-error:0.12752                               \n",
      "\n",
      "[36]\ttrain-error:0.09892\ttest-error:0.12752                               \n",
      "\n",
      "[37]\ttrain-error:0.09843\ttest-error:0.12733                               \n",
      "\n",
      "[38]\ttrain-error:0.09757\ttest-error:0.12783                               \n",
      "\n",
      "[39]\ttrain-error:0.09687\ttest-error:0.12758                               \n",
      "\n",
      "[40]\ttrain-error:0.09677\ttest-error:0.12752                               \n",
      "\n",
      "[41]\ttrain-error:0.09622\ttest-error:0.12789                               \n",
      "\n",
      "[42]\ttrain-error:0.09579\ttest-error:0.12801                               \n",
      "\n",
      "[43]\ttrain-error:0.09518\ttest-error:0.12752                               \n",
      "\n",
      "[44]\ttrain-error:0.09472\ttest-error:0.12776                               \n",
      "\n",
      "[45]\ttrain-error:0.09456\ttest-error:0.12770                               \n",
      "\n",
      "[46]\ttrain-error:0.09438\ttest-error:0.12764                               \n",
      "\n",
      "[47]\ttrain-error:0.09389\ttest-error:0.12746                               \n",
      "\n",
      "[48]\ttrain-error:0.09340\ttest-error:0.12733                               \n",
      "\n",
      "[49]\ttrain-error:0.09272\ttest-error:0.12776                               \n",
      "\n",
      "[50]\ttrain-error:0.09205\ttest-error:0.12838                               \n",
      "\n",
      "[51]\ttrain-error:0.09192\ttest-error:0.12887                               \n",
      "\n",
      "[52]\ttrain-error:0.09152\ttest-error:0.12893                               \n",
      "\n",
      "[53]\ttrain-error:0.09042\ttest-error:0.12893                               \n",
      "\n",
      "[54]\ttrain-error:0.09011\ttest-error:0.12912                               \n",
      "\n",
      "[55]\ttrain-error:0.08882\ttest-error:0.12918                               \n",
      "\n",
      "[56]\ttrain-error:0.08818\ttest-error:0.12961                               \n",
      "\n",
      "[57]\ttrain-error:0.08750\ttest-error:0.12985                               \n",
      "\n",
      "[58]\ttrain-error:0.08612\ttest-error:0.12991                               \n",
      "\n",
      "[59]\ttrain-error:0.08596\ttest-error:0.12979                               \n",
      "\n",
      "[60]\ttrain-error:0.08560\ttest-error:0.12954                               \n",
      "\n",
      "[61]\ttrain-error:0.08526\ttest-error:0.12961                               \n",
      "\n",
      "[62]\ttrain-error:0.08504\ttest-error:0.12930                               \n",
      "\n",
      "[63]\ttrain-error:0.08431\ttest-error:0.12967                               \n",
      "\n",
      "[64]\ttrain-error:0.08418\ttest-error:0.12991                               \n",
      "\n",
      "[65]\ttrain-error:0.08375\ttest-error:0.12967                               \n",
      "\n",
      "[66]\ttrain-error:0.08277\ttest-error:0.13077                               \n",
      "\n",
      "[67]\ttrain-error:0.08237\ttest-error:0.13059                               \n",
      "\n",
      "[68]\ttrain-error:0.08182\ttest-error:0.13059                               \n",
      "\n",
      "[69]\ttrain-error:0.08142\ttest-error:0.13084                               \n",
      "\n",
      "[70]\ttrain-error:0.08124\ttest-error:0.13065                               \n",
      "\n",
      "[71]\ttrain-error:0.08099\ttest-error:0.13114                               \n",
      "\n",
      "[72]\ttrain-error:0.08022\ttest-error:0.13157                               \n",
      "\n",
      "[73]\ttrain-error:0.08007\ttest-error:0.13188                               \n",
      "\n",
      "[74]\ttrain-error:0.08001\ttest-error:0.13188                               \n",
      "\n",
      "[75]\ttrain-error:0.07961\ttest-error:0.13170                               \n",
      "\n",
      "[76]\ttrain-error:0.07899\ttest-error:0.13194                               \n",
      "\n",
      "[77]\ttrain-error:0.07844\ttest-error:0.13157                               \n",
      "\n",
      "[78]\ttrain-error:0.07801\ttest-error:0.13157                               \n",
      "\n",
      "[79]\ttrain-error:0.07770\ttest-error:0.13157                               \n",
      "\n",
      "[80]\ttrain-error:0.07718\ttest-error:0.13139                               \n",
      "\n",
      "[81]\ttrain-error:0.07629\ttest-error:0.13200                               \n",
      "\n",
      "[82]\ttrain-error:0.07608\ttest-error:0.13225                               \n",
      "\n",
      "[83]\ttrain-error:0.07611\ttest-error:0.13212                               \n",
      "\n",
      "[84]\ttrain-error:0.07574\ttest-error:0.13237                               \n",
      "\n",
      "[85]\ttrain-error:0.07472\ttest-error:0.13200                               \n",
      "\n",
      "[86]\ttrain-error:0.07429\ttest-error:0.13163                               \n",
      "\n",
      "[87]\ttrain-error:0.07359\ttest-error:0.13176                               \n",
      "\n",
      "[88]\ttrain-error:0.07316\ttest-error:0.13249                               \n",
      "\n",
      "[89]\ttrain-error:0.07285\ttest-error:0.13262                               \n",
      "\n",
      "[90]\ttrain-error:0.07221\ttest-error:0.13237                               \n",
      "\n",
      "[91]\ttrain-error:0.07190\ttest-error:0.13262                               \n",
      "\n",
      "[92]\ttrain-error:0.07159\ttest-error:0.13298                               \n",
      "\n",
      "[93]\ttrain-error:0.07113\ttest-error:0.13243                               \n",
      "\n",
      "[94]\ttrain-error:0.07116\ttest-error:0.13243                               \n",
      "\n",
      "[95]\ttrain-error:0.07039\ttest-error:0.13225                               \n",
      "\n",
      "[96]\ttrain-error:0.06999\ttest-error:0.13298                               \n",
      "\n",
      "[97]\ttrain-error:0.06917\ttest-error:0.13323                               \n",
      "\n",
      "[98]\ttrain-error:0.06926\ttest-error:0.13317                               \n",
      "\n",
      "[99]\ttrain-error:0.06852\ttest-error:0.13372                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'I', 'colsample_bylevel': 0.5555725221958163, 'colsample_bytree': 0.7090715163346437, 'eta': 0.10953953409870001, 'eval_metric': ('error',), 'extra_dims': 4, 'gamma': 0, 'lambda': 2.951078584534351e-06, 'max_depth': 6, 'min_child_weight': 0.012779789576738605, 'objective': 'binary:logistic', 'subsample': 0.7295690390932664}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:12:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14161\ttest-error:0.14300                                \n",
      "\n",
      "[1]\ttrain-error:0.13833\ttest-error:0.13993                                \n",
      "\n",
      "[2]\ttrain-error:0.13593\ttest-error:0.13784                                \n",
      "\n",
      "[3]\ttrain-error:0.13529\ttest-error:0.13544                                \n",
      "\n",
      "[4]\ttrain-error:0.13329\ttest-error:0.13458                                \n",
      "\n",
      "[5]\ttrain-error:0.13268\ttest-error:0.13434                                \n",
      "\n",
      "[6]\ttrain-error:0.13102\ttest-error:0.13274                                \n",
      "\n",
      "[7]\ttrain-error:0.12862\ttest-error:0.13102                                \n",
      "\n",
      "[8]\ttrain-error:0.12638\ttest-error:0.13053                                \n",
      "\n",
      "[9]\ttrain-error:0.12463\ttest-error:0.12936                                \n",
      "\n",
      "[10]\ttrain-error:0.12328\ttest-error:0.12813                               \n",
      "\n",
      "[11]\ttrain-error:0.12177\ttest-error:0.12795                               \n",
      "\n",
      "[12]\ttrain-error:0.12070\ttest-error:0.12709                               \n",
      "\n",
      "[13]\ttrain-error:0.11913\ttest-error:0.12629                               \n",
      "\n",
      "[14]\ttrain-error:0.11827\ttest-error:0.12672                               \n",
      "\n",
      "[15]\ttrain-error:0.11754\ttest-error:0.12672                               \n",
      "\n",
      "[16]\ttrain-error:0.11631\ttest-error:0.12684                               \n",
      "\n",
      "[17]\ttrain-error:0.11505\ttest-error:0.12654                               \n",
      "\n",
      "[18]\ttrain-error:0.11416\ttest-error:0.12703                               \n",
      "\n",
      "[19]\ttrain-error:0.11345\ttest-error:0.12654                               \n",
      "\n",
      "[20]\ttrain-error:0.11271\ttest-error:0.12690                               \n",
      "\n",
      "[21]\ttrain-error:0.11115\ttest-error:0.12672                               \n",
      "\n",
      "[22]\ttrain-error:0.11017\ttest-error:0.12678                               \n",
      "\n",
      "[23]\ttrain-error:0.10967\ttest-error:0.12703                               \n",
      "\n",
      "[24]\ttrain-error:0.10915\ttest-error:0.12703                               \n",
      "\n",
      "[25]\ttrain-error:0.10820\ttest-error:0.12715                               \n",
      "\n",
      "[26]\ttrain-error:0.10789\ttest-error:0.12666                               \n",
      "\n",
      "[27]\ttrain-error:0.10752\ttest-error:0.12617                               \n",
      "\n",
      "[28]\ttrain-error:0.10666\ttest-error:0.12641                               \n",
      "\n",
      "[29]\ttrain-error:0.10580\ttest-error:0.12611                               \n",
      "\n",
      "[30]\ttrain-error:0.10547\ttest-error:0.12629                               \n",
      "\n",
      "[31]\ttrain-error:0.10516\ttest-error:0.12604                               \n",
      "\n",
      "[32]\ttrain-error:0.10485\ttest-error:0.12641                               \n",
      "\n",
      "[33]\ttrain-error:0.10421\ttest-error:0.12586                               \n",
      "\n",
      "[34]\ttrain-error:0.10418\ttest-error:0.12555                               \n",
      "\n",
      "[35]\ttrain-error:0.10307\ttest-error:0.12604                               \n",
      "\n",
      "[36]\ttrain-error:0.10184\ttest-error:0.12654                               \n",
      "\n",
      "[37]\ttrain-error:0.10126\ttest-error:0.12629                               \n",
      "\n",
      "[38]\ttrain-error:0.09997\ttest-error:0.12647                               \n",
      "\n",
      "[39]\ttrain-error:0.09963\ttest-error:0.12703                               \n",
      "\n",
      "[40]\ttrain-error:0.09896\ttest-error:0.12641                               \n",
      "\n",
      "[41]\ttrain-error:0.09856\ttest-error:0.12666                               \n",
      "\n",
      "[42]\ttrain-error:0.09788\ttest-error:0.12684                               \n",
      "\n",
      "[43]\ttrain-error:0.09751\ttest-error:0.12654                               \n",
      "\n",
      "[44]\ttrain-error:0.09708\ttest-error:0.12758                               \n",
      "\n",
      "[45]\ttrain-error:0.09656\ttest-error:0.12832                               \n",
      "\n",
      "[46]\ttrain-error:0.09622\ttest-error:0.12770                               \n",
      "\n",
      "[47]\ttrain-error:0.09518\ttest-error:0.12770                               \n",
      "\n",
      "[48]\ttrain-error:0.09450\ttest-error:0.12789                               \n",
      "\n",
      "[49]\ttrain-error:0.09392\ttest-error:0.12746                               \n",
      "\n",
      "[50]\ttrain-error:0.09355\ttest-error:0.12795                               \n",
      "\n",
      "[51]\ttrain-error:0.09315\ttest-error:0.12819                               \n",
      "\n",
      "[52]\ttrain-error:0.09260\ttest-error:0.12838                               \n",
      "\n",
      "[53]\ttrain-error:0.09189\ttest-error:0.12819                               \n",
      "\n",
      "[54]\ttrain-error:0.09198\ttest-error:0.12826                               \n",
      "\n",
      "[55]\ttrain-error:0.09112\ttest-error:0.12844                               \n",
      "\n",
      "[56]\ttrain-error:0.09048\ttest-error:0.12875                               \n",
      "\n",
      "[57]\ttrain-error:0.09002\ttest-error:0.12862                               \n",
      "\n",
      "[58]\ttrain-error:0.08965\ttest-error:0.12887                               \n",
      "\n",
      "[59]\ttrain-error:0.08934\ttest-error:0.12875                               \n",
      "\n",
      "[60]\ttrain-error:0.08870\ttest-error:0.12869                               \n",
      "\n",
      "[61]\ttrain-error:0.08775\ttest-error:0.12875                               \n",
      "\n",
      "[62]\ttrain-error:0.08750\ttest-error:0.12961                               \n",
      "\n",
      "[63]\ttrain-error:0.08646\ttest-error:0.12924                               \n",
      "\n",
      "[64]\ttrain-error:0.08618\ttest-error:0.12930                               \n",
      "\n",
      "[65]\ttrain-error:0.08544\ttest-error:0.12954                               \n",
      "\n",
      "[66]\ttrain-error:0.08449\ttest-error:0.12961                               \n",
      "\n",
      "[67]\ttrain-error:0.08415\ttest-error:0.12973                               \n",
      "\n",
      "[68]\ttrain-error:0.08345\ttest-error:0.12973                               \n",
      "\n",
      "[69]\ttrain-error:0.08283\ttest-error:0.13016                               \n",
      "\n",
      "[70]\ttrain-error:0.08286\ttest-error:0.12985                               \n",
      "\n",
      "[71]\ttrain-error:0.08246\ttest-error:0.13010                               \n",
      "\n",
      "[72]\ttrain-error:0.08222\ttest-error:0.13016                               \n",
      "\n",
      "[73]\ttrain-error:0.08219\ttest-error:0.12948                               \n",
      "\n",
      "[74]\ttrain-error:0.08167\ttest-error:0.12973                               \n",
      "\n",
      "[75]\ttrain-error:0.08111\ttest-error:0.12991                               \n",
      "\n",
      "[76]\ttrain-error:0.08065\ttest-error:0.13016                               \n",
      "\n",
      "[77]\ttrain-error:0.08022\ttest-error:0.12991                               \n",
      "\n",
      "[78]\ttrain-error:0.07948\ttest-error:0.13034                               \n",
      "\n",
      "[79]\ttrain-error:0.07924\ttest-error:0.13028                               \n",
      "\n",
      "[80]\ttrain-error:0.07896\ttest-error:0.13028                               \n",
      "\n",
      "[81]\ttrain-error:0.07829\ttest-error:0.13016                               \n",
      "\n",
      "[82]\ttrain-error:0.07816\ttest-error:0.13010                               \n",
      "\n",
      "[83]\ttrain-error:0.07792\ttest-error:0.12998                               \n",
      "\n",
      "[84]\ttrain-error:0.07773\ttest-error:0.13004                               \n",
      "\n",
      "[85]\ttrain-error:0.07718\ttest-error:0.13034                               \n",
      "\n",
      "[86]\ttrain-error:0.07672\ttest-error:0.13071                               \n",
      "\n",
      "[87]\ttrain-error:0.07638\ttest-error:0.13071                               \n",
      "\n",
      "[88]\ttrain-error:0.07555\ttest-error:0.13090                               \n",
      "\n",
      "[89]\ttrain-error:0.07482\ttest-error:0.13016                               \n",
      "\n",
      "[90]\ttrain-error:0.07429\ttest-error:0.13016                               \n",
      "\n",
      "[91]\ttrain-error:0.07408\ttest-error:0.12985                               \n",
      "\n",
      "[92]\ttrain-error:0.07316\ttest-error:0.13010                               \n",
      "\n",
      "[93]\ttrain-error:0.07291\ttest-error:0.13040                               \n",
      "\n",
      "[94]\ttrain-error:0.07242\ttest-error:0.13120                               \n",
      "\n",
      "[95]\ttrain-error:0.07181\ttest-error:0.13139                               \n",
      "\n",
      "[96]\ttrain-error:0.07138\ttest-error:0.13120                               \n",
      "\n",
      "[97]\ttrain-error:0.07061\ttest-error:0.13139                               \n",
      "\n",
      "[98]\ttrain-error:0.06987\ttest-error:0.13145                               \n",
      "\n",
      "[99]\ttrain-error:0.06941\ttest-error:0.13102                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'I', 'colsample_bylevel': 0.7705851917739193, 'colsample_bytree': 0.6534639055235963, 'eta': 0.2935847651333616, 'eval_metric': ('error',), 'extra_dims': 6, 'gamma': 0, 'lambda': 0, 'max_depth': 2, 'min_child_weight': 0.050591536820393544, 'objective': 'binary:logistic', 'subsample': 0.8882981176878677}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:13:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.19567\ttest-error:0.19318                                \n",
      "\n",
      "[1]\ttrain-error:0.20614\ttest-error:0.20350                                \n",
      "\n",
      "[2]\ttrain-error:0.15390\ttest-error:0.15565                                \n",
      "\n",
      "[3]\ttrain-error:0.24773\ttest-error:0.24767                                \n",
      "\n",
      "[4]\ttrain-error:0.17924\ttest-error:0.17905                                \n",
      "\n",
      "[5]\ttrain-error:0.28126\ttest-error:0.28139                                \n",
      "\n",
      "[6]\ttrain-error:0.20350\ttest-error:0.20123                                \n",
      "\n",
      "[7]\ttrain-error:0.60488\ttest-error:0.60620                                \n",
      "\n",
      "[8]\ttrain-error:0.24082\ttest-error:0.23649                                \n",
      "\n",
      "[9]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[10]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[11]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[12]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[13]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[14]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[15]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[16]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[17]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[18]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[19]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[20]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[21]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[22]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[23]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[24]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[25]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[26]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[27]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[28]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[29]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[30]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[31]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[32]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[33]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[34]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[35]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[36]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[37]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[38]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[39]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[40]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[41]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[42]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[43]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[44]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[45]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[46]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[47]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[48]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[49]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[50]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[51]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[52]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[53]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[54]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[55]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[56]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[57]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[58]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[59]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[60]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[61]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[62]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[63]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[64]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[65]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[66]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[67]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[68]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[69]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[70]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[71]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[72]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[73]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[74]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[75]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[76]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[77]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[78]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[79]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[80]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[81]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[82]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[83]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[84]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[85]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[86]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[87]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[88]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[89]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[90]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[91]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[92]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[93]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[94]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[95]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[96]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[98]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[99]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "{'alpha': 0.00020979125137051763, 'btype': 'I', 'colsample_bylevel': 0.7431183163576391, 'colsample_bytree': 0.9597526604488409, 'eta': 0.001313749986846003, 'eval_metric': ('error',), 'extra_dims': 5, 'gamma': 0, 'lambda': 3.655040679951241e-07, 'max_depth': 9, 'min_child_weight': 3.83488878242048, 'objective': 'binary:logistic', 'subsample': 0.7538410221124217}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:13:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13900\ttest-error:0.14005                                \n",
      "\n",
      "[1]\ttrain-error:0.13695\ttest-error:0.13821                                \n",
      "\n",
      "[2]\ttrain-error:0.13732\ttest-error:0.13778                                \n",
      "\n",
      "[3]\ttrain-error:0.13655\ttest-error:0.13796                                \n",
      "\n",
      "[4]\ttrain-error:0.13661\ttest-error:0.13827                                \n",
      "\n",
      "[5]\ttrain-error:0.13713\ttest-error:0.13950                                \n",
      "\n",
      "[6]\ttrain-error:0.13725\ttest-error:0.13968                                \n",
      "\n",
      "[7]\ttrain-error:0.13725\ttest-error:0.13993                                \n",
      "\n",
      "[8]\ttrain-error:0.13759\ttest-error:0.14072                                \n",
      "\n",
      "[9]\ttrain-error:0.13858\ttest-error:0.14128                                \n",
      "\n",
      "[10]\ttrain-error:0.13802\ttest-error:0.14017                               \n",
      "\n",
      "[11]\ttrain-error:0.13728\ttest-error:0.13980                               \n",
      "\n",
      "[12]\ttrain-error:0.13722\ttest-error:0.13937                               \n",
      "\n",
      "[13]\ttrain-error:0.13713\ttest-error:0.13913                               \n",
      "\n",
      "[14]\ttrain-error:0.13722\ttest-error:0.13864                               \n",
      "\n",
      "[15]\ttrain-error:0.13735\ttest-error:0.13919                               \n",
      "\n",
      "[16]\ttrain-error:0.13750\ttest-error:0.13950                               \n",
      "\n",
      "[17]\ttrain-error:0.13716\ttest-error:0.13931                               \n",
      "\n",
      "[18]\ttrain-error:0.13704\ttest-error:0.13931                               \n",
      "\n",
      "[19]\ttrain-error:0.13725\ttest-error:0.13944                               \n",
      "\n",
      "[20]\ttrain-error:0.13753\ttest-error:0.13986                               \n",
      "\n",
      "[21]\ttrain-error:0.13728\ttest-error:0.13968                               \n",
      "\n",
      "[22]\ttrain-error:0.13747\ttest-error:0.14030                               \n",
      "\n",
      "[23]\ttrain-error:0.13738\ttest-error:0.14017                               \n",
      "\n",
      "[24]\ttrain-error:0.13732\ttest-error:0.13999                               \n",
      "\n",
      "[25]\ttrain-error:0.13738\ttest-error:0.14011                               \n",
      "\n",
      "[26]\ttrain-error:0.13713\ttest-error:0.13962                               \n",
      "\n",
      "[27]\ttrain-error:0.13716\ttest-error:0.13962                               \n",
      "\n",
      "[28]\ttrain-error:0.13722\ttest-error:0.13937                               \n",
      "\n",
      "[29]\ttrain-error:0.13704\ttest-error:0.13937                               \n",
      "\n",
      "[30]\ttrain-error:0.13689\ttest-error:0.13937                               \n",
      "\n",
      "[31]\ttrain-error:0.13689\ttest-error:0.13956                               \n",
      "\n",
      "[32]\ttrain-error:0.13692\ttest-error:0.13931                               \n",
      "\n",
      "[33]\ttrain-error:0.13689\ttest-error:0.13937                               \n",
      "\n",
      "[34]\ttrain-error:0.13698\ttest-error:0.13968                               \n",
      "\n",
      "[35]\ttrain-error:0.13692\ttest-error:0.13950                               \n",
      "\n",
      "[36]\ttrain-error:0.13679\ttest-error:0.13931                               \n",
      "\n",
      "[37]\ttrain-error:0.13686\ttest-error:0.13931                               \n",
      "\n",
      "[38]\ttrain-error:0.13698\ttest-error:0.13913                               \n",
      "\n",
      "[39]\ttrain-error:0.13698\ttest-error:0.13919                               \n",
      "\n",
      "[40]\ttrain-error:0.13689\ttest-error:0.13925                               \n",
      "\n",
      "[41]\ttrain-error:0.13692\ttest-error:0.13913                               \n",
      "\n",
      "[42]\ttrain-error:0.13698\ttest-error:0.13931                               \n",
      "\n",
      "[43]\ttrain-error:0.13701\ttest-error:0.13913                               \n",
      "\n",
      "[44]\ttrain-error:0.13707\ttest-error:0.13925                               \n",
      "\n",
      "[45]\ttrain-error:0.13698\ttest-error:0.13931                               \n",
      "\n",
      "[46]\ttrain-error:0.13701\ttest-error:0.13913                               \n",
      "\n",
      "[47]\ttrain-error:0.13692\ttest-error:0.13907                               \n",
      "\n",
      "[48]\ttrain-error:0.13682\ttest-error:0.13925                               \n",
      "\n",
      "[49]\ttrain-error:0.13676\ttest-error:0.13888                               \n",
      "\n",
      "[50]\ttrain-error:0.13679\ttest-error:0.13900                               \n",
      "\n",
      "[51]\ttrain-error:0.13695\ttest-error:0.13900                               \n",
      "\n",
      "[52]\ttrain-error:0.13686\ttest-error:0.13907                               \n",
      "\n",
      "[53]\ttrain-error:0.13686\ttest-error:0.13882                               \n",
      "\n",
      "[54]\ttrain-error:0.13679\ttest-error:0.13870                               \n",
      "\n",
      "[55]\ttrain-error:0.13686\ttest-error:0.13864                               \n",
      "\n",
      "[56]\ttrain-error:0.13679\ttest-error:0.13864                               \n",
      "\n",
      "[57]\ttrain-error:0.13692\ttest-error:0.13882                               \n",
      "\n",
      "[58]\ttrain-error:0.13692\ttest-error:0.13870                               \n",
      "\n",
      "[59]\ttrain-error:0.13679\ttest-error:0.13845                               \n",
      "\n",
      "[60]\ttrain-error:0.13692\ttest-error:0.13870                               \n",
      "\n",
      "[61]\ttrain-error:0.13679\ttest-error:0.13876                               \n",
      "\n",
      "[62]\ttrain-error:0.13679\ttest-error:0.13858                               \n",
      "\n",
      "[63]\ttrain-error:0.13670\ttest-error:0.13845                               \n",
      "\n",
      "[64]\ttrain-error:0.13673\ttest-error:0.13851                               \n",
      "\n",
      "[65]\ttrain-error:0.13664\ttest-error:0.13845                               \n",
      "\n",
      "[66]\ttrain-error:0.13661\ttest-error:0.13845                               \n",
      "\n",
      "[67]\ttrain-error:0.13664\ttest-error:0.13845                               \n",
      "\n",
      "[68]\ttrain-error:0.13667\ttest-error:0.13845                               \n",
      "\n",
      "[69]\ttrain-error:0.13673\ttest-error:0.13839                               \n",
      "\n",
      "[70]\ttrain-error:0.13667\ttest-error:0.13827                               \n",
      "\n",
      "[71]\ttrain-error:0.13655\ttest-error:0.13821                               \n",
      "\n",
      "[72]\ttrain-error:0.13646\ttest-error:0.13839                               \n",
      "\n",
      "[73]\ttrain-error:0.13642\ttest-error:0.13827                               \n",
      "\n",
      "[74]\ttrain-error:0.13642\ttest-error:0.13827                               \n",
      "\n",
      "[75]\ttrain-error:0.13642\ttest-error:0.13814                               \n",
      "\n",
      "[76]\ttrain-error:0.13639\ttest-error:0.13814                               \n",
      "\n",
      "[77]\ttrain-error:0.13649\ttest-error:0.13814                               \n",
      "\n",
      "[78]\ttrain-error:0.13642\ttest-error:0.13827                               \n",
      "\n",
      "[79]\ttrain-error:0.13636\ttest-error:0.13827                               \n",
      "\n",
      "[80]\ttrain-error:0.13646\ttest-error:0.13821                               \n",
      "\n",
      "[81]\ttrain-error:0.13630\ttest-error:0.13851                               \n",
      "\n",
      "[82]\ttrain-error:0.13633\ttest-error:0.13845                               \n",
      "\n",
      "[83]\ttrain-error:0.13636\ttest-error:0.13845                               \n",
      "\n",
      "[84]\ttrain-error:0.13630\ttest-error:0.13845                               \n",
      "\n",
      "[85]\ttrain-error:0.13621\ttest-error:0.13821                               \n",
      "\n",
      "[86]\ttrain-error:0.13609\ttest-error:0.13827                               \n",
      "\n",
      "[87]\ttrain-error:0.13609\ttest-error:0.13821                               \n",
      "\n",
      "[88]\ttrain-error:0.13612\ttest-error:0.13790                               \n",
      "\n",
      "[89]\ttrain-error:0.13624\ttest-error:0.13772                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90]\ttrain-error:0.13615\ttest-error:0.13778                               \n",
      "\n",
      "[91]\ttrain-error:0.13612\ttest-error:0.13772                               \n",
      "\n",
      "[92]\ttrain-error:0.13618\ttest-error:0.13778                               \n",
      "\n",
      "[93]\ttrain-error:0.13600\ttest-error:0.13784                               \n",
      "\n",
      "[94]\ttrain-error:0.13606\ttest-error:0.13772                               \n",
      "\n",
      "[95]\ttrain-error:0.13600\ttest-error:0.13778                               \n",
      "\n",
      "[96]\ttrain-error:0.13596\ttest-error:0.13759                               \n",
      "\n",
      "[97]\ttrain-error:0.13596\ttest-error:0.13778                               \n",
      "\n",
      "[98]\ttrain-error:0.13596\ttest-error:0.13772                               \n",
      "\n",
      "[99]\ttrain-error:0.13600\ttest-error:0.13778                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'In', 'colsample_bylevel': 0.9220638615242354, 'colsample_bytree': 0.7682929270243231, 'eta': 0.03907758401535366, 'eval_metric': ('error',), 'extra_dims': 0, 'gamma': 0.0039023245477000043, 'lambda': 0.0015108510781854504, 'max_depth': 3, 'min_child_weight': 136.6613870523947, 'objective': 'binary:logistic', 'subsample': 0.9348818106947293}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:14:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.16404\ttest-error:0.16554                                \n",
      "\n",
      "[1]\ttrain-error:0.15783\ttest-error:0.15989                                \n",
      "\n",
      "[2]\ttrain-error:0.18345\ttest-error:0.18335                                \n",
      "\n",
      "[3]\ttrain-error:0.15700\ttest-error:0.15909                                \n",
      "\n",
      "[4]\ttrain-error:0.18255\ttest-error:0.18280                                \n",
      "\n",
      "[5]\ttrain-error:0.15700\ttest-error:0.15909                                \n",
      "\n",
      "[6]\ttrain-error:0.15375\ttest-error:0.15516                                \n",
      "\n",
      "[7]\ttrain-error:0.15359\ttest-error:0.15448                                \n",
      "\n",
      "[8]\ttrain-error:0.15396\ttest-error:0.15436                                \n",
      "\n",
      "[9]\ttrain-error:0.15369\ttest-error:0.15516                                \n",
      "\n",
      "[10]\ttrain-error:0.15396\ttest-error:0.15436                               \n",
      "\n",
      "[11]\ttrain-error:0.15402\ttest-error:0.15442                               \n",
      "\n",
      "[12]\ttrain-error:0.15393\ttest-error:0.15375                               \n",
      "\n",
      "[13]\ttrain-error:0.15375\ttest-error:0.15369                               \n",
      "\n",
      "[14]\ttrain-error:0.15387\ttest-error:0.15381                               \n",
      "\n",
      "[15]\ttrain-error:0.15415\ttest-error:0.15454                               \n",
      "\n",
      "[16]\ttrain-error:0.15366\ttest-error:0.15332                               \n",
      "\n",
      "[17]\ttrain-error:0.15347\ttest-error:0.15424                               \n",
      "\n",
      "[18]\ttrain-error:0.15366\ttest-error:0.15442                               \n",
      "\n",
      "[19]\ttrain-error:0.15381\ttest-error:0.15356                               \n",
      "\n",
      "[20]\ttrain-error:0.15439\ttest-error:0.15412                               \n",
      "\n",
      "[21]\ttrain-error:0.15412\ttest-error:0.15405                               \n",
      "\n",
      "[22]\ttrain-error:0.15249\ttest-error:0.15209                               \n",
      "\n",
      "[23]\ttrain-error:0.15175\ttest-error:0.15129                               \n",
      "\n",
      "[24]\ttrain-error:0.15359\ttest-error:0.15240                               \n",
      "\n",
      "[25]\ttrain-error:0.15510\ttest-error:0.15436                               \n",
      "\n",
      "[26]\ttrain-error:0.15184\ttest-error:0.15104                               \n",
      "\n",
      "[27]\ttrain-error:0.15313\ttest-error:0.15203                               \n",
      "\n",
      "[28]\ttrain-error:0.15123\ttest-error:0.15055                               \n",
      "\n",
      "[29]\ttrain-error:0.15123\ttest-error:0.15055                               \n",
      "\n",
      "[30]\ttrain-error:0.15111\ttest-error:0.15055                               \n",
      "\n",
      "[31]\ttrain-error:0.15095\ttest-error:0.15031                               \n",
      "\n",
      "[32]\ttrain-error:0.15111\ttest-error:0.15025                               \n",
      "\n",
      "[33]\ttrain-error:0.15123\ttest-error:0.15018                               \n",
      "\n",
      "[34]\ttrain-error:0.15114\ttest-error:0.15037                               \n",
      "\n",
      "[35]\ttrain-error:0.15141\ttest-error:0.15037                               \n",
      "\n",
      "[36]\ttrain-error:0.15166\ttest-error:0.15055                               \n",
      "\n",
      "[37]\ttrain-error:0.15095\ttest-error:0.15037                               \n",
      "\n",
      "[38]\ttrain-error:0.15095\ttest-error:0.15043                               \n",
      "\n",
      "[39]\ttrain-error:0.15160\ttest-error:0.15074                               \n",
      "\n",
      "[40]\ttrain-error:0.15190\ttest-error:0.15104                               \n",
      "\n",
      "[41]\ttrain-error:0.15101\ttest-error:0.15049                               \n",
      "\n",
      "[42]\ttrain-error:0.15132\ttest-error:0.15061                               \n",
      "\n",
      "[43]\ttrain-error:0.15092\ttest-error:0.15025                               \n",
      "\n",
      "[44]\ttrain-error:0.15114\ttest-error:0.15031                               \n",
      "\n",
      "[45]\ttrain-error:0.15135\ttest-error:0.15074                               \n",
      "\n",
      "[46]\ttrain-error:0.15169\ttest-error:0.15068                               \n",
      "\n",
      "[47]\ttrain-error:0.15138\ttest-error:0.15049                               \n",
      "\n",
      "[48]\ttrain-error:0.15160\ttest-error:0.15061                               \n",
      "\n",
      "[49]\ttrain-error:0.15114\ttest-error:0.14945                               \n",
      "\n",
      "[50]\ttrain-error:0.15104\ttest-error:0.14951                               \n",
      "\n",
      "[51]\ttrain-error:0.15114\ttest-error:0.14963                               \n",
      "\n",
      "[52]\ttrain-error:0.15104\ttest-error:0.14963                               \n",
      "\n",
      "[53]\ttrain-error:0.15095\ttest-error:0.14939                               \n",
      "\n",
      "[54]\ttrain-error:0.15052\ttest-error:0.14914                               \n",
      "\n",
      "[55]\ttrain-error:0.15049\ttest-error:0.14889                               \n",
      "\n",
      "[56]\ttrain-error:0.15031\ttest-error:0.14902                               \n",
      "\n",
      "[57]\ttrain-error:0.15034\ttest-error:0.14889                               \n",
      "\n",
      "[58]\ttrain-error:0.15043\ttest-error:0.14920                               \n",
      "\n",
      "[59]\ttrain-error:0.14997\ttest-error:0.14846                               \n",
      "\n",
      "[60]\ttrain-error:0.14954\ttest-error:0.14810                               \n",
      "\n",
      "[61]\ttrain-error:0.14963\ttest-error:0.14853                               \n",
      "\n",
      "[62]\ttrain-error:0.14942\ttest-error:0.14834                               \n",
      "\n",
      "[63]\ttrain-error:0.14945\ttest-error:0.14834                               \n",
      "\n",
      "[64]\ttrain-error:0.14929\ttest-error:0.14816                               \n",
      "\n",
      "[65]\ttrain-error:0.14923\ttest-error:0.14810                               \n",
      "\n",
      "[66]\ttrain-error:0.14951\ttest-error:0.14816                               \n",
      "\n",
      "[67]\ttrain-error:0.14954\ttest-error:0.14816                               \n",
      "\n",
      "[68]\ttrain-error:0.14948\ttest-error:0.14760                               \n",
      "\n",
      "[69]\ttrain-error:0.14948\ttest-error:0.14803                               \n",
      "\n",
      "[70]\ttrain-error:0.14911\ttest-error:0.14773                               \n",
      "\n",
      "[71]\ttrain-error:0.14770\ttest-error:0.14717                               \n",
      "\n",
      "[72]\ttrain-error:0.14776\ttest-error:0.14717                               \n",
      "\n",
      "[73]\ttrain-error:0.14760\ttest-error:0.14687                               \n",
      "\n",
      "[74]\ttrain-error:0.14791\ttest-error:0.14693                               \n",
      "\n",
      "[75]\ttrain-error:0.14745\ttest-error:0.14656                               \n",
      "\n",
      "[76]\ttrain-error:0.14727\ttest-error:0.14650                               \n",
      "\n",
      "[77]\ttrain-error:0.14693\ttest-error:0.14502                               \n",
      "\n",
      "[78]\ttrain-error:0.14690\ttest-error:0.14539                               \n",
      "\n",
      "[79]\ttrain-error:0.14668\ttest-error:0.14496                               \n",
      "\n",
      "[80]\ttrain-error:0.14677\ttest-error:0.14472                               \n",
      "\n",
      "[81]\ttrain-error:0.14625\ttest-error:0.14478                               \n",
      "\n",
      "[82]\ttrain-error:0.14628\ttest-error:0.14490                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83]\ttrain-error:0.14628\ttest-error:0.14478                               \n",
      "\n",
      "[84]\ttrain-error:0.14582\ttest-error:0.14472                               \n",
      "\n",
      "[85]\ttrain-error:0.14610\ttest-error:0.14453                               \n",
      "\n",
      "[86]\ttrain-error:0.14601\ttest-error:0.14447                               \n",
      "\n",
      "[87]\ttrain-error:0.14595\ttest-error:0.14453                               \n",
      "\n",
      "[88]\ttrain-error:0.14591\ttest-error:0.14453                               \n",
      "\n",
      "[89]\ttrain-error:0.14601\ttest-error:0.14453                               \n",
      "\n",
      "[90]\ttrain-error:0.14619\ttest-error:0.14435                               \n",
      "\n",
      "[91]\ttrain-error:0.14628\ttest-error:0.14429                               \n",
      "\n",
      "[92]\ttrain-error:0.14579\ttest-error:0.14416                               \n",
      "\n",
      "[93]\ttrain-error:0.14576\ttest-error:0.14423                               \n",
      "\n",
      "[94]\ttrain-error:0.14582\ttest-error:0.14423                               \n",
      "\n",
      "[95]\ttrain-error:0.14588\ttest-error:0.14416                               \n",
      "\n",
      "[96]\ttrain-error:0.14610\ttest-error:0.14447                               \n",
      "\n",
      "[97]\ttrain-error:0.14579\ttest-error:0.14416                               \n",
      "\n",
      "[98]\ttrain-error:0.14604\ttest-error:0.14453                               \n",
      "\n",
      "[99]\ttrain-error:0.14579\ttest-error:0.14423                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.9744068653867802, 'colsample_bytree': 0.6044508715645113, 'eta': 0.008178129533614277, 'eval_metric': ('error',), 'extra_dims': 7, 'gamma': 6.738264549063165e-05, 'lambda': 0, 'max_depth': 8, 'min_child_weight': 0.0044602531541121275, 'objective': 'binary:logistic', 'subsample': 0.5459197624797698}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:15:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13556\ttest-error:0.13888                                \n",
      "\n",
      "[1]\ttrain-error:0.13295\ttest-error:0.13464                                \n",
      "\n",
      "[2]\ttrain-error:0.13222\ttest-error:0.13520                                \n",
      "\n",
      "[3]\ttrain-error:0.13197\ttest-error:0.13434                                \n",
      "\n",
      "[4]\ttrain-error:0.13105\ttest-error:0.13464                                \n",
      "\n",
      "[5]\ttrain-error:0.13114\ttest-error:0.13514                                \n",
      "\n",
      "[6]\ttrain-error:0.13111\ttest-error:0.13526                                \n",
      "\n",
      "[7]\ttrain-error:0.13139\ttest-error:0.13606                                \n",
      "\n",
      "[8]\ttrain-error:0.13111\ttest-error:0.13532                                \n",
      "\n",
      "[9]\ttrain-error:0.13081\ttest-error:0.13526                                \n",
      "\n",
      "[10]\ttrain-error:0.12998\ttest-error:0.13550                               \n",
      "\n",
      "[11]\ttrain-error:0.12991\ttest-error:0.13507                               \n",
      "\n",
      "[12]\ttrain-error:0.12979\ttest-error:0.13428                               \n",
      "\n",
      "[13]\ttrain-error:0.12967\ttest-error:0.13372                               \n",
      "\n",
      "[14]\ttrain-error:0.12939\ttest-error:0.13378                               \n",
      "\n",
      "[15]\ttrain-error:0.12918\ttest-error:0.13292                               \n",
      "\n",
      "[16]\ttrain-error:0.12902\ttest-error:0.13280                               \n",
      "\n",
      "[17]\ttrain-error:0.12865\ttest-error:0.13298                               \n",
      "\n",
      "[18]\ttrain-error:0.12826\ttest-error:0.13329                               \n",
      "\n",
      "[19]\ttrain-error:0.12841\ttest-error:0.13286                               \n",
      "\n",
      "[20]\ttrain-error:0.12798\ttest-error:0.13298                               \n",
      "\n",
      "[21]\ttrain-error:0.12752\ttest-error:0.13249                               \n",
      "\n",
      "[22]\ttrain-error:0.12721\ttest-error:0.13256                               \n",
      "\n",
      "[23]\ttrain-error:0.12721\ttest-error:0.13176                               \n",
      "\n",
      "[24]\ttrain-error:0.12700\ttest-error:0.13139                               \n",
      "\n",
      "[25]\ttrain-error:0.12678\ttest-error:0.13077                               \n",
      "\n",
      "[26]\ttrain-error:0.12641\ttest-error:0.13102                               \n",
      "\n",
      "[27]\ttrain-error:0.12607\ttest-error:0.13096                               \n",
      "\n",
      "[28]\ttrain-error:0.12589\ttest-error:0.13065                               \n",
      "\n",
      "[29]\ttrain-error:0.12543\ttest-error:0.13022                               \n",
      "\n",
      "[30]\ttrain-error:0.12491\ttest-error:0.13022                               \n",
      "\n",
      "[31]\ttrain-error:0.12451\ttest-error:0.12961                               \n",
      "\n",
      "[32]\ttrain-error:0.12417\ttest-error:0.12924                               \n",
      "\n",
      "[33]\ttrain-error:0.12386\ttest-error:0.12936                               \n",
      "\n",
      "[34]\ttrain-error:0.12359\ttest-error:0.12912                               \n",
      "\n",
      "[35]\ttrain-error:0.12337\ttest-error:0.12918                               \n",
      "\n",
      "[36]\ttrain-error:0.12319\ttest-error:0.12936                               \n",
      "\n",
      "[37]\ttrain-error:0.12294\ttest-error:0.12948                               \n",
      "\n",
      "[38]\ttrain-error:0.12239\ttest-error:0.12936                               \n",
      "\n",
      "[39]\ttrain-error:0.12202\ttest-error:0.12881                               \n",
      "\n",
      "[40]\ttrain-error:0.12205\ttest-error:0.12893                               \n",
      "\n",
      "[41]\ttrain-error:0.12190\ttest-error:0.12875                               \n",
      "\n",
      "[42]\ttrain-error:0.12184\ttest-error:0.12875                               \n",
      "\n",
      "[43]\ttrain-error:0.12159\ttest-error:0.12838                               \n",
      "\n",
      "[44]\ttrain-error:0.12122\ttest-error:0.12813                               \n",
      "\n",
      "[45]\ttrain-error:0.12095\ttest-error:0.12813                               \n",
      "\n",
      "[46]\ttrain-error:0.12091\ttest-error:0.12807                               \n",
      "\n",
      "[47]\ttrain-error:0.12039\ttest-error:0.12795                               \n",
      "\n",
      "[48]\ttrain-error:0.12046\ttest-error:0.12764                               \n",
      "\n",
      "[49]\ttrain-error:0.12036\ttest-error:0.12733                               \n",
      "\n",
      "[50]\ttrain-error:0.12012\ttest-error:0.12740                               \n",
      "\n",
      "[51]\ttrain-error:0.11984\ttest-error:0.12690                               \n",
      "\n",
      "[52]\ttrain-error:0.11975\ttest-error:0.12690                               \n",
      "\n",
      "[53]\ttrain-error:0.11953\ttest-error:0.12709                               \n",
      "\n",
      "[54]\ttrain-error:0.11947\ttest-error:0.12690                               \n",
      "\n",
      "[55]\ttrain-error:0.11901\ttest-error:0.12709                               \n",
      "\n",
      "[56]\ttrain-error:0.11901\ttest-error:0.12703                               \n",
      "\n",
      "[57]\ttrain-error:0.11867\ttest-error:0.12666                               \n",
      "\n",
      "[58]\ttrain-error:0.11824\ttest-error:0.12623                               \n",
      "\n",
      "[59]\ttrain-error:0.11794\ttest-error:0.12629                               \n",
      "\n",
      "[60]\ttrain-error:0.11747\ttest-error:0.12623                               \n",
      "\n",
      "[61]\ttrain-error:0.11723\ttest-error:0.12641                               \n",
      "\n",
      "[62]\ttrain-error:0.11723\ttest-error:0.12666                               \n",
      "\n",
      "[63]\ttrain-error:0.11704\ttest-error:0.12635                               \n",
      "\n",
      "[64]\ttrain-error:0.11686\ttest-error:0.12641                               \n",
      "\n",
      "[65]\ttrain-error:0.11674\ttest-error:0.12629                               \n",
      "\n",
      "[66]\ttrain-error:0.11652\ttest-error:0.12611                               \n",
      "\n",
      "[67]\ttrain-error:0.11594\ttest-error:0.12592                               \n",
      "\n",
      "[68]\ttrain-error:0.11563\ttest-error:0.12586                               \n",
      "\n",
      "[69]\ttrain-error:0.11551\ttest-error:0.12604                               \n",
      "\n",
      "[70]\ttrain-error:0.11523\ttest-error:0.12598                               \n",
      "\n",
      "[71]\ttrain-error:0.11517\ttest-error:0.12629                               \n",
      "\n",
      "[72]\ttrain-error:0.11520\ttest-error:0.12617                               \n",
      "\n",
      "[73]\ttrain-error:0.11505\ttest-error:0.12617                               \n",
      "\n",
      "[74]\ttrain-error:0.11496\ttest-error:0.12611                               \n",
      "\n",
      "[75]\ttrain-error:0.11483\ttest-error:0.12580                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76]\ttrain-error:0.11474\ttest-error:0.12543                               \n",
      "\n",
      "[77]\ttrain-error:0.11453\ttest-error:0.12549                               \n",
      "\n",
      "[78]\ttrain-error:0.11425\ttest-error:0.12549                               \n",
      "\n",
      "[79]\ttrain-error:0.11428\ttest-error:0.12543                               \n",
      "\n",
      "[80]\ttrain-error:0.11391\ttest-error:0.12555                               \n",
      "\n",
      "[81]\ttrain-error:0.11354\ttest-error:0.12568                               \n",
      "\n",
      "[82]\ttrain-error:0.11330\ttest-error:0.12586                               \n",
      "\n",
      "[83]\ttrain-error:0.11314\ttest-error:0.12592                               \n",
      "\n",
      "[84]\ttrain-error:0.11290\ttest-error:0.12598                               \n",
      "\n",
      "[85]\ttrain-error:0.11268\ttest-error:0.12592                               \n",
      "\n",
      "[86]\ttrain-error:0.11259\ttest-error:0.12580                               \n",
      "\n",
      "[87]\ttrain-error:0.11241\ttest-error:0.12611                               \n",
      "\n",
      "[88]\ttrain-error:0.11235\ttest-error:0.12611                               \n",
      "\n",
      "[89]\ttrain-error:0.11210\ttest-error:0.12598                               \n",
      "\n",
      "[90]\ttrain-error:0.11170\ttest-error:0.12635                               \n",
      "\n",
      "[91]\ttrain-error:0.11161\ttest-error:0.12635                               \n",
      "\n",
      "[92]\ttrain-error:0.11149\ttest-error:0.12623                               \n",
      "\n",
      "[93]\ttrain-error:0.11109\ttest-error:0.12629                               \n",
      "\n",
      "[94]\ttrain-error:0.11090\ttest-error:0.12654                               \n",
      "\n",
      "[95]\ttrain-error:0.11084\ttest-error:0.12647                               \n",
      "\n",
      "[96]\ttrain-error:0.11084\ttest-error:0.12647                               \n",
      "\n",
      "[97]\ttrain-error:0.11053\ttest-error:0.12666                               \n",
      "\n",
      "[98]\ttrain-error:0.11035\ttest-error:0.12654                               \n",
      "\n",
      "[99]\ttrain-error:0.11020\ttest-error:0.12635                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'I', 'colsample_bylevel': 0.8521233635879016, 'colsample_bytree': 0.6586708106639287, 'eta': 0.16633491611776047, 'eval_metric': ('error',), 'extra_dims': 12, 'gamma': 0, 'lambda': 1.694379157652874e-05, 'max_depth': 7, 'min_child_weight': 0.019254326346224204, 'objective': 'binary:logistic', 'subsample': 0.934944145918444}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:16:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13624\ttest-error:0.13642                                \n",
      "\n",
      "[1]\ttrain-error:0.17847\ttest-error:0.19957                                \n",
      "\n",
      "[2]\ttrain-error:0.13274\ttest-error:0.14453                                \n",
      "\n",
      "[3]\ttrain-error:0.24665\ttest-error:0.26990                                \n",
      "\n",
      "[4]\ttrain-error:0.13827\ttest-error:0.15049                                \n",
      "\n",
      "[5]\ttrain-error:0.42138\ttest-error:0.42500                                \n",
      "\n",
      "[6]\ttrain-error:0.19134\ttest-error:0.19459                                \n",
      "\n",
      "[7]\ttrain-error:0.62095\ttest-error:0.62193                                \n",
      "\n",
      "[8]\ttrain-error:0.22494\ttest-error:0.22076                                \n",
      "\n",
      "[9]\ttrain-error:0.49883\ttest-error:0.50049                                \n",
      "\n",
      "[10]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[11]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[12]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[13]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[14]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[15]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[16]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[17]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[18]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[19]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[20]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[21]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[22]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[23]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[24]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[25]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[26]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[27]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[28]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[29]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[30]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[31]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[32]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[33]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[34]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[35]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[36]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[37]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[38]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[39]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[40]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[41]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[42]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[43]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[44]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[45]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[46]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[47]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[48]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[49]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[50]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[51]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[52]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[53]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[54]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[55]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[56]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[57]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[58]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[59]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[60]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[61]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[62]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[63]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[64]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[65]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[66]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[67]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[68]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[70]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[71]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[72]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[73]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[74]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[75]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[76]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[77]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[78]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[79]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[80]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[81]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[82]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[83]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[84]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[85]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[86]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[87]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[88]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[89]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[90]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[91]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[92]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[93]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[94]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[95]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[96]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[97]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[98]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[99]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'I', 'colsample_bylevel': 0.8076880434187601, 'colsample_bytree': 0.633966679260831, 'eta': 0.10150186352272703, 'eval_metric': ('error',), 'extra_dims': 4, 'gamma': 0, 'lambda': 8.340514061665648e-05, 'max_depth': 7, 'min_child_weight': 0.0006931634812785409, 'objective': 'binary:logistic', 'subsample': 0.9096985845001464}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:17:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13790\ttest-error:0.13913                                \n",
      "\n",
      "[1]\ttrain-error:0.13467\ttest-error:0.13686                                \n",
      "\n",
      "[2]\ttrain-error:0.13157\ttest-error:0.13452                                \n",
      "\n",
      "[3]\ttrain-error:0.13056\ttest-error:0.13366                                \n",
      "\n",
      "[4]\ttrain-error:0.12767\ttest-error:0.13256                                \n",
      "\n",
      "[5]\ttrain-error:0.12574\ttest-error:0.13188                                \n",
      "\n",
      "[6]\ttrain-error:0.12445\ttest-error:0.13133                                \n",
      "\n",
      "[7]\ttrain-error:0.12202\ttest-error:0.12936                                \n",
      "\n",
      "[8]\ttrain-error:0.11923\ttest-error:0.12819                                \n",
      "\n",
      "[9]\ttrain-error:0.11735\ttest-error:0.12678                                \n",
      "\n",
      "[10]\ttrain-error:0.11677\ttest-error:0.12684                               \n",
      "\n",
      "[11]\ttrain-error:0.11576\ttest-error:0.12678                               \n",
      "\n",
      "[12]\ttrain-error:0.11486\ttest-error:0.12647                               \n",
      "\n",
      "[13]\ttrain-error:0.11361\ttest-error:0.12598                               \n",
      "\n",
      "[14]\ttrain-error:0.11296\ttest-error:0.12568                               \n",
      "\n",
      "[15]\ttrain-error:0.11124\ttest-error:0.12647                               \n",
      "\n",
      "[16]\ttrain-error:0.10980\ttest-error:0.12654                               \n",
      "\n",
      "[17]\ttrain-error:0.10835\ttest-error:0.12623                               \n",
      "\n",
      "[18]\ttrain-error:0.10755\ttest-error:0.12617                               \n",
      "\n",
      "[19]\ttrain-error:0.10626\ttest-error:0.12672                               \n",
      "\n",
      "[20]\ttrain-error:0.10556\ttest-error:0.12647                               \n",
      "\n",
      "[21]\ttrain-error:0.10473\ttest-error:0.12666                               \n",
      "\n",
      "[22]\ttrain-error:0.10384\ttest-error:0.12623                               \n",
      "\n",
      "[23]\ttrain-error:0.10267\ttest-error:0.12617                               \n",
      "\n",
      "[24]\ttrain-error:0.10230\ttest-error:0.12586                               \n",
      "\n",
      "[25]\ttrain-error:0.10193\ttest-error:0.12635                               \n",
      "\n",
      "[26]\ttrain-error:0.10135\ttest-error:0.12604                               \n",
      "\n",
      "[27]\ttrain-error:0.10037\ttest-error:0.12512                               \n",
      "\n",
      "[28]\ttrain-error:0.09978\ttest-error:0.12500                               \n",
      "\n",
      "[29]\ttrain-error:0.09877\ttest-error:0.12512                               \n",
      "\n",
      "[30]\ttrain-error:0.09760\ttest-error:0.12488                               \n",
      "\n",
      "[31]\ttrain-error:0.09677\ttest-error:0.12549                               \n",
      "\n",
      "[32]\ttrain-error:0.09619\ttest-error:0.12574                               \n",
      "\n",
      "[33]\ttrain-error:0.09570\ttest-error:0.12586                               \n",
      "\n",
      "[34]\ttrain-error:0.09493\ttest-error:0.12592                               \n",
      "\n",
      "[35]\ttrain-error:0.09463\ttest-error:0.12592                               \n",
      "\n",
      "[36]\ttrain-error:0.09327\ttest-error:0.12549                               \n",
      "\n",
      "[37]\ttrain-error:0.09248\ttest-error:0.12598                               \n",
      "\n",
      "[38]\ttrain-error:0.09134\ttest-error:0.12611                               \n",
      "\n",
      "[39]\ttrain-error:0.09115\ttest-error:0.12598                               \n",
      "\n",
      "[40]\ttrain-error:0.09066\ttest-error:0.12635                               \n",
      "\n",
      "[41]\ttrain-error:0.08987\ttest-error:0.12617                               \n",
      "\n",
      "[42]\ttrain-error:0.08944\ttest-error:0.12611                               \n",
      "\n",
      "[43]\ttrain-error:0.08876\ttest-error:0.12604                               \n",
      "\n",
      "[44]\ttrain-error:0.08848\ttest-error:0.12635                               \n",
      "\n",
      "[45]\ttrain-error:0.08759\ttest-error:0.12629                               \n",
      "\n",
      "[46]\ttrain-error:0.08713\ttest-error:0.12647                               \n",
      "\n",
      "[47]\ttrain-error:0.08670\ttest-error:0.12604                               \n",
      "\n",
      "[48]\ttrain-error:0.08627\ttest-error:0.12611                               \n",
      "\n",
      "[49]\ttrain-error:0.08569\ttest-error:0.12684                               \n",
      "\n",
      "[50]\ttrain-error:0.08517\ttest-error:0.12684                               \n",
      "\n",
      "[51]\ttrain-error:0.08449\ttest-error:0.12709                               \n",
      "\n",
      "[52]\ttrain-error:0.08369\ttest-error:0.12678                               \n",
      "\n",
      "[53]\ttrain-error:0.08296\ttest-error:0.12727                               \n",
      "\n",
      "[54]\ttrain-error:0.08253\ttest-error:0.12727                               \n",
      "\n",
      "[55]\ttrain-error:0.08170\ttest-error:0.12727                               \n",
      "\n",
      "[56]\ttrain-error:0.08090\ttest-error:0.12709                               \n",
      "\n",
      "[57]\ttrain-error:0.08034\ttest-error:0.12752                               \n",
      "\n",
      "[58]\ttrain-error:0.08019\ttest-error:0.12740                               \n",
      "\n",
      "[59]\ttrain-error:0.07936\ttest-error:0.12684                               \n",
      "\n",
      "[60]\ttrain-error:0.07838\ttest-error:0.12770                               \n",
      "\n",
      "[61]\ttrain-error:0.07816\ttest-error:0.12746                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62]\ttrain-error:0.07743\ttest-error:0.12740                               \n",
      "\n",
      "[63]\ttrain-error:0.07715\ttest-error:0.12709                               \n",
      "\n",
      "[64]\ttrain-error:0.07583\ttest-error:0.12746                               \n",
      "\n",
      "[65]\ttrain-error:0.07509\ttest-error:0.12697                               \n",
      "\n",
      "[66]\ttrain-error:0.07460\ttest-error:0.12715                               \n",
      "\n",
      "[67]\ttrain-error:0.07383\ttest-error:0.12727                               \n",
      "\n",
      "[68]\ttrain-error:0.07297\ttest-error:0.12758                               \n",
      "\n",
      "[69]\ttrain-error:0.07248\ttest-error:0.12813                               \n",
      "\n",
      "[70]\ttrain-error:0.07211\ttest-error:0.12783                               \n",
      "\n",
      "[71]\ttrain-error:0.07208\ttest-error:0.12770                               \n",
      "\n",
      "[72]\ttrain-error:0.07156\ttest-error:0.12801                               \n",
      "\n",
      "[73]\ttrain-error:0.07092\ttest-error:0.12783                               \n",
      "\n",
      "[74]\ttrain-error:0.07036\ttest-error:0.12783                               \n",
      "\n",
      "[75]\ttrain-error:0.06932\ttest-error:0.12838                               \n",
      "\n",
      "[76]\ttrain-error:0.06904\ttest-error:0.12856                               \n",
      "\n",
      "[77]\ttrain-error:0.06870\ttest-error:0.12887                               \n",
      "\n",
      "[78]\ttrain-error:0.06781\ttest-error:0.12954                               \n",
      "\n",
      "[79]\ttrain-error:0.06747\ttest-error:0.12942                               \n",
      "\n",
      "[80]\ttrain-error:0.06695\ttest-error:0.12979                               \n",
      "\n",
      "[81]\ttrain-error:0.06668\ttest-error:0.12973                               \n",
      "\n",
      "[82]\ttrain-error:0.06646\ttest-error:0.12979                               \n",
      "\n",
      "[83]\ttrain-error:0.06603\ttest-error:0.12985                               \n",
      "\n",
      "[84]\ttrain-error:0.06545\ttest-error:0.13016                               \n",
      "\n",
      "[85]\ttrain-error:0.06490\ttest-error:0.13077                               \n",
      "\n",
      "[86]\ttrain-error:0.06394\ttest-error:0.13059                               \n",
      "\n",
      "[87]\ttrain-error:0.06342\ttest-error:0.13053                               \n",
      "\n",
      "[88]\ttrain-error:0.06281\ttest-error:0.13090                               \n",
      "\n",
      "[89]\ttrain-error:0.06229\ttest-error:0.13090                               \n",
      "\n",
      "[90]\ttrain-error:0.06124\ttest-error:0.13084                               \n",
      "\n",
      "[91]\ttrain-error:0.06075\ttest-error:0.13096                               \n",
      "\n",
      "[92]\ttrain-error:0.05992\ttest-error:0.13040                               \n",
      "\n",
      "[93]\ttrain-error:0.05958\ttest-error:0.13053                               \n",
      "\n",
      "[94]\ttrain-error:0.05885\ttest-error:0.13090                               \n",
      "\n",
      "[95]\ttrain-error:0.05817\ttest-error:0.13108                               \n",
      "\n",
      "[96]\ttrain-error:0.05759\ttest-error:0.13120                               \n",
      "\n",
      "[97]\ttrain-error:0.05670\ttest-error:0.13145                               \n",
      "\n",
      "[98]\ttrain-error:0.05614\ttest-error:0.13145                               \n",
      "\n",
      "[99]\ttrain-error:0.05587\ttest-error:0.13182                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'I', 'colsample_bylevel': 0.7093966802510487, 'colsample_bytree': 0.6882458800710868, 'eta': 0.4790585452265832, 'eval_metric': ('error',), 'extra_dims': 11, 'gamma': 0, 'lambda': 4.628728757035862e-06, 'max_depth': 7, 'min_child_weight': 0.00019401680715994842, 'objective': 'binary:logistic', 'subsample': 0.8430826453967759}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:18:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13556\ttest-error:0.13624                                \n",
      "\n",
      "[1]\ttrain-error:0.81066\ttest-error:0.81394                                \n",
      "\n",
      "[2]\ttrain-error:0.18707\ttest-error:0.18477                                \n",
      "\n",
      "[3]\ttrain-error:0.44782\ttest-error:0.44889                                \n",
      "\n",
      "[4]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[5]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[6]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[7]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[8]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[9]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[10]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[11]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[12]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[13]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[14]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[15]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[16]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[17]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[18]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[19]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[20]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[21]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[22]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[23]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[24]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[25]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[26]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[27]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[28]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[29]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[30]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[31]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[32]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[33]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[34]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[35]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[36]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[37]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[38]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[39]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[40]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[41]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[42]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[43]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[44]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[45]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[46]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[47]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[48]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[49]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[50]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[51]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[52]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[53]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[54]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[56]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[57]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[58]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[59]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[60]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[61]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[62]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[63]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[64]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[65]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[66]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[67]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[68]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[69]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[70]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[71]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[72]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[73]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[74]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[75]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[76]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[77]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[78]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[79]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[80]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[81]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[82]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[83]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[84]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[85]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[86]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[87]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[88]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[89]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[90]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[91]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[92]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[93]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[94]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[95]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[96]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[97]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[98]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[99]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.7620858698867484, 'colsample_bytree': 0.5161012842402182, 'eta': 0.07292309270540154, 'eval_metric': ('error',), 'extra_dims': 14, 'gamma': 0, 'lambda': 4.362514272802681e-07, 'max_depth': 7, 'min_child_weight': 0.06997946459190947, 'objective': 'binary:logistic', 'subsample': 0.9987819586794885}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:19:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13603\ttest-error:0.13722                                \n",
      "\n",
      "[1]\ttrain-error:0.13053\ttest-error:0.13397                                \n",
      "\n",
      "[2]\ttrain-error:0.12687\ttest-error:0.12924                                \n",
      "\n",
      "[3]\ttrain-error:0.12405\ttest-error:0.12862                                \n",
      "\n",
      "[4]\ttrain-error:0.11962\ttest-error:0.12604                                \n",
      "\n",
      "[5]\ttrain-error:0.11668\ttest-error:0.12457                                \n",
      "\n",
      "[6]\ttrain-error:0.11373\ttest-error:0.12396                                \n",
      "\n",
      "[7]\ttrain-error:0.11182\ttest-error:0.12439                                \n",
      "\n",
      "[8]\ttrain-error:0.11133\ttest-error:0.12439                                \n",
      "\n",
      "[9]\ttrain-error:0.10980\ttest-error:0.12469                                \n",
      "\n",
      "[10]\ttrain-error:0.10906\ttest-error:0.12420                               \n",
      "\n",
      "[11]\ttrain-error:0.10697\ttest-error:0.12408                               \n",
      "\n",
      "[12]\ttrain-error:0.10608\ttest-error:0.12396                               \n",
      "\n",
      "[13]\ttrain-error:0.10556\ttest-error:0.12328                               \n",
      "\n",
      "[14]\ttrain-error:0.10467\ttest-error:0.12359                               \n",
      "\n",
      "[15]\ttrain-error:0.10338\ttest-error:0.12359                               \n",
      "\n",
      "[16]\ttrain-error:0.10209\ttest-error:0.12414                               \n",
      "\n",
      "[17]\ttrain-error:0.10138\ttest-error:0.12371                               \n",
      "\n",
      "[18]\ttrain-error:0.10117\ttest-error:0.12377                               \n",
      "\n",
      "[19]\ttrain-error:0.09988\ttest-error:0.12420                               \n",
      "\n",
      "[20]\ttrain-error:0.09923\ttest-error:0.12383                               \n",
      "\n",
      "[21]\ttrain-error:0.09813\ttest-error:0.12377                               \n",
      "\n",
      "[22]\ttrain-error:0.09767\ttest-error:0.12371                               \n",
      "\n",
      "[23]\ttrain-error:0.09708\ttest-error:0.12365                               \n",
      "\n",
      "[24]\ttrain-error:0.09641\ttest-error:0.12383                               \n",
      "\n",
      "[25]\ttrain-error:0.09558\ttest-error:0.12414                               \n",
      "\n",
      "[26]\ttrain-error:0.09512\ttest-error:0.12383                               \n",
      "\n",
      "[27]\ttrain-error:0.09435\ttest-error:0.12512                               \n",
      "\n",
      "[28]\ttrain-error:0.09361\ttest-error:0.12482                               \n",
      "\n",
      "[29]\ttrain-error:0.09205\ttest-error:0.12469                               \n",
      "\n",
      "[30]\ttrain-error:0.09134\ttest-error:0.12518                               \n",
      "\n",
      "[31]\ttrain-error:0.09017\ttest-error:0.12580                               \n",
      "\n",
      "[32]\ttrain-error:0.08916\ttest-error:0.12592                               \n",
      "\n",
      "[33]\ttrain-error:0.08811\ttest-error:0.12635                               \n",
      "\n",
      "[34]\ttrain-error:0.08719\ttest-error:0.12617                               \n",
      "\n",
      "[35]\ttrain-error:0.08679\ttest-error:0.12678                               \n",
      "\n",
      "[36]\ttrain-error:0.08636\ttest-error:0.12617                               \n",
      "\n",
      "[37]\ttrain-error:0.08618\ttest-error:0.12623                               \n",
      "\n",
      "[38]\ttrain-error:0.08541\ttest-error:0.12617                               \n",
      "\n",
      "[39]\ttrain-error:0.08486\ttest-error:0.12617                               \n",
      "\n",
      "[40]\ttrain-error:0.08415\ttest-error:0.12617                               \n",
      "\n",
      "[41]\ttrain-error:0.08259\ttest-error:0.12654                               \n",
      "\n",
      "[42]\ttrain-error:0.08216\ttest-error:0.12666                               \n",
      "\n",
      "[43]\ttrain-error:0.08167\ttest-error:0.12660                               \n",
      "\n",
      "[44]\ttrain-error:0.08087\ttest-error:0.12709                               \n",
      "\n",
      "[45]\ttrain-error:0.07991\ttest-error:0.12715                               \n",
      "\n",
      "[46]\ttrain-error:0.07930\ttest-error:0.12733                               \n",
      "\n",
      "[47]\ttrain-error:0.07859\ttest-error:0.12697                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48]\ttrain-error:0.07773\ttest-error:0.12740                               \n",
      "\n",
      "[49]\ttrain-error:0.07715\ttest-error:0.12727                               \n",
      "\n",
      "[50]\ttrain-error:0.07647\ttest-error:0.12746                               \n",
      "\n",
      "[51]\ttrain-error:0.07574\ttest-error:0.12758                               \n",
      "\n",
      "[52]\ttrain-error:0.07515\ttest-error:0.12733                               \n",
      "\n",
      "[53]\ttrain-error:0.07460\ttest-error:0.12746                               \n",
      "\n",
      "[54]\ttrain-error:0.07383\ttest-error:0.12838                               \n",
      "\n",
      "[55]\ttrain-error:0.07276\ttest-error:0.12875                               \n",
      "\n",
      "[56]\ttrain-error:0.07248\ttest-error:0.12856                               \n",
      "\n",
      "[57]\ttrain-error:0.07153\ttest-error:0.12899                               \n",
      "\n",
      "[58]\ttrain-error:0.07085\ttest-error:0.12924                               \n",
      "\n",
      "[59]\ttrain-error:0.07012\ttest-error:0.12948                               \n",
      "\n",
      "[60]\ttrain-error:0.06926\ttest-error:0.12961                               \n",
      "\n",
      "[61]\ttrain-error:0.06846\ttest-error:0.12985                               \n",
      "\n",
      "[62]\ttrain-error:0.06815\ttest-error:0.13022                               \n",
      "\n",
      "[63]\ttrain-error:0.06769\ttest-error:0.12985                               \n",
      "\n",
      "[64]\ttrain-error:0.06729\ttest-error:0.13010                               \n",
      "\n",
      "[65]\ttrain-error:0.06649\ttest-error:0.13016                               \n",
      "\n",
      "[66]\ttrain-error:0.06576\ttest-error:0.13022                               \n",
      "\n",
      "[67]\ttrain-error:0.06557\ttest-error:0.13004                               \n",
      "\n",
      "[68]\ttrain-error:0.06434\ttest-error:0.12973                               \n",
      "\n",
      "[69]\ttrain-error:0.06379\ttest-error:0.12991                               \n",
      "\n",
      "[70]\ttrain-error:0.06333\ttest-error:0.13022                               \n",
      "\n",
      "[71]\ttrain-error:0.06290\ttest-error:0.13065                               \n",
      "\n",
      "[72]\ttrain-error:0.06238\ttest-error:0.13047                               \n",
      "\n",
      "[73]\ttrain-error:0.06186\ttest-error:0.13034                               \n",
      "\n",
      "[74]\ttrain-error:0.06106\ttest-error:0.13040                               \n",
      "\n",
      "[75]\ttrain-error:0.06014\ttest-error:0.13077                               \n",
      "\n",
      "[76]\ttrain-error:0.05967\ttest-error:0.13151                               \n",
      "\n",
      "[77]\ttrain-error:0.05912\ttest-error:0.13126                               \n",
      "\n",
      "[78]\ttrain-error:0.05842\ttest-error:0.13133                               \n",
      "\n",
      "[79]\ttrain-error:0.05792\ttest-error:0.13151                               \n",
      "\n",
      "[80]\ttrain-error:0.05706\ttest-error:0.13108                               \n",
      "\n",
      "[81]\ttrain-error:0.05676\ttest-error:0.13176                               \n",
      "\n",
      "[82]\ttrain-error:0.05627\ttest-error:0.13157                               \n",
      "\n",
      "[83]\ttrain-error:0.05614\ttest-error:0.13176                               \n",
      "\n",
      "[84]\ttrain-error:0.05574\ttest-error:0.13225                               \n",
      "\n",
      "[85]\ttrain-error:0.05473\ttest-error:0.13212                               \n",
      "\n",
      "[86]\ttrain-error:0.05390\ttest-error:0.13182                               \n",
      "\n",
      "[87]\ttrain-error:0.05375\ttest-error:0.13182                               \n",
      "\n",
      "[88]\ttrain-error:0.05335\ttest-error:0.13139                               \n",
      "\n",
      "[89]\ttrain-error:0.05246\ttest-error:0.13157                               \n",
      "\n",
      "[90]\ttrain-error:0.05157\ttest-error:0.13206                               \n",
      "\n",
      "[91]\ttrain-error:0.05074\ttest-error:0.13256                               \n",
      "\n",
      "[92]\ttrain-error:0.04982\ttest-error:0.13262                               \n",
      "\n",
      "[93]\ttrain-error:0.04975\ttest-error:0.13311                               \n",
      "\n",
      "[94]\ttrain-error:0.04856\ttest-error:0.13292                               \n",
      "\n",
      "[95]\ttrain-error:0.04794\ttest-error:0.13274                               \n",
      "\n",
      "[96]\ttrain-error:0.04708\ttest-error:0.13249                               \n",
      "\n",
      "[97]\ttrain-error:0.04613\ttest-error:0.13280                               \n",
      "\n",
      "[98]\ttrain-error:0.04573\ttest-error:0.13256                               \n",
      "\n",
      "[99]\ttrain-error:0.04548\ttest-error:0.13268                               \n",
      "\n",
      "NEW BEST VALUE!                                                           \n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.67899096836173, 'colsample_bytree': 0.5013022742971183, 'eta': 0.027081944362322766, 'eval_metric': ('error',), 'extra_dims': 14, 'gamma': 0, 'lambda': 5.938700772813259e-07, 'max_depth': 7, 'min_child_weight': 0.07929281662344634, 'objective': 'binary:logistic', 'subsample': 0.995772092645462}\n",
      "Overwriting param `num_class`                                            \n",
      "Overwriting param `objective` while setting `obj` in train.              \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                  \n",
      "Setting param `disable_default_eval_metric` to 1.                        \n",
      "[23:22:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13756\ttest-error:0.13839                               \n",
      "\n",
      "[1]\ttrain-error:0.13474\ttest-error:0.13722                               \n",
      "\n",
      "[2]\ttrain-error:0.13421\ttest-error:0.13544                               \n",
      "\n",
      "[3]\ttrain-error:0.13256\ttest-error:0.13378                               \n",
      "\n",
      "[4]\ttrain-error:0.13081\ttest-error:0.13231                               \n",
      "\n",
      "[5]\ttrain-error:0.12942\ttest-error:0.13151                               \n",
      "\n",
      "[6]\ttrain-error:0.12832\ttest-error:0.12973                               \n",
      "\n",
      "[7]\ttrain-error:0.12681\ttest-error:0.12936                               \n",
      "\n",
      "[8]\ttrain-error:0.12525\ttest-error:0.12832                               \n",
      "\n",
      "[9]\ttrain-error:0.12374\ttest-error:0.12776                               \n",
      "\n",
      "[10]\ttrain-error:0.12230\ttest-error:0.12746                              \n",
      "\n",
      "[11]\ttrain-error:0.12110\ttest-error:0.12690                              \n",
      "\n",
      "[12]\ttrain-error:0.11941\ttest-error:0.12623                              \n",
      "\n",
      "[13]\ttrain-error:0.11840\ttest-error:0.12617                              \n",
      "\n",
      "[14]\ttrain-error:0.11704\ttest-error:0.12555                              \n",
      "\n",
      "[15]\ttrain-error:0.11603\ttest-error:0.12518                              \n",
      "\n",
      "[16]\ttrain-error:0.11514\ttest-error:0.12549                              \n",
      "\n",
      "[17]\ttrain-error:0.11453\ttest-error:0.12506                              \n",
      "\n",
      "[18]\ttrain-error:0.11394\ttest-error:0.12445                              \n",
      "\n",
      "[19]\ttrain-error:0.11361\ttest-error:0.12457                              \n",
      "\n",
      "[20]\ttrain-error:0.11308\ttest-error:0.12463                              \n",
      "\n",
      "[21]\ttrain-error:0.11225\ttest-error:0.12439                              \n",
      "\n",
      "[22]\ttrain-error:0.11136\ttest-error:0.12518                              \n",
      "\n",
      "[23]\ttrain-error:0.11084\ttest-error:0.12518                              \n",
      "\n",
      "[24]\ttrain-error:0.11026\ttest-error:0.12525                              \n",
      "\n",
      "[25]\ttrain-error:0.11001\ttest-error:0.12537                              \n",
      "\n",
      "[26]\ttrain-error:0.10958\ttest-error:0.12537                              \n",
      "\n",
      "[27]\ttrain-error:0.10906\ttest-error:0.12531                              \n",
      "\n",
      "[28]\ttrain-error:0.10851\ttest-error:0.12549                              \n",
      "\n",
      "[29]\ttrain-error:0.10795\ttest-error:0.12518                              \n",
      "\n",
      "[30]\ttrain-error:0.10737\ttest-error:0.12506                              \n",
      "\n",
      "[31]\ttrain-error:0.10697\ttest-error:0.12475                              \n",
      "\n",
      "[32]\ttrain-error:0.10673\ttest-error:0.12463                              \n",
      "\n",
      "[33]\ttrain-error:0.10626\ttest-error:0.12475                              \n",
      "\n",
      "[34]\ttrain-error:0.10559\ttest-error:0.12494                              \n",
      "\n",
      "[35]\ttrain-error:0.10534\ttest-error:0.12445                              \n",
      "\n",
      "[36]\ttrain-error:0.10497\ttest-error:0.12445                              \n",
      "\n",
      "[37]\ttrain-error:0.10476\ttest-error:0.12439                              \n",
      "\n",
      "[38]\ttrain-error:0.10430\ttest-error:0.12420                              \n",
      "\n",
      "[39]\ttrain-error:0.10405\ttest-error:0.12451                              \n",
      "\n",
      "[40]\ttrain-error:0.10359\ttest-error:0.12463                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41]\ttrain-error:0.10301\ttest-error:0.12451                              \n",
      "\n",
      "[42]\ttrain-error:0.10295\ttest-error:0.12457                              \n",
      "\n",
      "[43]\ttrain-error:0.10273\ttest-error:0.12439                              \n",
      "\n",
      "[44]\ttrain-error:0.10243\ttest-error:0.12420                              \n",
      "\n",
      "[45]\ttrain-error:0.10203\ttest-error:0.12439                              \n",
      "\n",
      "[46]\ttrain-error:0.10184\ttest-error:0.12420                              \n",
      "\n",
      "[47]\ttrain-error:0.10150\ttest-error:0.12383                              \n",
      "\n",
      "[48]\ttrain-error:0.10135\ttest-error:0.12402                              \n",
      "\n",
      "[49]\ttrain-error:0.10114\ttest-error:0.12432                              \n",
      "\n",
      "[50]\ttrain-error:0.10046\ttest-error:0.12457                              \n",
      "\n",
      "[51]\ttrain-error:0.10006\ttest-error:0.12439                              \n",
      "\n",
      "[52]\ttrain-error:0.09951\ttest-error:0.12371                              \n",
      "\n",
      "[53]\ttrain-error:0.09905\ttest-error:0.12365                              \n",
      "\n",
      "[54]\ttrain-error:0.09859\ttest-error:0.12365                              \n",
      "\n",
      "[55]\ttrain-error:0.09813\ttest-error:0.12383                              \n",
      "\n",
      "[56]\ttrain-error:0.09785\ttest-error:0.12414                              \n",
      "\n",
      "[57]\ttrain-error:0.09773\ttest-error:0.12414                              \n",
      "\n",
      "[58]\ttrain-error:0.09751\ttest-error:0.12383                              \n",
      "\n",
      "[59]\ttrain-error:0.09724\ttest-error:0.12383                              \n",
      "\n",
      "[60]\ttrain-error:0.09677\ttest-error:0.12402                              \n",
      "\n",
      "[61]\ttrain-error:0.09644\ttest-error:0.12383                              \n",
      "\n",
      "[62]\ttrain-error:0.09635\ttest-error:0.12432                              \n",
      "\n",
      "[63]\ttrain-error:0.09595\ttest-error:0.12414                              \n",
      "\n",
      "[64]\ttrain-error:0.09539\ttest-error:0.12414                              \n",
      "\n",
      "[65]\ttrain-error:0.09524\ttest-error:0.12396                              \n",
      "\n",
      "[66]\ttrain-error:0.09475\ttest-error:0.12377                              \n",
      "\n",
      "[67]\ttrain-error:0.09438\ttest-error:0.12402                              \n",
      "\n",
      "[68]\ttrain-error:0.09420\ttest-error:0.12377                              \n",
      "\n",
      "[69]\ttrain-error:0.09407\ttest-error:0.12359                              \n",
      "\n",
      "[70]\ttrain-error:0.09380\ttest-error:0.12396                              \n",
      "\n",
      "[71]\ttrain-error:0.09367\ttest-error:0.12396                              \n",
      "\n",
      "[72]\ttrain-error:0.09321\ttest-error:0.12365                              \n",
      "\n",
      "[73]\ttrain-error:0.09315\ttest-error:0.12377                              \n",
      "\n",
      "[74]\ttrain-error:0.09284\ttest-error:0.12432                              \n",
      "\n",
      "[75]\ttrain-error:0.09260\ttest-error:0.12420                              \n",
      "\n",
      "[76]\ttrain-error:0.09217\ttest-error:0.12469                              \n",
      "\n",
      "[77]\ttrain-error:0.09152\ttest-error:0.12475                              \n",
      "\n",
      "[78]\ttrain-error:0.09122\ttest-error:0.12463                              \n",
      "\n",
      "[79]\ttrain-error:0.09094\ttest-error:0.12451                              \n",
      "\n",
      "[80]\ttrain-error:0.09045\ttest-error:0.12432                              \n",
      "\n",
      "[81]\ttrain-error:0.09030\ttest-error:0.12482                              \n",
      "\n",
      "[82]\ttrain-error:0.08974\ttest-error:0.12488                              \n",
      "\n",
      "[83]\ttrain-error:0.08950\ttest-error:0.12488                              \n",
      "\n",
      "[84]\ttrain-error:0.08947\ttest-error:0.12500                              \n",
      "\n",
      "[85]\ttrain-error:0.08919\ttest-error:0.12500                              \n",
      "\n",
      "[86]\ttrain-error:0.08873\ttest-error:0.12469                              \n",
      "\n",
      "[87]\ttrain-error:0.08851\ttest-error:0.12482                              \n",
      "\n",
      "[88]\ttrain-error:0.08799\ttest-error:0.12475                              \n",
      "\n",
      "[89]\ttrain-error:0.08762\ttest-error:0.12445                              \n",
      "\n",
      "[90]\ttrain-error:0.08701\ttest-error:0.12488                              \n",
      "\n",
      "[91]\ttrain-error:0.08661\ttest-error:0.12457                              \n",
      "\n",
      "[92]\ttrain-error:0.08649\ttest-error:0.12482                              \n",
      "\n",
      "[93]\ttrain-error:0.08612\ttest-error:0.12500                              \n",
      "\n",
      "[94]\ttrain-error:0.08569\ttest-error:0.12531                              \n",
      "\n",
      "[95]\ttrain-error:0.08535\ttest-error:0.12494                              \n",
      "\n",
      "[96]\ttrain-error:0.08507\ttest-error:0.12531                              \n",
      "\n",
      "[97]\ttrain-error:0.08455\ttest-error:0.12518                              \n",
      "\n",
      "[98]\ttrain-error:0.08434\ttest-error:0.12525                              \n",
      "\n",
      "[99]\ttrain-error:0.08412\ttest-error:0.12543                              \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.6796655601556253, 'colsample_bytree': 0.5025171195175089, 'eta': 0.02435273440919242, 'eval_metric': ('error',), 'extra_dims': 14, 'gamma': 0, 'lambda': 3.3507061209255893e-07, 'max_depth': 7, 'min_child_weight': 1.0476948956934466, 'objective': 'binary:logistic', 'subsample': 0.9831739430373759}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:24:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13950\ttest-error:0.13888                                \n",
      "\n",
      "[1]\ttrain-error:0.13790\ttest-error:0.13870                                \n",
      "\n",
      "[2]\ttrain-error:0.13686\ttest-error:0.13759                                \n",
      "\n",
      "[3]\ttrain-error:0.13716\ttest-error:0.13735                                \n",
      "\n",
      "[4]\ttrain-error:0.13593\ttest-error:0.13550                                \n",
      "\n",
      "[5]\ttrain-error:0.13486\ttest-error:0.13440                                \n",
      "\n",
      "[6]\ttrain-error:0.13378\ttest-error:0.13311                                \n",
      "\n",
      "[7]\ttrain-error:0.13170\ttest-error:0.13219                                \n",
      "\n",
      "[8]\ttrain-error:0.13117\ttest-error:0.13071                                \n",
      "\n",
      "[9]\ttrain-error:0.13037\ttest-error:0.13028                                \n",
      "\n",
      "[10]\ttrain-error:0.12939\ttest-error:0.13010                               \n",
      "\n",
      "[11]\ttrain-error:0.12862\ttest-error:0.12961                               \n",
      "\n",
      "[12]\ttrain-error:0.12776\ttest-error:0.12899                               \n",
      "\n",
      "[13]\ttrain-error:0.12629\ttest-error:0.12905                               \n",
      "\n",
      "[14]\ttrain-error:0.12552\ttest-error:0.12869                               \n",
      "\n",
      "[15]\ttrain-error:0.12445\ttest-error:0.12826                               \n",
      "\n",
      "[16]\ttrain-error:0.12359\ttest-error:0.12783                               \n",
      "\n",
      "[17]\ttrain-error:0.12310\ttest-error:0.12715                               \n",
      "\n",
      "[18]\ttrain-error:0.12245\ttest-error:0.12690                               \n",
      "\n",
      "[19]\ttrain-error:0.12196\ttest-error:0.12617                               \n",
      "\n",
      "[20]\ttrain-error:0.12150\ttest-error:0.12598                               \n",
      "\n",
      "[21]\ttrain-error:0.12089\ttest-error:0.12568                               \n",
      "\n",
      "[22]\ttrain-error:0.12033\ttest-error:0.12561                               \n",
      "\n",
      "[23]\ttrain-error:0.11978\ttest-error:0.12555                               \n",
      "\n",
      "[24]\ttrain-error:0.11972\ttest-error:0.12568                               \n",
      "\n",
      "[25]\ttrain-error:0.11932\ttest-error:0.12561                               \n",
      "\n",
      "[26]\ttrain-error:0.11892\ttest-error:0.12555                               \n",
      "\n",
      "[27]\ttrain-error:0.11892\ttest-error:0.12592                               \n",
      "\n",
      "[28]\ttrain-error:0.11858\ttest-error:0.12574                               \n",
      "\n",
      "[29]\ttrain-error:0.11806\ttest-error:0.12598                               \n",
      "\n",
      "[30]\ttrain-error:0.11775\ttest-error:0.12549                               \n",
      "\n",
      "[31]\ttrain-error:0.11794\ttest-error:0.12518                               \n",
      "\n",
      "[32]\ttrain-error:0.11769\ttest-error:0.12537                               \n",
      "\n",
      "[33]\ttrain-error:0.11757\ttest-error:0.12518                               \n",
      "\n",
      "[34]\ttrain-error:0.11726\ttest-error:0.12512                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35]\ttrain-error:0.11695\ttest-error:0.12561                               \n",
      "\n",
      "[36]\ttrain-error:0.11643\ttest-error:0.12531                               \n",
      "\n",
      "[37]\ttrain-error:0.11628\ttest-error:0.12531                               \n",
      "\n",
      "[38]\ttrain-error:0.11609\ttest-error:0.12525                               \n",
      "\n",
      "[39]\ttrain-error:0.11606\ttest-error:0.12512                               \n",
      "\n",
      "[40]\ttrain-error:0.11591\ttest-error:0.12512                               \n",
      "\n",
      "[41]\ttrain-error:0.11529\ttest-error:0.12537                               \n",
      "\n",
      "[42]\ttrain-error:0.11526\ttest-error:0.12506                               \n",
      "\n",
      "[43]\ttrain-error:0.11480\ttest-error:0.12500                               \n",
      "\n",
      "[44]\ttrain-error:0.11477\ttest-error:0.12482                               \n",
      "\n",
      "[45]\ttrain-error:0.11450\ttest-error:0.12488                               \n",
      "\n",
      "[46]\ttrain-error:0.11425\ttest-error:0.12518                               \n",
      "\n",
      "[47]\ttrain-error:0.11419\ttest-error:0.12518                               \n",
      "\n",
      "[48]\ttrain-error:0.11413\ttest-error:0.12475                               \n",
      "\n",
      "[49]\ttrain-error:0.11397\ttest-error:0.12469                               \n",
      "\n",
      "[50]\ttrain-error:0.11410\ttest-error:0.12475                               \n",
      "\n",
      "[51]\ttrain-error:0.11364\ttest-error:0.12469                               \n",
      "\n",
      "[52]\ttrain-error:0.11351\ttest-error:0.12445                               \n",
      "\n",
      "[53]\ttrain-error:0.11345\ttest-error:0.12451                               \n",
      "\n",
      "[54]\ttrain-error:0.11339\ttest-error:0.12475                               \n",
      "\n",
      "[55]\ttrain-error:0.11302\ttest-error:0.12451                               \n",
      "\n",
      "[56]\ttrain-error:0.11271\ttest-error:0.12426                               \n",
      "\n",
      "[57]\ttrain-error:0.11244\ttest-error:0.12420                               \n",
      "\n",
      "[58]\ttrain-error:0.11235\ttest-error:0.12439                               \n",
      "\n",
      "[59]\ttrain-error:0.11241\ttest-error:0.12457                               \n",
      "\n",
      "[60]\ttrain-error:0.11201\ttest-error:0.12432                               \n",
      "\n",
      "[61]\ttrain-error:0.11210\ttest-error:0.12426                               \n",
      "\n",
      "[62]\ttrain-error:0.11195\ttest-error:0.12414                               \n",
      "\n",
      "[63]\ttrain-error:0.11170\ttest-error:0.12457                               \n",
      "\n",
      "[64]\ttrain-error:0.11176\ttest-error:0.12439                               \n",
      "\n",
      "[65]\ttrain-error:0.11161\ttest-error:0.12426                               \n",
      "\n",
      "[66]\ttrain-error:0.11161\ttest-error:0.12414                               \n",
      "\n",
      "[67]\ttrain-error:0.11130\ttest-error:0.12439                               \n",
      "\n",
      "[68]\ttrain-error:0.11109\ttest-error:0.12408                               \n",
      "\n",
      "[69]\ttrain-error:0.11087\ttest-error:0.12445                               \n",
      "\n",
      "[70]\ttrain-error:0.11069\ttest-error:0.12439                               \n",
      "\n",
      "[71]\ttrain-error:0.11056\ttest-error:0.12432                               \n",
      "\n",
      "[72]\ttrain-error:0.11056\ttest-error:0.12426                               \n",
      "\n",
      "[73]\ttrain-error:0.11038\ttest-error:0.12414                               \n",
      "\n",
      "[74]\ttrain-error:0.10998\ttest-error:0.12402                               \n",
      "\n",
      "[75]\ttrain-error:0.10986\ttest-error:0.12414                               \n",
      "\n",
      "[76]\ttrain-error:0.10964\ttest-error:0.12420                               \n",
      "\n",
      "[77]\ttrain-error:0.10943\ttest-error:0.12396                               \n",
      "\n",
      "[78]\ttrain-error:0.10918\ttest-error:0.12420                               \n",
      "\n",
      "[79]\ttrain-error:0.10903\ttest-error:0.12420                               \n",
      "\n",
      "[80]\ttrain-error:0.10894\ttest-error:0.12408                               \n",
      "\n",
      "[81]\ttrain-error:0.10918\ttest-error:0.12408                               \n",
      "\n",
      "[82]\ttrain-error:0.10903\ttest-error:0.12426                               \n",
      "\n",
      "[83]\ttrain-error:0.10903\ttest-error:0.12420                               \n",
      "\n",
      "[84]\ttrain-error:0.10881\ttest-error:0.12439                               \n",
      "\n",
      "[85]\ttrain-error:0.10863\ttest-error:0.12432                               \n",
      "\n",
      "[86]\ttrain-error:0.10857\ttest-error:0.12463                               \n",
      "\n",
      "[87]\ttrain-error:0.10851\ttest-error:0.12445                               \n",
      "\n",
      "[88]\ttrain-error:0.10814\ttest-error:0.12445                               \n",
      "\n",
      "[89]\ttrain-error:0.10783\ttest-error:0.12482                               \n",
      "\n",
      "[90]\ttrain-error:0.10762\ttest-error:0.12475                               \n",
      "\n",
      "[91]\ttrain-error:0.10740\ttest-error:0.12432                               \n",
      "\n",
      "[92]\ttrain-error:0.10731\ttest-error:0.12469                               \n",
      "\n",
      "[93]\ttrain-error:0.10694\ttest-error:0.12451                               \n",
      "\n",
      "[94]\ttrain-error:0.10685\ttest-error:0.12445                               \n",
      "\n",
      "[95]\ttrain-error:0.10688\ttest-error:0.12463                               \n",
      "\n",
      "[96]\ttrain-error:0.10676\ttest-error:0.12475                               \n",
      "\n",
      "[97]\ttrain-error:0.10666\ttest-error:0.12494                               \n",
      "\n",
      "[98]\ttrain-error:0.10654\ttest-error:0.12518                               \n",
      "\n",
      "[99]\ttrain-error:0.10645\ttest-error:0.12531                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.5853089196687662, 'colsample_bytree': 0.5179623658806295, 'eta': 0.01452233789222872, 'eval_metric': ('error',), 'extra_dims': 14, 'gamma': 0, 'lambda': 0.016307221626701156, 'max_depth': 10, 'min_child_weight': 12.097517265771167, 'objective': 'binary:logistic', 'subsample': 0.9602586307347606}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:26:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15731\ttest-error:0.15946                                \n",
      "\n",
      "[1]\ttrain-error:0.15645\ttest-error:0.15946                                \n",
      "\n",
      "[2]\ttrain-error:0.15144\ttest-error:0.15461                                \n",
      "\n",
      "[3]\ttrain-error:0.14837\ttest-error:0.14969                                \n",
      "\n",
      "[4]\ttrain-error:0.14757\ttest-error:0.14767                                \n",
      "\n",
      "[5]\ttrain-error:0.14616\ttest-error:0.14588                                \n",
      "\n",
      "[6]\ttrain-error:0.14567\ttest-error:0.14539                                \n",
      "\n",
      "[7]\ttrain-error:0.14453\ttest-error:0.14355                                \n",
      "\n",
      "[8]\ttrain-error:0.14291\ttest-error:0.14091                                \n",
      "\n",
      "[9]\ttrain-error:0.14198\ttest-error:0.14005                                \n",
      "\n",
      "[10]\ttrain-error:0.14183\ttest-error:0.14030                               \n",
      "\n",
      "[11]\ttrain-error:0.14036\ttest-error:0.13907                               \n",
      "\n",
      "[12]\ttrain-error:0.13974\ttest-error:0.13858                               \n",
      "\n",
      "[13]\ttrain-error:0.13894\ttest-error:0.13790                               \n",
      "\n",
      "[14]\ttrain-error:0.13811\ttest-error:0.13772                               \n",
      "\n",
      "[15]\ttrain-error:0.13710\ttest-error:0.13679                               \n",
      "\n",
      "[16]\ttrain-error:0.13673\ttest-error:0.13649                               \n",
      "\n",
      "[17]\ttrain-error:0.13673\ttest-error:0.13569                               \n",
      "\n",
      "[18]\ttrain-error:0.13581\ttest-error:0.13501                               \n",
      "\n",
      "[19]\ttrain-error:0.13532\ttest-error:0.13464                               \n",
      "\n",
      "[20]\ttrain-error:0.13489\ttest-error:0.13415                               \n",
      "\n",
      "[21]\ttrain-error:0.13461\ttest-error:0.13384                               \n",
      "\n",
      "[22]\ttrain-error:0.13381\ttest-error:0.13366                               \n",
      "\n",
      "[23]\ttrain-error:0.13348\ttest-error:0.13335                               \n",
      "\n",
      "[24]\ttrain-error:0.13280\ttest-error:0.13292                               \n",
      "\n",
      "[25]\ttrain-error:0.13253\ttest-error:0.13286                               \n",
      "\n",
      "[26]\ttrain-error:0.13191\ttest-error:0.13249                               \n",
      "\n",
      "[27]\ttrain-error:0.13182\ttest-error:0.13225                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28]\ttrain-error:0.13133\ttest-error:0.13225                               \n",
      "\n",
      "[29]\ttrain-error:0.13077\ttest-error:0.13188                               \n",
      "\n",
      "[30]\ttrain-error:0.13068\ttest-error:0.13170                               \n",
      "\n",
      "[31]\ttrain-error:0.13044\ttest-error:0.13170                               \n",
      "\n",
      "[32]\ttrain-error:0.13007\ttest-error:0.13133                               \n",
      "\n",
      "[33]\ttrain-error:0.12988\ttest-error:0.13090                               \n",
      "\n",
      "[34]\ttrain-error:0.12958\ttest-error:0.13102                               \n",
      "\n",
      "[35]\ttrain-error:0.12915\ttest-error:0.13084                               \n",
      "\n",
      "[36]\ttrain-error:0.12884\ttest-error:0.13059                               \n",
      "\n",
      "[37]\ttrain-error:0.12847\ttest-error:0.13065                               \n",
      "\n",
      "[38]\ttrain-error:0.12823\ttest-error:0.13059                               \n",
      "\n",
      "[39]\ttrain-error:0.12823\ttest-error:0.13065                               \n",
      "\n",
      "[40]\ttrain-error:0.12764\ttest-error:0.13022                               \n",
      "\n",
      "[41]\ttrain-error:0.12749\ttest-error:0.13040                               \n",
      "\n",
      "[42]\ttrain-error:0.12743\ttest-error:0.13010                               \n",
      "\n",
      "[43]\ttrain-error:0.12749\ttest-error:0.12979                               \n",
      "\n",
      "[44]\ttrain-error:0.12718\ttest-error:0.12979                               \n",
      "\n",
      "[45]\ttrain-error:0.12709\ttest-error:0.12991                               \n",
      "\n",
      "[46]\ttrain-error:0.12681\ttest-error:0.12985                               \n",
      "\n",
      "[47]\ttrain-error:0.12678\ttest-error:0.12998                               \n",
      "\n",
      "[48]\ttrain-error:0.12657\ttest-error:0.12991                               \n",
      "\n",
      "[49]\ttrain-error:0.12626\ttest-error:0.12979                               \n",
      "\n",
      "[50]\ttrain-error:0.12617\ttest-error:0.12985                               \n",
      "\n",
      "[51]\ttrain-error:0.12632\ttest-error:0.12961                               \n",
      "\n",
      "[52]\ttrain-error:0.12598\ttest-error:0.12967                               \n",
      "\n",
      "[53]\ttrain-error:0.12620\ttest-error:0.12985                               \n",
      "\n",
      "[54]\ttrain-error:0.12595\ttest-error:0.12961                               \n",
      "\n",
      "[55]\ttrain-error:0.12577\ttest-error:0.12948                               \n",
      "\n",
      "[56]\ttrain-error:0.12574\ttest-error:0.12930                               \n",
      "\n",
      "[57]\ttrain-error:0.12565\ttest-error:0.12881                               \n",
      "\n",
      "[58]\ttrain-error:0.12552\ttest-error:0.12899                               \n",
      "\n",
      "[59]\ttrain-error:0.12543\ttest-error:0.12912                               \n",
      "\n",
      "[60]\ttrain-error:0.12543\ttest-error:0.12918                               \n",
      "\n",
      "[61]\ttrain-error:0.12515\ttest-error:0.12936                               \n",
      "\n",
      "[62]\ttrain-error:0.12482\ttest-error:0.12942                               \n",
      "\n",
      "[63]\ttrain-error:0.12482\ttest-error:0.12924                               \n",
      "\n",
      "[64]\ttrain-error:0.12469\ttest-error:0.12924                               \n",
      "\n",
      "[65]\ttrain-error:0.12445\ttest-error:0.12924                               \n",
      "\n",
      "[66]\ttrain-error:0.12454\ttest-error:0.12924                               \n",
      "\n",
      "[67]\ttrain-error:0.12448\ttest-error:0.12924                               \n",
      "\n",
      "[68]\ttrain-error:0.12442\ttest-error:0.12924                               \n",
      "\n",
      "[69]\ttrain-error:0.12448\ttest-error:0.12912                               \n",
      "\n",
      "[70]\ttrain-error:0.12414\ttest-error:0.12912                               \n",
      "\n",
      "[71]\ttrain-error:0.12426\ttest-error:0.12912                               \n",
      "\n",
      "[72]\ttrain-error:0.12426\ttest-error:0.12875                               \n",
      "\n",
      "[73]\ttrain-error:0.12426\ttest-error:0.12832                               \n",
      "\n",
      "[74]\ttrain-error:0.12420\ttest-error:0.12838                               \n",
      "\n",
      "[75]\ttrain-error:0.12417\ttest-error:0.12832                               \n",
      "\n",
      "[76]\ttrain-error:0.12396\ttest-error:0.12850                               \n",
      "\n",
      "[77]\ttrain-error:0.12399\ttest-error:0.12856                               \n",
      "\n",
      "[78]\ttrain-error:0.12386\ttest-error:0.12856                               \n",
      "\n",
      "[79]\ttrain-error:0.12386\ttest-error:0.12862                               \n",
      "\n",
      "[80]\ttrain-error:0.12389\ttest-error:0.12850                               \n",
      "\n",
      "[81]\ttrain-error:0.12374\ttest-error:0.12856                               \n",
      "\n",
      "[82]\ttrain-error:0.12365\ttest-error:0.12856                               \n",
      "\n",
      "[83]\ttrain-error:0.12346\ttest-error:0.12844                               \n",
      "\n",
      "[84]\ttrain-error:0.12322\ttest-error:0.12844                               \n",
      "\n",
      "[85]\ttrain-error:0.12316\ttest-error:0.12832                               \n",
      "\n",
      "[86]\ttrain-error:0.12306\ttest-error:0.12832                               \n",
      "\n",
      "[87]\ttrain-error:0.12300\ttest-error:0.12838                               \n",
      "\n",
      "[88]\ttrain-error:0.12273\ttest-error:0.12869                               \n",
      "\n",
      "[89]\ttrain-error:0.12254\ttest-error:0.12850                               \n",
      "\n",
      "[90]\ttrain-error:0.12267\ttest-error:0.12875                               \n",
      "\n",
      "[91]\ttrain-error:0.12248\ttest-error:0.12905                               \n",
      "\n",
      "[92]\ttrain-error:0.12245\ttest-error:0.12905                               \n",
      "\n",
      "[93]\ttrain-error:0.12236\ttest-error:0.12912                               \n",
      "\n",
      "[94]\ttrain-error:0.12227\ttest-error:0.12893                               \n",
      "\n",
      "[95]\ttrain-error:0.12233\ttest-error:0.12912                               \n",
      "\n",
      "[96]\ttrain-error:0.12220\ttest-error:0.12924                               \n",
      "\n",
      "[97]\ttrain-error:0.12217\ttest-error:0.12912                               \n",
      "\n",
      "[98]\ttrain-error:0.12184\ttest-error:0.12905                               \n",
      "\n",
      "[99]\ttrain-error:0.12174\ttest-error:0.12887                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.6261447955477483, 'colsample_bytree': 0.5598675876323314, 'eta': 0.06740445691747836, 'eval_metric': ('error',), 'extra_dims': 14, 'gamma': 0, 'lambda': 0.03173665561441266, 'max_depth': 5, 'min_child_weight': 0.08047493164421338, 'objective': 'binary:logistic', 'subsample': 0.9968065361821689}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:28:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14524\ttest-error:0.14601                                \n",
      "\n",
      "[1]\ttrain-error:0.14026\ttest-error:0.14072                                \n",
      "\n",
      "[2]\ttrain-error:0.13710\ttest-error:0.13704                                \n",
      "\n",
      "[3]\ttrain-error:0.13514\ttest-error:0.13421                                \n",
      "\n",
      "[4]\ttrain-error:0.13298\ttest-error:0.13262                                \n",
      "\n",
      "[5]\ttrain-error:0.13059\ttest-error:0.13126                                \n",
      "\n",
      "[6]\ttrain-error:0.12752\ttest-error:0.12893                                \n",
      "\n",
      "[7]\ttrain-error:0.12482\ttest-error:0.12856                                \n",
      "\n",
      "[8]\ttrain-error:0.12386\ttest-error:0.12770                                \n",
      "\n",
      "[9]\ttrain-error:0.12193\ttest-error:0.12586                                \n",
      "\n",
      "[10]\ttrain-error:0.12058\ttest-error:0.12574                               \n",
      "\n",
      "[11]\ttrain-error:0.11913\ttest-error:0.12482                               \n",
      "\n",
      "[12]\ttrain-error:0.11876\ttest-error:0.12463                               \n",
      "\n",
      "[13]\ttrain-error:0.11830\ttest-error:0.12426                               \n",
      "\n",
      "[14]\ttrain-error:0.11729\ttest-error:0.12451                               \n",
      "\n",
      "[15]\ttrain-error:0.11677\ttest-error:0.12420                               \n",
      "\n",
      "[16]\ttrain-error:0.11597\ttest-error:0.12389                               \n",
      "\n",
      "[17]\ttrain-error:0.11566\ttest-error:0.12414                               \n",
      "\n",
      "[18]\ttrain-error:0.11490\ttest-error:0.12371                               \n",
      "\n",
      "[19]\ttrain-error:0.11413\ttest-error:0.12340                               \n",
      "\n",
      "[20]\ttrain-error:0.11367\ttest-error:0.12297                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21]\ttrain-error:0.11345\ttest-error:0.12297                               \n",
      "\n",
      "[22]\ttrain-error:0.11259\ttest-error:0.12254                               \n",
      "\n",
      "[23]\ttrain-error:0.11195\ttest-error:0.12297                               \n",
      "\n",
      "[24]\ttrain-error:0.11161\ttest-error:0.12328                               \n",
      "\n",
      "[25]\ttrain-error:0.11115\ttest-error:0.12310                               \n",
      "\n",
      "[26]\ttrain-error:0.11090\ttest-error:0.12303                               \n",
      "\n",
      "[27]\ttrain-error:0.11038\ttest-error:0.12303                               \n",
      "\n",
      "[28]\ttrain-error:0.10967\ttest-error:0.12303                               \n",
      "\n",
      "[29]\ttrain-error:0.10884\ttest-error:0.12279                               \n",
      "\n",
      "[30]\ttrain-error:0.10857\ttest-error:0.12310                               \n",
      "\n",
      "[31]\ttrain-error:0.10792\ttest-error:0.12328                               \n",
      "\n",
      "[32]\ttrain-error:0.10737\ttest-error:0.12328                               \n",
      "\n",
      "[33]\ttrain-error:0.10712\ttest-error:0.12316                               \n",
      "\n",
      "[34]\ttrain-error:0.10639\ttest-error:0.12310                               \n",
      "\n",
      "[35]\ttrain-error:0.10617\ttest-error:0.12340                               \n",
      "\n",
      "[36]\ttrain-error:0.10596\ttest-error:0.12365                               \n",
      "\n",
      "[37]\ttrain-error:0.10559\ttest-error:0.12328                               \n",
      "\n",
      "[38]\ttrain-error:0.10534\ttest-error:0.12340                               \n",
      "\n",
      "[39]\ttrain-error:0.10522\ttest-error:0.12328                               \n",
      "\n",
      "[40]\ttrain-error:0.10467\ttest-error:0.12322                               \n",
      "\n",
      "[41]\ttrain-error:0.10430\ttest-error:0.12353                               \n",
      "\n",
      "[42]\ttrain-error:0.10418\ttest-error:0.12371                               \n",
      "\n",
      "[43]\ttrain-error:0.10375\ttest-error:0.12371                               \n",
      "\n",
      "[44]\ttrain-error:0.10356\ttest-error:0.12389                               \n",
      "\n",
      "[45]\ttrain-error:0.10316\ttest-error:0.12426                               \n",
      "\n",
      "[46]\ttrain-error:0.10267\ttest-error:0.12432                               \n",
      "\n",
      "[47]\ttrain-error:0.10240\ttest-error:0.12426                               \n",
      "\n",
      "[48]\ttrain-error:0.10221\ttest-error:0.12408                               \n",
      "\n",
      "[49]\ttrain-error:0.10193\ttest-error:0.12402                               \n",
      "\n",
      "[50]\ttrain-error:0.10111\ttest-error:0.12371                               \n",
      "\n",
      "[51]\ttrain-error:0.10092\ttest-error:0.12414                               \n",
      "\n",
      "[52]\ttrain-error:0.10083\ttest-error:0.12451                               \n",
      "\n",
      "[53]\ttrain-error:0.09975\ttest-error:0.12469                               \n",
      "\n",
      "[54]\ttrain-error:0.09960\ttest-error:0.12420                               \n",
      "\n",
      "[55]\ttrain-error:0.09966\ttest-error:0.12445                               \n",
      "\n",
      "[56]\ttrain-error:0.09899\ttest-error:0.12432                               \n",
      "\n",
      "[57]\ttrain-error:0.09822\ttest-error:0.12457                               \n",
      "\n",
      "[58]\ttrain-error:0.09806\ttest-error:0.12426                               \n",
      "\n",
      "[59]\ttrain-error:0.09782\ttest-error:0.12396                               \n",
      "\n",
      "[60]\ttrain-error:0.09763\ttest-error:0.12439                               \n",
      "\n",
      "[61]\ttrain-error:0.09733\ttest-error:0.12469                               \n",
      "\n",
      "[62]\ttrain-error:0.09677\ttest-error:0.12457                               \n",
      "\n",
      "[63]\ttrain-error:0.09659\ttest-error:0.12408                               \n",
      "\n",
      "[64]\ttrain-error:0.09592\ttest-error:0.12445                               \n",
      "\n",
      "[65]\ttrain-error:0.09545\ttest-error:0.12432                               \n",
      "\n",
      "[66]\ttrain-error:0.09502\ttest-error:0.12402                               \n",
      "\n",
      "[67]\ttrain-error:0.09453\ttest-error:0.12426                               \n",
      "\n",
      "[68]\ttrain-error:0.09429\ttest-error:0.12457                               \n",
      "\n",
      "[69]\ttrain-error:0.09410\ttest-error:0.12469                               \n",
      "\n",
      "[70]\ttrain-error:0.09404\ttest-error:0.12469                               \n",
      "\n",
      "[71]\ttrain-error:0.09377\ttest-error:0.12457                               \n",
      "\n",
      "[72]\ttrain-error:0.09327\ttest-error:0.12488                               \n",
      "\n",
      "[73]\ttrain-error:0.09294\ttest-error:0.12488                               \n",
      "\n",
      "[74]\ttrain-error:0.09244\ttest-error:0.12432                               \n",
      "\n",
      "[75]\ttrain-error:0.09208\ttest-error:0.12463                               \n",
      "\n",
      "[76]\ttrain-error:0.09192\ttest-error:0.12488                               \n",
      "\n",
      "[77]\ttrain-error:0.09174\ttest-error:0.12469                               \n",
      "\n",
      "[78]\ttrain-error:0.09103\ttest-error:0.12488                               \n",
      "\n",
      "[79]\ttrain-error:0.09066\ttest-error:0.12531                               \n",
      "\n",
      "[80]\ttrain-error:0.09051\ttest-error:0.12525                               \n",
      "\n",
      "[81]\ttrain-error:0.09011\ttest-error:0.12512                               \n",
      "\n",
      "[82]\ttrain-error:0.08993\ttest-error:0.12500                               \n",
      "\n",
      "[83]\ttrain-error:0.08950\ttest-error:0.12463                               \n",
      "\n",
      "[84]\ttrain-error:0.08907\ttest-error:0.12494                               \n",
      "\n",
      "[85]\ttrain-error:0.08830\ttest-error:0.12469                               \n",
      "\n",
      "[86]\ttrain-error:0.08793\ttest-error:0.12463                               \n",
      "\n",
      "[87]\ttrain-error:0.08753\ttest-error:0.12463                               \n",
      "\n",
      "[88]\ttrain-error:0.08729\ttest-error:0.12457                               \n",
      "\n",
      "[89]\ttrain-error:0.08664\ttest-error:0.12439                               \n",
      "\n",
      "[90]\ttrain-error:0.08615\ttest-error:0.12445                               \n",
      "\n",
      "[91]\ttrain-error:0.08569\ttest-error:0.12457                               \n",
      "\n",
      "[92]\ttrain-error:0.08529\ttest-error:0.12457                               \n",
      "\n",
      "[93]\ttrain-error:0.08517\ttest-error:0.12512                               \n",
      "\n",
      "[94]\ttrain-error:0.08471\ttest-error:0.12506                               \n",
      "\n",
      "[95]\ttrain-error:0.08443\ttest-error:0.12580                               \n",
      "\n",
      "[96]\ttrain-error:0.08424\ttest-error:0.12561                               \n",
      "\n",
      "[97]\ttrain-error:0.08400\ttest-error:0.12549                               \n",
      "\n",
      "[98]\ttrain-error:0.08381\ttest-error:0.12506                               \n",
      "\n",
      "[99]\ttrain-error:0.08317\ttest-error:0.12586                               \n",
      "\n",
      "NEW BEST VALUE!                                                           \n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.6368584066698935, 'colsample_bytree': 0.5658890255839802, 'eta': 0.04571805025821978, 'eval_metric': ('error',), 'extra_dims': 14, 'gamma': 0, 'lambda': 0.03795287018282543, 'max_depth': 5, 'min_child_weight': 0.16987677054378736, 'objective': 'binary:logistic', 'subsample': 0.9690714461892719}\n",
      "Overwriting param `num_class`                                              \n",
      "Overwriting param `objective` while setting `obj` in train.                \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                    \n",
      "Setting param `disable_default_eval_metric` to 1.                          \n",
      "[23:30:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:   \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14717\ttest-error:0.14834                                 \n",
      "\n",
      "[1]\ttrain-error:0.14189\ttest-error:0.14269                                 \n",
      "\n",
      "[2]\ttrain-error:0.13937\ttest-error:0.13864                                 \n",
      "\n",
      "[3]\ttrain-error:0.13928\ttest-error:0.13790                                 \n",
      "\n",
      "[4]\ttrain-error:0.13882\ttest-error:0.13735                                 \n",
      "\n",
      "[5]\ttrain-error:0.13725\ttest-error:0.13563                                 \n",
      "\n",
      "[6]\ttrain-error:0.13483\ttest-error:0.13249                                 \n",
      "\n",
      "[7]\ttrain-error:0.13375\ttest-error:0.13157                                 \n",
      "\n",
      "[8]\ttrain-error:0.13099\ttest-error:0.12954                                 \n",
      "\n",
      "[9]\ttrain-error:0.12933\ttest-error:0.12862                                 \n",
      "\n",
      "[10]\ttrain-error:0.12859\ttest-error:0.12838                                \n",
      "\n",
      "[11]\ttrain-error:0.12697\ttest-error:0.12764                                \n",
      "\n",
      "[12]\ttrain-error:0.12583\ttest-error:0.12666                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13]\ttrain-error:0.12457\ttest-error:0.12598                                \n",
      "\n",
      "[14]\ttrain-error:0.12349\ttest-error:0.12561                                \n",
      "\n",
      "[15]\ttrain-error:0.12267\ttest-error:0.12580                                \n",
      "\n",
      "[16]\ttrain-error:0.12153\ttest-error:0.12592                                \n",
      "\n",
      "[17]\ttrain-error:0.12079\ttest-error:0.12506                                \n",
      "\n",
      "[18]\ttrain-error:0.12024\ttest-error:0.12488                                \n",
      "\n",
      "[19]\ttrain-error:0.11941\ttest-error:0.12463                                \n",
      "\n",
      "[20]\ttrain-error:0.11889\ttest-error:0.12494                                \n",
      "\n",
      "[21]\ttrain-error:0.11833\ttest-error:0.12488                                \n",
      "\n",
      "[22]\ttrain-error:0.11754\ttest-error:0.12506                                \n",
      "\n",
      "[23]\ttrain-error:0.11711\ttest-error:0.12469                                \n",
      "\n",
      "[24]\ttrain-error:0.11655\ttest-error:0.12500                                \n",
      "\n",
      "[25]\ttrain-error:0.11612\ttest-error:0.12512                                \n",
      "\n",
      "[26]\ttrain-error:0.11576\ttest-error:0.12488                                \n",
      "\n",
      "[27]\ttrain-error:0.11536\ttest-error:0.12518                                \n",
      "\n",
      "[28]\ttrain-error:0.11468\ttest-error:0.12512                                \n",
      "\n",
      "[29]\ttrain-error:0.11425\ttest-error:0.12500                                \n",
      "\n",
      "[30]\ttrain-error:0.11388\ttest-error:0.12506                                \n",
      "\n",
      "[31]\ttrain-error:0.11345\ttest-error:0.12506                                \n",
      "\n",
      "[32]\ttrain-error:0.11314\ttest-error:0.12512                                \n",
      "\n",
      "[33]\ttrain-error:0.11293\ttest-error:0.12537                                \n",
      "\n",
      "[34]\ttrain-error:0.11238\ttest-error:0.12488                                \n",
      "\n",
      "[35]\ttrain-error:0.11201\ttest-error:0.12494                                \n",
      "\n",
      "[36]\ttrain-error:0.11198\ttest-error:0.12488                                \n",
      "\n",
      "[37]\ttrain-error:0.11173\ttest-error:0.12432                                \n",
      "\n",
      "[38]\ttrain-error:0.11139\ttest-error:0.12439                                \n",
      "\n",
      "[39]\ttrain-error:0.11127\ttest-error:0.12475                                \n",
      "\n",
      "[40]\ttrain-error:0.11093\ttest-error:0.12457                                \n",
      "\n",
      "[41]\ttrain-error:0.11081\ttest-error:0.12475                                \n",
      "\n",
      "[42]\ttrain-error:0.11050\ttest-error:0.12494                                \n",
      "\n",
      "[43]\ttrain-error:0.11007\ttest-error:0.12457                                \n",
      "\n",
      "[44]\ttrain-error:0.10992\ttest-error:0.12488                                \n",
      "\n",
      "[45]\ttrain-error:0.10964\ttest-error:0.12451                                \n",
      "\n",
      "[46]\ttrain-error:0.10909\ttest-error:0.12457                                \n",
      "\n",
      "[47]\ttrain-error:0.10891\ttest-error:0.12439                                \n",
      "\n",
      "[48]\ttrain-error:0.10891\ttest-error:0.12439                                \n",
      "\n",
      "[49]\ttrain-error:0.10835\ttest-error:0.12408                                \n",
      "\n",
      "[50]\ttrain-error:0.10805\ttest-error:0.12414                                \n",
      "\n",
      "[51]\ttrain-error:0.10792\ttest-error:0.12414                                \n",
      "\n",
      "[52]\ttrain-error:0.10765\ttest-error:0.12420                                \n",
      "\n",
      "[53]\ttrain-error:0.10752\ttest-error:0.12426                                \n",
      "\n",
      "[54]\ttrain-error:0.10722\ttest-error:0.12426                                \n",
      "\n",
      "[55]\ttrain-error:0.10679\ttest-error:0.12445                                \n",
      "\n",
      "[56]\ttrain-error:0.10660\ttest-error:0.12396                                \n",
      "\n",
      "[57]\ttrain-error:0.10630\ttest-error:0.12414                                \n",
      "\n",
      "[58]\ttrain-error:0.10611\ttest-error:0.12426                                \n",
      "\n",
      "[59]\ttrain-error:0.10587\ttest-error:0.12414                                \n",
      "\n",
      "[60]\ttrain-error:0.10540\ttest-error:0.12371                                \n",
      "\n",
      "[61]\ttrain-error:0.10501\ttest-error:0.12396                                \n",
      "\n",
      "[62]\ttrain-error:0.10501\ttest-error:0.12383                                \n",
      "\n",
      "[63]\ttrain-error:0.10485\ttest-error:0.12377                                \n",
      "\n",
      "[64]\ttrain-error:0.10461\ttest-error:0.12377                                \n",
      "\n",
      "[65]\ttrain-error:0.10415\ttest-error:0.12383                                \n",
      "\n",
      "[66]\ttrain-error:0.10405\ttest-error:0.12371                                \n",
      "\n",
      "[67]\ttrain-error:0.10390\ttest-error:0.12377                                \n",
      "\n",
      "[68]\ttrain-error:0.10365\ttest-error:0.12420                                \n",
      "\n",
      "[69]\ttrain-error:0.10356\ttest-error:0.12402                                \n",
      "\n",
      "[70]\ttrain-error:0.10344\ttest-error:0.12389                                \n",
      "\n",
      "[71]\ttrain-error:0.10319\ttest-error:0.12396                                \n",
      "\n",
      "[72]\ttrain-error:0.10292\ttest-error:0.12420                                \n",
      "\n",
      "[73]\ttrain-error:0.10267\ttest-error:0.12396                                \n",
      "\n",
      "[74]\ttrain-error:0.10258\ttest-error:0.12408                                \n",
      "\n",
      "[75]\ttrain-error:0.10203\ttest-error:0.12383                                \n",
      "\n",
      "[76]\ttrain-error:0.10184\ttest-error:0.12402                                \n",
      "\n",
      "[77]\ttrain-error:0.10157\ttest-error:0.12426                                \n",
      "\n",
      "[78]\ttrain-error:0.10129\ttest-error:0.12439                                \n",
      "\n",
      "[79]\ttrain-error:0.10095\ttest-error:0.12463                                \n",
      "\n",
      "[80]\ttrain-error:0.10077\ttest-error:0.12463                                \n",
      "\n",
      "[81]\ttrain-error:0.10043\ttest-error:0.12451                                \n",
      "\n",
      "[82]\ttrain-error:0.10015\ttest-error:0.12439                                \n",
      "\n",
      "[83]\ttrain-error:0.09985\ttest-error:0.12414                                \n",
      "\n",
      "[84]\ttrain-error:0.09985\ttest-error:0.12445                                \n",
      "\n",
      "[85]\ttrain-error:0.09972\ttest-error:0.12451                                \n",
      "\n",
      "[86]\ttrain-error:0.09923\ttest-error:0.12426                                \n",
      "\n",
      "[87]\ttrain-error:0.09889\ttest-error:0.12426                                \n",
      "\n",
      "[88]\ttrain-error:0.09892\ttest-error:0.12457                                \n",
      "\n",
      "[89]\ttrain-error:0.09883\ttest-error:0.12463                                \n",
      "\n",
      "[90]\ttrain-error:0.09880\ttest-error:0.12457                                \n",
      "\n",
      "[91]\ttrain-error:0.09831\ttest-error:0.12451                                \n",
      "\n",
      "[92]\ttrain-error:0.09785\ttest-error:0.12457                                \n",
      "\n",
      "[93]\ttrain-error:0.09742\ttest-error:0.12494                                \n",
      "\n",
      "[94]\ttrain-error:0.09705\ttest-error:0.12506                                \n",
      "\n",
      "[95]\ttrain-error:0.09696\ttest-error:0.12488                                \n",
      "\n",
      "[96]\ttrain-error:0.09693\ttest-error:0.12488                                \n",
      "\n",
      "[97]\ttrain-error:0.09650\ttest-error:0.12469                                \n",
      "\n",
      "[98]\ttrain-error:0.09638\ttest-error:0.12500                                \n",
      "\n",
      "[99]\ttrain-error:0.09613\ttest-error:0.12482                                \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.6574183237648061, 'colsample_bytree': 0.5480124552554546, 'eta': 0.06606591671763425, 'eval_metric': ('error',), 'extra_dims': 14, 'gamma': 0, 'lambda': 0.002756269177337475, 'max_depth': 5, 'min_child_weight': 2.0506953836966324, 'objective': 'binary:logistic', 'subsample': 0.9459823438956072}\n",
      "Overwriting param `num_class`                                              \n",
      "Overwriting param `objective` while setting `obj` in train.                \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                    \n",
      "Setting param `disable_default_eval_metric` to 1.                          \n",
      "[23:31:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:   \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14349\ttest-error:0.14294                                 \n",
      "\n",
      "[1]\ttrain-error:0.14333\ttest-error:0.14202                                 \n",
      "\n",
      "[2]\ttrain-error:0.14039\ttest-error:0.13759                                 \n",
      "\n",
      "[3]\ttrain-error:0.13808\ttest-error:0.13526                                 \n",
      "\n",
      "[4]\ttrain-error:0.13658\ttest-error:0.13415                                 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttrain-error:0.13308\ttest-error:0.13102                                 \n",
      "\n",
      "[6]\ttrain-error:0.13010\ttest-error:0.12942                                 \n",
      "\n",
      "[7]\ttrain-error:0.12865\ttest-error:0.12918                                 \n",
      "\n",
      "[8]\ttrain-error:0.12684\ttest-error:0.12740                                 \n",
      "\n",
      "[9]\ttrain-error:0.12580\ttest-error:0.12697                                 \n",
      "\n",
      "[10]\ttrain-error:0.12518\ttest-error:0.12715                                \n",
      "\n",
      "[11]\ttrain-error:0.12478\ttest-error:0.12611                                \n",
      "\n",
      "[12]\ttrain-error:0.12374\ttest-error:0.12574                                \n",
      "\n",
      "[13]\ttrain-error:0.12306\ttest-error:0.12574                                \n",
      "\n",
      "[14]\ttrain-error:0.12257\ttest-error:0.12525                                \n",
      "\n",
      "[15]\ttrain-error:0.12208\ttest-error:0.12586                                \n",
      "\n",
      "[16]\ttrain-error:0.12190\ttest-error:0.12647                                \n",
      "\n",
      "[17]\ttrain-error:0.12119\ttest-error:0.12586                                \n",
      "\n",
      "[18]\ttrain-error:0.12073\ttest-error:0.12623                                \n",
      "\n",
      "[19]\ttrain-error:0.12048\ttest-error:0.12586                                \n",
      "\n",
      "[20]\ttrain-error:0.11990\ttest-error:0.12568                                \n",
      "\n",
      "[21]\ttrain-error:0.11935\ttest-error:0.12555                                \n",
      "\n",
      "[22]\ttrain-error:0.11901\ttest-error:0.12568                                \n",
      "\n",
      "[23]\ttrain-error:0.11830\ttest-error:0.12537                                \n",
      "\n",
      "[24]\ttrain-error:0.11790\ttest-error:0.12580                                \n",
      "\n",
      "[25]\ttrain-error:0.11784\ttest-error:0.12549                                \n",
      "\n",
      "[26]\ttrain-error:0.11760\ttest-error:0.12537                                \n",
      "\n",
      "[27]\ttrain-error:0.11732\ttest-error:0.12500                                \n",
      "\n",
      "[28]\ttrain-error:0.11720\ttest-error:0.12549                                \n",
      "\n",
      "[29]\ttrain-error:0.11704\ttest-error:0.12574                                \n",
      "\n",
      "[30]\ttrain-error:0.11692\ttest-error:0.12543                                \n",
      "\n",
      "[31]\ttrain-error:0.11674\ttest-error:0.12549                                \n",
      "\n",
      "[32]\ttrain-error:0.11655\ttest-error:0.12482                                \n",
      "\n",
      "[33]\ttrain-error:0.11640\ttest-error:0.12432                                \n",
      "\n",
      "[34]\ttrain-error:0.11606\ttest-error:0.12475                                \n",
      "\n",
      "[35]\ttrain-error:0.11572\ttest-error:0.12457                                \n",
      "\n",
      "[36]\ttrain-error:0.11548\ttest-error:0.12469                                \n",
      "\n",
      "[37]\ttrain-error:0.11533\ttest-error:0.12451                                \n",
      "\n",
      "[38]\ttrain-error:0.11529\ttest-error:0.12512                                \n",
      "\n",
      "[39]\ttrain-error:0.11496\ttest-error:0.12512                                \n",
      "\n",
      "[40]\ttrain-error:0.11468\ttest-error:0.12482                                \n",
      "\n",
      "[41]\ttrain-error:0.11434\ttest-error:0.12512                                \n",
      "\n",
      "[42]\ttrain-error:0.11428\ttest-error:0.12561                                \n",
      "\n",
      "[43]\ttrain-error:0.11388\ttest-error:0.12568                                \n",
      "\n",
      "[44]\ttrain-error:0.11376\ttest-error:0.12525                                \n",
      "\n",
      "[45]\ttrain-error:0.11321\ttest-error:0.12555                                \n",
      "\n",
      "[46]\ttrain-error:0.11330\ttest-error:0.12518                                \n",
      "\n",
      "[47]\ttrain-error:0.11305\ttest-error:0.12543                                \n",
      "\n",
      "[48]\ttrain-error:0.11330\ttest-error:0.12537                                \n",
      "\n",
      "[49]\ttrain-error:0.11281\ttest-error:0.12543                                \n",
      "\n",
      "[50]\ttrain-error:0.11259\ttest-error:0.12561                                \n",
      "\n",
      "[51]\ttrain-error:0.11213\ttest-error:0.12586                                \n",
      "\n",
      "[52]\ttrain-error:0.11219\ttest-error:0.12574                                \n",
      "\n",
      "[53]\ttrain-error:0.11182\ttest-error:0.12549                                \n",
      "\n",
      "[54]\ttrain-error:0.11149\ttest-error:0.12537                                \n",
      "\n",
      "[55]\ttrain-error:0.11124\ttest-error:0.12506                                \n",
      "\n",
      "[56]\ttrain-error:0.11106\ttest-error:0.12500                                \n",
      "\n",
      "[57]\ttrain-error:0.11084\ttest-error:0.12475                                \n",
      "\n",
      "[58]\ttrain-error:0.11063\ttest-error:0.12512                                \n",
      "\n",
      "[59]\ttrain-error:0.11010\ttest-error:0.12488                                \n",
      "\n",
      "[60]\ttrain-error:0.10995\ttest-error:0.12457                                \n",
      "\n",
      "[61]\ttrain-error:0.10967\ttest-error:0.12469                                \n",
      "\n",
      "[62]\ttrain-error:0.10958\ttest-error:0.12500                                \n",
      "\n",
      "[63]\ttrain-error:0.10961\ttest-error:0.12494                                \n",
      "\n",
      "[64]\ttrain-error:0.10918\ttest-error:0.12475                                \n",
      "\n",
      "[65]\ttrain-error:0.10906\ttest-error:0.12445                                \n",
      "\n",
      "[66]\ttrain-error:0.10894\ttest-error:0.12457                                \n",
      "\n",
      "[67]\ttrain-error:0.10884\ttest-error:0.12451                                \n",
      "\n",
      "[68]\ttrain-error:0.10878\ttest-error:0.12451                                \n",
      "\n",
      "[69]\ttrain-error:0.10848\ttest-error:0.12494                                \n",
      "\n",
      "[70]\ttrain-error:0.10838\ttest-error:0.12488                                \n",
      "\n",
      "[71]\ttrain-error:0.10817\ttest-error:0.12531                                \n",
      "\n",
      "[72]\ttrain-error:0.10805\ttest-error:0.12525                                \n",
      "\n",
      "[73]\ttrain-error:0.10802\ttest-error:0.12549                                \n",
      "\n",
      "[74]\ttrain-error:0.10798\ttest-error:0.12531                                \n",
      "\n",
      "[75]\ttrain-error:0.10783\ttest-error:0.12586                                \n",
      "\n",
      "[76]\ttrain-error:0.10771\ttest-error:0.12623                                \n",
      "\n",
      "[77]\ttrain-error:0.10755\ttest-error:0.12617                                \n",
      "\n",
      "[78]\ttrain-error:0.10765\ttest-error:0.12555                                \n",
      "\n",
      "[79]\ttrain-error:0.10740\ttest-error:0.12500                                \n",
      "\n",
      "[80]\ttrain-error:0.10706\ttest-error:0.12537                                \n",
      "\n",
      "[81]\ttrain-error:0.10691\ttest-error:0.12561                                \n",
      "\n",
      "[82]\ttrain-error:0.10716\ttest-error:0.12586                                \n",
      "\n",
      "[83]\ttrain-error:0.10691\ttest-error:0.12561                                \n",
      "\n",
      "[84]\ttrain-error:0.10663\ttest-error:0.12568                                \n",
      "\n",
      "[85]\ttrain-error:0.10642\ttest-error:0.12549                                \n",
      "\n",
      "[86]\ttrain-error:0.10605\ttest-error:0.12555                                \n",
      "\n",
      "[87]\ttrain-error:0.10593\ttest-error:0.12568                                \n",
      "\n",
      "[88]\ttrain-error:0.10565\ttest-error:0.12561                                \n",
      "\n",
      "[89]\ttrain-error:0.10534\ttest-error:0.12580                                \n",
      "\n",
      "[90]\ttrain-error:0.10540\ttest-error:0.12561                                \n",
      "\n",
      "[91]\ttrain-error:0.10513\ttest-error:0.12555                                \n",
      "\n",
      "[92]\ttrain-error:0.10504\ttest-error:0.12537                                \n",
      "\n",
      "[93]\ttrain-error:0.10476\ttest-error:0.12568                                \n",
      "\n",
      "[94]\ttrain-error:0.10454\ttest-error:0.12555                                \n",
      "\n",
      "[95]\ttrain-error:0.10454\ttest-error:0.12549                                \n",
      "\n",
      "[96]\ttrain-error:0.10448\ttest-error:0.12611                                \n",
      "\n",
      "[97]\ttrain-error:0.10418\ttest-error:0.12598                                \n",
      "\n",
      "[98]\ttrain-error:0.10387\ttest-error:0.12580                                \n",
      "\n",
      "[99]\ttrain-error:0.10375\ttest-error:0.12580                                \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.514189583219152, 'colsample_bytree': 0.8768099039047016, 'eta': 0.23705650824204313, 'eval_metric': ('error',), 'extra_dims': 14, 'gamma': 0, 'lambda': 0.010643242766013127, 'max_depth': 5, 'min_child_weight': 0.36279130896644035, 'objective': 'binary:logistic', 'subsample': 0.9967998206617597}\n",
      "Overwriting param `num_class`                                              \n",
      "Overwriting param `objective` while setting `obj` in train.                \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                    \n",
      "Setting param `disable_default_eval_metric` to 1.                          \n",
      "[23:33:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:   \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.14730\ttest-error:0.14699                                 \n",
      "\n",
      "[1]\ttrain-error:0.79177\ttest-error:0.79552                                 \n",
      "\n",
      "[2]\ttrain-error:0.18547\ttest-error:0.18372                                 \n",
      "\n",
      "[3]\ttrain-error:0.37291\ttest-error:0.36542                                 \n",
      "\n",
      "[4]\ttrain-error:0.24082\ttest-error:0.23624                                 \n",
      "\n",
      "[5]\ttrain-error:0.75918\ttest-error:0.76376                                 \n",
      "\n",
      "[6]\ttrain-error:0.24082\ttest-error:0.23624                                 \n",
      "\n",
      "[7]\ttrain-error:0.24082\ttest-error:0.23624                                 \n",
      "\n",
      "[8]\ttrain-error:0.24082\ttest-error:0.23624                                 \n",
      "\n",
      "[9]\ttrain-error:0.75918\ttest-error:0.76376                                 \n",
      "\n",
      "[10]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[11]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[12]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[13]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[14]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[15]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[16]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[17]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[18]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[19]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[20]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[21]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[22]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[23]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[24]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[25]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[26]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[27]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[28]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[29]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[30]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[31]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[32]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[33]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[34]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[35]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[36]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[37]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[38]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[39]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[40]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[41]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[42]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[43]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[44]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[45]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[46]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[47]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[48]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[49]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[50]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[51]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[52]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[53]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[54]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[55]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[56]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[57]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[58]\ttrain-error:0.30356\ttest-error:0.30117                                \n",
      "\n",
      "[59]\ttrain-error:0.32426\ttest-error:0.32518                                \n",
      "\n",
      "[60]\ttrain-error:0.26216\ttest-error:0.25878                                \n",
      "\n",
      "[61]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[62]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[63]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[64]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[65]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[66]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[67]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[68]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[69]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[70]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[71]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[72]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[73]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[74]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[75]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[76]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[77]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[78]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[79]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[80]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[81]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[82]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[83]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[84]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[85]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[86]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[87]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[88]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[89]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[90]\ttrain-error:0.24659\ttest-error:0.24214                                \n",
      "\n",
      "[91]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[92]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[93]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[94]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[95]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[96]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[97]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[98]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[99]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.6247032721882584, 'colsample_bytree': 0.5231606937913154, 'eta': 0.034591485336751174, 'eval_metric': ('error',), 'extra_dims': 5, 'gamma': 0, 'lambda': 3.472088637788513, 'max_depth': 5, 'min_child_weight': 70.1668283501794, 'objective': 'binary:logistic', 'subsample': 0.879124542467531}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:34:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.19266\ttest-error:0.18950                                \n",
      "\n",
      "[1]\ttrain-error:0.18074\ttest-error:0.18004                                \n",
      "\n",
      "[2]\ttrain-error:0.17571\ttest-error:0.17617                                \n",
      "\n",
      "[3]\ttrain-error:0.17620\ttest-error:0.17543                                \n",
      "\n",
      "[4]\ttrain-error:0.17227\ttest-error:0.17162                                \n",
      "\n",
      "[5]\ttrain-error:0.16895\ttest-error:0.16978                                \n",
      "\n",
      "[6]\ttrain-error:0.16889\ttest-error:0.17003                                \n",
      "\n",
      "[7]\ttrain-error:0.16738\ttest-error:0.16873                                \n",
      "\n",
      "[8]\ttrain-error:0.16453\ttest-error:0.16511                                \n",
      "\n",
      "[9]\ttrain-error:0.16367\ttest-error:0.16167                                \n",
      "\n",
      "[10]\ttrain-error:0.16050\ttest-error:0.15749                               \n",
      "\n",
      "[11]\ttrain-error:0.15921\ttest-error:0.15639                               \n",
      "\n",
      "[12]\ttrain-error:0.15860\ttest-error:0.15584                               \n",
      "\n",
      "[13]\ttrain-error:0.15688\ttest-error:0.15418                               \n",
      "\n",
      "[14]\ttrain-error:0.15538\ttest-error:0.15313                               \n",
      "\n",
      "[15]\ttrain-error:0.15485\ttest-error:0.15313                               \n",
      "\n",
      "[16]\ttrain-error:0.15439\ttest-error:0.15221                               \n",
      "\n",
      "[17]\ttrain-error:0.15412\ttest-error:0.15129                               \n",
      "\n",
      "[18]\ttrain-error:0.15326\ttest-error:0.15123                               \n",
      "\n",
      "[19]\ttrain-error:0.15301\ttest-error:0.15184                               \n",
      "\n",
      "[20]\ttrain-error:0.15304\ttest-error:0.15068                               \n",
      "\n",
      "[21]\ttrain-error:0.15178\ttest-error:0.15000                               \n",
      "\n",
      "[22]\ttrain-error:0.15187\ttest-error:0.14957                               \n",
      "\n",
      "[23]\ttrain-error:0.15135\ttest-error:0.14822                               \n",
      "\n",
      "[24]\ttrain-error:0.15080\ttest-error:0.14730                               \n",
      "\n",
      "[25]\ttrain-error:0.15055\ttest-error:0.14717                               \n",
      "\n",
      "[26]\ttrain-error:0.15065\ttest-error:0.14631                               \n",
      "\n",
      "[27]\ttrain-error:0.14979\ttest-error:0.14509                               \n",
      "\n",
      "[28]\ttrain-error:0.14920\ttest-error:0.14453                               \n",
      "\n",
      "[29]\ttrain-error:0.14865\ttest-error:0.14380                               \n",
      "\n",
      "[30]\ttrain-error:0.14825\ttest-error:0.14324                               \n",
      "\n",
      "[31]\ttrain-error:0.14751\ttest-error:0.14269                               \n",
      "\n",
      "[32]\ttrain-error:0.14714\ttest-error:0.14263                               \n",
      "\n",
      "[33]\ttrain-error:0.14677\ttest-error:0.14281                               \n",
      "\n",
      "[34]\ttrain-error:0.14662\ttest-error:0.14251                               \n",
      "\n",
      "[35]\ttrain-error:0.14613\ttest-error:0.14220                               \n",
      "\n",
      "[36]\ttrain-error:0.14585\ttest-error:0.14140                               \n",
      "\n",
      "[37]\ttrain-error:0.14595\ttest-error:0.14152                               \n",
      "\n",
      "[38]\ttrain-error:0.14509\ttest-error:0.14085                               \n",
      "\n",
      "[39]\ttrain-error:0.14496\ttest-error:0.14066                               \n",
      "\n",
      "[40]\ttrain-error:0.14490\ttest-error:0.14060                               \n",
      "\n",
      "[41]\ttrain-error:0.14481\ttest-error:0.14060                               \n",
      "\n",
      "[42]\ttrain-error:0.14484\ttest-error:0.14030                               \n",
      "\n",
      "[43]\ttrain-error:0.14475\ttest-error:0.14023                               \n",
      "\n",
      "[44]\ttrain-error:0.14469\ttest-error:0.14023                               \n",
      "\n",
      "[45]\ttrain-error:0.14463\ttest-error:0.14005                               \n",
      "\n",
      "[46]\ttrain-error:0.14453\ttest-error:0.13993                               \n",
      "\n",
      "[47]\ttrain-error:0.14438\ttest-error:0.13980                               \n",
      "\n",
      "[48]\ttrain-error:0.14429\ttest-error:0.13956                               \n",
      "\n",
      "[49]\ttrain-error:0.14401\ttest-error:0.13925                               \n",
      "\n",
      "[50]\ttrain-error:0.14374\ttest-error:0.13931                               \n",
      "\n",
      "[51]\ttrain-error:0.14380\ttest-error:0.13925                               \n",
      "\n",
      "[52]\ttrain-error:0.14346\ttest-error:0.13900                               \n",
      "\n",
      "[53]\ttrain-error:0.14327\ttest-error:0.13882                               \n",
      "\n",
      "[54]\ttrain-error:0.14358\ttest-error:0.13882                               \n",
      "\n",
      "[55]\ttrain-error:0.14321\ttest-error:0.13888                               \n",
      "\n",
      "[56]\ttrain-error:0.14337\ttest-error:0.13894                               \n",
      "\n",
      "[57]\ttrain-error:0.14312\ttest-error:0.13870                               \n",
      "\n",
      "[58]\ttrain-error:0.14269\ttest-error:0.13821                               \n",
      "\n",
      "[59]\ttrain-error:0.14269\ttest-error:0.13821                               \n",
      "\n",
      "[60]\ttrain-error:0.14272\ttest-error:0.13814                               \n",
      "\n",
      "[61]\ttrain-error:0.14244\ttest-error:0.13808                               \n",
      "\n",
      "[62]\ttrain-error:0.14217\ttest-error:0.13814                               \n",
      "\n",
      "[63]\ttrain-error:0.14195\ttest-error:0.13790                               \n",
      "\n",
      "[64]\ttrain-error:0.14189\ttest-error:0.13802                               \n",
      "\n",
      "[65]\ttrain-error:0.14168\ttest-error:0.13772                               \n",
      "\n",
      "[66]\ttrain-error:0.14161\ttest-error:0.13790                               \n",
      "\n",
      "[67]\ttrain-error:0.14137\ttest-error:0.13753                               \n",
      "\n",
      "[68]\ttrain-error:0.14103\ttest-error:0.13735                               \n",
      "\n",
      "[69]\ttrain-error:0.14109\ttest-error:0.13747                               \n",
      "\n",
      "[70]\ttrain-error:0.14103\ttest-error:0.13735                               \n",
      "\n",
      "[71]\ttrain-error:0.14112\ttest-error:0.13728                               \n",
      "\n",
      "[72]\ttrain-error:0.14119\ttest-error:0.13728                               \n",
      "\n",
      "[73]\ttrain-error:0.14103\ttest-error:0.13722                               \n",
      "\n",
      "[74]\ttrain-error:0.14085\ttest-error:0.13747                               \n",
      "\n",
      "[75]\ttrain-error:0.14060\ttest-error:0.13784                               \n",
      "\n",
      "[76]\ttrain-error:0.14069\ttest-error:0.13796                               \n",
      "\n",
      "[77]\ttrain-error:0.14060\ttest-error:0.13778                               \n",
      "\n",
      "[78]\ttrain-error:0.14051\ttest-error:0.13784                               \n",
      "\n",
      "[79]\ttrain-error:0.14051\ttest-error:0.13784                               \n",
      "\n",
      "[80]\ttrain-error:0.14033\ttest-error:0.13753                               \n",
      "\n",
      "[81]\ttrain-error:0.14057\ttest-error:0.13778                               \n",
      "\n",
      "[82]\ttrain-error:0.14045\ttest-error:0.13802                               \n",
      "\n",
      "[83]\ttrain-error:0.14023\ttest-error:0.13827                               \n",
      "\n",
      "[84]\ttrain-error:0.14014\ttest-error:0.13845                               \n",
      "\n",
      "[85]\ttrain-error:0.13983\ttest-error:0.13839                               \n",
      "\n",
      "[86]\ttrain-error:0.13983\ttest-error:0.13814                               \n",
      "\n",
      "[87]\ttrain-error:0.13999\ttest-error:0.13790                               \n",
      "\n",
      "[88]\ttrain-error:0.13993\ttest-error:0.13796                               \n",
      "\n",
      "[89]\ttrain-error:0.13990\ttest-error:0.13759                               \n",
      "\n",
      "[90]\ttrain-error:0.13999\ttest-error:0.13735                               \n",
      "\n",
      "[91]\ttrain-error:0.13996\ttest-error:0.13759                               \n",
      "\n",
      "[92]\ttrain-error:0.13983\ttest-error:0.13802                               \n",
      "\n",
      "[93]\ttrain-error:0.13983\ttest-error:0.13790                               \n",
      "\n",
      "[94]\ttrain-error:0.13980\ttest-error:0.13833                               \n",
      "\n",
      "[95]\ttrain-error:0.13965\ttest-error:0.13833                               \n",
      "\n",
      "[96]\ttrain-error:0.13965\ttest-error:0.13839                               \n",
      "\n",
      "[97]\ttrain-error:0.13965\ttest-error:0.13833                               \n",
      "\n",
      "[98]\ttrain-error:0.13974\ttest-error:0.13833                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99]\ttrain-error:0.13977\ttest-error:0.13833                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.5961952827264391, 'colsample_bytree': 0.5335496026216053, 'eta': 0.7621530493575637, 'eval_metric': ('error',), 'extra_dims': 2, 'gamma': 0, 'lambda': 0.07272109821690484, 'max_depth': 5, 'min_child_weight': 0.03458581429256846, 'objective': 'binary:logistic', 'subsample': 0.6159474128611103}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:35:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15544\ttest-error:0.15387                                \n",
      "\n",
      "[1]\ttrain-error:0.22583\ttest-error:0.23040                                \n",
      "\n",
      "[2]\ttrain-error:0.16511\ttest-error:0.16646                                \n",
      "\n",
      "[3]\ttrain-error:0.63523\ttest-error:0.64392                                \n",
      "\n",
      "[4]\ttrain-error:0.23977\ttest-error:0.23495                                \n",
      "\n",
      "[5]\ttrain-error:0.74926\ttest-error:0.75442                                \n",
      "\n",
      "[6]\ttrain-error:0.24205\ttest-error:0.23722                                \n",
      "\n",
      "[7]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[8]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[9]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[10]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[11]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[12]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[13]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[14]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[15]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[16]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[17]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[18]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[19]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[20]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[21]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[22]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[23]\ttrain-error:0.59542\ttest-error:0.60190                               \n",
      "\n",
      "[24]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[25]\ttrain-error:0.59079\ttest-error:0.59754                               \n",
      "\n",
      "[26]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[27]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[28]\ttrain-error:0.59337\ttest-error:0.59969                               \n",
      "\n",
      "[29]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[30]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[31]\ttrain-error:0.59404\ttest-error:0.60049                               \n",
      "\n",
      "[32]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[33]\ttrain-error:0.39450\ttest-error:0.39392                               \n",
      "\n",
      "[34]\ttrain-error:0.20246\ttest-error:0.20043                               \n",
      "\n",
      "[35]\ttrain-error:0.59450\ttest-error:0.60098                               \n",
      "\n",
      "[36]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[37]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[38]\ttrain-error:0.59183\ttest-error:0.59865                               \n",
      "\n",
      "[39]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[40]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[41]\ttrain-error:0.59180\ttest-error:0.59859                               \n",
      "\n",
      "[42]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[43]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[44]\ttrain-error:0.59183\ttest-error:0.59865                               \n",
      "\n",
      "[45]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[46]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[47]\ttrain-error:0.59192\ttest-error:0.59871                               \n",
      "\n",
      "[48]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[49]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[50]\ttrain-error:0.59192\ttest-error:0.59871                               \n",
      "\n",
      "[51]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[52]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[53]\ttrain-error:0.59183\ttest-error:0.59865                               \n",
      "\n",
      "[54]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[55]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[56]\ttrain-error:0.59183\ttest-error:0.59865                               \n",
      "\n",
      "[57]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[58]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[59]\ttrain-error:0.59183\ttest-error:0.59865                               \n",
      "\n",
      "[60]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[61]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[62]\ttrain-error:0.59174\ttest-error:0.59853                               \n",
      "\n",
      "[63]\ttrain-error:0.21628\ttest-error:0.21296                               \n",
      "\n",
      "[64]\ttrain-error:0.19991\ttest-error:0.19785                               \n",
      "\n",
      "[65]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[66]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[67]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[68]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[69]\ttrain-error:0.59165\ttest-error:0.59834                               \n",
      "\n",
      "[70]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[71]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[72]\ttrain-error:0.59183\ttest-error:0.59865                               \n",
      "\n",
      "[73]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[74]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[75]\ttrain-error:0.59183\ttest-error:0.59865                               \n",
      "\n",
      "[76]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[77]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[78]\ttrain-error:0.65012\ttest-error:0.65448                               \n",
      "\n",
      "[79]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[80]\ttrain-error:0.24079\ttest-error:0.23624                               \n",
      "\n",
      "[81]\ttrain-error:0.59069\ttest-error:0.59748                               \n",
      "\n",
      "[82]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[83]\ttrain-error:0.21401\ttest-error:0.21130                               \n",
      "\n",
      "[84]\ttrain-error:0.59069\ttest-error:0.59748                               \n",
      "\n",
      "[85]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[86]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[87]\ttrain-error:0.59069\ttest-error:0.59748                               \n",
      "\n",
      "[88]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[89]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[90]\ttrain-error:0.59069\ttest-error:0.59748                               \n",
      "\n",
      "[91]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[93]\ttrain-error:0.59109\ttest-error:0.59785                               \n",
      "\n",
      "[94]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[95]\ttrain-error:0.21388\ttest-error:0.21112                               \n",
      "\n",
      "[96]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[97]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[98]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[99]\ttrain-error:0.21843\ttest-error:0.21437                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.555898991153925, 'colsample_bytree': 0.9817975595911943, 'eta': 0.004554902572844547, 'eval_metric': ('error',), 'extra_dims': 14, 'gamma': 0, 'lambda': 0.03104780795755463, 'max_depth': 1, 'min_child_weight': 25.794335064628047, 'objective': 'binary:logistic', 'subsample': 0.9771864168962905}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:36:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[1]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[2]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[3]\ttrain-error:0.22245\ttest-error:0.21843                                \n",
      "\n",
      "[4]\ttrain-error:0.22221\ttest-error:0.21806                                \n",
      "\n",
      "[5]\ttrain-error:0.22052\ttest-error:0.21665                                \n",
      "\n",
      "[6]\ttrain-error:0.20863\ttest-error:0.20565                                \n",
      "\n",
      "[7]\ttrain-error:0.20863\ttest-error:0.20565                                \n",
      "\n",
      "[8]\ttrain-error:0.20814\ttest-error:0.20491                                \n",
      "\n",
      "[9]\ttrain-error:0.20651\ttest-error:0.20362                                \n",
      "\n",
      "[10]\ttrain-error:0.20651\ttest-error:0.20362                               \n",
      "\n",
      "[11]\ttrain-error:0.20651\ttest-error:0.20362                               \n",
      "\n",
      "[12]\ttrain-error:0.20651\ttest-error:0.20362                               \n",
      "\n",
      "[13]\ttrain-error:0.20476\ttest-error:0.20209                               \n",
      "\n",
      "[14]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[15]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[16]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[17]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[18]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[19]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[20]\ttrain-error:0.20458\ttest-error:0.20190                               \n",
      "\n",
      "[21]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[22]\ttrain-error:0.20458\ttest-error:0.20190                               \n",
      "\n",
      "[23]\ttrain-error:0.20458\ttest-error:0.20190                               \n",
      "\n",
      "[24]\ttrain-error:0.20458\ttest-error:0.20190                               \n",
      "\n",
      "[25]\ttrain-error:0.20458\ttest-error:0.20190                               \n",
      "\n",
      "[26]\ttrain-error:0.20458\ttest-error:0.20190                               \n",
      "\n",
      "[27]\ttrain-error:0.20458\ttest-error:0.20190                               \n",
      "\n",
      "[28]\ttrain-error:0.20458\ttest-error:0.20190                               \n",
      "\n",
      "[29]\ttrain-error:0.20458\ttest-error:0.20190                               \n",
      "\n",
      "[30]\ttrain-error:0.20458\ttest-error:0.20190                               \n",
      "\n",
      "[31]\ttrain-error:0.20458\ttest-error:0.20190                               \n",
      "\n",
      "[32]\ttrain-error:0.20458\ttest-error:0.20190                               \n",
      "\n",
      "[33]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[34]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[35]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[36]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[37]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[38]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[39]\ttrain-error:0.20455\ttest-error:0.20190                               \n",
      "\n",
      "[40]\ttrain-error:0.20280\ttest-error:0.20025                               \n",
      "\n",
      "[41]\ttrain-error:0.20283\ttest-error:0.20025                               \n",
      "\n",
      "[42]\ttrain-error:0.19951\ttest-error:0.19742                               \n",
      "\n",
      "[43]\ttrain-error:0.19423\ttest-error:0.19275                               \n",
      "\n",
      "[44]\ttrain-error:0.18655\ttest-error:0.18513                               \n",
      "\n",
      "[45]\ttrain-error:0.17654\ttest-error:0.17580                               \n",
      "\n",
      "[46]\ttrain-error:0.17598\ttest-error:0.17512                               \n",
      "\n",
      "[47]\ttrain-error:0.17500\ttest-error:0.17389                               \n",
      "\n",
      "[48]\ttrain-error:0.17239\ttest-error:0.17174                               \n",
      "\n",
      "[49]\ttrain-error:0.17159\ttest-error:0.17082                               \n",
      "\n",
      "[50]\ttrain-error:0.17227\ttest-error:0.17162                               \n",
      "\n",
      "[51]\ttrain-error:0.17141\ttest-error:0.17064                               \n",
      "\n",
      "[52]\ttrain-error:0.17122\ttest-error:0.17058                               \n",
      "\n",
      "[53]\ttrain-error:0.16235\ttest-error:0.16247                               \n",
      "\n",
      "[54]\ttrain-error:0.16225\ttest-error:0.16241                               \n",
      "\n",
      "[55]\ttrain-error:0.16222\ttest-error:0.16235                               \n",
      "\n",
      "[56]\ttrain-error:0.16225\ttest-error:0.16222                               \n",
      "\n",
      "[57]\ttrain-error:0.16164\ttest-error:0.16167                               \n",
      "\n",
      "[58]\ttrain-error:0.16164\ttest-error:0.16167                               \n",
      "\n",
      "[59]\ttrain-error:0.16164\ttest-error:0.16161                               \n",
      "\n",
      "[60]\ttrain-error:0.16164\ttest-error:0.16161                               \n",
      "\n",
      "[61]\ttrain-error:0.16161\ttest-error:0.16136                               \n",
      "\n",
      "[62]\ttrain-error:0.16161\ttest-error:0.16130                               \n",
      "\n",
      "[63]\ttrain-error:0.16152\ttest-error:0.16112                               \n",
      "\n",
      "[64]\ttrain-error:0.16136\ttest-error:0.16099                               \n",
      "\n",
      "[65]\ttrain-error:0.16112\ttest-error:0.16087                               \n",
      "\n",
      "[66]\ttrain-error:0.16103\ttest-error:0.16075                               \n",
      "\n",
      "[67]\ttrain-error:0.16090\ttest-error:0.16075                               \n",
      "\n",
      "[68]\ttrain-error:0.16087\ttest-error:0.16063                               \n",
      "\n",
      "[69]\ttrain-error:0.16069\ttest-error:0.16044                               \n",
      "\n",
      "[70]\ttrain-error:0.16020\ttest-error:0.15946                               \n",
      "\n",
      "[71]\ttrain-error:0.16013\ttest-error:0.15940                               \n",
      "\n",
      "[72]\ttrain-error:0.15983\ttest-error:0.15934                               \n",
      "\n",
      "[73]\ttrain-error:0.15949\ttest-error:0.15897                               \n",
      "\n",
      "[74]\ttrain-error:0.15924\ttest-error:0.15878                               \n",
      "\n",
      "[75]\ttrain-error:0.15900\ttest-error:0.15872                               \n",
      "\n",
      "[76]\ttrain-error:0.15881\ttest-error:0.15860                               \n",
      "\n",
      "[77]\ttrain-error:0.15884\ttest-error:0.15860                               \n",
      "\n",
      "[78]\ttrain-error:0.15829\ttest-error:0.15811                               \n",
      "\n",
      "[79]\ttrain-error:0.15832\ttest-error:0.15811                               \n",
      "\n",
      "[80]\ttrain-error:0.15826\ttest-error:0.15805                               \n",
      "\n",
      "[81]\ttrain-error:0.15826\ttest-error:0.15774                               \n",
      "\n",
      "[82]\ttrain-error:0.15820\ttest-error:0.15768                               \n",
      "\n",
      "[83]\ttrain-error:0.15823\ttest-error:0.15768                               \n",
      "\n",
      "[84]\ttrain-error:0.15814\ttest-error:0.15756                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85]\ttrain-error:0.15783\ttest-error:0.15725                               \n",
      "\n",
      "[86]\ttrain-error:0.15783\ttest-error:0.15712                               \n",
      "\n",
      "[87]\ttrain-error:0.15706\ttest-error:0.15614                               \n",
      "\n",
      "[88]\ttrain-error:0.15691\ttest-error:0.15614                               \n",
      "\n",
      "[89]\ttrain-error:0.15513\ttest-error:0.15504                               \n",
      "\n",
      "[90]\ttrain-error:0.15488\ttest-error:0.15504                               \n",
      "\n",
      "[91]\ttrain-error:0.15470\ttest-error:0.15485                               \n",
      "\n",
      "[92]\ttrain-error:0.15415\ttest-error:0.15461                               \n",
      "\n",
      "[93]\ttrain-error:0.15421\ttest-error:0.15442                               \n",
      "\n",
      "[94]\ttrain-error:0.15418\ttest-error:0.15442                               \n",
      "\n",
      "[95]\ttrain-error:0.15402\ttest-error:0.15430                               \n",
      "\n",
      "[96]\ttrain-error:0.15378\ttest-error:0.15430                               \n",
      "\n",
      "[97]\ttrain-error:0.15381\ttest-error:0.15430                               \n",
      "\n",
      "[98]\ttrain-error:0.15384\ttest-error:0.15430                               \n",
      "\n",
      "[99]\ttrain-error:0.15384\ttest-error:0.15424                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.7134558318935154, 'colsample_bytree': 0.5895507814697428, 'eta': 0.07626271885044414, 'eval_metric': ('error',), 'extra_dims': 15, 'gamma': 0, 'lambda': 0.39096643839401174, 'max_depth': 3, 'min_child_weight': 0.006523193584056429, 'objective': 'binary:logistic', 'subsample': 0.9190989925474292}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:37:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15712\ttest-error:0.15756                                \n",
      "\n",
      "[1]\ttrain-error:0.14668\ttest-error:0.14650                                \n",
      "\n",
      "[2]\ttrain-error:0.14275\ttest-error:0.14140                                \n",
      "\n",
      "[3]\ttrain-error:0.14180\ttest-error:0.14091                                \n",
      "\n",
      "[4]\ttrain-error:0.13977\ttest-error:0.13900                                \n",
      "\n",
      "[5]\ttrain-error:0.13778\ttest-error:0.13649                                \n",
      "\n",
      "[6]\ttrain-error:0.13569\ttest-error:0.13470                                \n",
      "\n",
      "[7]\ttrain-error:0.13492\ttest-error:0.13311                                \n",
      "\n",
      "[8]\ttrain-error:0.13384\ttest-error:0.13200                                \n",
      "\n",
      "[9]\ttrain-error:0.13240\ttest-error:0.13065                                \n",
      "\n",
      "[10]\ttrain-error:0.13105\ttest-error:0.13059                               \n",
      "\n",
      "[11]\ttrain-error:0.13007\ttest-error:0.13040                               \n",
      "\n",
      "[12]\ttrain-error:0.12964\ttest-error:0.13034                               \n",
      "\n",
      "[13]\ttrain-error:0.12872\ttest-error:0.13022                               \n",
      "\n",
      "[14]\ttrain-error:0.12810\ttest-error:0.12967                               \n",
      "\n",
      "[15]\ttrain-error:0.12767\ttest-error:0.12948                               \n",
      "\n",
      "[16]\ttrain-error:0.12663\ttest-error:0.12887                               \n",
      "\n",
      "[17]\ttrain-error:0.12644\ttest-error:0.12924                               \n",
      "\n",
      "[18]\ttrain-error:0.12583\ttest-error:0.12881                               \n",
      "\n",
      "[19]\ttrain-error:0.12571\ttest-error:0.12881                               \n",
      "\n",
      "[20]\ttrain-error:0.12531\ttest-error:0.12801                               \n",
      "\n",
      "[21]\ttrain-error:0.12491\ttest-error:0.12813                               \n",
      "\n",
      "[22]\ttrain-error:0.12435\ttest-error:0.12819                               \n",
      "\n",
      "[23]\ttrain-error:0.12389\ttest-error:0.12826                               \n",
      "\n",
      "[24]\ttrain-error:0.12343\ttest-error:0.12801                               \n",
      "\n",
      "[25]\ttrain-error:0.12313\ttest-error:0.12740                               \n",
      "\n",
      "[26]\ttrain-error:0.12260\ttest-error:0.12684                               \n",
      "\n",
      "[27]\ttrain-error:0.12233\ttest-error:0.12654                               \n",
      "\n",
      "[28]\ttrain-error:0.12165\ttest-error:0.12598                               \n",
      "\n",
      "[29]\ttrain-error:0.12165\ttest-error:0.12586                               \n",
      "\n",
      "[30]\ttrain-error:0.12104\ttest-error:0.12586                               \n",
      "\n",
      "[31]\ttrain-error:0.12089\ttest-error:0.12580                               \n",
      "\n",
      "[32]\ttrain-error:0.12091\ttest-error:0.12518                               \n",
      "\n",
      "[33]\ttrain-error:0.12024\ttest-error:0.12525                               \n",
      "\n",
      "[34]\ttrain-error:0.12015\ttest-error:0.12494                               \n",
      "\n",
      "[35]\ttrain-error:0.12015\ttest-error:0.12500                               \n",
      "\n",
      "[36]\ttrain-error:0.11987\ttest-error:0.12488                               \n",
      "\n",
      "[37]\ttrain-error:0.11960\ttest-error:0.12537                               \n",
      "\n",
      "[38]\ttrain-error:0.11913\ttest-error:0.12568                               \n",
      "\n",
      "[39]\ttrain-error:0.11901\ttest-error:0.12543                               \n",
      "\n",
      "[40]\ttrain-error:0.11867\ttest-error:0.12537                               \n",
      "\n",
      "[41]\ttrain-error:0.11827\ttest-error:0.12500                               \n",
      "\n",
      "[42]\ttrain-error:0.11833\ttest-error:0.12518                               \n",
      "\n",
      "[43]\ttrain-error:0.11800\ttest-error:0.12543                               \n",
      "\n",
      "[44]\ttrain-error:0.11763\ttest-error:0.12500                               \n",
      "\n",
      "[45]\ttrain-error:0.11747\ttest-error:0.12500                               \n",
      "\n",
      "[46]\ttrain-error:0.11744\ttest-error:0.12518                               \n",
      "\n",
      "[47]\ttrain-error:0.11704\ttest-error:0.12518                               \n",
      "\n",
      "[48]\ttrain-error:0.11689\ttest-error:0.12488                               \n",
      "\n",
      "[49]\ttrain-error:0.11655\ttest-error:0.12482                               \n",
      "\n",
      "[50]\ttrain-error:0.11637\ttest-error:0.12512                               \n",
      "\n",
      "[51]\ttrain-error:0.11615\ttest-error:0.12457                               \n",
      "\n",
      "[52]\ttrain-error:0.11622\ttest-error:0.12512                               \n",
      "\n",
      "[53]\ttrain-error:0.11597\ttest-error:0.12506                               \n",
      "\n",
      "[54]\ttrain-error:0.11569\ttest-error:0.12457                               \n",
      "\n",
      "[55]\ttrain-error:0.11536\ttest-error:0.12469                               \n",
      "\n",
      "[56]\ttrain-error:0.11517\ttest-error:0.12482                               \n",
      "\n",
      "[57]\ttrain-error:0.11486\ttest-error:0.12475                               \n",
      "\n",
      "[58]\ttrain-error:0.11443\ttest-error:0.12488                               \n",
      "\n",
      "[59]\ttrain-error:0.11425\ttest-error:0.12500                               \n",
      "\n",
      "[60]\ttrain-error:0.11422\ttest-error:0.12488                               \n",
      "\n",
      "[61]\ttrain-error:0.11413\ttest-error:0.12457                               \n",
      "\n",
      "[62]\ttrain-error:0.11391\ttest-error:0.12457                               \n",
      "\n",
      "[63]\ttrain-error:0.11404\ttest-error:0.12426                               \n",
      "\n",
      "[64]\ttrain-error:0.11385\ttest-error:0.12377                               \n",
      "\n",
      "[65]\ttrain-error:0.11367\ttest-error:0.12402                               \n",
      "\n",
      "[66]\ttrain-error:0.11367\ttest-error:0.12426                               \n",
      "\n",
      "[67]\ttrain-error:0.11351\ttest-error:0.12469                               \n",
      "\n",
      "[68]\ttrain-error:0.11342\ttest-error:0.12445                               \n",
      "\n",
      "[69]\ttrain-error:0.11330\ttest-error:0.12463                               \n",
      "\n",
      "[70]\ttrain-error:0.11305\ttest-error:0.12414                               \n",
      "\n",
      "[71]\ttrain-error:0.11278\ttest-error:0.12439                               \n",
      "\n",
      "[72]\ttrain-error:0.11253\ttest-error:0.12426                               \n",
      "\n",
      "[73]\ttrain-error:0.11253\ttest-error:0.12482                               \n",
      "\n",
      "[74]\ttrain-error:0.11241\ttest-error:0.12469                               \n",
      "\n",
      "[75]\ttrain-error:0.11219\ttest-error:0.12488                               \n",
      "\n",
      "[76]\ttrain-error:0.11198\ttest-error:0.12494                               \n",
      "\n",
      "[77]\ttrain-error:0.11170\ttest-error:0.12512                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78]\ttrain-error:0.11167\ttest-error:0.12568                               \n",
      "\n",
      "[79]\ttrain-error:0.11139\ttest-error:0.12537                               \n",
      "\n",
      "[80]\ttrain-error:0.11124\ttest-error:0.12525                               \n",
      "\n",
      "[81]\ttrain-error:0.11130\ttest-error:0.12506                               \n",
      "\n",
      "[82]\ttrain-error:0.11109\ttest-error:0.12506                               \n",
      "\n",
      "[83]\ttrain-error:0.11053\ttest-error:0.12494                               \n",
      "\n",
      "[84]\ttrain-error:0.11026\ttest-error:0.12525                               \n",
      "\n",
      "[85]\ttrain-error:0.10992\ttest-error:0.12512                               \n",
      "\n",
      "[86]\ttrain-error:0.11004\ttest-error:0.12512                               \n",
      "\n",
      "[87]\ttrain-error:0.11010\ttest-error:0.12506                               \n",
      "\n",
      "[88]\ttrain-error:0.11020\ttest-error:0.12506                               \n",
      "\n",
      "[89]\ttrain-error:0.10964\ttest-error:0.12482                               \n",
      "\n",
      "[90]\ttrain-error:0.10967\ttest-error:0.12512                               \n",
      "\n",
      "[91]\ttrain-error:0.10934\ttest-error:0.12494                               \n",
      "\n",
      "[92]\ttrain-error:0.10918\ttest-error:0.12506                               \n",
      "\n",
      "[93]\ttrain-error:0.10894\ttest-error:0.12469                               \n",
      "\n",
      "[94]\ttrain-error:0.10875\ttest-error:0.12475                               \n",
      "\n",
      "[95]\ttrain-error:0.10866\ttest-error:0.12531                               \n",
      "\n",
      "[96]\ttrain-error:0.10863\ttest-error:0.12525                               \n",
      "\n",
      "[97]\ttrain-error:0.10826\ttest-error:0.12537                               \n",
      "\n",
      "[98]\ttrain-error:0.10848\ttest-error:0.12512                               \n",
      "\n",
      "[99]\ttrain-error:0.10820\ttest-error:0.12531                               \n",
      "\n",
      "{'alpha': 0.461401083001147, 'btype': 'Rn', 'colsample_bylevel': 0.7907304056332163, 'colsample_bytree': 0.8246028513763737, 'eta': 0.1430540209827448, 'eval_metric': ('error',), 'extra_dims': 10, 'gamma': 0, 'lambda': 0.1511533552025915, 'max_depth': 4, 'min_child_weight': 0.002409423434480503, 'objective': 'binary:logistic', 'subsample': 0.9539260248416003}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:39:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15000\ttest-error:0.14926                                \n",
      "\n",
      "[1]\ttrain-error:0.14247\ttest-error:0.14054                                \n",
      "\n",
      "[2]\ttrain-error:0.13664\ttest-error:0.13452                                \n",
      "\n",
      "[3]\ttrain-error:0.13342\ttest-error:0.13335                                \n",
      "\n",
      "[4]\ttrain-error:0.13077\ttest-error:0.13114                                \n",
      "\n",
      "[5]\ttrain-error:0.12970\ttest-error:0.12954                                \n",
      "\n",
      "[6]\ttrain-error:0.12749\ttest-error:0.12783                                \n",
      "\n",
      "[7]\ttrain-error:0.12485\ttest-error:0.12752                                \n",
      "\n",
      "[8]\ttrain-error:0.12399\ttest-error:0.12690                                \n",
      "\n",
      "[9]\ttrain-error:0.12328\ttest-error:0.12727                                \n",
      "\n",
      "[10]\ttrain-error:0.12245\ttest-error:0.12758                               \n",
      "\n",
      "[11]\ttrain-error:0.12116\ttest-error:0.12746                               \n",
      "\n",
      "[12]\ttrain-error:0.12058\ttest-error:0.12740                               \n",
      "\n",
      "[13]\ttrain-error:0.11993\ttest-error:0.12678                               \n",
      "\n",
      "[14]\ttrain-error:0.11904\ttest-error:0.12690                               \n",
      "\n",
      "[15]\ttrain-error:0.11855\ttest-error:0.12623                               \n",
      "\n",
      "[16]\ttrain-error:0.11738\ttest-error:0.12598                               \n",
      "\n",
      "[17]\ttrain-error:0.11655\ttest-error:0.12574                               \n",
      "\n",
      "[18]\ttrain-error:0.11579\ttest-error:0.12555                               \n",
      "\n",
      "[19]\ttrain-error:0.11465\ttest-error:0.12512                               \n",
      "\n",
      "[20]\ttrain-error:0.11453\ttest-error:0.12537                               \n",
      "\n",
      "[21]\ttrain-error:0.11425\ttest-error:0.12531                               \n",
      "\n",
      "[22]\ttrain-error:0.11351\ttest-error:0.12586                               \n",
      "\n",
      "[23]\ttrain-error:0.11290\ttest-error:0.12598                               \n",
      "\n",
      "[24]\ttrain-error:0.11241\ttest-error:0.12580                               \n",
      "\n",
      "[25]\ttrain-error:0.11176\ttest-error:0.12568                               \n",
      "\n",
      "[26]\ttrain-error:0.11093\ttest-error:0.12543                               \n",
      "\n",
      "[27]\ttrain-error:0.11032\ttest-error:0.12574                               \n",
      "\n",
      "[28]\ttrain-error:0.11010\ttest-error:0.12543                               \n",
      "\n",
      "[29]\ttrain-error:0.10977\ttest-error:0.12549                               \n",
      "\n",
      "[30]\ttrain-error:0.10881\ttest-error:0.12568                               \n",
      "\n",
      "[31]\ttrain-error:0.10884\ttest-error:0.12629                               \n",
      "\n",
      "[32]\ttrain-error:0.10832\ttest-error:0.12647                               \n",
      "\n",
      "[33]\ttrain-error:0.10780\ttest-error:0.12641                               \n",
      "\n",
      "[34]\ttrain-error:0.10759\ttest-error:0.12672                               \n",
      "\n",
      "[35]\ttrain-error:0.10679\ttest-error:0.12641                               \n",
      "\n",
      "[36]\ttrain-error:0.10645\ttest-error:0.12617                               \n",
      "\n",
      "[37]\ttrain-error:0.10577\ttest-error:0.12647                               \n",
      "\n",
      "[38]\ttrain-error:0.10559\ttest-error:0.12715                               \n",
      "\n",
      "[39]\ttrain-error:0.10519\ttest-error:0.12684                               \n",
      "\n",
      "[40]\ttrain-error:0.10488\ttest-error:0.12733                               \n",
      "\n",
      "[41]\ttrain-error:0.10430\ttest-error:0.12740                               \n",
      "\n",
      "[42]\ttrain-error:0.10418\ttest-error:0.12727                               \n",
      "\n",
      "[43]\ttrain-error:0.10393\ttest-error:0.12709                               \n",
      "\n",
      "[44]\ttrain-error:0.10344\ttest-error:0.12703                               \n",
      "\n",
      "[45]\ttrain-error:0.10298\ttest-error:0.12721                               \n",
      "\n",
      "[46]\ttrain-error:0.10252\ttest-error:0.12807                               \n",
      "\n",
      "[47]\ttrain-error:0.10212\ttest-error:0.12776                               \n",
      "\n",
      "[48]\ttrain-error:0.10193\ttest-error:0.12801                               \n",
      "\n",
      "[49]\ttrain-error:0.10169\ttest-error:0.12783                               \n",
      "\n",
      "[50]\ttrain-error:0.10132\ttest-error:0.12764                               \n",
      "\n",
      "[51]\ttrain-error:0.10114\ttest-error:0.12770                               \n",
      "\n",
      "[52]\ttrain-error:0.10068\ttest-error:0.12807                               \n",
      "\n",
      "[53]\ttrain-error:0.10025\ttest-error:0.12838                               \n",
      "\n",
      "[54]\ttrain-error:0.09982\ttest-error:0.12862                               \n",
      "\n",
      "[55]\ttrain-error:0.09923\ttest-error:0.12893                               \n",
      "\n",
      "[56]\ttrain-error:0.09856\ttest-error:0.12887                               \n",
      "\n",
      "[57]\ttrain-error:0.09853\ttest-error:0.12893                               \n",
      "\n",
      "[58]\ttrain-error:0.09871\ttest-error:0.12887                               \n",
      "\n",
      "[59]\ttrain-error:0.09763\ttest-error:0.12869                               \n",
      "\n",
      "[60]\ttrain-error:0.09730\ttest-error:0.12875                               \n",
      "\n",
      "[61]\ttrain-error:0.09684\ttest-error:0.12875                               \n",
      "\n",
      "[62]\ttrain-error:0.09616\ttest-error:0.12887                               \n",
      "\n",
      "[63]\ttrain-error:0.09598\ttest-error:0.12887                               \n",
      "\n",
      "[64]\ttrain-error:0.09570\ttest-error:0.12930                               \n",
      "\n",
      "[65]\ttrain-error:0.09524\ttest-error:0.12954                               \n",
      "\n",
      "[66]\ttrain-error:0.09509\ttest-error:0.12967                               \n",
      "\n",
      "[67]\ttrain-error:0.09506\ttest-error:0.12979                               \n",
      "\n",
      "[68]\ttrain-error:0.09441\ttest-error:0.13016                               \n",
      "\n",
      "[69]\ttrain-error:0.09392\ttest-error:0.12985                               \n",
      "\n",
      "[70]\ttrain-error:0.09340\ttest-error:0.12967                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71]\ttrain-error:0.09291\ttest-error:0.12991                               \n",
      "\n",
      "[72]\ttrain-error:0.09269\ttest-error:0.12979                               \n",
      "\n",
      "[73]\ttrain-error:0.09263\ttest-error:0.13047                               \n",
      "\n",
      "[74]\ttrain-error:0.09235\ttest-error:0.13022                               \n",
      "\n",
      "[75]\ttrain-error:0.09208\ttest-error:0.13004                               \n",
      "\n",
      "[76]\ttrain-error:0.09174\ttest-error:0.13040                               \n",
      "\n",
      "[77]\ttrain-error:0.09168\ttest-error:0.13059                               \n",
      "\n",
      "[78]\ttrain-error:0.09109\ttest-error:0.13084                               \n",
      "\n",
      "[79]\ttrain-error:0.09115\ttest-error:0.13102                               \n",
      "\n",
      "[80]\ttrain-error:0.09073\ttest-error:0.13071                               \n",
      "\n",
      "[81]\ttrain-error:0.09060\ttest-error:0.13126                               \n",
      "\n",
      "[82]\ttrain-error:0.09014\ttest-error:0.13084                               \n",
      "\n",
      "[83]\ttrain-error:0.08990\ttest-error:0.13096                               \n",
      "\n",
      "[84]\ttrain-error:0.08925\ttest-error:0.13139                               \n",
      "\n",
      "[85]\ttrain-error:0.08891\ttest-error:0.13120                               \n",
      "\n",
      "[86]\ttrain-error:0.08885\ttest-error:0.13071                               \n",
      "\n",
      "[87]\ttrain-error:0.08861\ttest-error:0.13120                               \n",
      "\n",
      "[88]\ttrain-error:0.08821\ttest-error:0.13102                               \n",
      "\n",
      "[89]\ttrain-error:0.08747\ttest-error:0.13170                               \n",
      "\n",
      "[90]\ttrain-error:0.08793\ttest-error:0.13126                               \n",
      "\n",
      "[91]\ttrain-error:0.08775\ttest-error:0.13145                               \n",
      "\n",
      "[92]\ttrain-error:0.08738\ttest-error:0.13120                               \n",
      "\n",
      "[93]\ttrain-error:0.08741\ttest-error:0.13133                               \n",
      "\n",
      "[94]\ttrain-error:0.08686\ttest-error:0.13145                               \n",
      "\n",
      "[95]\ttrain-error:0.08679\ttest-error:0.13163                               \n",
      "\n",
      "[96]\ttrain-error:0.08643\ttest-error:0.13157                               \n",
      "\n",
      "[97]\ttrain-error:0.08596\ttest-error:0.13145                               \n",
      "\n",
      "[98]\ttrain-error:0.08557\ttest-error:0.13126                               \n",
      "\n",
      "[99]\ttrain-error:0.08514\ttest-error:0.13102                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.6668345669429515, 'colsample_bytree': 0.542997713523733, 'eta': 0.018208265535172807, 'eval_metric': ('error',), 'extra_dims': 5, 'gamma': 0, 'lambda': 0.0013269605581970095, 'max_depth': 6, 'min_child_weight': 0.084144020090956, 'objective': 'binary:logistic', 'subsample': 0.9325965705593794}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:40:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14257\ttest-error:0.14288                                \n",
      "\n",
      "[1]\ttrain-error:0.13968\ttest-error:0.13913                                \n",
      "\n",
      "[2]\ttrain-error:0.13814\ttest-error:0.13765                                \n",
      "\n",
      "[3]\ttrain-error:0.13953\ttest-error:0.13956                                \n",
      "\n",
      "[4]\ttrain-error:0.13947\ttest-error:0.13993                                \n",
      "\n",
      "[5]\ttrain-error:0.13916\ttest-error:0.13980                                \n",
      "\n",
      "[6]\ttrain-error:0.13916\ttest-error:0.13925                                \n",
      "\n",
      "[7]\ttrain-error:0.13873\ttest-error:0.13845                                \n",
      "\n",
      "[8]\ttrain-error:0.13885\ttest-error:0.13864                                \n",
      "\n",
      "[9]\ttrain-error:0.13919\ttest-error:0.13858                                \n",
      "\n",
      "[10]\ttrain-error:0.13848\ttest-error:0.13870                               \n",
      "\n",
      "[11]\ttrain-error:0.13842\ttest-error:0.13864                               \n",
      "\n",
      "[12]\ttrain-error:0.13799\ttest-error:0.13759                               \n",
      "\n",
      "[13]\ttrain-error:0.13756\ttest-error:0.13649                               \n",
      "\n",
      "[14]\ttrain-error:0.13710\ttest-error:0.13667                               \n",
      "\n",
      "[15]\ttrain-error:0.13710\ttest-error:0.13642                               \n",
      "\n",
      "[16]\ttrain-error:0.13673\ttest-error:0.13569                               \n",
      "\n",
      "[17]\ttrain-error:0.13655\ttest-error:0.13544                               \n",
      "\n",
      "[18]\ttrain-error:0.13627\ttest-error:0.13526                               \n",
      "\n",
      "[19]\ttrain-error:0.13618\ttest-error:0.13526                               \n",
      "\n",
      "[20]\ttrain-error:0.13618\ttest-error:0.13544                               \n",
      "\n",
      "[21]\ttrain-error:0.13587\ttest-error:0.13507                               \n",
      "\n",
      "[22]\ttrain-error:0.13563\ttest-error:0.13501                               \n",
      "\n",
      "[23]\ttrain-error:0.13569\ttest-error:0.13464                               \n",
      "\n",
      "[24]\ttrain-error:0.13538\ttest-error:0.13507                               \n",
      "\n",
      "[25]\ttrain-error:0.13501\ttest-error:0.13446                               \n",
      "\n",
      "[26]\ttrain-error:0.13474\ttest-error:0.13428                               \n",
      "\n",
      "[27]\ttrain-error:0.13437\ttest-error:0.13360                               \n",
      "\n",
      "[28]\ttrain-error:0.13434\ttest-error:0.13311                               \n",
      "\n",
      "[29]\ttrain-error:0.13391\ttest-error:0.13249                               \n",
      "\n",
      "[30]\ttrain-error:0.13378\ttest-error:0.13200                               \n",
      "\n",
      "[31]\ttrain-error:0.13348\ttest-error:0.13200                               \n",
      "\n",
      "[32]\ttrain-error:0.13305\ttest-error:0.13182                               \n",
      "\n",
      "[33]\ttrain-error:0.13231\ttest-error:0.13084                               \n",
      "\n",
      "[34]\ttrain-error:0.13167\ttest-error:0.13120                               \n",
      "\n",
      "[35]\ttrain-error:0.13148\ttest-error:0.13139                               \n",
      "\n",
      "[36]\ttrain-error:0.13081\ttest-error:0.13065                               \n",
      "\n",
      "[37]\ttrain-error:0.13050\ttest-error:0.13016                               \n",
      "\n",
      "[38]\ttrain-error:0.13025\ttest-error:0.13004                               \n",
      "\n",
      "[39]\ttrain-error:0.13028\ttest-error:0.12991                               \n",
      "\n",
      "[40]\ttrain-error:0.12979\ttest-error:0.12954                               \n",
      "\n",
      "[41]\ttrain-error:0.12958\ttest-error:0.12948                               \n",
      "\n",
      "[42]\ttrain-error:0.12951\ttest-error:0.12930                               \n",
      "\n",
      "[43]\ttrain-error:0.12936\ttest-error:0.12930                               \n",
      "\n",
      "[44]\ttrain-error:0.12899\ttest-error:0.12905                               \n",
      "\n",
      "[45]\ttrain-error:0.12881\ttest-error:0.12893                               \n",
      "\n",
      "[46]\ttrain-error:0.12813\ttest-error:0.12887                               \n",
      "\n",
      "[47]\ttrain-error:0.12807\ttest-error:0.12869                               \n",
      "\n",
      "[48]\ttrain-error:0.12764\ttest-error:0.12850                               \n",
      "\n",
      "[49]\ttrain-error:0.12749\ttest-error:0.12832                               \n",
      "\n",
      "[50]\ttrain-error:0.12703\ttest-error:0.12783                               \n",
      "\n",
      "[51]\ttrain-error:0.12693\ttest-error:0.12764                               \n",
      "\n",
      "[52]\ttrain-error:0.12666\ttest-error:0.12703                               \n",
      "\n",
      "[53]\ttrain-error:0.12647\ttest-error:0.12703                               \n",
      "\n",
      "[54]\ttrain-error:0.12589\ttest-error:0.12678                               \n",
      "\n",
      "[55]\ttrain-error:0.12552\ttest-error:0.12666                               \n",
      "\n",
      "[56]\ttrain-error:0.12515\ttest-error:0.12617                               \n",
      "\n",
      "[57]\ttrain-error:0.12503\ttest-error:0.12629                               \n",
      "\n",
      "[58]\ttrain-error:0.12460\ttest-error:0.12611                               \n",
      "\n",
      "[59]\ttrain-error:0.12445\ttest-error:0.12623                               \n",
      "\n",
      "[60]\ttrain-error:0.12429\ttest-error:0.12623                               \n",
      "\n",
      "[61]\ttrain-error:0.12371\ttest-error:0.12561                               \n",
      "\n",
      "[62]\ttrain-error:0.12371\ttest-error:0.12555                               \n",
      "\n",
      "[63]\ttrain-error:0.12337\ttest-error:0.12568                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64]\ttrain-error:0.12310\ttest-error:0.12537                               \n",
      "\n",
      "[65]\ttrain-error:0.12291\ttest-error:0.12537                               \n",
      "\n",
      "[66]\ttrain-error:0.12267\ttest-error:0.12500                               \n",
      "\n",
      "[67]\ttrain-error:0.12245\ttest-error:0.12482                               \n",
      "\n",
      "[68]\ttrain-error:0.12245\ttest-error:0.12488                               \n",
      "\n",
      "[69]\ttrain-error:0.12236\ttest-error:0.12457                               \n",
      "\n",
      "[70]\ttrain-error:0.12217\ttest-error:0.12488                               \n",
      "\n",
      "[71]\ttrain-error:0.12211\ttest-error:0.12494                               \n",
      "\n",
      "[72]\ttrain-error:0.12205\ttest-error:0.12457                               \n",
      "\n",
      "[73]\ttrain-error:0.12162\ttest-error:0.12432                               \n",
      "\n",
      "[74]\ttrain-error:0.12156\ttest-error:0.12432                               \n",
      "\n",
      "[75]\ttrain-error:0.12138\ttest-error:0.12445                               \n",
      "\n",
      "[76]\ttrain-error:0.12134\ttest-error:0.12463                               \n",
      "\n",
      "[77]\ttrain-error:0.12119\ttest-error:0.12451                               \n",
      "\n",
      "[78]\ttrain-error:0.12085\ttest-error:0.12475                               \n",
      "\n",
      "[79]\ttrain-error:0.12067\ttest-error:0.12469                               \n",
      "\n",
      "[80]\ttrain-error:0.12058\ttest-error:0.12475                               \n",
      "\n",
      "[81]\ttrain-error:0.12052\ttest-error:0.12488                               \n",
      "\n",
      "[82]\ttrain-error:0.12039\ttest-error:0.12500                               \n",
      "\n",
      "[83]\ttrain-error:0.12005\ttest-error:0.12463                               \n",
      "\n",
      "[84]\ttrain-error:0.12012\ttest-error:0.12469                               \n",
      "\n",
      "[85]\ttrain-error:0.11999\ttest-error:0.12488                               \n",
      "\n",
      "[86]\ttrain-error:0.11972\ttest-error:0.12482                               \n",
      "\n",
      "[87]\ttrain-error:0.11972\ttest-error:0.12469                               \n",
      "\n",
      "[88]\ttrain-error:0.11926\ttest-error:0.12482                               \n",
      "\n",
      "[89]\ttrain-error:0.11913\ttest-error:0.12469                               \n",
      "\n",
      "[90]\ttrain-error:0.11886\ttest-error:0.12475                               \n",
      "\n",
      "[91]\ttrain-error:0.11883\ttest-error:0.12469                               \n",
      "\n",
      "[92]\ttrain-error:0.11873\ttest-error:0.12475                               \n",
      "\n",
      "[93]\ttrain-error:0.11883\ttest-error:0.12482                               \n",
      "\n",
      "[94]\ttrain-error:0.11861\ttest-error:0.12482                               \n",
      "\n",
      "[95]\ttrain-error:0.11855\ttest-error:0.12469                               \n",
      "\n",
      "[96]\ttrain-error:0.11855\ttest-error:0.12457                               \n",
      "\n",
      "[97]\ttrain-error:0.11833\ttest-error:0.12488                               \n",
      "\n",
      "[98]\ttrain-error:0.11837\ttest-error:0.12488                               \n",
      "\n",
      "[99]\ttrain-error:0.11837\ttest-error:0.12488                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.8233426742100154, 'colsample_bytree': 0.9163593497382785, 'eta': 0.3447785848282787, 'eval_metric': ('error',), 'extra_dims': 3, 'gamma': 0, 'lambda': 0, 'max_depth': 2, 'min_child_weight': 3.221412134880356, 'objective': 'binary:logistic', 'subsample': 0.8196075742667389}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:41:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.16923\ttest-error:0.16800                                \n",
      "\n",
      "[1]\ttrain-error:0.15273\ttest-error:0.15135                                \n",
      "\n",
      "[2]\ttrain-error:0.14966\ttest-error:0.14883                                \n",
      "\n",
      "[3]\ttrain-error:0.14601\ttest-error:0.14558                                \n",
      "\n",
      "[4]\ttrain-error:0.14546\ttest-error:0.14447                                \n",
      "\n",
      "[5]\ttrain-error:0.14515\ttest-error:0.14398                                \n",
      "\n",
      "[6]\ttrain-error:0.14300\ttest-error:0.14275                                \n",
      "\n",
      "[7]\ttrain-error:0.14072\ttest-error:0.14091                                \n",
      "\n",
      "[8]\ttrain-error:0.13990\ttest-error:0.13999                                \n",
      "\n",
      "[9]\ttrain-error:0.13919\ttest-error:0.13888                                \n",
      "\n",
      "[10]\ttrain-error:0.13753\ttest-error:0.13741                               \n",
      "\n",
      "[11]\ttrain-error:0.13695\ttest-error:0.13710                               \n",
      "\n",
      "[12]\ttrain-error:0.13578\ttest-error:0.13593                               \n",
      "\n",
      "[13]\ttrain-error:0.13566\ttest-error:0.13587                               \n",
      "\n",
      "[14]\ttrain-error:0.13535\ttest-error:0.13563                               \n",
      "\n",
      "[15]\ttrain-error:0.13464\ttest-error:0.13489                               \n",
      "\n",
      "[16]\ttrain-error:0.13400\ttest-error:0.13403                               \n",
      "\n",
      "[17]\ttrain-error:0.13332\ttest-error:0.13354                               \n",
      "\n",
      "[18]\ttrain-error:0.13259\ttest-error:0.13329                               \n",
      "\n",
      "[19]\ttrain-error:0.13145\ttest-error:0.13268                               \n",
      "\n",
      "[20]\ttrain-error:0.13081\ttest-error:0.13151                               \n",
      "\n",
      "[21]\ttrain-error:0.13068\ttest-error:0.13084                               \n",
      "\n",
      "[22]\ttrain-error:0.13037\ttest-error:0.13084                               \n",
      "\n",
      "[23]\ttrain-error:0.12998\ttest-error:0.13090                               \n",
      "\n",
      "[24]\ttrain-error:0.12973\ttest-error:0.13096                               \n",
      "\n",
      "[25]\ttrain-error:0.12954\ttest-error:0.13047                               \n",
      "\n",
      "[26]\ttrain-error:0.12924\ttest-error:0.13047                               \n",
      "\n",
      "[27]\ttrain-error:0.12881\ttest-error:0.13065                               \n",
      "\n",
      "[28]\ttrain-error:0.12887\ttest-error:0.13034                               \n",
      "\n",
      "[29]\ttrain-error:0.12896\ttest-error:0.13059                               \n",
      "\n",
      "[30]\ttrain-error:0.12847\ttest-error:0.13034                               \n",
      "\n",
      "[31]\ttrain-error:0.12801\ttest-error:0.13010                               \n",
      "\n",
      "[32]\ttrain-error:0.12779\ttest-error:0.12991                               \n",
      "\n",
      "[33]\ttrain-error:0.12761\ttest-error:0.13004                               \n",
      "\n",
      "[34]\ttrain-error:0.12672\ttest-error:0.13059                               \n",
      "\n",
      "[35]\ttrain-error:0.12669\ttest-error:0.13022                               \n",
      "\n",
      "[36]\ttrain-error:0.12611\ttest-error:0.12948                               \n",
      "\n",
      "[37]\ttrain-error:0.12568\ttest-error:0.12862                               \n",
      "\n",
      "[38]\ttrain-error:0.12546\ttest-error:0.12936                               \n",
      "\n",
      "[39]\ttrain-error:0.12509\ttest-error:0.12887                               \n",
      "\n",
      "[40]\ttrain-error:0.12549\ttest-error:0.12826                               \n",
      "\n",
      "[41]\ttrain-error:0.12512\ttest-error:0.12826                               \n",
      "\n",
      "[42]\ttrain-error:0.12506\ttest-error:0.12813                               \n",
      "\n",
      "[43]\ttrain-error:0.12463\ttest-error:0.12789                               \n",
      "\n",
      "[44]\ttrain-error:0.12485\ttest-error:0.12813                               \n",
      "\n",
      "[45]\ttrain-error:0.12454\ttest-error:0.12826                               \n",
      "\n",
      "[46]\ttrain-error:0.12448\ttest-error:0.12801                               \n",
      "\n",
      "[47]\ttrain-error:0.12417\ttest-error:0.12746                               \n",
      "\n",
      "[48]\ttrain-error:0.12396\ttest-error:0.12623                               \n",
      "\n",
      "[49]\ttrain-error:0.12386\ttest-error:0.12758                               \n",
      "\n",
      "[50]\ttrain-error:0.12349\ttest-error:0.12776                               \n",
      "\n",
      "[51]\ttrain-error:0.12383\ttest-error:0.12740                               \n",
      "\n",
      "[52]\ttrain-error:0.12343\ttest-error:0.12684                               \n",
      "\n",
      "[53]\ttrain-error:0.12328\ttest-error:0.12740                               \n",
      "\n",
      "[54]\ttrain-error:0.12267\ttest-error:0.12666                               \n",
      "\n",
      "[55]\ttrain-error:0.12267\ttest-error:0.12635                               \n",
      "\n",
      "[56]\ttrain-error:0.12236\ttest-error:0.12684                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57]\ttrain-error:0.12251\ttest-error:0.12623                               \n",
      "\n",
      "[58]\ttrain-error:0.12208\ttest-error:0.12727                               \n",
      "\n",
      "[59]\ttrain-error:0.12251\ttest-error:0.12789                               \n",
      "\n",
      "[60]\ttrain-error:0.12254\ttest-error:0.12783                               \n",
      "\n",
      "[61]\ttrain-error:0.12233\ttest-error:0.12758                               \n",
      "\n",
      "[62]\ttrain-error:0.12233\ttest-error:0.12770                               \n",
      "\n",
      "[63]\ttrain-error:0.12205\ttest-error:0.12721                               \n",
      "\n",
      "[64]\ttrain-error:0.12184\ttest-error:0.12715                               \n",
      "\n",
      "[65]\ttrain-error:0.12190\ttest-error:0.12721                               \n",
      "\n",
      "[66]\ttrain-error:0.12165\ttest-error:0.12684                               \n",
      "\n",
      "[67]\ttrain-error:0.12153\ttest-error:0.12678                               \n",
      "\n",
      "[68]\ttrain-error:0.12134\ttest-error:0.12660                               \n",
      "\n",
      "[69]\ttrain-error:0.12073\ttest-error:0.12629                               \n",
      "\n",
      "[70]\ttrain-error:0.12058\ttest-error:0.12641                               \n",
      "\n",
      "[71]\ttrain-error:0.12089\ttest-error:0.12690                               \n",
      "\n",
      "[72]\ttrain-error:0.12073\ttest-error:0.12635                               \n",
      "\n",
      "[73]\ttrain-error:0.12089\ttest-error:0.12647                               \n",
      "\n",
      "[74]\ttrain-error:0.12070\ttest-error:0.12660                               \n",
      "\n",
      "[75]\ttrain-error:0.12021\ttest-error:0.12666                               \n",
      "\n",
      "[76]\ttrain-error:0.12018\ttest-error:0.12647                               \n",
      "\n",
      "[77]\ttrain-error:0.12012\ttest-error:0.12647                               \n",
      "\n",
      "[78]\ttrain-error:0.11960\ttest-error:0.12629                               \n",
      "\n",
      "[79]\ttrain-error:0.11960\ttest-error:0.12684                               \n",
      "\n",
      "[80]\ttrain-error:0.11944\ttest-error:0.12641                               \n",
      "\n",
      "[81]\ttrain-error:0.11932\ttest-error:0.12598                               \n",
      "\n",
      "[82]\ttrain-error:0.11953\ttest-error:0.12531                               \n",
      "\n",
      "[83]\ttrain-error:0.11969\ttest-error:0.12568                               \n",
      "\n",
      "[84]\ttrain-error:0.11919\ttest-error:0.12543                               \n",
      "\n",
      "[85]\ttrain-error:0.11910\ttest-error:0.12555                               \n",
      "\n",
      "[86]\ttrain-error:0.11904\ttest-error:0.12580                               \n",
      "\n",
      "[87]\ttrain-error:0.11876\ttest-error:0.12604                               \n",
      "\n",
      "[88]\ttrain-error:0.11901\ttest-error:0.12592                               \n",
      "\n",
      "[89]\ttrain-error:0.11929\ttest-error:0.12549                               \n",
      "\n",
      "[90]\ttrain-error:0.11843\ttest-error:0.12568                               \n",
      "\n",
      "[91]\ttrain-error:0.11883\ttest-error:0.12561                               \n",
      "\n",
      "[92]\ttrain-error:0.11886\ttest-error:0.12604                               \n",
      "\n",
      "[93]\ttrain-error:0.11855\ttest-error:0.12574                               \n",
      "\n",
      "[94]\ttrain-error:0.11827\ttest-error:0.12586                               \n",
      "\n",
      "[95]\ttrain-error:0.11840\ttest-error:0.12641                               \n",
      "\n",
      "[96]\ttrain-error:0.11837\ttest-error:0.12598                               \n",
      "\n",
      "[97]\ttrain-error:0.11821\ttest-error:0.12617                               \n",
      "\n",
      "[98]\ttrain-error:0.11800\ttest-error:0.12623                               \n",
      "\n",
      "[99]\ttrain-error:0.11837\ttest-error:0.12549                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.6924080109031999, 'colsample_bytree': 0.6057614828184016, 'eta': 0.05493467594255584, 'eval_metric': ('error',), 'extra_dims': 9, 'gamma': 0, 'lambda': 0.7799446855652032, 'max_depth': 9, 'min_child_weight': 1.0962141417163118, 'objective': 'binary:logistic', 'subsample': 0.9888305915729843}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:42:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13882\ttest-error:0.14079                                \n",
      "\n",
      "[1]\ttrain-error:0.13440\ttest-error:0.13544                                \n",
      "\n",
      "[2]\ttrain-error:0.13228\ttest-error:0.13452                                \n",
      "\n",
      "[3]\ttrain-error:0.12964\ttest-error:0.13397                                \n",
      "\n",
      "[4]\ttrain-error:0.12651\ttest-error:0.13102                                \n",
      "\n",
      "[5]\ttrain-error:0.12429\ttest-error:0.13040                                \n",
      "\n",
      "[6]\ttrain-error:0.12362\ttest-error:0.12881                                \n",
      "\n",
      "[7]\ttrain-error:0.12254\ttest-error:0.12850                                \n",
      "\n",
      "[8]\ttrain-error:0.12098\ttest-error:0.12690                                \n",
      "\n",
      "[9]\ttrain-error:0.11932\ttest-error:0.12635                                \n",
      "\n",
      "[10]\ttrain-error:0.11803\ttest-error:0.12684                               \n",
      "\n",
      "[11]\ttrain-error:0.11695\ttest-error:0.12623                               \n",
      "\n",
      "[12]\ttrain-error:0.11637\ttest-error:0.12568                               \n",
      "\n",
      "[13]\ttrain-error:0.11511\ttest-error:0.12635                               \n",
      "\n",
      "[14]\ttrain-error:0.11462\ttest-error:0.12568                               \n",
      "\n",
      "[15]\ttrain-error:0.11391\ttest-error:0.12537                               \n",
      "\n",
      "[16]\ttrain-error:0.11345\ttest-error:0.12580                               \n",
      "\n",
      "[17]\ttrain-error:0.11271\ttest-error:0.12555                               \n",
      "\n",
      "[18]\ttrain-error:0.11210\ttest-error:0.12561                               \n",
      "\n",
      "[19]\ttrain-error:0.11182\ttest-error:0.12549                               \n",
      "\n",
      "[20]\ttrain-error:0.11093\ttest-error:0.12580                               \n",
      "\n",
      "[21]\ttrain-error:0.11087\ttest-error:0.12531                               \n",
      "\n",
      "[22]\ttrain-error:0.11020\ttest-error:0.12555                               \n",
      "\n",
      "[23]\ttrain-error:0.10995\ttest-error:0.12488                               \n",
      "\n",
      "[24]\ttrain-error:0.10949\ttest-error:0.12568                               \n",
      "\n",
      "[25]\ttrain-error:0.10909\ttest-error:0.12555                               \n",
      "\n",
      "[26]\ttrain-error:0.10851\ttest-error:0.12586                               \n",
      "\n",
      "[27]\ttrain-error:0.10829\ttest-error:0.12506                               \n",
      "\n",
      "[28]\ttrain-error:0.10798\ttest-error:0.12500                               \n",
      "\n",
      "[29]\ttrain-error:0.10765\ttest-error:0.12518                               \n",
      "\n",
      "[30]\ttrain-error:0.10743\ttest-error:0.12525                               \n",
      "\n",
      "[31]\ttrain-error:0.10712\ttest-error:0.12549                               \n",
      "\n",
      "[32]\ttrain-error:0.10676\ttest-error:0.12518                               \n",
      "\n",
      "[33]\ttrain-error:0.10645\ttest-error:0.12518                               \n",
      "\n",
      "[34]\ttrain-error:0.10580\ttest-error:0.12531                               \n",
      "\n",
      "[35]\ttrain-error:0.10596\ttest-error:0.12561                               \n",
      "\n",
      "[36]\ttrain-error:0.10568\ttest-error:0.12549                               \n",
      "\n",
      "[37]\ttrain-error:0.10494\ttest-error:0.12537                               \n",
      "\n",
      "[38]\ttrain-error:0.10470\ttest-error:0.12549                               \n",
      "\n",
      "[39]\ttrain-error:0.10427\ttest-error:0.12580                               \n",
      "\n",
      "[40]\ttrain-error:0.10393\ttest-error:0.12574                               \n",
      "\n",
      "[41]\ttrain-error:0.10381\ttest-error:0.12561                               \n",
      "\n",
      "[42]\ttrain-error:0.10353\ttest-error:0.12555                               \n",
      "\n",
      "[43]\ttrain-error:0.10273\ttest-error:0.12568                               \n",
      "\n",
      "[44]\ttrain-error:0.10276\ttest-error:0.12568                               \n",
      "\n",
      "[45]\ttrain-error:0.10267\ttest-error:0.12568                               \n",
      "\n",
      "[46]\ttrain-error:0.10215\ttest-error:0.12580                               \n",
      "\n",
      "[47]\ttrain-error:0.10190\ttest-error:0.12654                               \n",
      "\n",
      "[48]\ttrain-error:0.10150\ttest-error:0.12635                               \n",
      "\n",
      "[49]\ttrain-error:0.10098\ttest-error:0.12623                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain-error:0.10101\ttest-error:0.12611                               \n",
      "\n",
      "[51]\ttrain-error:0.10074\ttest-error:0.12629                               \n",
      "\n",
      "[52]\ttrain-error:0.10031\ttest-error:0.12623                               \n",
      "\n",
      "[53]\ttrain-error:0.10006\ttest-error:0.12604                               \n",
      "\n",
      "[54]\ttrain-error:0.09975\ttest-error:0.12598                               \n",
      "\n",
      "[55]\ttrain-error:0.09966\ttest-error:0.12617                               \n",
      "\n",
      "[56]\ttrain-error:0.09911\ttest-error:0.12617                               \n",
      "\n",
      "[57]\ttrain-error:0.09896\ttest-error:0.12598                               \n",
      "\n",
      "[58]\ttrain-error:0.09880\ttest-error:0.12629                               \n",
      "\n",
      "[59]\ttrain-error:0.09822\ttest-error:0.12629                               \n",
      "\n",
      "[60]\ttrain-error:0.09794\ttest-error:0.12654                               \n",
      "\n",
      "[61]\ttrain-error:0.09754\ttest-error:0.12672                               \n",
      "\n",
      "[62]\ttrain-error:0.09736\ttest-error:0.12635                               \n",
      "\n",
      "[63]\ttrain-error:0.09745\ttest-error:0.12666                               \n",
      "\n",
      "[64]\ttrain-error:0.09724\ttest-error:0.12647                               \n",
      "\n",
      "[65]\ttrain-error:0.09681\ttest-error:0.12684                               \n",
      "\n",
      "[66]\ttrain-error:0.09631\ttest-error:0.12678                               \n",
      "\n",
      "[67]\ttrain-error:0.09610\ttest-error:0.12709                               \n",
      "\n",
      "[68]\ttrain-error:0.09601\ttest-error:0.12709                               \n",
      "\n",
      "[69]\ttrain-error:0.09567\ttest-error:0.12684                               \n",
      "\n",
      "[70]\ttrain-error:0.09539\ttest-error:0.12672                               \n",
      "\n",
      "[71]\ttrain-error:0.09499\ttest-error:0.12697                               \n",
      "\n",
      "[72]\ttrain-error:0.09453\ttest-error:0.12684                               \n",
      "\n",
      "[73]\ttrain-error:0.09386\ttest-error:0.12660                               \n",
      "\n",
      "[74]\ttrain-error:0.09395\ttest-error:0.12684                               \n",
      "\n",
      "[75]\ttrain-error:0.09364\ttest-error:0.12721                               \n",
      "\n",
      "[76]\ttrain-error:0.09340\ttest-error:0.12721                               \n",
      "\n",
      "[77]\ttrain-error:0.09309\ttest-error:0.12752                               \n",
      "\n",
      "[78]\ttrain-error:0.09232\ttest-error:0.12727                               \n",
      "\n",
      "[79]\ttrain-error:0.09226\ttest-error:0.12727                               \n",
      "\n",
      "[80]\ttrain-error:0.09214\ttest-error:0.12727                               \n",
      "\n",
      "[81]\ttrain-error:0.09201\ttest-error:0.12746                               \n",
      "\n",
      "[82]\ttrain-error:0.09168\ttest-error:0.12721                               \n",
      "\n",
      "[83]\ttrain-error:0.09119\ttest-error:0.12733                               \n",
      "\n",
      "[84]\ttrain-error:0.09100\ttest-error:0.12733                               \n",
      "\n",
      "[85]\ttrain-error:0.09085\ttest-error:0.12697                               \n",
      "\n",
      "[86]\ttrain-error:0.09091\ttest-error:0.12690                               \n",
      "\n",
      "[87]\ttrain-error:0.09091\ttest-error:0.12684                               \n",
      "\n",
      "[88]\ttrain-error:0.09069\ttest-error:0.12684                               \n",
      "\n",
      "[89]\ttrain-error:0.09042\ttest-error:0.12752                               \n",
      "\n",
      "[90]\ttrain-error:0.09033\ttest-error:0.12758                               \n",
      "\n",
      "[91]\ttrain-error:0.09011\ttest-error:0.12752                               \n",
      "\n",
      "[92]\ttrain-error:0.09014\ttest-error:0.12746                               \n",
      "\n",
      "[93]\ttrain-error:0.08953\ttest-error:0.12758                               \n",
      "\n",
      "[94]\ttrain-error:0.08913\ttest-error:0.12789                               \n",
      "\n",
      "[95]\ttrain-error:0.08901\ttest-error:0.12770                               \n",
      "\n",
      "[96]\ttrain-error:0.08867\ttest-error:0.12764                               \n",
      "\n",
      "[97]\ttrain-error:0.08830\ttest-error:0.12783                               \n",
      "\n",
      "[98]\ttrain-error:0.08793\ttest-error:0.12752                               \n",
      "\n",
      "[99]\ttrain-error:0.08747\ttest-error:0.12746                               \n",
      "\n",
      "{'alpha': 7.282339390560057, 'btype': 'Rn', 'colsample_bylevel': 0.7587848556124601, 'colsample_bytree': 0.5728815618108722, 'eta': 0.04374311487838936, 'eval_metric': ('error',), 'extra_dims': 13, 'gamma': 0, 'lambda': 0.025432761534935774, 'max_depth': 3, 'min_child_weight': 0.2250606435535761, 'objective': 'binary:logistic', 'subsample': 0.6598478010649739}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:43:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.17171\ttest-error:0.16917                                \n",
      "\n",
      "[1]\ttrain-error:0.16063\ttest-error:0.15946                                \n",
      "\n",
      "[2]\ttrain-error:0.15399\ttest-error:0.15197                                \n",
      "\n",
      "[3]\ttrain-error:0.15138\ttest-error:0.14951                                \n",
      "\n",
      "[4]\ttrain-error:0.14902\ttest-error:0.14785                                \n",
      "\n",
      "[5]\ttrain-error:0.14576\ttest-error:0.14423                                \n",
      "\n",
      "[6]\ttrain-error:0.14413\ttest-error:0.14269                                \n",
      "\n",
      "[7]\ttrain-error:0.14330\ttest-error:0.14208                                \n",
      "\n",
      "[8]\ttrain-error:0.14358\ttest-error:0.14158                                \n",
      "\n",
      "[9]\ttrain-error:0.14306\ttest-error:0.14030                                \n",
      "\n",
      "[10]\ttrain-error:0.14254\ttest-error:0.14036                               \n",
      "\n",
      "[11]\ttrain-error:0.14171\ttest-error:0.13950                               \n",
      "\n",
      "[12]\ttrain-error:0.14128\ttest-error:0.13851                               \n",
      "\n",
      "[13]\ttrain-error:0.14112\ttest-error:0.13790                               \n",
      "\n",
      "[14]\ttrain-error:0.14097\ttest-error:0.13679                               \n",
      "\n",
      "[15]\ttrain-error:0.14076\ttest-error:0.13630                               \n",
      "\n",
      "[16]\ttrain-error:0.14039\ttest-error:0.13612                               \n",
      "\n",
      "[17]\ttrain-error:0.13959\ttest-error:0.13563                               \n",
      "\n",
      "[18]\ttrain-error:0.13934\ttest-error:0.13538                               \n",
      "\n",
      "[19]\ttrain-error:0.13913\ttest-error:0.13556                               \n",
      "\n",
      "[20]\ttrain-error:0.13821\ttest-error:0.13477                               \n",
      "\n",
      "[21]\ttrain-error:0.13765\ttest-error:0.13501                               \n",
      "\n",
      "[22]\ttrain-error:0.13728\ttest-error:0.13415                               \n",
      "\n",
      "[23]\ttrain-error:0.13686\ttest-error:0.13415                               \n",
      "\n",
      "[24]\ttrain-error:0.13639\ttest-error:0.13403                               \n",
      "\n",
      "[25]\ttrain-error:0.13618\ttest-error:0.13335                               \n",
      "\n",
      "[26]\ttrain-error:0.13600\ttest-error:0.13298                               \n",
      "\n",
      "[27]\ttrain-error:0.13566\ttest-error:0.13305                               \n",
      "\n",
      "[28]\ttrain-error:0.13538\ttest-error:0.13280                               \n",
      "\n",
      "[29]\ttrain-error:0.13553\ttest-error:0.13274                               \n",
      "\n",
      "[30]\ttrain-error:0.13523\ttest-error:0.13305                               \n",
      "\n",
      "[31]\ttrain-error:0.13477\ttest-error:0.13305                               \n",
      "\n",
      "[32]\ttrain-error:0.13440\ttest-error:0.13280                               \n",
      "\n",
      "[33]\ttrain-error:0.13434\ttest-error:0.13286                               \n",
      "\n",
      "[34]\ttrain-error:0.13348\ttest-error:0.13268                               \n",
      "\n",
      "[35]\ttrain-error:0.13314\ttest-error:0.13286                               \n",
      "\n",
      "[36]\ttrain-error:0.13283\ttest-error:0.13256                               \n",
      "\n",
      "[37]\ttrain-error:0.13240\ttest-error:0.13280                               \n",
      "\n",
      "[38]\ttrain-error:0.13212\ttest-error:0.13268                               \n",
      "\n",
      "[39]\ttrain-error:0.13228\ttest-error:0.13243                               \n",
      "\n",
      "[40]\ttrain-error:0.13209\ttest-error:0.13225                               \n",
      "\n",
      "[41]\ttrain-error:0.13191\ttest-error:0.13219                               \n",
      "\n",
      "[42]\ttrain-error:0.13160\ttest-error:0.13206                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43]\ttrain-error:0.13154\ttest-error:0.13206                               \n",
      "\n",
      "[44]\ttrain-error:0.13123\ttest-error:0.13231                               \n",
      "\n",
      "[45]\ttrain-error:0.13108\ttest-error:0.13200                               \n",
      "\n",
      "[46]\ttrain-error:0.13105\ttest-error:0.13170                               \n",
      "\n",
      "[47]\ttrain-error:0.13114\ttest-error:0.13182                               \n",
      "\n",
      "[48]\ttrain-error:0.13108\ttest-error:0.13170                               \n",
      "\n",
      "[49]\ttrain-error:0.13108\ttest-error:0.13120                               \n",
      "\n",
      "[50]\ttrain-error:0.13090\ttest-error:0.13114                               \n",
      "\n",
      "[51]\ttrain-error:0.13068\ttest-error:0.13120                               \n",
      "\n",
      "[52]\ttrain-error:0.13037\ttest-error:0.13126                               \n",
      "\n",
      "[53]\ttrain-error:0.13013\ttest-error:0.13126                               \n",
      "\n",
      "[54]\ttrain-error:0.12973\ttest-error:0.13102                               \n",
      "\n",
      "[55]\ttrain-error:0.12982\ttest-error:0.13096                               \n",
      "\n",
      "[56]\ttrain-error:0.12995\ttest-error:0.13065                               \n",
      "\n",
      "[57]\ttrain-error:0.12988\ttest-error:0.13090                               \n",
      "\n",
      "[58]\ttrain-error:0.12985\ttest-error:0.13077                               \n",
      "\n",
      "[59]\ttrain-error:0.12961\ttest-error:0.13071                               \n",
      "\n",
      "[60]\ttrain-error:0.12961\ttest-error:0.13077                               \n",
      "\n",
      "[61]\ttrain-error:0.12951\ttest-error:0.13059                               \n",
      "\n",
      "[62]\ttrain-error:0.12939\ttest-error:0.13059                               \n",
      "\n",
      "[63]\ttrain-error:0.12958\ttest-error:0.13065                               \n",
      "\n",
      "[64]\ttrain-error:0.12942\ttest-error:0.13047                               \n",
      "\n",
      "[65]\ttrain-error:0.12951\ttest-error:0.13028                               \n",
      "\n",
      "[66]\ttrain-error:0.12933\ttest-error:0.13034                               \n",
      "\n",
      "[67]\ttrain-error:0.12915\ttest-error:0.13022                               \n",
      "\n",
      "[68]\ttrain-error:0.12899\ttest-error:0.13010                               \n",
      "\n",
      "[69]\ttrain-error:0.12878\ttest-error:0.13028                               \n",
      "\n",
      "[70]\ttrain-error:0.12884\ttest-error:0.13022                               \n",
      "\n",
      "[71]\ttrain-error:0.12872\ttest-error:0.12973                               \n",
      "\n",
      "[72]\ttrain-error:0.12878\ttest-error:0.12998                               \n",
      "\n",
      "[73]\ttrain-error:0.12847\ttest-error:0.12967                               \n",
      "\n",
      "[74]\ttrain-error:0.12838\ttest-error:0.12973                               \n",
      "\n",
      "[75]\ttrain-error:0.12853\ttest-error:0.12961                               \n",
      "\n",
      "[76]\ttrain-error:0.12838\ttest-error:0.12954                               \n",
      "\n",
      "[77]\ttrain-error:0.12807\ttest-error:0.12942                               \n",
      "\n",
      "[78]\ttrain-error:0.12798\ttest-error:0.12961                               \n",
      "\n",
      "[79]\ttrain-error:0.12801\ttest-error:0.12918                               \n",
      "\n",
      "[80]\ttrain-error:0.12804\ttest-error:0.12948                               \n",
      "\n",
      "[81]\ttrain-error:0.12792\ttest-error:0.12912                               \n",
      "\n",
      "[82]\ttrain-error:0.12770\ttest-error:0.12936                               \n",
      "\n",
      "[83]\ttrain-error:0.12755\ttest-error:0.12936                               \n",
      "\n",
      "[84]\ttrain-error:0.12776\ttest-error:0.12905                               \n",
      "\n",
      "[85]\ttrain-error:0.12749\ttest-error:0.12899                               \n",
      "\n",
      "[86]\ttrain-error:0.12746\ttest-error:0.12924                               \n",
      "\n",
      "[87]\ttrain-error:0.12743\ttest-error:0.12899                               \n",
      "\n",
      "[88]\ttrain-error:0.12709\ttest-error:0.12924                               \n",
      "\n",
      "[89]\ttrain-error:0.12721\ttest-error:0.12942                               \n",
      "\n",
      "[90]\ttrain-error:0.12712\ttest-error:0.12942                               \n",
      "\n",
      "[91]\ttrain-error:0.12706\ttest-error:0.12924                               \n",
      "\n",
      "[92]\ttrain-error:0.12690\ttest-error:0.12918                               \n",
      "\n",
      "[93]\ttrain-error:0.12724\ttest-error:0.12942                               \n",
      "\n",
      "[94]\ttrain-error:0.12721\ttest-error:0.12954                               \n",
      "\n",
      "[95]\ttrain-error:0.12693\ttest-error:0.12930                               \n",
      "\n",
      "[96]\ttrain-error:0.12706\ttest-error:0.12930                               \n",
      "\n",
      "[97]\ttrain-error:0.12718\ttest-error:0.12942                               \n",
      "\n",
      "[98]\ttrain-error:0.12733\ttest-error:0.12918                               \n",
      "\n",
      "[99]\ttrain-error:0.12727\ttest-error:0.12930                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.7435547773411553, 'colsample_bytree': 0.5570410143836337, 'eta': 0.20327508214504972, 'eval_metric': ('error',), 'extra_dims': 12, 'gamma': 0, 'lambda': 0.0034039467265548112, 'max_depth': 5, 'min_child_weight': 0.020302571518892403, 'objective': 'binary:logistic', 'subsample': 0.9637809821759816}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:45:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14247\ttest-error:0.14447                                \n",
      "\n",
      "[1]\ttrain-error:0.33747\ttest-error:0.34459                                \n",
      "\n",
      "[2]\ttrain-error:0.18851\ttest-error:0.18845                                \n",
      "\n",
      "[3]\ttrain-error:0.75894\ttest-error:0.76351                                \n",
      "\n",
      "[4]\ttrain-error:0.24085\ttest-error:0.23630                                \n",
      "\n",
      "[5]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[6]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[7]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[8]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[9]\ttrain-error:0.75918\ttest-error:0.76376                                \n",
      "\n",
      "[10]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[11]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[12]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[13]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[14]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[15]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[16]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[17]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[18]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[19]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[20]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[21]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[22]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[23]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[24]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[25]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[26]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[27]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[28]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[29]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[30]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[31]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[32]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[33]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[34]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[35]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[37]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[38]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[39]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[40]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[41]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[42]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[43]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[44]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[45]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[46]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[47]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[48]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[49]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[50]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[51]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[52]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[53]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[54]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[55]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[56]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[57]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[58]\ttrain-error:0.41308\ttest-error:0.41099                               \n",
      "\n",
      "[59]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[60]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[61]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[62]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[63]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[64]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[65]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[66]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[67]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[68]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[69]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[70]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[71]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[72]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[73]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[74]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[75]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[76]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[77]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[78]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[79]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[80]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[81]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[82]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[83]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[84]\ttrain-error:0.75654\ttest-error:0.76204                               \n",
      "\n",
      "[85]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[86]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[87]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[88]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[89]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[90]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[91]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[92]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[93]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[94]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[95]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[96]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[97]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[98]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[99]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.7250429577357648, 'colsample_bytree': 0.5103271017541984, 'eta': 0.08799621395957356, 'eval_metric': ('error',), 'extra_dims': 1, 'gamma': 0, 'lambda': 0.00025382076869045583, 'max_depth': 8, 'min_child_weight': 10.348799058881301, 'objective': 'binary:logistic', 'subsample': 0.8711731615686956}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:46:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.16348\ttest-error:0.16229                                \n",
      "\n",
      "[1]\ttrain-error:0.14426\ttest-error:0.14570                                \n",
      "\n",
      "[2]\ttrain-error:0.14217\ttest-error:0.14226                                \n",
      "\n",
      "[3]\ttrain-error:0.14223\ttest-error:0.14171                                \n",
      "\n",
      "[4]\ttrain-error:0.13910\ttest-error:0.13950                                \n",
      "\n",
      "[5]\ttrain-error:0.13765\ttest-error:0.13753                                \n",
      "\n",
      "[6]\ttrain-error:0.13725\ttest-error:0.13796                                \n",
      "\n",
      "[7]\ttrain-error:0.13704\ttest-error:0.13606                                \n",
      "\n",
      "[8]\ttrain-error:0.13655\ttest-error:0.13587                                \n",
      "\n",
      "[9]\ttrain-error:0.13621\ttest-error:0.13563                                \n",
      "\n",
      "[10]\ttrain-error:0.13621\ttest-error:0.13520                               \n",
      "\n",
      "[11]\ttrain-error:0.13535\ttest-error:0.13612                               \n",
      "\n",
      "[12]\ttrain-error:0.13474\ttest-error:0.13563                               \n",
      "\n",
      "[13]\ttrain-error:0.13480\ttest-error:0.13514                               \n",
      "\n",
      "[14]\ttrain-error:0.13458\ttest-error:0.13446                               \n",
      "\n",
      "[15]\ttrain-error:0.13372\ttest-error:0.13421                               \n",
      "\n",
      "[16]\ttrain-error:0.13360\ttest-error:0.13342                               \n",
      "\n",
      "[17]\ttrain-error:0.13320\ttest-error:0.13243                               \n",
      "\n",
      "[18]\ttrain-error:0.13298\ttest-error:0.13243                               \n",
      "\n",
      "[19]\ttrain-error:0.13209\ttest-error:0.13219                               \n",
      "\n",
      "[20]\ttrain-error:0.13185\ttest-error:0.13145                               \n",
      "\n",
      "[21]\ttrain-error:0.13068\ttest-error:0.13102                               \n",
      "\n",
      "[22]\ttrain-error:0.13001\ttest-error:0.13071                               \n",
      "\n",
      "[23]\ttrain-error:0.12988\ttest-error:0.12991                               \n",
      "\n",
      "[24]\ttrain-error:0.12909\ttest-error:0.12893                               \n",
      "\n",
      "[25]\ttrain-error:0.12890\ttest-error:0.12918                               \n",
      "\n",
      "[26]\ttrain-error:0.12865\ttest-error:0.12954                               \n",
      "\n",
      "[27]\ttrain-error:0.12798\ttest-error:0.12930                               \n",
      "\n",
      "[28]\ttrain-error:0.12730\ttest-error:0.12942                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29]\ttrain-error:0.12700\ttest-error:0.12905                               \n",
      "\n",
      "[30]\ttrain-error:0.12697\ttest-error:0.12936                               \n",
      "\n",
      "[31]\ttrain-error:0.12678\ttest-error:0.12967                               \n",
      "\n",
      "[32]\ttrain-error:0.12617\ttest-error:0.12936                               \n",
      "\n",
      "[33]\ttrain-error:0.12638\ttest-error:0.12905                               \n",
      "\n",
      "[34]\ttrain-error:0.12598\ttest-error:0.12832                               \n",
      "\n",
      "[35]\ttrain-error:0.12589\ttest-error:0.12832                               \n",
      "\n",
      "[36]\ttrain-error:0.12549\ttest-error:0.12795                               \n",
      "\n",
      "[37]\ttrain-error:0.12531\ttest-error:0.12764                               \n",
      "\n",
      "[38]\ttrain-error:0.12503\ttest-error:0.12807                               \n",
      "\n",
      "[39]\ttrain-error:0.12472\ttest-error:0.12807                               \n",
      "\n",
      "[40]\ttrain-error:0.12435\ttest-error:0.12783                               \n",
      "\n",
      "[41]\ttrain-error:0.12402\ttest-error:0.12752                               \n",
      "\n",
      "[42]\ttrain-error:0.12377\ttest-error:0.12776                               \n",
      "\n",
      "[43]\ttrain-error:0.12343\ttest-error:0.12733                               \n",
      "\n",
      "[44]\ttrain-error:0.12334\ttest-error:0.12776                               \n",
      "\n",
      "[45]\ttrain-error:0.12313\ttest-error:0.12801                               \n",
      "\n",
      "[46]\ttrain-error:0.12254\ttest-error:0.12752                               \n",
      "\n",
      "[47]\ttrain-error:0.12263\ttest-error:0.12758                               \n",
      "\n",
      "[48]\ttrain-error:0.12233\ttest-error:0.12746                               \n",
      "\n",
      "[49]\ttrain-error:0.12233\ttest-error:0.12801                               \n",
      "\n",
      "[50]\ttrain-error:0.12220\ttest-error:0.12746                               \n",
      "\n",
      "[51]\ttrain-error:0.12214\ttest-error:0.12746                               \n",
      "\n",
      "[52]\ttrain-error:0.12190\ttest-error:0.12776                               \n",
      "\n",
      "[53]\ttrain-error:0.12171\ttest-error:0.12733                               \n",
      "\n",
      "[54]\ttrain-error:0.12181\ttest-error:0.12770                               \n",
      "\n",
      "[55]\ttrain-error:0.12150\ttest-error:0.12758                               \n",
      "\n",
      "[56]\ttrain-error:0.12110\ttest-error:0.12758                               \n",
      "\n",
      "[57]\ttrain-error:0.12122\ttest-error:0.12727                               \n",
      "\n",
      "[58]\ttrain-error:0.12101\ttest-error:0.12721                               \n",
      "\n",
      "[59]\ttrain-error:0.12064\ttest-error:0.12746                               \n",
      "\n",
      "[60]\ttrain-error:0.12067\ttest-error:0.12758                               \n",
      "\n",
      "[61]\ttrain-error:0.12048\ttest-error:0.12733                               \n",
      "\n",
      "[62]\ttrain-error:0.12046\ttest-error:0.12758                               \n",
      "\n",
      "[63]\ttrain-error:0.12033\ttest-error:0.12770                               \n",
      "\n",
      "[64]\ttrain-error:0.12033\ttest-error:0.12752                               \n",
      "\n",
      "[65]\ttrain-error:0.12027\ttest-error:0.12783                               \n",
      "\n",
      "[66]\ttrain-error:0.12024\ttest-error:0.12758                               \n",
      "\n",
      "[67]\ttrain-error:0.12036\ttest-error:0.12758                               \n",
      "\n",
      "[68]\ttrain-error:0.12003\ttest-error:0.12746                               \n",
      "\n",
      "[69]\ttrain-error:0.11981\ttest-error:0.12740                               \n",
      "\n",
      "[70]\ttrain-error:0.11962\ttest-error:0.12764                               \n",
      "\n",
      "[71]\ttrain-error:0.11941\ttest-error:0.12740                               \n",
      "\n",
      "[72]\ttrain-error:0.11938\ttest-error:0.12715                               \n",
      "\n",
      "[73]\ttrain-error:0.11935\ttest-error:0.12733                               \n",
      "\n",
      "[74]\ttrain-error:0.11929\ttest-error:0.12709                               \n",
      "\n",
      "[75]\ttrain-error:0.11913\ttest-error:0.12721                               \n",
      "\n",
      "[76]\ttrain-error:0.11898\ttest-error:0.12733                               \n",
      "\n",
      "[77]\ttrain-error:0.11824\ttest-error:0.12721                               \n",
      "\n",
      "[78]\ttrain-error:0.11830\ttest-error:0.12721                               \n",
      "\n",
      "[79]\ttrain-error:0.11824\ttest-error:0.12715                               \n",
      "\n",
      "[80]\ttrain-error:0.11821\ttest-error:0.12752                               \n",
      "\n",
      "[81]\ttrain-error:0.11815\ttest-error:0.12721                               \n",
      "\n",
      "[82]\ttrain-error:0.11815\ttest-error:0.12752                               \n",
      "\n",
      "[83]\ttrain-error:0.11754\ttest-error:0.12746                               \n",
      "\n",
      "[84]\ttrain-error:0.11729\ttest-error:0.12721                               \n",
      "\n",
      "[85]\ttrain-error:0.11717\ttest-error:0.12746                               \n",
      "\n",
      "[86]\ttrain-error:0.11714\ttest-error:0.12746                               \n",
      "\n",
      "[87]\ttrain-error:0.11704\ttest-error:0.12752                               \n",
      "\n",
      "[88]\ttrain-error:0.11729\ttest-error:0.12697                               \n",
      "\n",
      "[89]\ttrain-error:0.11683\ttest-error:0.12654                               \n",
      "\n",
      "[90]\ttrain-error:0.11711\ttest-error:0.12690                               \n",
      "\n",
      "[91]\ttrain-error:0.11720\ttest-error:0.12709                               \n",
      "\n",
      "[92]\ttrain-error:0.11701\ttest-error:0.12703                               \n",
      "\n",
      "[93]\ttrain-error:0.11674\ttest-error:0.12697                               \n",
      "\n",
      "[94]\ttrain-error:0.11658\ttest-error:0.12690                               \n",
      "\n",
      "[95]\ttrain-error:0.11637\ttest-error:0.12709                               \n",
      "\n",
      "[96]\ttrain-error:0.11640\ttest-error:0.12697                               \n",
      "\n",
      "[97]\ttrain-error:0.11597\ttest-error:0.12684                               \n",
      "\n",
      "[98]\ttrain-error:0.11569\ttest-error:0.12666                               \n",
      "\n",
      "[99]\ttrain-error:0.11557\ttest-error:0.12635                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.7015759196872196, 'colsample_bytree': 0.7950745328522406, 'eta': 0.2638126797942663, 'eval_metric': ('error',), 'extra_dims': 0, 'gamma': 0, 'lambda': 0, 'max_depth': 1, 'min_child_weight': 0.7885851191053008, 'objective': 'binary:logistic', 'subsample': 0.6991108342390604}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:46:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.24082\ttest-error:0.23624                                \n",
      "\n",
      "[1]\ttrain-error:0.19739\ttest-error:0.19509                                \n",
      "\n",
      "[2]\ttrain-error:0.20455\ttest-error:0.20190                                \n",
      "\n",
      "[3]\ttrain-error:0.20455\ttest-error:0.20190                                \n",
      "\n",
      "[4]\ttrain-error:0.20455\ttest-error:0.20190                                \n",
      "\n",
      "[5]\ttrain-error:0.19877\ttest-error:0.19638                                \n",
      "\n",
      "[6]\ttrain-error:0.20455\ttest-error:0.20190                                \n",
      "\n",
      "[7]\ttrain-error:0.19877\ttest-error:0.19638                                \n",
      "\n",
      "[8]\ttrain-error:0.20009\ttest-error:0.19730                                \n",
      "\n",
      "[9]\ttrain-error:0.19846\ttest-error:0.19625                                \n",
      "\n",
      "[10]\ttrain-error:0.15964\ttest-error:0.15786                               \n",
      "\n",
      "[11]\ttrain-error:0.15964\ttest-error:0.15786                               \n",
      "\n",
      "[12]\ttrain-error:0.16017\ttest-error:0.15811                               \n",
      "\n",
      "[13]\ttrain-error:0.15848\ttest-error:0.15682                               \n",
      "\n",
      "[14]\ttrain-error:0.15869\ttest-error:0.15694                               \n",
      "\n",
      "[15]\ttrain-error:0.15808\ttest-error:0.15620                               \n",
      "\n",
      "[16]\ttrain-error:0.15835\ttest-error:0.15633                               \n",
      "\n",
      "[17]\ttrain-error:0.15734\ttest-error:0.15547                               \n",
      "\n",
      "[18]\ttrain-error:0.15611\ttest-error:0.15461                               \n",
      "\n",
      "[19]\ttrain-error:0.15740\ttest-error:0.15498                               \n",
      "\n",
      "[20]\ttrain-error:0.15624\ttest-error:0.15381                               \n",
      "\n",
      "[21]\ttrain-error:0.15522\ttest-error:0.15332                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\ttrain-error:0.15482\ttest-error:0.15350                               \n",
      "\n",
      "[23]\ttrain-error:0.15510\ttest-error:0.15356                               \n",
      "\n",
      "[24]\ttrain-error:0.15412\ttest-error:0.15319                               \n",
      "\n",
      "[25]\ttrain-error:0.15412\ttest-error:0.15313                               \n",
      "\n",
      "[26]\ttrain-error:0.15381\ttest-error:0.15227                               \n",
      "\n",
      "[27]\ttrain-error:0.15359\ttest-error:0.15215                               \n",
      "\n",
      "[28]\ttrain-error:0.15338\ttest-error:0.15209                               \n",
      "\n",
      "[29]\ttrain-error:0.15329\ttest-error:0.15184                               \n",
      "\n",
      "[30]\ttrain-error:0.15323\ttest-error:0.15147                               \n",
      "\n",
      "[31]\ttrain-error:0.15212\ttest-error:0.14994                               \n",
      "\n",
      "[32]\ttrain-error:0.15175\ttest-error:0.14982                               \n",
      "\n",
      "[33]\ttrain-error:0.15209\ttest-error:0.14988                               \n",
      "\n",
      "[34]\ttrain-error:0.15169\ttest-error:0.14945                               \n",
      "\n",
      "[35]\ttrain-error:0.15126\ttest-error:0.14896                               \n",
      "\n",
      "[36]\ttrain-error:0.15135\ttest-error:0.14939                               \n",
      "\n",
      "[37]\ttrain-error:0.15089\ttest-error:0.14853                               \n",
      "\n",
      "[38]\ttrain-error:0.15086\ttest-error:0.14828                               \n",
      "\n",
      "[39]\ttrain-error:0.15046\ttest-error:0.14840                               \n",
      "\n",
      "[40]\ttrain-error:0.15031\ttest-error:0.14760                               \n",
      "\n",
      "[41]\ttrain-error:0.15037\ttest-error:0.14779                               \n",
      "\n",
      "[42]\ttrain-error:0.15000\ttest-error:0.14797                               \n",
      "\n",
      "[43]\ttrain-error:0.15025\ttest-error:0.14767                               \n",
      "\n",
      "[44]\ttrain-error:0.15000\ttest-error:0.14810                               \n",
      "\n",
      "[45]\ttrain-error:0.15000\ttest-error:0.14822                               \n",
      "\n",
      "[46]\ttrain-error:0.14991\ttest-error:0.14742                               \n",
      "\n",
      "[47]\ttrain-error:0.14969\ttest-error:0.14724                               \n",
      "\n",
      "[48]\ttrain-error:0.14969\ttest-error:0.14730                               \n",
      "\n",
      "[49]\ttrain-error:0.14975\ttest-error:0.14730                               \n",
      "\n",
      "[50]\ttrain-error:0.14966\ttest-error:0.14693                               \n",
      "\n",
      "[51]\ttrain-error:0.14939\ttest-error:0.14656                               \n",
      "\n",
      "[52]\ttrain-error:0.14935\ttest-error:0.14656                               \n",
      "\n",
      "[53]\ttrain-error:0.14945\ttest-error:0.14668                               \n",
      "\n",
      "[54]\ttrain-error:0.14908\ttest-error:0.14631                               \n",
      "\n",
      "[55]\ttrain-error:0.14911\ttest-error:0.14601                               \n",
      "\n",
      "[56]\ttrain-error:0.14945\ttest-error:0.14650                               \n",
      "\n",
      "[57]\ttrain-error:0.14899\ttest-error:0.14564                               \n",
      "\n",
      "[58]\ttrain-error:0.14908\ttest-error:0.14546                               \n",
      "\n",
      "[59]\ttrain-error:0.14905\ttest-error:0.14447                               \n",
      "\n",
      "[60]\ttrain-error:0.14920\ttest-error:0.14496                               \n",
      "\n",
      "[61]\ttrain-error:0.14862\ttest-error:0.14435                               \n",
      "\n",
      "[62]\ttrain-error:0.14896\ttest-error:0.14466                               \n",
      "\n",
      "[63]\ttrain-error:0.14862\ttest-error:0.14496                               \n",
      "\n",
      "[64]\ttrain-error:0.14871\ttest-error:0.14435                               \n",
      "\n",
      "[65]\ttrain-error:0.14840\ttest-error:0.14466                               \n",
      "\n",
      "[66]\ttrain-error:0.14874\ttest-error:0.14441                               \n",
      "\n",
      "[67]\ttrain-error:0.14862\ttest-error:0.14441                               \n",
      "\n",
      "[68]\ttrain-error:0.14886\ttest-error:0.14460                               \n",
      "\n",
      "[69]\ttrain-error:0.14896\ttest-error:0.14484                               \n",
      "\n",
      "[70]\ttrain-error:0.14908\ttest-error:0.14515                               \n",
      "\n",
      "[71]\ttrain-error:0.14896\ttest-error:0.14502                               \n",
      "\n",
      "[72]\ttrain-error:0.14773\ttest-error:0.14367                               \n",
      "\n",
      "[73]\ttrain-error:0.14776\ttest-error:0.14374                               \n",
      "\n",
      "[74]\ttrain-error:0.14785\ttest-error:0.14386                               \n",
      "\n",
      "[75]\ttrain-error:0.14785\ttest-error:0.14386                               \n",
      "\n",
      "[76]\ttrain-error:0.14797\ttest-error:0.14380                               \n",
      "\n",
      "[77]\ttrain-error:0.14819\ttest-error:0.14435                               \n",
      "\n",
      "[78]\ttrain-error:0.14794\ttest-error:0.14392                               \n",
      "\n",
      "[79]\ttrain-error:0.14773\ttest-error:0.14380                               \n",
      "\n",
      "[80]\ttrain-error:0.14748\ttest-error:0.14355                               \n",
      "\n",
      "[81]\ttrain-error:0.14779\ttest-error:0.14374                               \n",
      "\n",
      "[82]\ttrain-error:0.14797\ttest-error:0.14288                               \n",
      "\n",
      "[83]\ttrain-error:0.14776\ttest-error:0.14238                               \n",
      "\n",
      "[84]\ttrain-error:0.14770\ttest-error:0.14257                               \n",
      "\n",
      "[85]\ttrain-error:0.14760\ttest-error:0.14312                               \n",
      "\n",
      "[86]\ttrain-error:0.14742\ttest-error:0.14330                               \n",
      "\n",
      "[87]\ttrain-error:0.14754\ttest-error:0.14337                               \n",
      "\n",
      "[88]\ttrain-error:0.14757\ttest-error:0.14355                               \n",
      "\n",
      "[89]\ttrain-error:0.14770\ttest-error:0.14349                               \n",
      "\n",
      "[90]\ttrain-error:0.14767\ttest-error:0.14361                               \n",
      "\n",
      "[91]\ttrain-error:0.14785\ttest-error:0.14380                               \n",
      "\n",
      "[92]\ttrain-error:0.14785\ttest-error:0.14367                               \n",
      "\n",
      "[93]\ttrain-error:0.14773\ttest-error:0.14361                               \n",
      "\n",
      "[94]\ttrain-error:0.14770\ttest-error:0.14367                               \n",
      "\n",
      "[95]\ttrain-error:0.14763\ttest-error:0.14330                               \n",
      "\n",
      "[96]\ttrain-error:0.14776\ttest-error:0.14361                               \n",
      "\n",
      "[97]\ttrain-error:0.14770\ttest-error:0.14343                               \n",
      "\n",
      "[98]\ttrain-error:0.14770\ttest-error:0.14355                               \n",
      "\n",
      "[99]\ttrain-error:0.14757\ttest-error:0.14343                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.5423581849188346, 'colsample_bytree': 0.6445705916871833, 'eta': 0.06633325164450204, 'eval_metric': ('error',), 'extra_dims': 14, 'gamma': 0, 'lambda': 2.2680145897198156, 'max_depth': 10, 'min_child_weight': 0.05915489687012691, 'objective': 'binary:logistic', 'subsample': 0.8623916505513202}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:46:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13437\ttest-error:0.13833                                \n",
      "\n",
      "[1]\ttrain-error:0.13050\ttest-error:0.13298                                \n",
      "\n",
      "[2]\ttrain-error:0.12494\ttest-error:0.13034                                \n",
      "\n",
      "[3]\ttrain-error:0.12251\ttest-error:0.12869                                \n",
      "\n",
      "[4]\ttrain-error:0.11969\ttest-error:0.12930                                \n",
      "\n",
      "[5]\ttrain-error:0.11717\ttest-error:0.12826                                \n",
      "\n",
      "[6]\ttrain-error:0.11508\ttest-error:0.12721                                \n",
      "\n",
      "[7]\ttrain-error:0.11333\ttest-error:0.12721                                \n",
      "\n",
      "[8]\ttrain-error:0.11262\ttest-error:0.12733                                \n",
      "\n",
      "[9]\ttrain-error:0.11063\ttest-error:0.12740                                \n",
      "\n",
      "[10]\ttrain-error:0.10912\ttest-error:0.12690                               \n",
      "\n",
      "[11]\ttrain-error:0.10749\ttest-error:0.12641                               \n",
      "\n",
      "[12]\ttrain-error:0.10676\ttest-error:0.12666                               \n",
      "\n",
      "[13]\ttrain-error:0.10565\ttest-error:0.12703                               \n",
      "\n",
      "[14]\ttrain-error:0.10461\ttest-error:0.12684                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15]\ttrain-error:0.10304\ttest-error:0.12733                               \n",
      "\n",
      "[16]\ttrain-error:0.10135\ttest-error:0.12733                               \n",
      "\n",
      "[17]\ttrain-error:0.10015\ttest-error:0.12752                               \n",
      "\n",
      "[18]\ttrain-error:0.09939\ttest-error:0.12813                               \n",
      "\n",
      "[19]\ttrain-error:0.09840\ttest-error:0.12727                               \n",
      "\n",
      "[20]\ttrain-error:0.09656\ttest-error:0.12684                               \n",
      "\n",
      "[21]\ttrain-error:0.09545\ttest-error:0.12697                               \n",
      "\n",
      "[22]\ttrain-error:0.09367\ttest-error:0.12678                               \n",
      "\n",
      "[23]\ttrain-error:0.09337\ttest-error:0.12740                               \n",
      "\n",
      "[24]\ttrain-error:0.09183\ttest-error:0.12721                               \n",
      "\n",
      "[25]\ttrain-error:0.09060\ttest-error:0.12776                               \n",
      "\n",
      "[26]\ttrain-error:0.08888\ttest-error:0.12783                               \n",
      "\n",
      "[27]\ttrain-error:0.08759\ttest-error:0.12733                               \n",
      "\n",
      "[28]\ttrain-error:0.08686\ttest-error:0.12758                               \n",
      "\n",
      "[29]\ttrain-error:0.08541\ttest-error:0.12740                               \n",
      "\n",
      "[30]\ttrain-error:0.08477\ttest-error:0.12813                               \n",
      "\n",
      "[31]\ttrain-error:0.08378\ttest-error:0.12838                               \n",
      "\n",
      "[32]\ttrain-error:0.08268\ttest-error:0.12893                               \n",
      "\n",
      "[33]\ttrain-error:0.08133\ttest-error:0.12942                               \n",
      "\n",
      "[34]\ttrain-error:0.07970\ttest-error:0.12912                               \n",
      "\n",
      "[35]\ttrain-error:0.07881\ttest-error:0.12942                               \n",
      "\n",
      "[36]\ttrain-error:0.07819\ttest-error:0.12942                               \n",
      "\n",
      "[37]\ttrain-error:0.07749\ttest-error:0.12893                               \n",
      "\n",
      "[38]\ttrain-error:0.07651\ttest-error:0.12918                               \n",
      "\n",
      "[39]\ttrain-error:0.07525\ttest-error:0.12930                               \n",
      "\n",
      "[40]\ttrain-error:0.07423\ttest-error:0.12942                               \n",
      "\n",
      "[41]\ttrain-error:0.07325\ttest-error:0.12985                               \n",
      "\n",
      "[42]\ttrain-error:0.07260\ttest-error:0.12979                               \n",
      "\n",
      "[43]\ttrain-error:0.07138\ttest-error:0.13053                               \n",
      "\n",
      "[44]\ttrain-error:0.07018\ttest-error:0.13034                               \n",
      "\n",
      "[45]\ttrain-error:0.06874\ttest-error:0.13133                               \n",
      "\n",
      "[46]\ttrain-error:0.06788\ttest-error:0.13084                               \n",
      "\n",
      "[47]\ttrain-error:0.06692\ttest-error:0.13139                               \n",
      "\n",
      "[48]\ttrain-error:0.06548\ttest-error:0.13090                               \n",
      "\n",
      "[49]\ttrain-error:0.06483\ttest-error:0.13071                               \n",
      "\n",
      "[50]\ttrain-error:0.06391\ttest-error:0.13053                               \n",
      "\n",
      "[51]\ttrain-error:0.06256\ttest-error:0.13022                               \n",
      "\n",
      "[52]\ttrain-error:0.06176\ttest-error:0.13040                               \n",
      "\n",
      "[53]\ttrain-error:0.06115\ttest-error:0.13071                               \n",
      "\n",
      "[54]\ttrain-error:0.06047\ttest-error:0.13096                               \n",
      "\n",
      "[55]\ttrain-error:0.05958\ttest-error:0.13090                               \n",
      "\n",
      "[56]\ttrain-error:0.05891\ttest-error:0.13176                               \n",
      "\n",
      "[57]\ttrain-error:0.05783\ttest-error:0.13225                               \n",
      "\n",
      "[58]\ttrain-error:0.05709\ttest-error:0.13200                               \n",
      "\n",
      "[59]\ttrain-error:0.05614\ttest-error:0.13206                               \n",
      "\n",
      "[60]\ttrain-error:0.05541\ttest-error:0.13188                               \n",
      "\n",
      "[61]\ttrain-error:0.05491\ttest-error:0.13256                               \n",
      "\n",
      "[62]\ttrain-error:0.05390\ttest-error:0.13305                               \n",
      "\n",
      "[63]\ttrain-error:0.05316\ttest-error:0.13354                               \n",
      "\n",
      "[64]\ttrain-error:0.05230\ttest-error:0.13372                               \n",
      "\n",
      "[65]\ttrain-error:0.05120\ttest-error:0.13403                               \n",
      "\n",
      "[66]\ttrain-error:0.05040\ttest-error:0.13421                               \n",
      "\n",
      "[67]\ttrain-error:0.04975\ttest-error:0.13483                               \n",
      "\n",
      "[68]\ttrain-error:0.04899\ttest-error:0.13446                               \n",
      "\n",
      "[69]\ttrain-error:0.04825\ttest-error:0.13458                               \n",
      "\n",
      "[70]\ttrain-error:0.04773\ttest-error:0.13470                               \n",
      "\n",
      "[71]\ttrain-error:0.04665\ttest-error:0.13507                               \n",
      "\n",
      "[72]\ttrain-error:0.04591\ttest-error:0.13470                               \n",
      "\n",
      "[73]\ttrain-error:0.04555\ttest-error:0.13501                               \n",
      "\n",
      "[74]\ttrain-error:0.04515\ttest-error:0.13477                               \n",
      "\n",
      "[75]\ttrain-error:0.04423\ttest-error:0.13477                               \n",
      "\n",
      "[76]\ttrain-error:0.04331\ttest-error:0.13514                               \n",
      "\n",
      "[77]\ttrain-error:0.04263\ttest-error:0.13563                               \n",
      "\n",
      "[78]\ttrain-error:0.04201\ttest-error:0.13550                               \n",
      "\n",
      "[79]\ttrain-error:0.04122\ttest-error:0.13600                               \n",
      "\n",
      "[80]\ttrain-error:0.04057\ttest-error:0.13563                               \n",
      "\n",
      "[81]\ttrain-error:0.04026\ttest-error:0.13520                               \n",
      "\n",
      "[82]\ttrain-error:0.03950\ttest-error:0.13514                               \n",
      "\n",
      "[83]\ttrain-error:0.03913\ttest-error:0.13612                               \n",
      "\n",
      "[84]\ttrain-error:0.03845\ttest-error:0.13556                               \n",
      "\n",
      "[85]\ttrain-error:0.03778\ttest-error:0.13532                               \n",
      "\n",
      "[86]\ttrain-error:0.03719\ttest-error:0.13526                               \n",
      "\n",
      "[87]\ttrain-error:0.03636\ttest-error:0.13495                               \n",
      "\n",
      "[88]\ttrain-error:0.03587\ttest-error:0.13514                               \n",
      "\n",
      "[89]\ttrain-error:0.03492\ttest-error:0.13507                               \n",
      "\n",
      "[90]\ttrain-error:0.03455\ttest-error:0.13514                               \n",
      "\n",
      "[91]\ttrain-error:0.03415\ttest-error:0.13532                               \n",
      "\n",
      "[92]\ttrain-error:0.03360\ttest-error:0.13587                               \n",
      "\n",
      "[93]\ttrain-error:0.03265\ttest-error:0.13581                               \n",
      "\n",
      "[94]\ttrain-error:0.03206\ttest-error:0.13575                               \n",
      "\n",
      "[95]\ttrain-error:0.03163\ttest-error:0.13575                               \n",
      "\n",
      "[96]\ttrain-error:0.03093\ttest-error:0.13514                               \n",
      "\n",
      "[97]\ttrain-error:0.03019\ttest-error:0.13593                               \n",
      "\n",
      "[98]\ttrain-error:0.03001\ttest-error:0.13642                               \n",
      "\n",
      "[99]\ttrain-error:0.02902\ttest-error:0.13636                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.608724347495054, 'colsample_bytree': 0.6252410123584603, 'eta': 0.01277928261996231, 'eval_metric': ('error',), 'extra_dims': 11, 'gamma': 0, 'lambda': 0.0005968601298597759, 'max_depth': 3, 'min_child_weight': 2.4882012459383698, 'objective': 'binary:logistic', 'subsample': 0.9118332857774017}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:49:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15626\ttest-error:0.15485                                \n",
      "\n",
      "[1]\ttrain-error:0.16139\ttest-error:0.16044                                \n",
      "\n",
      "[2]\ttrain-error:0.15952\ttest-error:0.15866                                \n",
      "\n",
      "[3]\ttrain-error:0.15544\ttest-error:0.15369                                \n",
      "\n",
      "[4]\ttrain-error:0.15513\ttest-error:0.15362                                \n",
      "\n",
      "[5]\ttrain-error:0.15396\ttest-error:0.15375                                \n",
      "\n",
      "[6]\ttrain-error:0.15418\ttest-error:0.15270                                \n",
      "\n",
      "[7]\ttrain-error:0.15283\ttest-error:0.15209                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain-error:0.15237\ttest-error:0.15197                                \n",
      "\n",
      "[9]\ttrain-error:0.15227\ttest-error:0.15135                                \n",
      "\n",
      "[10]\ttrain-error:0.15224\ttest-error:0.15080                               \n",
      "\n",
      "[11]\ttrain-error:0.15074\ttest-error:0.15006                               \n",
      "\n",
      "[12]\ttrain-error:0.15037\ttest-error:0.14975                               \n",
      "\n",
      "[13]\ttrain-error:0.14939\ttest-error:0.14914                               \n",
      "\n",
      "[14]\ttrain-error:0.14874\ttest-error:0.14896                               \n",
      "\n",
      "[15]\ttrain-error:0.14760\ttest-error:0.14779                               \n",
      "\n",
      "[16]\ttrain-error:0.14717\ttest-error:0.14748                               \n",
      "\n",
      "[17]\ttrain-error:0.14699\ttest-error:0.14668                               \n",
      "\n",
      "[18]\ttrain-error:0.14638\ttest-error:0.14595                               \n",
      "\n",
      "[19]\ttrain-error:0.14505\ttest-error:0.14429                               \n",
      "\n",
      "[20]\ttrain-error:0.14512\ttest-error:0.14410                               \n",
      "\n",
      "[21]\ttrain-error:0.14502\ttest-error:0.14398                               \n",
      "\n",
      "[22]\ttrain-error:0.14466\ttest-error:0.14349                               \n",
      "\n",
      "[23]\ttrain-error:0.14435\ttest-error:0.14380                               \n",
      "\n",
      "[24]\ttrain-error:0.14460\ttest-error:0.14337                               \n",
      "\n",
      "[25]\ttrain-error:0.14441\ttest-error:0.14330                               \n",
      "\n",
      "[26]\ttrain-error:0.14429\ttest-error:0.14251                               \n",
      "\n",
      "[27]\ttrain-error:0.14374\ttest-error:0.14238                               \n",
      "\n",
      "[28]\ttrain-error:0.14333\ttest-error:0.14220                               \n",
      "\n",
      "[29]\ttrain-error:0.14306\ttest-error:0.14208                               \n",
      "\n",
      "[30]\ttrain-error:0.14272\ttest-error:0.14214                               \n",
      "\n",
      "[31]\ttrain-error:0.14260\ttest-error:0.14189                               \n",
      "\n",
      "[32]\ttrain-error:0.14269\ttest-error:0.14177                               \n",
      "\n",
      "[33]\ttrain-error:0.14220\ttest-error:0.14116                               \n",
      "\n",
      "[34]\ttrain-error:0.14217\ttest-error:0.14060                               \n",
      "\n",
      "[35]\ttrain-error:0.14223\ttest-error:0.14048                               \n",
      "\n",
      "[36]\ttrain-error:0.14226\ttest-error:0.14011                               \n",
      "\n",
      "[37]\ttrain-error:0.14195\ttest-error:0.14011                               \n",
      "\n",
      "[38]\ttrain-error:0.14180\ttest-error:0.14011                               \n",
      "\n",
      "[39]\ttrain-error:0.14146\ttest-error:0.13999                               \n",
      "\n",
      "[40]\ttrain-error:0.14143\ttest-error:0.13980                               \n",
      "\n",
      "[41]\ttrain-error:0.14140\ttest-error:0.13974                               \n",
      "\n",
      "[42]\ttrain-error:0.14106\ttest-error:0.13925                               \n",
      "\n",
      "[43]\ttrain-error:0.14063\ttest-error:0.13913                               \n",
      "\n",
      "[44]\ttrain-error:0.14033\ttest-error:0.13882                               \n",
      "\n",
      "[45]\ttrain-error:0.14026\ttest-error:0.13845                               \n",
      "\n",
      "[46]\ttrain-error:0.14048\ttest-error:0.13833                               \n",
      "\n",
      "[47]\ttrain-error:0.14033\ttest-error:0.13784                               \n",
      "\n",
      "[48]\ttrain-error:0.13990\ttest-error:0.13741                               \n",
      "\n",
      "[49]\ttrain-error:0.14005\ttest-error:0.13716                               \n",
      "\n",
      "[50]\ttrain-error:0.13986\ttest-error:0.13747                               \n",
      "\n",
      "[51]\ttrain-error:0.13993\ttest-error:0.13735                               \n",
      "\n",
      "[52]\ttrain-error:0.13965\ttest-error:0.13673                               \n",
      "\n",
      "[53]\ttrain-error:0.13934\ttest-error:0.13679                               \n",
      "\n",
      "[54]\ttrain-error:0.13913\ttest-error:0.13636                               \n",
      "\n",
      "[55]\ttrain-error:0.13897\ttest-error:0.13624                               \n",
      "\n",
      "[56]\ttrain-error:0.13879\ttest-error:0.13630                               \n",
      "\n",
      "[57]\ttrain-error:0.13888\ttest-error:0.13593                               \n",
      "\n",
      "[58]\ttrain-error:0.13891\ttest-error:0.13587                               \n",
      "\n",
      "[59]\ttrain-error:0.13870\ttest-error:0.13569                               \n",
      "\n",
      "[60]\ttrain-error:0.13854\ttest-error:0.13538                               \n",
      "\n",
      "[61]\ttrain-error:0.13818\ttest-error:0.13483                               \n",
      "\n",
      "[62]\ttrain-error:0.13802\ttest-error:0.13458                               \n",
      "\n",
      "[63]\ttrain-error:0.13759\ttest-error:0.13440                               \n",
      "\n",
      "[64]\ttrain-error:0.13747\ttest-error:0.13428                               \n",
      "\n",
      "[65]\ttrain-error:0.13716\ttest-error:0.13391                               \n",
      "\n",
      "[66]\ttrain-error:0.13710\ttest-error:0.13378                               \n",
      "\n",
      "[67]\ttrain-error:0.13695\ttest-error:0.13366                               \n",
      "\n",
      "[68]\ttrain-error:0.13658\ttest-error:0.13372                               \n",
      "\n",
      "[69]\ttrain-error:0.13639\ttest-error:0.13317                               \n",
      "\n",
      "[70]\ttrain-error:0.13615\ttest-error:0.13329                               \n",
      "\n",
      "[71]\ttrain-error:0.13590\ttest-error:0.13335                               \n",
      "\n",
      "[72]\ttrain-error:0.13575\ttest-error:0.13292                               \n",
      "\n",
      "[73]\ttrain-error:0.13550\ttest-error:0.13268                               \n",
      "\n",
      "[74]\ttrain-error:0.13541\ttest-error:0.13268                               \n",
      "\n",
      "[75]\ttrain-error:0.13538\ttest-error:0.13280                               \n",
      "\n",
      "[76]\ttrain-error:0.13532\ttest-error:0.13286                               \n",
      "\n",
      "[77]\ttrain-error:0.13514\ttest-error:0.13274                               \n",
      "\n",
      "[78]\ttrain-error:0.13492\ttest-error:0.13262                               \n",
      "\n",
      "[79]\ttrain-error:0.13477\ttest-error:0.13286                               \n",
      "\n",
      "[80]\ttrain-error:0.13458\ttest-error:0.13298                               \n",
      "\n",
      "[81]\ttrain-error:0.13446\ttest-error:0.13268                               \n",
      "\n",
      "[82]\ttrain-error:0.13431\ttest-error:0.13268                               \n",
      "\n",
      "[83]\ttrain-error:0.13409\ttest-error:0.13268                               \n",
      "\n",
      "[84]\ttrain-error:0.13397\ttest-error:0.13243                               \n",
      "\n",
      "[85]\ttrain-error:0.13375\ttest-error:0.13231                               \n",
      "\n",
      "[86]\ttrain-error:0.13339\ttest-error:0.13206                               \n",
      "\n",
      "[87]\ttrain-error:0.13332\ttest-error:0.13206                               \n",
      "\n",
      "[88]\ttrain-error:0.13320\ttest-error:0.13225                               \n",
      "\n",
      "[89]\ttrain-error:0.13305\ttest-error:0.13219                               \n",
      "\n",
      "[90]\ttrain-error:0.13286\ttest-error:0.13200                               \n",
      "\n",
      "[91]\ttrain-error:0.13292\ttest-error:0.13188                               \n",
      "\n",
      "[92]\ttrain-error:0.13286\ttest-error:0.13176                               \n",
      "\n",
      "[93]\ttrain-error:0.13262\ttest-error:0.13157                               \n",
      "\n",
      "[94]\ttrain-error:0.13262\ttest-error:0.13163                               \n",
      "\n",
      "[95]\ttrain-error:0.13253\ttest-error:0.13176                               \n",
      "\n",
      "[96]\ttrain-error:0.13219\ttest-error:0.13145                               \n",
      "\n",
      "[97]\ttrain-error:0.13225\ttest-error:0.13139                               \n",
      "\n",
      "[98]\ttrain-error:0.13225\ttest-error:0.13108                               \n",
      "\n",
      "[99]\ttrain-error:0.13222\ttest-error:0.13102                               \n",
      "\n",
      "{'alpha': 7.273640535587841e-07, 'btype': 'Rn', 'colsample_bylevel': 0.6223888977866093, 'colsample_bytree': 0.7436175986497323, 'eta': 0.028116909477954814, 'eval_metric': ('error',), 'extra_dims': 6, 'gamma': 0, 'lambda': 0.009690708658756906, 'max_depth': 4, 'min_child_weight': 0.001241902362790002, 'objective': 'binary:logistic', 'subsample': 0.894483915364102}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:50:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14628\ttest-error:0.14515                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-error:0.14573\ttest-error:0.14662                                \n",
      "\n",
      "[2]\ttrain-error:0.14582\ttest-error:0.14472                                \n",
      "\n",
      "[3]\ttrain-error:0.14604\ttest-error:0.14527                                \n",
      "\n",
      "[4]\ttrain-error:0.14576\ttest-error:0.14478                                \n",
      "\n",
      "[5]\ttrain-error:0.14588\ttest-error:0.14484                                \n",
      "\n",
      "[6]\ttrain-error:0.14539\ttest-error:0.14447                                \n",
      "\n",
      "[7]\ttrain-error:0.14450\ttest-error:0.14392                                \n",
      "\n",
      "[8]\ttrain-error:0.14374\ttest-error:0.14386                                \n",
      "\n",
      "[9]\ttrain-error:0.14364\ttest-error:0.14404                                \n",
      "\n",
      "[10]\ttrain-error:0.14183\ttest-error:0.14226                               \n",
      "\n",
      "[11]\ttrain-error:0.14155\ttest-error:0.14165                               \n",
      "\n",
      "[12]\ttrain-error:0.14152\ttest-error:0.14140                               \n",
      "\n",
      "[13]\ttrain-error:0.14112\ttest-error:0.14042                               \n",
      "\n",
      "[14]\ttrain-error:0.14134\ttest-error:0.14036                               \n",
      "\n",
      "[15]\ttrain-error:0.14097\ttest-error:0.13974                               \n",
      "\n",
      "[16]\ttrain-error:0.14069\ttest-error:0.13919                               \n",
      "\n",
      "[17]\ttrain-error:0.14051\ttest-error:0.13882                               \n",
      "\n",
      "[18]\ttrain-error:0.14020\ttest-error:0.13851                               \n",
      "\n",
      "[19]\ttrain-error:0.13959\ttest-error:0.13778                               \n",
      "\n",
      "[20]\ttrain-error:0.13928\ttest-error:0.13759                               \n",
      "\n",
      "[21]\ttrain-error:0.13888\ttest-error:0.13698                               \n",
      "\n",
      "[22]\ttrain-error:0.13873\ttest-error:0.13661                               \n",
      "\n",
      "[23]\ttrain-error:0.13851\ttest-error:0.13667                               \n",
      "\n",
      "[24]\ttrain-error:0.13808\ttest-error:0.13612                               \n",
      "\n",
      "[25]\ttrain-error:0.13732\ttest-error:0.13593                               \n",
      "\n",
      "[26]\ttrain-error:0.13722\ttest-error:0.13563                               \n",
      "\n",
      "[27]\ttrain-error:0.13686\ttest-error:0.13489                               \n",
      "\n",
      "[28]\ttrain-error:0.13618\ttest-error:0.13403                               \n",
      "\n",
      "[29]\ttrain-error:0.13584\ttest-error:0.13348                               \n",
      "\n",
      "[30]\ttrain-error:0.13572\ttest-error:0.13317                               \n",
      "\n",
      "[31]\ttrain-error:0.13538\ttest-error:0.13292                               \n",
      "\n",
      "[32]\ttrain-error:0.13489\ttest-error:0.13249                               \n",
      "\n",
      "[33]\ttrain-error:0.13437\ttest-error:0.13249                               \n",
      "\n",
      "[34]\ttrain-error:0.13391\ttest-error:0.13237                               \n",
      "\n",
      "[35]\ttrain-error:0.13345\ttest-error:0.13188                               \n",
      "\n",
      "[36]\ttrain-error:0.13320\ttest-error:0.13145                               \n",
      "\n",
      "[37]\ttrain-error:0.13283\ttest-error:0.13084                               \n",
      "\n",
      "[38]\ttrain-error:0.13203\ttest-error:0.13040                               \n",
      "\n",
      "[39]\ttrain-error:0.13145\ttest-error:0.13053                               \n",
      "\n",
      "[40]\ttrain-error:0.13102\ttest-error:0.12973                               \n",
      "\n",
      "[41]\ttrain-error:0.13065\ttest-error:0.12954                               \n",
      "\n",
      "[42]\ttrain-error:0.13044\ttest-error:0.12875                               \n",
      "\n",
      "[43]\ttrain-error:0.13016\ttest-error:0.12881                               \n",
      "\n",
      "[44]\ttrain-error:0.12961\ttest-error:0.12801                               \n",
      "\n",
      "[45]\ttrain-error:0.12924\ttest-error:0.12764                               \n",
      "\n",
      "[46]\ttrain-error:0.12890\ttest-error:0.12764                               \n",
      "\n",
      "[47]\ttrain-error:0.12853\ttest-error:0.12733                               \n",
      "\n",
      "[48]\ttrain-error:0.12813\ttest-error:0.12740                               \n",
      "\n",
      "[49]\ttrain-error:0.12770\ttest-error:0.12715                               \n",
      "\n",
      "[50]\ttrain-error:0.12703\ttest-error:0.12697                               \n",
      "\n",
      "[51]\ttrain-error:0.12666\ttest-error:0.12709                               \n",
      "\n",
      "[52]\ttrain-error:0.12620\ttest-error:0.12715                               \n",
      "\n",
      "[53]\ttrain-error:0.12604\ttest-error:0.12715                               \n",
      "\n",
      "[54]\ttrain-error:0.12589\ttest-error:0.12684                               \n",
      "\n",
      "[55]\ttrain-error:0.12540\ttest-error:0.12715                               \n",
      "\n",
      "[56]\ttrain-error:0.12534\ttest-error:0.12715                               \n",
      "\n",
      "[57]\ttrain-error:0.12509\ttest-error:0.12690                               \n",
      "\n",
      "[58]\ttrain-error:0.12497\ttest-error:0.12715                               \n",
      "\n",
      "[59]\ttrain-error:0.12478\ttest-error:0.12709                               \n",
      "\n",
      "[60]\ttrain-error:0.12445\ttest-error:0.12690                               \n",
      "\n",
      "[61]\ttrain-error:0.12423\ttest-error:0.12672                               \n",
      "\n",
      "[62]\ttrain-error:0.12417\ttest-error:0.12690                               \n",
      "\n",
      "[63]\ttrain-error:0.12396\ttest-error:0.12666                               \n",
      "\n",
      "[64]\ttrain-error:0.12380\ttest-error:0.12647                               \n",
      "\n",
      "[65]\ttrain-error:0.12346\ttest-error:0.12635                               \n",
      "\n",
      "[66]\ttrain-error:0.12343\ttest-error:0.12598                               \n",
      "\n",
      "[67]\ttrain-error:0.12310\ttest-error:0.12574                               \n",
      "\n",
      "[68]\ttrain-error:0.12297\ttest-error:0.12592                               \n",
      "\n",
      "[69]\ttrain-error:0.12279\ttest-error:0.12592                               \n",
      "\n",
      "[70]\ttrain-error:0.12257\ttest-error:0.12580                               \n",
      "\n",
      "[71]\ttrain-error:0.12248\ttest-error:0.12623                               \n",
      "\n",
      "[72]\ttrain-error:0.12227\ttest-error:0.12617                               \n",
      "\n",
      "[73]\ttrain-error:0.12220\ttest-error:0.12617                               \n",
      "\n",
      "[74]\ttrain-error:0.12227\ttest-error:0.12586                               \n",
      "\n",
      "[75]\ttrain-error:0.12187\ttest-error:0.12574                               \n",
      "\n",
      "[76]\ttrain-error:0.12165\ttest-error:0.12580                               \n",
      "\n",
      "[77]\ttrain-error:0.12147\ttest-error:0.12561                               \n",
      "\n",
      "[78]\ttrain-error:0.12107\ttest-error:0.12531                               \n",
      "\n",
      "[79]\ttrain-error:0.12101\ttest-error:0.12518                               \n",
      "\n",
      "[80]\ttrain-error:0.12089\ttest-error:0.12525                               \n",
      "\n",
      "[81]\ttrain-error:0.12076\ttest-error:0.12506                               \n",
      "\n",
      "[82]\ttrain-error:0.12061\ttest-error:0.12494                               \n",
      "\n",
      "[83]\ttrain-error:0.12070\ttest-error:0.12494                               \n",
      "\n",
      "[84]\ttrain-error:0.12048\ttest-error:0.12500                               \n",
      "\n",
      "[85]\ttrain-error:0.12048\ttest-error:0.12512                               \n",
      "\n",
      "[86]\ttrain-error:0.12030\ttest-error:0.12494                               \n",
      "\n",
      "[87]\ttrain-error:0.12009\ttest-error:0.12512                               \n",
      "\n",
      "[88]\ttrain-error:0.12003\ttest-error:0.12518                               \n",
      "\n",
      "[89]\ttrain-error:0.12005\ttest-error:0.12525                               \n",
      "\n",
      "[90]\ttrain-error:0.11993\ttest-error:0.12506                               \n",
      "\n",
      "[91]\ttrain-error:0.11996\ttest-error:0.12525                               \n",
      "\n",
      "[92]\ttrain-error:0.12005\ttest-error:0.12500                               \n",
      "\n",
      "[93]\ttrain-error:0.11975\ttest-error:0.12482                               \n",
      "\n",
      "[94]\ttrain-error:0.11950\ttest-error:0.12482                               \n",
      "\n",
      "[95]\ttrain-error:0.11932\ttest-error:0.12463                               \n",
      "\n",
      "[96]\ttrain-error:0.11913\ttest-error:0.12506                               \n",
      "\n",
      "[97]\ttrain-error:0.11873\ttest-error:0.12494                               \n",
      "\n",
      "[98]\ttrain-error:0.11855\ttest-error:0.12475                               \n",
      "\n",
      "[99]\ttrain-error:0.11833\ttest-error:0.12475                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.663820086986719, 'colsample_bytree': 0.714371288822609, 'eta': 0.11951241990657371, 'eval_metric': ('error',), 'extra_dims': 7, 'gamma': 0, 'lambda': 0, 'max_depth': 6, 'min_child_weight': 49.158472863483446, 'objective': 'binary:logistic', 'subsample': 0.9489639379243773}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:51:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15614\ttest-error:0.15338                                \n",
      "\n",
      "[1]\ttrain-error:0.14435\ttest-error:0.14103                                \n",
      "\n",
      "[2]\ttrain-error:0.14300\ttest-error:0.13858                                \n",
      "\n",
      "[3]\ttrain-error:0.14137\ttest-error:0.13679                                \n",
      "\n",
      "[4]\ttrain-error:0.13990\ttest-error:0.13722                                \n",
      "\n",
      "[5]\ttrain-error:0.13811\ttest-error:0.13612                                \n",
      "\n",
      "[6]\ttrain-error:0.13728\ttest-error:0.13630                                \n",
      "\n",
      "[7]\ttrain-error:0.13655\ttest-error:0.13649                                \n",
      "\n",
      "[8]\ttrain-error:0.13633\ttest-error:0.13606                                \n",
      "\n",
      "[9]\ttrain-error:0.13578\ttest-error:0.13538                                \n",
      "\n",
      "[10]\ttrain-error:0.13553\ttest-error:0.13550                               \n",
      "\n",
      "[11]\ttrain-error:0.13514\ttest-error:0.13581                               \n",
      "\n",
      "[12]\ttrain-error:0.13418\ttest-error:0.13569                               \n",
      "\n",
      "[13]\ttrain-error:0.13446\ttest-error:0.13532                               \n",
      "\n",
      "[14]\ttrain-error:0.13403\ttest-error:0.13526                               \n",
      "\n",
      "[15]\ttrain-error:0.13363\ttest-error:0.13470                               \n",
      "\n",
      "[16]\ttrain-error:0.13339\ttest-error:0.13415                               \n",
      "\n",
      "[17]\ttrain-error:0.13289\ttest-error:0.13409                               \n",
      "\n",
      "[18]\ttrain-error:0.13292\ttest-error:0.13397                               \n",
      "\n",
      "[19]\ttrain-error:0.13262\ttest-error:0.13378                               \n",
      "\n",
      "[20]\ttrain-error:0.13209\ttest-error:0.13366                               \n",
      "\n",
      "[21]\ttrain-error:0.13185\ttest-error:0.13372                               \n",
      "\n",
      "[22]\ttrain-error:0.13157\ttest-error:0.13360                               \n",
      "\n",
      "[23]\ttrain-error:0.13145\ttest-error:0.13397                               \n",
      "\n",
      "[24]\ttrain-error:0.13120\ttest-error:0.13354                               \n",
      "\n",
      "[25]\ttrain-error:0.13090\ttest-error:0.13360                               \n",
      "\n",
      "[26]\ttrain-error:0.13093\ttest-error:0.13354                               \n",
      "\n",
      "[27]\ttrain-error:0.12998\ttest-error:0.13378                               \n",
      "\n",
      "[28]\ttrain-error:0.12982\ttest-error:0.13384                               \n",
      "\n",
      "[29]\ttrain-error:0.12991\ttest-error:0.13428                               \n",
      "\n",
      "[30]\ttrain-error:0.12945\ttest-error:0.13428                               \n",
      "\n",
      "[31]\ttrain-error:0.12915\ttest-error:0.13397                               \n",
      "\n",
      "[32]\ttrain-error:0.12893\ttest-error:0.13397                               \n",
      "\n",
      "[33]\ttrain-error:0.12865\ttest-error:0.13348                               \n",
      "\n",
      "[34]\ttrain-error:0.12838\ttest-error:0.13360                               \n",
      "\n",
      "[35]\ttrain-error:0.12869\ttest-error:0.13317                               \n",
      "\n",
      "[36]\ttrain-error:0.12807\ttest-error:0.13360                               \n",
      "\n",
      "[37]\ttrain-error:0.12810\ttest-error:0.13378                               \n",
      "\n",
      "[38]\ttrain-error:0.12810\ttest-error:0.13372                               \n",
      "\n",
      "[39]\ttrain-error:0.12773\ttest-error:0.13372                               \n",
      "\n",
      "[40]\ttrain-error:0.12764\ttest-error:0.13403                               \n",
      "\n",
      "[41]\ttrain-error:0.12752\ttest-error:0.13366                               \n",
      "\n",
      "[42]\ttrain-error:0.12755\ttest-error:0.13366                               \n",
      "\n",
      "[43]\ttrain-error:0.12730\ttest-error:0.13378                               \n",
      "\n",
      "[44]\ttrain-error:0.12727\ttest-error:0.13366                               \n",
      "\n",
      "[45]\ttrain-error:0.12693\ttest-error:0.13335                               \n",
      "\n",
      "[46]\ttrain-error:0.12697\ttest-error:0.13292                               \n",
      "\n",
      "[47]\ttrain-error:0.12651\ttest-error:0.13280                               \n",
      "\n",
      "[48]\ttrain-error:0.12611\ttest-error:0.13317                               \n",
      "\n",
      "[49]\ttrain-error:0.12604\ttest-error:0.13348                               \n",
      "\n",
      "[50]\ttrain-error:0.12617\ttest-error:0.13342                               \n",
      "\n",
      "[51]\ttrain-error:0.12604\ttest-error:0.13311                               \n",
      "\n",
      "[52]\ttrain-error:0.12611\ttest-error:0.13317                               \n",
      "\n",
      "[53]\ttrain-error:0.12607\ttest-error:0.13311                               \n",
      "\n",
      "[54]\ttrain-error:0.12552\ttest-error:0.13317                               \n",
      "\n",
      "[55]\ttrain-error:0.12518\ttest-error:0.13311                               \n",
      "\n",
      "[56]\ttrain-error:0.12512\ttest-error:0.13342                               \n",
      "\n",
      "[57]\ttrain-error:0.12531\ttest-error:0.13311                               \n",
      "\n",
      "[58]\ttrain-error:0.12472\ttest-error:0.13311                               \n",
      "\n",
      "[59]\ttrain-error:0.12509\ttest-error:0.13372                               \n",
      "\n",
      "[60]\ttrain-error:0.12451\ttest-error:0.13292                               \n",
      "\n",
      "[61]\ttrain-error:0.12414\ttest-error:0.13329                               \n",
      "\n",
      "[62]\ttrain-error:0.12420\ttest-error:0.13354                               \n",
      "\n",
      "[63]\ttrain-error:0.12383\ttest-error:0.13335                               \n",
      "\n",
      "[64]\ttrain-error:0.12405\ttest-error:0.13342                               \n",
      "\n",
      "[65]\ttrain-error:0.12405\ttest-error:0.13280                               \n",
      "\n",
      "[66]\ttrain-error:0.12386\ttest-error:0.13311                               \n",
      "\n",
      "[67]\ttrain-error:0.12356\ttest-error:0.13335                               \n",
      "\n",
      "[68]\ttrain-error:0.12331\ttest-error:0.13329                               \n",
      "\n",
      "[69]\ttrain-error:0.12316\ttest-error:0.13305                               \n",
      "\n",
      "[70]\ttrain-error:0.12273\ttest-error:0.13311                               \n",
      "\n",
      "[71]\ttrain-error:0.12297\ttest-error:0.13311                               \n",
      "\n",
      "[72]\ttrain-error:0.12282\ttest-error:0.13323                               \n",
      "\n",
      "[73]\ttrain-error:0.12267\ttest-error:0.13323                               \n",
      "\n",
      "[74]\ttrain-error:0.12245\ttest-error:0.13268                               \n",
      "\n",
      "[75]\ttrain-error:0.12245\ttest-error:0.13280                               \n",
      "\n",
      "[76]\ttrain-error:0.12220\ttest-error:0.13249                               \n",
      "\n",
      "[77]\ttrain-error:0.12270\ttest-error:0.13262                               \n",
      "\n",
      "[78]\ttrain-error:0.12251\ttest-error:0.13280                               \n",
      "\n",
      "[79]\ttrain-error:0.12190\ttest-error:0.13286                               \n",
      "\n",
      "[80]\ttrain-error:0.12193\ttest-error:0.13317                               \n",
      "\n",
      "[81]\ttrain-error:0.12181\ttest-error:0.13286                               \n",
      "\n",
      "[82]\ttrain-error:0.12168\ttest-error:0.13274                               \n",
      "\n",
      "[83]\ttrain-error:0.12156\ttest-error:0.13231                               \n",
      "\n",
      "[84]\ttrain-error:0.12159\ttest-error:0.13219                               \n",
      "\n",
      "[85]\ttrain-error:0.12144\ttest-error:0.13206                               \n",
      "\n",
      "[86]\ttrain-error:0.12174\ttest-error:0.13237                               \n",
      "\n",
      "[87]\ttrain-error:0.12150\ttest-error:0.13249                               \n",
      "\n",
      "[88]\ttrain-error:0.12171\ttest-error:0.13237                               \n",
      "\n",
      "[89]\ttrain-error:0.12147\ttest-error:0.13237                               \n",
      "\n",
      "[90]\ttrain-error:0.12122\ttest-error:0.13188                               \n",
      "\n",
      "[91]\ttrain-error:0.12119\ttest-error:0.13188                               \n",
      "\n",
      "[92]\ttrain-error:0.12091\ttest-error:0.13176                               \n",
      "\n",
      "[93]\ttrain-error:0.12091\ttest-error:0.13194                               \n",
      "\n",
      "[94]\ttrain-error:0.12101\ttest-error:0.13145                               \n",
      "\n",
      "[95]\ttrain-error:0.12091\ttest-error:0.13163                               \n",
      "\n",
      "[96]\ttrain-error:0.12091\ttest-error:0.13176                               \n",
      "\n",
      "[97]\ttrain-error:0.12101\ttest-error:0.13194                               \n",
      "\n",
      "[98]\ttrain-error:0.12119\ttest-error:0.13182                               \n",
      "\n",
      "[99]\ttrain-error:0.12089\ttest-error:0.13188                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.5752628010487555, 'colsample_bytree': 0.8910910197642606, 'eta': 0.1735204467822237, 'eval_metric': ('error',), 'extra_dims': 5, 'gamma': 0, 'lambda': 0.04390889531421843, 'max_depth': 3, 'min_child_weight': 0.13490322470544913, 'objective': 'binary:logistic', 'subsample': 0.8022610996011723}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:52:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15396\ttest-error:0.15405                                \n",
      "\n",
      "[1]\ttrain-error:0.15117\ttest-error:0.14982                                \n",
      "\n",
      "[2]\ttrain-error:0.14223\ttest-error:0.14152                                \n",
      "\n",
      "[3]\ttrain-error:0.14171\ttest-error:0.13968                                \n",
      "\n",
      "[4]\ttrain-error:0.14033\ttest-error:0.13845                                \n",
      "\n",
      "[5]\ttrain-error:0.13891\ttest-error:0.13704                                \n",
      "\n",
      "[6]\ttrain-error:0.13775\ttest-error:0.13440                                \n",
      "\n",
      "[7]\ttrain-error:0.13658\ttest-error:0.13446                                \n",
      "\n",
      "[8]\ttrain-error:0.13470\ttest-error:0.13206                                \n",
      "\n",
      "[9]\ttrain-error:0.13381\ttest-error:0.13243                                \n",
      "\n",
      "[10]\ttrain-error:0.13302\ttest-error:0.13268                               \n",
      "\n",
      "[11]\ttrain-error:0.13173\ttest-error:0.13188                               \n",
      "\n",
      "[12]\ttrain-error:0.13071\ttest-error:0.13133                               \n",
      "\n",
      "[13]\ttrain-error:0.12927\ttest-error:0.13071                               \n",
      "\n",
      "[14]\ttrain-error:0.12841\ttest-error:0.13084                               \n",
      "\n",
      "[15]\ttrain-error:0.12807\ttest-error:0.13096                               \n",
      "\n",
      "[16]\ttrain-error:0.12749\ttest-error:0.13065                               \n",
      "\n",
      "[17]\ttrain-error:0.12669\ttest-error:0.13059                               \n",
      "\n",
      "[18]\ttrain-error:0.12626\ttest-error:0.12991                               \n",
      "\n",
      "[19]\ttrain-error:0.12534\ttest-error:0.12912                               \n",
      "\n",
      "[20]\ttrain-error:0.12454\ttest-error:0.12905                               \n",
      "\n",
      "[21]\ttrain-error:0.12365\ttest-error:0.12789                               \n",
      "\n",
      "[22]\ttrain-error:0.12313\ttest-error:0.12776                               \n",
      "\n",
      "[23]\ttrain-error:0.12242\ttest-error:0.12764                               \n",
      "\n",
      "[24]\ttrain-error:0.12273\ttest-error:0.12807                               \n",
      "\n",
      "[25]\ttrain-error:0.12233\ttest-error:0.12826                               \n",
      "\n",
      "[26]\ttrain-error:0.12138\ttest-error:0.12838                               \n",
      "\n",
      "[27]\ttrain-error:0.12156\ttest-error:0.12752                               \n",
      "\n",
      "[28]\ttrain-error:0.12089\ttest-error:0.12727                               \n",
      "\n",
      "[29]\ttrain-error:0.12048\ttest-error:0.12727                               \n",
      "\n",
      "[30]\ttrain-error:0.11987\ttest-error:0.12672                               \n",
      "\n",
      "[31]\ttrain-error:0.11984\ttest-error:0.12647                               \n",
      "\n",
      "[32]\ttrain-error:0.11947\ttest-error:0.12690                               \n",
      "\n",
      "[33]\ttrain-error:0.11901\ttest-error:0.12654                               \n",
      "\n",
      "[34]\ttrain-error:0.11864\ttest-error:0.12715                               \n",
      "\n",
      "[35]\ttrain-error:0.11858\ttest-error:0.12672                               \n",
      "\n",
      "[36]\ttrain-error:0.11800\ttest-error:0.12647                               \n",
      "\n",
      "[37]\ttrain-error:0.11781\ttest-error:0.12635                               \n",
      "\n",
      "[38]\ttrain-error:0.11766\ttest-error:0.12604                               \n",
      "\n",
      "[39]\ttrain-error:0.11689\ttest-error:0.12617                               \n",
      "\n",
      "[40]\ttrain-error:0.11665\ttest-error:0.12635                               \n",
      "\n",
      "[41]\ttrain-error:0.11652\ttest-error:0.12586                               \n",
      "\n",
      "[42]\ttrain-error:0.11631\ttest-error:0.12555                               \n",
      "\n",
      "[43]\ttrain-error:0.11582\ttest-error:0.12598                               \n",
      "\n",
      "[44]\ttrain-error:0.11560\ttest-error:0.12598                               \n",
      "\n",
      "[45]\ttrain-error:0.11511\ttest-error:0.12647                               \n",
      "\n",
      "[46]\ttrain-error:0.11514\ttest-error:0.12617                               \n",
      "\n",
      "[47]\ttrain-error:0.11499\ttest-error:0.12641                               \n",
      "\n",
      "[48]\ttrain-error:0.11499\ttest-error:0.12641                               \n",
      "\n",
      "[49]\ttrain-error:0.11471\ttest-error:0.12672                               \n",
      "\n",
      "[50]\ttrain-error:0.11422\ttest-error:0.12568                               \n",
      "\n",
      "[51]\ttrain-error:0.11367\ttest-error:0.12592                               \n",
      "\n",
      "[52]\ttrain-error:0.11373\ttest-error:0.12574                               \n",
      "\n",
      "[53]\ttrain-error:0.11388\ttest-error:0.12629                               \n",
      "\n",
      "[54]\ttrain-error:0.11376\ttest-error:0.12598                               \n",
      "\n",
      "[55]\ttrain-error:0.11311\ttest-error:0.12623                               \n",
      "\n",
      "[56]\ttrain-error:0.11275\ttest-error:0.12617                               \n",
      "\n",
      "[57]\ttrain-error:0.11321\ttest-error:0.12568                               \n",
      "\n",
      "[58]\ttrain-error:0.11296\ttest-error:0.12574                               \n",
      "\n",
      "[59]\ttrain-error:0.11281\ttest-error:0.12611                               \n",
      "\n",
      "[60]\ttrain-error:0.11176\ttest-error:0.12690                               \n",
      "\n",
      "[61]\ttrain-error:0.11170\ttest-error:0.12690                               \n",
      "\n",
      "[62]\ttrain-error:0.11170\ttest-error:0.12709                               \n",
      "\n",
      "[63]\ttrain-error:0.11121\ttest-error:0.12709                               \n",
      "\n",
      "[64]\ttrain-error:0.11106\ttest-error:0.12709                               \n",
      "\n",
      "[65]\ttrain-error:0.11103\ttest-error:0.12727                               \n",
      "\n",
      "[66]\ttrain-error:0.11066\ttest-error:0.12733                               \n",
      "\n",
      "[67]\ttrain-error:0.11038\ttest-error:0.12703                               \n",
      "\n",
      "[68]\ttrain-error:0.11050\ttest-error:0.12727                               \n",
      "\n",
      "[69]\ttrain-error:0.11038\ttest-error:0.12721                               \n",
      "\n",
      "[70]\ttrain-error:0.10998\ttest-error:0.12721                               \n",
      "\n",
      "[71]\ttrain-error:0.11020\ttest-error:0.12721                               \n",
      "\n",
      "[72]\ttrain-error:0.10989\ttest-error:0.12690                               \n",
      "\n",
      "[73]\ttrain-error:0.10961\ttest-error:0.12629                               \n",
      "\n",
      "[74]\ttrain-error:0.10927\ttest-error:0.12660                               \n",
      "\n",
      "[75]\ttrain-error:0.10894\ttest-error:0.12721                               \n",
      "\n",
      "[76]\ttrain-error:0.10866\ttest-error:0.12740                               \n",
      "\n",
      "[77]\ttrain-error:0.10829\ttest-error:0.12783                               \n",
      "\n",
      "[78]\ttrain-error:0.10854\ttest-error:0.12789                               \n",
      "\n",
      "[79]\ttrain-error:0.10826\ttest-error:0.12795                               \n",
      "\n",
      "[80]\ttrain-error:0.10792\ttest-error:0.12807                               \n",
      "\n",
      "[81]\ttrain-error:0.10783\ttest-error:0.12801                               \n",
      "\n",
      "[82]\ttrain-error:0.10749\ttest-error:0.12844                               \n",
      "\n",
      "[83]\ttrain-error:0.10709\ttest-error:0.12918                               \n",
      "\n",
      "[84]\ttrain-error:0.10716\ttest-error:0.12899                               \n",
      "\n",
      "[85]\ttrain-error:0.10679\ttest-error:0.12905                               \n",
      "\n",
      "[86]\ttrain-error:0.10654\ttest-error:0.12924                               \n",
      "\n",
      "[87]\ttrain-error:0.10639\ttest-error:0.13004                               \n",
      "\n",
      "[88]\ttrain-error:0.10614\ttest-error:0.12973                               \n",
      "\n",
      "[89]\ttrain-error:0.10605\ttest-error:0.12991                               \n",
      "\n",
      "[90]\ttrain-error:0.10587\ttest-error:0.12998                               \n",
      "\n",
      "[91]\ttrain-error:0.10605\ttest-error:0.13016                               \n",
      "\n",
      "[92]\ttrain-error:0.10565\ttest-error:0.12998                               \n",
      "\n",
      "[93]\ttrain-error:0.10583\ttest-error:0.12998                               \n",
      "\n",
      "[94]\ttrain-error:0.10553\ttest-error:0.13016                               \n",
      "\n",
      "[95]\ttrain-error:0.10559\ttest-error:0.12998                               \n",
      "\n",
      "[96]\ttrain-error:0.10556\ttest-error:0.12979                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97]\ttrain-error:0.10497\ttest-error:0.12961                               \n",
      "\n",
      "[98]\ttrain-error:0.10451\ttest-error:0.12961                               \n",
      "\n",
      "[99]\ttrain-error:0.10470\ttest-error:0.12918                               \n",
      "\n",
      "{'alpha': 0.0006581333853152834, 'btype': 'R', 'colsample_bylevel': 0.7331919478847185, 'colsample_bytree': 0.5824141136123185, 'eta': 0.45144860067352965, 'eval_metric': ('error',), 'extra_dims': 2, 'gamma': 0, 'lambda': 0.23403079161000526, 'max_depth': 5, 'min_child_weight': 0.03052457800675896, 'objective': 'binary:logistic', 'subsample': 0.8821742880892252}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:53:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15378\ttest-error:0.15356                                \n",
      "\n",
      "[1]\ttrain-error:0.13993\ttest-error:0.13986                                \n",
      "\n",
      "[2]\ttrain-error:0.13667\ttest-error:0.13581                                \n",
      "\n",
      "[3]\ttrain-error:0.13332\ttest-error:0.13384                                \n",
      "\n",
      "[4]\ttrain-error:0.13004\ttest-error:0.13335                                \n",
      "\n",
      "[5]\ttrain-error:0.12697\ttest-error:0.13126                                \n",
      "\n",
      "[6]\ttrain-error:0.12463\ttest-error:0.13065                                \n",
      "\n",
      "[7]\ttrain-error:0.12316\ttest-error:0.13040                                \n",
      "\n",
      "[8]\ttrain-error:0.12089\ttest-error:0.12826                                \n",
      "\n",
      "[9]\ttrain-error:0.11990\ttest-error:0.12832                                \n",
      "\n",
      "[10]\ttrain-error:0.11889\ttest-error:0.12715                               \n",
      "\n",
      "[11]\ttrain-error:0.11747\ttest-error:0.12740                               \n",
      "\n",
      "[12]\ttrain-error:0.11603\ttest-error:0.12697                               \n",
      "\n",
      "[13]\ttrain-error:0.11545\ttest-error:0.12703                               \n",
      "\n",
      "[14]\ttrain-error:0.11447\ttest-error:0.12690                               \n",
      "\n",
      "[15]\ttrain-error:0.11428\ttest-error:0.12672                               \n",
      "\n",
      "[16]\ttrain-error:0.11330\ttest-error:0.12641                               \n",
      "\n",
      "[17]\ttrain-error:0.11216\ttest-error:0.12611                               \n",
      "\n",
      "[18]\ttrain-error:0.11121\ttest-error:0.12752                               \n",
      "\n",
      "[19]\ttrain-error:0.11032\ttest-error:0.12684                               \n",
      "\n",
      "[20]\ttrain-error:0.10998\ttest-error:0.12715                               \n",
      "\n",
      "[21]\ttrain-error:0.11010\ttest-error:0.12715                               \n",
      "\n",
      "[22]\ttrain-error:0.10977\ttest-error:0.12752                               \n",
      "\n",
      "[23]\ttrain-error:0.10924\ttest-error:0.12789                               \n",
      "\n",
      "[24]\ttrain-error:0.10878\ttest-error:0.12758                               \n",
      "\n",
      "[25]\ttrain-error:0.10851\ttest-error:0.12801                               \n",
      "\n",
      "[26]\ttrain-error:0.10805\ttest-error:0.12764                               \n",
      "\n",
      "[27]\ttrain-error:0.10762\ttest-error:0.12801                               \n",
      "\n",
      "[28]\ttrain-error:0.10697\ttest-error:0.12832                               \n",
      "\n",
      "[29]\ttrain-error:0.10617\ttest-error:0.12826                               \n",
      "\n",
      "[30]\ttrain-error:0.10577\ttest-error:0.12770                               \n",
      "\n",
      "[31]\ttrain-error:0.10485\ttest-error:0.12813                               \n",
      "\n",
      "[32]\ttrain-error:0.10418\ttest-error:0.12783                               \n",
      "\n",
      "[33]\ttrain-error:0.10298\ttest-error:0.12697                               \n",
      "\n",
      "[34]\ttrain-error:0.10218\ttest-error:0.12752                               \n",
      "\n",
      "[35]\ttrain-error:0.10135\ttest-error:0.12783                               \n",
      "\n",
      "[36]\ttrain-error:0.10043\ttest-error:0.12862                               \n",
      "\n",
      "[37]\ttrain-error:0.09954\ttest-error:0.12905                               \n",
      "\n",
      "[38]\ttrain-error:0.09896\ttest-error:0.12838                               \n",
      "\n",
      "[39]\ttrain-error:0.09782\ttest-error:0.12918                               \n",
      "\n",
      "[40]\ttrain-error:0.09745\ttest-error:0.12893                               \n",
      "\n",
      "[41]\ttrain-error:0.09730\ttest-error:0.12942                               \n",
      "\n",
      "[42]\ttrain-error:0.09616\ttest-error:0.12985                               \n",
      "\n",
      "[43]\ttrain-error:0.09592\ttest-error:0.12967                               \n",
      "\n",
      "[44]\ttrain-error:0.09545\ttest-error:0.12881                               \n",
      "\n",
      "[45]\ttrain-error:0.09490\ttest-error:0.12948                               \n",
      "\n",
      "[46]\ttrain-error:0.09389\ttest-error:0.12905                               \n",
      "\n",
      "[47]\ttrain-error:0.09346\ttest-error:0.12967                               \n",
      "\n",
      "[48]\ttrain-error:0.09272\ttest-error:0.13004                               \n",
      "\n",
      "[49]\ttrain-error:0.09229\ttest-error:0.13059                               \n",
      "\n",
      "[50]\ttrain-error:0.09229\ttest-error:0.12991                               \n",
      "\n",
      "[51]\ttrain-error:0.09174\ttest-error:0.13053                               \n",
      "\n",
      "[52]\ttrain-error:0.09128\ttest-error:0.13059                               \n",
      "\n",
      "[53]\ttrain-error:0.09082\ttest-error:0.13004                               \n",
      "\n",
      "[54]\ttrain-error:0.09051\ttest-error:0.12985                               \n",
      "\n",
      "[55]\ttrain-error:0.09002\ttest-error:0.12973                               \n",
      "\n",
      "[56]\ttrain-error:0.08907\ttest-error:0.13096                               \n",
      "\n",
      "[57]\ttrain-error:0.08861\ttest-error:0.13139                               \n",
      "\n",
      "[58]\ttrain-error:0.08793\ttest-error:0.13157                               \n",
      "\n",
      "[59]\ttrain-error:0.08722\ttest-error:0.13280                               \n",
      "\n",
      "[60]\ttrain-error:0.08707\ttest-error:0.13200                               \n",
      "\n",
      "[61]\ttrain-error:0.08655\ttest-error:0.13225                               \n",
      "\n",
      "[62]\ttrain-error:0.08590\ttest-error:0.13206                               \n",
      "\n",
      "[63]\ttrain-error:0.08584\ttest-error:0.13256                               \n",
      "\n",
      "[64]\ttrain-error:0.08529\ttest-error:0.13268                               \n",
      "\n",
      "[65]\ttrain-error:0.08471\ttest-error:0.13342                               \n",
      "\n",
      "[66]\ttrain-error:0.08471\ttest-error:0.13366                               \n",
      "\n",
      "[67]\ttrain-error:0.08354\ttest-error:0.13372                               \n",
      "\n",
      "[68]\ttrain-error:0.08323\ttest-error:0.13397                               \n",
      "\n",
      "[69]\ttrain-error:0.08259\ttest-error:0.13397                               \n",
      "\n",
      "[70]\ttrain-error:0.08222\ttest-error:0.13415                               \n",
      "\n",
      "[71]\ttrain-error:0.08188\ttest-error:0.13446                               \n",
      "\n",
      "[72]\ttrain-error:0.08163\ttest-error:0.13452                               \n",
      "\n",
      "[73]\ttrain-error:0.08102\ttest-error:0.13421                               \n",
      "\n",
      "[74]\ttrain-error:0.08050\ttest-error:0.13366                               \n",
      "\n",
      "[75]\ttrain-error:0.07982\ttest-error:0.13403                               \n",
      "\n",
      "[76]\ttrain-error:0.07915\ttest-error:0.13391                               \n",
      "\n",
      "[77]\ttrain-error:0.07936\ttest-error:0.13354                               \n",
      "\n",
      "[78]\ttrain-error:0.07878\ttest-error:0.13403                               \n",
      "\n",
      "[79]\ttrain-error:0.07792\ttest-error:0.13298                               \n",
      "\n",
      "[80]\ttrain-error:0.07746\ttest-error:0.13391                               \n",
      "\n",
      "[81]\ttrain-error:0.07727\ttest-error:0.13311                               \n",
      "\n",
      "[82]\ttrain-error:0.07660\ttest-error:0.13360                               \n",
      "\n",
      "[83]\ttrain-error:0.07601\ttest-error:0.13329                               \n",
      "\n",
      "[84]\ttrain-error:0.07558\ttest-error:0.13360                               \n",
      "\n",
      "[85]\ttrain-error:0.07543\ttest-error:0.13311                               \n",
      "\n",
      "[86]\ttrain-error:0.07482\ttest-error:0.13415                               \n",
      "\n",
      "[87]\ttrain-error:0.07466\ttest-error:0.13458                               \n",
      "\n",
      "[88]\ttrain-error:0.07494\ttest-error:0.13464                               \n",
      "\n",
      "[89]\ttrain-error:0.07472\ttest-error:0.13415                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90]\ttrain-error:0.07414\ttest-error:0.13470                               \n",
      "\n",
      "[91]\ttrain-error:0.07408\ttest-error:0.13348                               \n",
      "\n",
      "[92]\ttrain-error:0.07353\ttest-error:0.13409                               \n",
      "\n",
      "[93]\ttrain-error:0.07325\ttest-error:0.13483                               \n",
      "\n",
      "[94]\ttrain-error:0.07239\ttest-error:0.13514                               \n",
      "\n",
      "[95]\ttrain-error:0.07221\ttest-error:0.13507                               \n",
      "\n",
      "[96]\ttrain-error:0.07147\ttest-error:0.13434                               \n",
      "\n",
      "[97]\ttrain-error:0.07107\ttest-error:0.13452                               \n",
      "\n",
      "[98]\ttrain-error:0.07067\ttest-error:0.13428                               \n",
      "\n",
      "[99]\ttrain-error:0.06996\ttest-error:0.13495                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.7828279941855758, 'colsample_bytree': 0.8376490184603514, 'eta': 0.13934345248614477, 'eval_metric': ('error',), 'extra_dims': 14, 'gamma': 0, 'lambda': 0.10983018751315067, 'max_depth': 2, 'min_child_weight': 0.50481579165408, 'objective': 'binary:logistic', 'subsample': 0.5314592917053274}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:53:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15983\ttest-error:0.16032                                \n",
      "\n",
      "[1]\ttrain-error:0.18854\ttest-error:0.18894                                \n",
      "\n",
      "[2]\ttrain-error:0.15104\ttest-error:0.15111                                \n",
      "\n",
      "[3]\ttrain-error:0.18062\ttest-error:0.18004                                \n",
      "\n",
      "[4]\ttrain-error:0.16837\ttest-error:0.16751                                \n",
      "\n",
      "[5]\ttrain-error:0.22577\ttest-error:0.22936                                \n",
      "\n",
      "[6]\ttrain-error:0.18901\ttest-error:0.18710                                \n",
      "\n",
      "[7]\ttrain-error:0.32715\ttest-error:0.32887                                \n",
      "\n",
      "[8]\ttrain-error:0.23256\ttest-error:0.22832                                \n",
      "\n",
      "[9]\ttrain-error:0.75617\ttest-error:0.75970                                \n",
      "\n",
      "[10]\ttrain-error:0.29097\ttest-error:0.28876                               \n",
      "\n",
      "[11]\ttrain-error:0.49730\ttest-error:0.49552                               \n",
      "\n",
      "[12]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[13]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[14]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[15]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[16]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[17]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[18]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[19]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[20]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[21]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[22]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[23]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[24]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[25]\ttrain-error:0.73169\ttest-error:0.73397                               \n",
      "\n",
      "[26]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[27]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[28]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[29]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[30]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[31]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[32]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[33]\ttrain-error:0.49730\ttest-error:0.49552                               \n",
      "\n",
      "[34]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[35]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[36]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[37]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[38]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[39]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[40]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[41]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[42]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[43]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[44]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[45]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[46]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[47]\ttrain-error:0.60362\ttest-error:0.59945                               \n",
      "\n",
      "[48]\ttrain-error:0.36901\ttest-error:0.36769                               \n",
      "\n",
      "[49]\ttrain-error:0.50163\ttest-error:0.50080                               \n",
      "\n",
      "[50]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[51]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[52]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[53]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[54]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[55]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[56]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[57]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[58]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[59]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[60]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[61]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[62]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[63]\ttrain-error:0.72239\ttest-error:0.72383                               \n",
      "\n",
      "[64]\ttrain-error:0.49426\ttest-error:0.49300                               \n",
      "\n",
      "[65]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[66]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[67]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[68]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[69]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[70]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[71]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[72]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[73]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[74]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[75]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[76]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[77]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[78]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[79]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[80]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[81]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[82]\ttrain-error:0.52822\ttest-error:0.53163                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[84]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[85]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[86]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[87]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[88]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[89]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[90]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[91]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[92]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "[93]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[94]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[95]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[96]\ttrain-error:0.71253\ttest-error:0.71892                               \n",
      "\n",
      "[97]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[98]\ttrain-error:0.24082\ttest-error:0.23624                               \n",
      "\n",
      "[99]\ttrain-error:0.75918\ttest-error:0.76376                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'R', 'colsample_bylevel': 0.5021019182611393, 'colsample_bytree': 0.6708400251262667, 'eta': 0.00854407524475244, 'eval_metric': ('error',), 'extra_dims': 10, 'gamma': 0, 'lambda': 0.06441719470006921, 'max_depth': 9, 'min_child_weight': 0.004226343018372277, 'objective': 'binary:logistic', 'subsample': 0.7783718464580859}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:54:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13096\ttest-error:0.13428                                \n",
      "\n",
      "[1]\ttrain-error:0.12976\ttest-error:0.13360                                \n",
      "\n",
      "[2]\ttrain-error:0.12921\ttest-error:0.13470                                \n",
      "\n",
      "[3]\ttrain-error:0.12973\ttest-error:0.13477                                \n",
      "\n",
      "[4]\ttrain-error:0.12948\ttest-error:0.13520                                \n",
      "\n",
      "[5]\ttrain-error:0.12924\ttest-error:0.13520                                \n",
      "\n",
      "[6]\ttrain-error:0.12912\ttest-error:0.13526                                \n",
      "\n",
      "[7]\ttrain-error:0.12835\ttest-error:0.13458                                \n",
      "\n",
      "[8]\ttrain-error:0.12779\ttest-error:0.13415                                \n",
      "\n",
      "[9]\ttrain-error:0.12749\ttest-error:0.13360                                \n",
      "\n",
      "[10]\ttrain-error:0.12684\ttest-error:0.13342                               \n",
      "\n",
      "[11]\ttrain-error:0.12644\ttest-error:0.13354                               \n",
      "\n",
      "[12]\ttrain-error:0.12577\ttest-error:0.13366                               \n",
      "\n",
      "[13]\ttrain-error:0.12549\ttest-error:0.13317                               \n",
      "\n",
      "[14]\ttrain-error:0.12497\ttest-error:0.13292                               \n",
      "\n",
      "[15]\ttrain-error:0.12469\ttest-error:0.13268                               \n",
      "\n",
      "[16]\ttrain-error:0.12371\ttest-error:0.13225                               \n",
      "\n",
      "[17]\ttrain-error:0.12337\ttest-error:0.13170                               \n",
      "\n",
      "[18]\ttrain-error:0.12297\ttest-error:0.13145                               \n",
      "\n",
      "[19]\ttrain-error:0.12245\ttest-error:0.13102                               \n",
      "\n",
      "[20]\ttrain-error:0.12190\ttest-error:0.13047                               \n",
      "\n",
      "[21]\ttrain-error:0.12150\ttest-error:0.13028                               \n",
      "\n",
      "[22]\ttrain-error:0.12089\ttest-error:0.13022                               \n",
      "\n",
      "[23]\ttrain-error:0.12046\ttest-error:0.13016                               \n",
      "\n",
      "[24]\ttrain-error:0.12009\ttest-error:0.13040                               \n",
      "\n",
      "[25]\ttrain-error:0.11960\ttest-error:0.12998                               \n",
      "\n",
      "[26]\ttrain-error:0.11935\ttest-error:0.12973                               \n",
      "\n",
      "[27]\ttrain-error:0.11916\ttest-error:0.12948                               \n",
      "\n",
      "[28]\ttrain-error:0.11904\ttest-error:0.12930                               \n",
      "\n",
      "[29]\ttrain-error:0.11794\ttest-error:0.12918                               \n",
      "\n",
      "[30]\ttrain-error:0.11732\ttest-error:0.12893                               \n",
      "\n",
      "[31]\ttrain-error:0.11717\ttest-error:0.12887                               \n",
      "\n",
      "[32]\ttrain-error:0.11671\ttest-error:0.12875                               \n",
      "\n",
      "[33]\ttrain-error:0.11649\ttest-error:0.12832                               \n",
      "\n",
      "[34]\ttrain-error:0.11603\ttest-error:0.12862                               \n",
      "\n",
      "[35]\ttrain-error:0.11557\ttest-error:0.12819                               \n",
      "\n",
      "[36]\ttrain-error:0.11511\ttest-error:0.12838                               \n",
      "\n",
      "[37]\ttrain-error:0.11447\ttest-error:0.12807                               \n",
      "\n",
      "[38]\ttrain-error:0.11431\ttest-error:0.12783                               \n",
      "\n",
      "[39]\ttrain-error:0.11400\ttest-error:0.12776                               \n",
      "\n",
      "[40]\ttrain-error:0.11342\ttest-error:0.12746                               \n",
      "\n",
      "[41]\ttrain-error:0.11333\ttest-error:0.12752                               \n",
      "\n",
      "[42]\ttrain-error:0.11290\ttest-error:0.12746                               \n",
      "\n",
      "[43]\ttrain-error:0.11262\ttest-error:0.12764                               \n",
      "\n",
      "[44]\ttrain-error:0.11241\ttest-error:0.12721                               \n",
      "\n",
      "[45]\ttrain-error:0.11201\ttest-error:0.12684                               \n",
      "\n",
      "[46]\ttrain-error:0.11161\ttest-error:0.12647                               \n",
      "\n",
      "[47]\ttrain-error:0.11149\ttest-error:0.12660                               \n",
      "\n",
      "[48]\ttrain-error:0.11106\ttest-error:0.12678                               \n",
      "\n",
      "[49]\ttrain-error:0.11084\ttest-error:0.12666                               \n",
      "\n",
      "[50]\ttrain-error:0.11069\ttest-error:0.12678                               \n",
      "\n",
      "[51]\ttrain-error:0.11041\ttest-error:0.12678                               \n",
      "\n",
      "[52]\ttrain-error:0.11001\ttest-error:0.12635                               \n",
      "\n",
      "[53]\ttrain-error:0.10964\ttest-error:0.12666                               \n",
      "\n",
      "[54]\ttrain-error:0.10934\ttest-error:0.12598                               \n",
      "\n",
      "[55]\ttrain-error:0.10903\ttest-error:0.12641                               \n",
      "\n",
      "[56]\ttrain-error:0.10848\ttest-error:0.12647                               \n",
      "\n",
      "[57]\ttrain-error:0.10841\ttest-error:0.12641                               \n",
      "\n",
      "[58]\ttrain-error:0.10838\ttest-error:0.12647                               \n",
      "\n",
      "[59]\ttrain-error:0.10820\ttest-error:0.12629                               \n",
      "\n",
      "[60]\ttrain-error:0.10783\ttest-error:0.12592                               \n",
      "\n",
      "[61]\ttrain-error:0.10746\ttest-error:0.12561                               \n",
      "\n",
      "[62]\ttrain-error:0.10712\ttest-error:0.12611                               \n",
      "\n",
      "[63]\ttrain-error:0.10709\ttest-error:0.12623                               \n",
      "\n",
      "[64]\ttrain-error:0.10679\ttest-error:0.12635                               \n",
      "\n",
      "[65]\ttrain-error:0.10663\ttest-error:0.12635                               \n",
      "\n",
      "[66]\ttrain-error:0.10639\ttest-error:0.12623                               \n",
      "\n",
      "[67]\ttrain-error:0.10633\ttest-error:0.12604                               \n",
      "\n",
      "[68]\ttrain-error:0.10602\ttest-error:0.12629                               \n",
      "\n",
      "[69]\ttrain-error:0.10599\ttest-error:0.12660                               \n",
      "\n",
      "[70]\ttrain-error:0.10577\ttest-error:0.12660                               \n",
      "\n",
      "[71]\ttrain-error:0.10574\ttest-error:0.12654                               \n",
      "\n",
      "[72]\ttrain-error:0.10547\ttest-error:0.12635                               \n",
      "\n",
      "[73]\ttrain-error:0.10544\ttest-error:0.12635                               \n",
      "\n",
      "[74]\ttrain-error:0.10504\ttest-error:0.12647                               \n",
      "\n",
      "[75]\ttrain-error:0.10458\ttest-error:0.12635                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76]\ttrain-error:0.10436\ttest-error:0.12629                               \n",
      "\n",
      "[77]\ttrain-error:0.10396\ttest-error:0.12654                               \n",
      "\n",
      "[78]\ttrain-error:0.10362\ttest-error:0.12641                               \n",
      "\n",
      "[79]\ttrain-error:0.10353\ttest-error:0.12623                               \n",
      "\n",
      "[80]\ttrain-error:0.10332\ttest-error:0.12617                               \n",
      "\n",
      "[81]\ttrain-error:0.10322\ttest-error:0.12611                               \n",
      "\n",
      "[82]\ttrain-error:0.10261\ttest-error:0.12598                               \n",
      "\n",
      "[83]\ttrain-error:0.10258\ttest-error:0.12611                               \n",
      "\n",
      "[84]\ttrain-error:0.10215\ttest-error:0.12617                               \n",
      "\n",
      "[85]\ttrain-error:0.10206\ttest-error:0.12617                               \n",
      "\n",
      "[86]\ttrain-error:0.10175\ttest-error:0.12598                               \n",
      "\n",
      "[87]\ttrain-error:0.10129\ttest-error:0.12629                               \n",
      "\n",
      "[88]\ttrain-error:0.10086\ttest-error:0.12654                               \n",
      "\n",
      "[89]\ttrain-error:0.10058\ttest-error:0.12654                               \n",
      "\n",
      "[90]\ttrain-error:0.10037\ttest-error:0.12666                               \n",
      "\n",
      "[91]\ttrain-error:0.10025\ttest-error:0.12635                               \n",
      "\n",
      "[92]\ttrain-error:0.10003\ttest-error:0.12635                               \n",
      "\n",
      "[93]\ttrain-error:0.09960\ttest-error:0.12635                               \n",
      "\n",
      "[94]\ttrain-error:0.09954\ttest-error:0.12617                               \n",
      "\n",
      "[95]\ttrain-error:0.09929\ttest-error:0.12641                               \n",
      "\n",
      "[96]\ttrain-error:0.09896\ttest-error:0.12635                               \n",
      "\n",
      "[97]\ttrain-error:0.09892\ttest-error:0.12629                               \n",
      "\n",
      "[98]\ttrain-error:0.09874\ttest-error:0.12629                               \n",
      "\n",
      "[99]\ttrain-error:0.09825\ttest-error:0.12635                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.8898731088812945, 'colsample_bytree': 0.8528242743103842, 'eta': 0.021539011659643063, 'eval_metric': ('error',), 'extra_dims': 15, 'gamma': 0, 'lambda': 0, 'max_depth': 8, 'min_child_weight': 0.2888336734021333, 'objective': 'binary:logistic', 'subsample': 0.5718417290814761}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:56:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13560\ttest-error:0.13636                                \n",
      "\n",
      "[1]\ttrain-error:0.13498\ttest-error:0.13649                                \n",
      "\n",
      "[2]\ttrain-error:0.13259\ttest-error:0.13520                                \n",
      "\n",
      "[3]\ttrain-error:0.13037\ttest-error:0.13249                                \n",
      "\n",
      "[4]\ttrain-error:0.12872\ttest-error:0.13090                                \n",
      "\n",
      "[5]\ttrain-error:0.12697\ttest-error:0.12954                                \n",
      "\n",
      "[6]\ttrain-error:0.12589\ttest-error:0.12942                                \n",
      "\n",
      "[7]\ttrain-error:0.12414\ttest-error:0.12899                                \n",
      "\n",
      "[8]\ttrain-error:0.12300\ttest-error:0.12721                                \n",
      "\n",
      "[9]\ttrain-error:0.12233\ttest-error:0.12703                                \n",
      "\n",
      "[10]\ttrain-error:0.12125\ttest-error:0.12678                               \n",
      "\n",
      "[11]\ttrain-error:0.12012\ttest-error:0.12678                               \n",
      "\n",
      "[12]\ttrain-error:0.11926\ttest-error:0.12684                               \n",
      "\n",
      "[13]\ttrain-error:0.11754\ttest-error:0.12592                               \n",
      "\n",
      "[14]\ttrain-error:0.11619\ttest-error:0.12604                               \n",
      "\n",
      "[15]\ttrain-error:0.11576\ttest-error:0.12604                               \n",
      "\n",
      "[16]\ttrain-error:0.11514\ttest-error:0.12611                               \n",
      "\n",
      "[17]\ttrain-error:0.11431\ttest-error:0.12598                               \n",
      "\n",
      "[18]\ttrain-error:0.11351\ttest-error:0.12604                               \n",
      "\n",
      "[19]\ttrain-error:0.11265\ttest-error:0.12549                               \n",
      "\n",
      "[20]\ttrain-error:0.11204\ttest-error:0.12604                               \n",
      "\n",
      "[21]\ttrain-error:0.11099\ttest-error:0.12580                               \n",
      "\n",
      "[22]\ttrain-error:0.11010\ttest-error:0.12568                               \n",
      "\n",
      "[23]\ttrain-error:0.10955\ttest-error:0.12623                               \n",
      "\n",
      "[24]\ttrain-error:0.10851\ttest-error:0.12641                               \n",
      "\n",
      "[25]\ttrain-error:0.10808\ttest-error:0.12690                               \n",
      "\n",
      "[26]\ttrain-error:0.10679\ttest-error:0.12672                               \n",
      "\n",
      "[27]\ttrain-error:0.10587\ttest-error:0.12623                               \n",
      "\n",
      "[28]\ttrain-error:0.10516\ttest-error:0.12586                               \n",
      "\n",
      "[29]\ttrain-error:0.10458\ttest-error:0.12592                               \n",
      "\n",
      "[30]\ttrain-error:0.10408\ttest-error:0.12617                               \n",
      "\n",
      "[31]\ttrain-error:0.10347\ttest-error:0.12623                               \n",
      "\n",
      "[32]\ttrain-error:0.10286\ttest-error:0.12678                               \n",
      "\n",
      "[33]\ttrain-error:0.10273\ttest-error:0.12697                               \n",
      "\n",
      "[34]\ttrain-error:0.10209\ttest-error:0.12666                               \n",
      "\n",
      "[35]\ttrain-error:0.10166\ttest-error:0.12666                               \n",
      "\n",
      "[36]\ttrain-error:0.10086\ttest-error:0.12697                               \n",
      "\n",
      "[37]\ttrain-error:0.10049\ttest-error:0.12647                               \n",
      "\n",
      "[38]\ttrain-error:0.09994\ttest-error:0.12617                               \n",
      "\n",
      "[39]\ttrain-error:0.09948\ttest-error:0.12623                               \n",
      "\n",
      "[40]\ttrain-error:0.09874\ttest-error:0.12654                               \n",
      "\n",
      "[41]\ttrain-error:0.09828\ttest-error:0.12666                               \n",
      "\n",
      "[42]\ttrain-error:0.09754\ttest-error:0.12678                               \n",
      "\n",
      "[43]\ttrain-error:0.09708\ttest-error:0.12623                               \n",
      "\n",
      "[44]\ttrain-error:0.09613\ttest-error:0.12678                               \n",
      "\n",
      "[45]\ttrain-error:0.09561\ttest-error:0.12623                               \n",
      "\n",
      "[46]\ttrain-error:0.09496\ttest-error:0.12678                               \n",
      "\n",
      "[47]\ttrain-error:0.09370\ttest-error:0.12715                               \n",
      "\n",
      "[48]\ttrain-error:0.09355\ttest-error:0.12690                               \n",
      "\n",
      "[49]\ttrain-error:0.09324\ttest-error:0.12690                               \n",
      "\n",
      "[50]\ttrain-error:0.09248\ttest-error:0.12697                               \n",
      "\n",
      "[51]\ttrain-error:0.09171\ttest-error:0.12660                               \n",
      "\n",
      "[52]\ttrain-error:0.09109\ttest-error:0.12684                               \n",
      "\n",
      "[53]\ttrain-error:0.09002\ttest-error:0.12709                               \n",
      "\n",
      "[54]\ttrain-error:0.08993\ttest-error:0.12715                               \n",
      "\n",
      "[55]\ttrain-error:0.08904\ttest-error:0.12764                               \n",
      "\n",
      "[56]\ttrain-error:0.08827\ttest-error:0.12789                               \n",
      "\n",
      "[57]\ttrain-error:0.08787\ttest-error:0.12801                               \n",
      "\n",
      "[58]\ttrain-error:0.08765\ttest-error:0.12801                               \n",
      "\n",
      "[59]\ttrain-error:0.08686\ttest-error:0.12807                               \n",
      "\n",
      "[60]\ttrain-error:0.08636\ttest-error:0.12856                               \n",
      "\n",
      "[61]\ttrain-error:0.08600\ttest-error:0.12795                               \n",
      "\n",
      "[62]\ttrain-error:0.08560\ttest-error:0.12826                               \n",
      "\n",
      "[63]\ttrain-error:0.08486\ttest-error:0.12795                               \n",
      "\n",
      "[64]\ttrain-error:0.08440\ttest-error:0.12826                               \n",
      "\n",
      "[65]\ttrain-error:0.08406\ttest-error:0.12832                               \n",
      "\n",
      "[66]\ttrain-error:0.08360\ttest-error:0.12869                               \n",
      "\n",
      "[67]\ttrain-error:0.08283\ttest-error:0.12887                               \n",
      "\n",
      "[68]\ttrain-error:0.08256\ttest-error:0.12850                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69]\ttrain-error:0.08197\ttest-error:0.12881                               \n",
      "\n",
      "[70]\ttrain-error:0.08185\ttest-error:0.12875                               \n",
      "\n",
      "[71]\ttrain-error:0.08114\ttest-error:0.12893                               \n",
      "\n",
      "[72]\ttrain-error:0.08022\ttest-error:0.12887                               \n",
      "\n",
      "[73]\ttrain-error:0.07948\ttest-error:0.12875                               \n",
      "\n",
      "[74]\ttrain-error:0.07909\ttest-error:0.12862                               \n",
      "\n",
      "[75]\ttrain-error:0.07844\ttest-error:0.12912                               \n",
      "\n",
      "[76]\ttrain-error:0.07783\ttest-error:0.12912                               \n",
      "\n",
      "[77]\ttrain-error:0.07761\ttest-error:0.12887                               \n",
      "\n",
      "[78]\ttrain-error:0.07678\ttest-error:0.12893                               \n",
      "\n",
      "[79]\ttrain-error:0.07666\ttest-error:0.12918                               \n",
      "\n",
      "[80]\ttrain-error:0.07654\ttest-error:0.12948                               \n",
      "\n",
      "[81]\ttrain-error:0.07583\ttest-error:0.12967                               \n",
      "\n",
      "[82]\ttrain-error:0.07555\ttest-error:0.13004                               \n",
      "\n",
      "[83]\ttrain-error:0.07475\ttest-error:0.12998                               \n",
      "\n",
      "[84]\ttrain-error:0.07402\ttest-error:0.12998                               \n",
      "\n",
      "[85]\ttrain-error:0.07356\ttest-error:0.12948                               \n",
      "\n",
      "[86]\ttrain-error:0.07325\ttest-error:0.12998                               \n",
      "\n",
      "[87]\ttrain-error:0.07307\ttest-error:0.13047                               \n",
      "\n",
      "[88]\ttrain-error:0.07288\ttest-error:0.13059                               \n",
      "\n",
      "[89]\ttrain-error:0.07227\ttest-error:0.13028                               \n",
      "\n",
      "[90]\ttrain-error:0.07181\ttest-error:0.13071                               \n",
      "\n",
      "[91]\ttrain-error:0.07159\ttest-error:0.13071                               \n",
      "\n",
      "[92]\ttrain-error:0.07079\ttest-error:0.13090                               \n",
      "\n",
      "[93]\ttrain-error:0.07061\ttest-error:0.13139                               \n",
      "\n",
      "[94]\ttrain-error:0.06996\ttest-error:0.13170                               \n",
      "\n",
      "[95]\ttrain-error:0.06987\ttest-error:0.13133                               \n",
      "\n",
      "[96]\ttrain-error:0.06972\ttest-error:0.13139                               \n",
      "\n",
      "[97]\ttrain-error:0.06898\ttest-error:0.13126                               \n",
      "\n",
      "[98]\ttrain-error:0.06864\ttest-error:0.13139                               \n",
      "\n",
      "[99]\ttrain-error:0.06843\ttest-error:0.13065                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.8050519137699899, 'colsample_bytree': 0.5608078107871111, 'eta': 0.033527314094175115, 'eval_metric': ('error',), 'extra_dims': 3, 'gamma': 0, 'lambda': 0.006774930922623894, 'max_depth': 5, 'min_child_weight': 8.068107328733578e-05, 'objective': 'binary:logistic', 'subsample': 0.9805661022139391}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:58:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15396\ttest-error:0.15258                                \n",
      "\n",
      "[1]\ttrain-error:0.14460\ttest-error:0.14662                                \n",
      "\n",
      "[2]\ttrain-error:0.14180\ttest-error:0.14226                                \n",
      "\n",
      "[3]\ttrain-error:0.13956\ttest-error:0.13790                                \n",
      "\n",
      "[4]\ttrain-error:0.13980\ttest-error:0.14017                                \n",
      "\n",
      "[5]\ttrain-error:0.14039\ttest-error:0.14097                                \n",
      "\n",
      "[6]\ttrain-error:0.14020\ttest-error:0.14146                                \n",
      "\n",
      "[7]\ttrain-error:0.13959\ttest-error:0.14036                                \n",
      "\n",
      "[8]\ttrain-error:0.13928\ttest-error:0.14011                                \n",
      "\n",
      "[9]\ttrain-error:0.13971\ttest-error:0.14017                                \n",
      "\n",
      "[10]\ttrain-error:0.13882\ttest-error:0.13962                               \n",
      "\n",
      "[11]\ttrain-error:0.13885\ttest-error:0.13919                               \n",
      "\n",
      "[12]\ttrain-error:0.13851\ttest-error:0.13796                               \n",
      "\n",
      "[13]\ttrain-error:0.13870\ttest-error:0.13784                               \n",
      "\n",
      "[14]\ttrain-error:0.13882\ttest-error:0.13759                               \n",
      "\n",
      "[15]\ttrain-error:0.13876\ttest-error:0.13772                               \n",
      "\n",
      "[16]\ttrain-error:0.13858\ttest-error:0.13735                               \n",
      "\n",
      "[17]\ttrain-error:0.13851\ttest-error:0.13765                               \n",
      "\n",
      "[18]\ttrain-error:0.13827\ttest-error:0.13716                               \n",
      "\n",
      "[19]\ttrain-error:0.13762\ttest-error:0.13667                               \n",
      "\n",
      "[20]\ttrain-error:0.13713\ttest-error:0.13587                               \n",
      "\n",
      "[21]\ttrain-error:0.13701\ttest-error:0.13575                               \n",
      "\n",
      "[22]\ttrain-error:0.13701\ttest-error:0.13532                               \n",
      "\n",
      "[23]\ttrain-error:0.13682\ttest-error:0.13563                               \n",
      "\n",
      "[24]\ttrain-error:0.13664\ttest-error:0.13520                               \n",
      "\n",
      "[25]\ttrain-error:0.13627\ttest-error:0.13452                               \n",
      "\n",
      "[26]\ttrain-error:0.13596\ttest-error:0.13428                               \n",
      "\n",
      "[27]\ttrain-error:0.13584\ttest-error:0.13440                               \n",
      "\n",
      "[28]\ttrain-error:0.13544\ttest-error:0.13440                               \n",
      "\n",
      "[29]\ttrain-error:0.13526\ttest-error:0.13391                               \n",
      "\n",
      "[30]\ttrain-error:0.13510\ttest-error:0.13391                               \n",
      "\n",
      "[31]\ttrain-error:0.13480\ttest-error:0.13384                               \n",
      "\n",
      "[32]\ttrain-error:0.13470\ttest-error:0.13378                               \n",
      "\n",
      "[33]\ttrain-error:0.13464\ttest-error:0.13354                               \n",
      "\n",
      "[34]\ttrain-error:0.13434\ttest-error:0.13335                               \n",
      "\n",
      "[35]\ttrain-error:0.13397\ttest-error:0.13317                               \n",
      "\n",
      "[36]\ttrain-error:0.13363\ttest-error:0.13249                               \n",
      "\n",
      "[37]\ttrain-error:0.13335\ttest-error:0.13219                               \n",
      "\n",
      "[38]\ttrain-error:0.13295\ttest-error:0.13188                               \n",
      "\n",
      "[39]\ttrain-error:0.13271\ttest-error:0.13157                               \n",
      "\n",
      "[40]\ttrain-error:0.13246\ttest-error:0.13126                               \n",
      "\n",
      "[41]\ttrain-error:0.13228\ttest-error:0.13084                               \n",
      "\n",
      "[42]\ttrain-error:0.13188\ttest-error:0.13053                               \n",
      "\n",
      "[43]\ttrain-error:0.13133\ttest-error:0.13016                               \n",
      "\n",
      "[44]\ttrain-error:0.13123\ttest-error:0.13028                               \n",
      "\n",
      "[45]\ttrain-error:0.13093\ttest-error:0.13004                               \n",
      "\n",
      "[46]\ttrain-error:0.13053\ttest-error:0.12979                               \n",
      "\n",
      "[47]\ttrain-error:0.13013\ttest-error:0.12942                               \n",
      "\n",
      "[48]\ttrain-error:0.12982\ttest-error:0.12924                               \n",
      "\n",
      "[49]\ttrain-error:0.12933\ttest-error:0.12905                               \n",
      "\n",
      "[50]\ttrain-error:0.12862\ttest-error:0.12856                               \n",
      "\n",
      "[51]\ttrain-error:0.12832\ttest-error:0.12862                               \n",
      "\n",
      "[52]\ttrain-error:0.12804\ttest-error:0.12850                               \n",
      "\n",
      "[53]\ttrain-error:0.12783\ttest-error:0.12856                               \n",
      "\n",
      "[54]\ttrain-error:0.12764\ttest-error:0.12850                               \n",
      "\n",
      "[55]\ttrain-error:0.12715\ttest-error:0.12862                               \n",
      "\n",
      "[56]\ttrain-error:0.12693\ttest-error:0.12844                               \n",
      "\n",
      "[57]\ttrain-error:0.12681\ttest-error:0.12832                               \n",
      "\n",
      "[58]\ttrain-error:0.12651\ttest-error:0.12826                               \n",
      "\n",
      "[59]\ttrain-error:0.12647\ttest-error:0.12801                               \n",
      "\n",
      "[60]\ttrain-error:0.12644\ttest-error:0.12746                               \n",
      "\n",
      "[61]\ttrain-error:0.12604\ttest-error:0.12709                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62]\ttrain-error:0.12595\ttest-error:0.12721                               \n",
      "\n",
      "[63]\ttrain-error:0.12589\ttest-error:0.12703                               \n",
      "\n",
      "[64]\ttrain-error:0.12558\ttest-error:0.12641                               \n",
      "\n",
      "[65]\ttrain-error:0.12521\ttest-error:0.12635                               \n",
      "\n",
      "[66]\ttrain-error:0.12506\ttest-error:0.12666                               \n",
      "\n",
      "[67]\ttrain-error:0.12460\ttest-error:0.12635                               \n",
      "\n",
      "[68]\ttrain-error:0.12445\ttest-error:0.12611                               \n",
      "\n",
      "[69]\ttrain-error:0.12392\ttest-error:0.12611                               \n",
      "\n",
      "[70]\ttrain-error:0.12359\ttest-error:0.12617                               \n",
      "\n",
      "[71]\ttrain-error:0.12340\ttest-error:0.12611                               \n",
      "\n",
      "[72]\ttrain-error:0.12356\ttest-error:0.12586                               \n",
      "\n",
      "[73]\ttrain-error:0.12337\ttest-error:0.12635                               \n",
      "\n",
      "[74]\ttrain-error:0.12328\ttest-error:0.12635                               \n",
      "\n",
      "[75]\ttrain-error:0.12313\ttest-error:0.12617                               \n",
      "\n",
      "[76]\ttrain-error:0.12288\ttest-error:0.12641                               \n",
      "\n",
      "[77]\ttrain-error:0.12285\ttest-error:0.12635                               \n",
      "\n",
      "[78]\ttrain-error:0.12276\ttest-error:0.12617                               \n",
      "\n",
      "[79]\ttrain-error:0.12245\ttest-error:0.12598                               \n",
      "\n",
      "[80]\ttrain-error:0.12211\ttest-error:0.12574                               \n",
      "\n",
      "[81]\ttrain-error:0.12202\ttest-error:0.12574                               \n",
      "\n",
      "[82]\ttrain-error:0.12168\ttest-error:0.12623                               \n",
      "\n",
      "[83]\ttrain-error:0.12156\ttest-error:0.12623                               \n",
      "\n",
      "[84]\ttrain-error:0.12122\ttest-error:0.12586                               \n",
      "\n",
      "[85]\ttrain-error:0.12113\ttest-error:0.12549                               \n",
      "\n",
      "[86]\ttrain-error:0.12101\ttest-error:0.12531                               \n",
      "\n",
      "[87]\ttrain-error:0.12082\ttest-error:0.12506                               \n",
      "\n",
      "[88]\ttrain-error:0.12085\ttest-error:0.12488                               \n",
      "\n",
      "[89]\ttrain-error:0.12070\ttest-error:0.12494                               \n",
      "\n",
      "[90]\ttrain-error:0.12052\ttest-error:0.12506                               \n",
      "\n",
      "[91]\ttrain-error:0.12036\ttest-error:0.12475                               \n",
      "\n",
      "[92]\ttrain-error:0.12033\ttest-error:0.12488                               \n",
      "\n",
      "[93]\ttrain-error:0.12018\ttest-error:0.12457                               \n",
      "\n",
      "[94]\ttrain-error:0.12005\ttest-error:0.12445                               \n",
      "\n",
      "[95]\ttrain-error:0.11993\ttest-error:0.12463                               \n",
      "\n",
      "[96]\ttrain-error:0.11984\ttest-error:0.12457                               \n",
      "\n",
      "[97]\ttrain-error:0.11990\ttest-error:0.12445                               \n",
      "\n",
      "[98]\ttrain-error:0.11962\ttest-error:0.12475                               \n",
      "\n",
      "[99]\ttrain-error:0.11935\ttest-error:0.12439                               \n",
      "\n",
      "{'alpha': 0.003816556183016135, 'btype': 'R', 'colsample_bylevel': 0.7637694899594396, 'colsample_bytree': 0.5922382494575776, 'eta': 0.09468468165840639, 'eval_metric': ('error',), 'extra_dims': 9, 'gamma': 0, 'lambda': 0.0009494852004724761, 'max_depth': 10, 'min_child_weight': 1.4638114419122137, 'objective': 'binary:logistic', 'subsample': 0.8339380286186534}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[23:59:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.13756\ttest-error:0.14036                                \n",
      "\n",
      "[1]\ttrain-error:0.13308\ttest-error:0.13520                                \n",
      "\n",
      "[2]\ttrain-error:0.12789\ttest-error:0.13323                                \n",
      "\n",
      "[3]\ttrain-error:0.12402\ttest-error:0.13151                                \n",
      "\n",
      "[4]\ttrain-error:0.12027\ttest-error:0.12801                                \n",
      "\n",
      "[5]\ttrain-error:0.11833\ttest-error:0.12543                                \n",
      "\n",
      "[6]\ttrain-error:0.11683\ttest-error:0.12672                                \n",
      "\n",
      "[7]\ttrain-error:0.11622\ttest-error:0.12561                                \n",
      "\n",
      "[8]\ttrain-error:0.11440\ttest-error:0.12568                                \n",
      "\n",
      "[9]\ttrain-error:0.11281\ttest-error:0.12561                                \n",
      "\n",
      "[10]\ttrain-error:0.11189\ttest-error:0.12531                               \n",
      "\n",
      "[11]\ttrain-error:0.11139\ttest-error:0.12500                               \n",
      "\n",
      "[12]\ttrain-error:0.10995\ttest-error:0.12574                               \n",
      "\n",
      "[13]\ttrain-error:0.10891\ttest-error:0.12537                               \n",
      "\n",
      "[14]\ttrain-error:0.10755\ttest-error:0.12604                               \n",
      "\n",
      "[15]\ttrain-error:0.10651\ttest-error:0.12690                               \n",
      "\n",
      "[16]\ttrain-error:0.10522\ttest-error:0.12690                               \n",
      "\n",
      "[17]\ttrain-error:0.10341\ttest-error:0.12629                               \n",
      "\n",
      "[18]\ttrain-error:0.10267\ttest-error:0.12568                               \n",
      "\n",
      "[19]\ttrain-error:0.10206\ttest-error:0.12592                               \n",
      "\n",
      "[20]\ttrain-error:0.10138\ttest-error:0.12647                               \n",
      "\n",
      "[21]\ttrain-error:0.10114\ttest-error:0.12635                               \n",
      "\n",
      "[22]\ttrain-error:0.09991\ttest-error:0.12604                               \n",
      "\n",
      "[23]\ttrain-error:0.09883\ttest-error:0.12654                               \n",
      "\n",
      "[24]\ttrain-error:0.09711\ttest-error:0.12690                               \n",
      "\n",
      "[25]\ttrain-error:0.09592\ttest-error:0.12721                               \n",
      "\n",
      "[26]\ttrain-error:0.09564\ttest-error:0.12690                               \n",
      "\n",
      "[27]\ttrain-error:0.09499\ttest-error:0.12746                               \n",
      "\n",
      "[28]\ttrain-error:0.09453\ttest-error:0.12727                               \n",
      "\n",
      "[29]\ttrain-error:0.09410\ttest-error:0.12709                               \n",
      "\n",
      "[30]\ttrain-error:0.09312\ttest-error:0.12783                               \n",
      "\n",
      "[31]\ttrain-error:0.09149\ttest-error:0.12789                               \n",
      "\n",
      "[32]\ttrain-error:0.09054\ttest-error:0.12764                               \n",
      "\n",
      "[33]\ttrain-error:0.08940\ttest-error:0.12770                               \n",
      "\n",
      "[34]\ttrain-error:0.08901\ttest-error:0.12776                               \n",
      "\n",
      "[35]\ttrain-error:0.08821\ttest-error:0.12697                               \n",
      "\n",
      "[36]\ttrain-error:0.08778\ttest-error:0.12795                               \n",
      "\n",
      "[37]\ttrain-error:0.08713\ttest-error:0.12758                               \n",
      "\n",
      "[38]\ttrain-error:0.08606\ttest-error:0.12783                               \n",
      "\n",
      "[39]\ttrain-error:0.08526\ttest-error:0.12856                               \n",
      "\n",
      "[40]\ttrain-error:0.08424\ttest-error:0.12875                               \n",
      "\n",
      "[41]\ttrain-error:0.08381\ttest-error:0.12899                               \n",
      "\n",
      "[42]\ttrain-error:0.08326\ttest-error:0.12942                               \n",
      "\n",
      "[43]\ttrain-error:0.08246\ttest-error:0.12936                               \n",
      "\n",
      "[44]\ttrain-error:0.08206\ttest-error:0.12979                               \n",
      "\n",
      "[45]\ttrain-error:0.08096\ttest-error:0.12998                               \n",
      "\n",
      "[46]\ttrain-error:0.08031\ttest-error:0.13010                               \n",
      "\n",
      "[47]\ttrain-error:0.07942\ttest-error:0.12967                               \n",
      "\n",
      "[48]\ttrain-error:0.07872\ttest-error:0.12973                               \n",
      "\n",
      "[49]\ttrain-error:0.07804\ttest-error:0.12967                               \n",
      "\n",
      "[50]\ttrain-error:0.07740\ttest-error:0.12985                               \n",
      "\n",
      "[51]\ttrain-error:0.07681\ttest-error:0.12948                               \n",
      "\n",
      "[52]\ttrain-error:0.07614\ttest-error:0.12967                               \n",
      "\n",
      "[53]\ttrain-error:0.07601\ttest-error:0.13016                               \n",
      "\n",
      "[54]\ttrain-error:0.07540\ttest-error:0.12973                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55]\ttrain-error:0.07497\ttest-error:0.12954                               \n",
      "\n",
      "[56]\ttrain-error:0.07494\ttest-error:0.13047                               \n",
      "\n",
      "[57]\ttrain-error:0.07393\ttest-error:0.13096                               \n",
      "\n",
      "[58]\ttrain-error:0.07291\ttest-error:0.13059                               \n",
      "\n",
      "[59]\ttrain-error:0.07230\ttest-error:0.13102                               \n",
      "\n",
      "[60]\ttrain-error:0.07144\ttest-error:0.13139                               \n",
      "\n",
      "[61]\ttrain-error:0.07119\ttest-error:0.13157                               \n",
      "\n",
      "[62]\ttrain-error:0.07070\ttest-error:0.13237                               \n",
      "\n",
      "[63]\ttrain-error:0.07024\ttest-error:0.13219                               \n",
      "\n",
      "[64]\ttrain-error:0.06953\ttest-error:0.13170                               \n",
      "\n",
      "[65]\ttrain-error:0.06864\ttest-error:0.13182                               \n",
      "\n",
      "[66]\ttrain-error:0.06812\ttest-error:0.13249                               \n",
      "\n",
      "[67]\ttrain-error:0.06723\ttest-error:0.13243                               \n",
      "\n",
      "[68]\ttrain-error:0.06711\ttest-error:0.13268                               \n",
      "\n",
      "[69]\ttrain-error:0.06643\ttest-error:0.13280                               \n",
      "\n",
      "[70]\ttrain-error:0.06520\ttest-error:0.13274                               \n",
      "\n",
      "[71]\ttrain-error:0.06490\ttest-error:0.13323                               \n",
      "\n",
      "[72]\ttrain-error:0.06444\ttest-error:0.13249                               \n",
      "\n",
      "[73]\ttrain-error:0.06401\ttest-error:0.13280                               \n",
      "\n",
      "[74]\ttrain-error:0.06361\ttest-error:0.13292                               \n",
      "\n",
      "[75]\ttrain-error:0.06281\ttest-error:0.13342                               \n",
      "\n",
      "[76]\ttrain-error:0.06265\ttest-error:0.13305                               \n",
      "\n",
      "[77]\ttrain-error:0.06210\ttest-error:0.13286                               \n",
      "\n",
      "[78]\ttrain-error:0.06130\ttest-error:0.13280                               \n",
      "\n",
      "[79]\ttrain-error:0.06053\ttest-error:0.13286                               \n",
      "\n",
      "[80]\ttrain-error:0.06029\ttest-error:0.13280                               \n",
      "\n",
      "[81]\ttrain-error:0.05955\ttest-error:0.13286                               \n",
      "\n",
      "[82]\ttrain-error:0.05912\ttest-error:0.13317                               \n",
      "\n",
      "[83]\ttrain-error:0.05872\ttest-error:0.13298                               \n",
      "\n",
      "[84]\ttrain-error:0.05838\ttest-error:0.13311                               \n",
      "\n",
      "[85]\ttrain-error:0.05799\ttest-error:0.13360                               \n",
      "\n",
      "[86]\ttrain-error:0.05731\ttest-error:0.13335                               \n",
      "\n",
      "[87]\ttrain-error:0.05685\ttest-error:0.13280                               \n",
      "\n",
      "[88]\ttrain-error:0.05630\ttest-error:0.13342                               \n",
      "\n",
      "[89]\ttrain-error:0.05574\ttest-error:0.13409                               \n",
      "\n",
      "[90]\ttrain-error:0.05479\ttest-error:0.13384                               \n",
      "\n",
      "[91]\ttrain-error:0.05421\ttest-error:0.13372                               \n",
      "\n",
      "[92]\ttrain-error:0.05384\ttest-error:0.13434                               \n",
      "\n",
      "[93]\ttrain-error:0.05316\ttest-error:0.13464                               \n",
      "\n",
      "[94]\ttrain-error:0.05323\ttest-error:0.13495                               \n",
      "\n",
      "[95]\ttrain-error:0.05240\ttest-error:0.13440                               \n",
      "\n",
      "[96]\ttrain-error:0.05221\ttest-error:0.13428                               \n",
      "\n",
      "[97]\ttrain-error:0.05138\ttest-error:0.13446                               \n",
      "\n",
      "[98]\ttrain-error:0.05049\ttest-error:0.13452                               \n",
      "\n",
      "[99]\ttrain-error:0.05037\ttest-error:0.13458                               \n",
      "\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.853947709593122, 'colsample_bytree': 0.8109694171140288, 'eta': 0.32080201195952, 'eval_metric': ('error',), 'extra_dims': 5, 'gamma': 0, 'lambda': 6.188038534616943, 'max_depth': 3, 'min_child_weight': 0.014587598466306502, 'objective': 'binary:logistic', 'subsample': 0.9288221843352984}\n",
      "Overwriting param `num_class`                                             \n",
      "Overwriting param `objective` while setting `obj` in train.               \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                                   \n",
      "Setting param `disable_default_eval_metric` to 1.                         \n",
      "[00:00:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480:  \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.15427\ttest-error:0.15313                                \n",
      "\n",
      "[1]\ttrain-error:0.14628\ttest-error:0.14386                                \n",
      "\n",
      "[2]\ttrain-error:0.14119\ttest-error:0.13999                                \n",
      "\n",
      "[3]\ttrain-error:0.13922\ttest-error:0.13808                                \n",
      "\n",
      "[4]\ttrain-error:0.13980\ttest-error:0.13845                                \n",
      "\n",
      "[5]\ttrain-error:0.13618\ttest-error:0.13520                                \n",
      "\n",
      "[6]\ttrain-error:0.13437\ttest-error:0.13593                                \n",
      "\n",
      "[7]\ttrain-error:0.13320\ttest-error:0.13470                                \n",
      "\n",
      "[8]\ttrain-error:0.13298\ttest-error:0.13360                                \n",
      "\n",
      "[9]\ttrain-error:0.13050\ttest-error:0.13243                                \n",
      "\n",
      "[10]\ttrain-error:0.12958\ttest-error:0.13053                               \n",
      "\n",
      "[11]\ttrain-error:0.12826\ttest-error:0.13022                               \n",
      "\n",
      "[12]\ttrain-error:0.12862\ttest-error:0.12887                               \n",
      "\n",
      "[13]\ttrain-error:0.12626\ttest-error:0.12844                               \n",
      "\n",
      "[14]\ttrain-error:0.12730\ttest-error:0.12764                               \n",
      "\n",
      "[15]\ttrain-error:0.12592\ttest-error:0.12844                               \n",
      "\n",
      "[16]\ttrain-error:0.12632\ttest-error:0.12733                               \n",
      "\n",
      "[17]\ttrain-error:0.12463\ttest-error:0.12758                               \n",
      "\n",
      "[18]\ttrain-error:0.12392\ttest-error:0.12654                               \n",
      "\n",
      "[19]\ttrain-error:0.12439\ttest-error:0.12746                               \n",
      "\n",
      "[20]\ttrain-error:0.12328\ttest-error:0.12660                               \n",
      "\n",
      "[21]\ttrain-error:0.12300\ttest-error:0.12758                               \n",
      "\n",
      "[22]\ttrain-error:0.12242\ttest-error:0.12740                               \n",
      "\n",
      "[23]\ttrain-error:0.12217\ttest-error:0.12721                               \n",
      "\n",
      "[24]\ttrain-error:0.12196\ttest-error:0.12647                               \n",
      "\n",
      "[25]\ttrain-error:0.12159\ttest-error:0.12684                               \n",
      "\n",
      "[26]\ttrain-error:0.12184\ttest-error:0.12678                               \n",
      "\n",
      "[27]\ttrain-error:0.12089\ttest-error:0.12647                               \n",
      "\n",
      "[28]\ttrain-error:0.12101\ttest-error:0.12635                               \n",
      "\n",
      "[29]\ttrain-error:0.12046\ttest-error:0.12684                               \n",
      "\n",
      "[30]\ttrain-error:0.12046\ttest-error:0.12647                               \n",
      "\n",
      "[31]\ttrain-error:0.12039\ttest-error:0.12654                               \n",
      "\n",
      "[32]\ttrain-error:0.11999\ttest-error:0.12697                               \n",
      "\n",
      "[33]\ttrain-error:0.11996\ttest-error:0.12752                               \n",
      "\n",
      "[34]\ttrain-error:0.11953\ttest-error:0.12752                               \n",
      "\n",
      "[35]\ttrain-error:0.11935\ttest-error:0.12715                               \n",
      "\n",
      "[36]\ttrain-error:0.11935\ttest-error:0.12678                               \n",
      "\n",
      "[37]\ttrain-error:0.11923\ttest-error:0.12660                               \n",
      "\n",
      "[38]\ttrain-error:0.11892\ttest-error:0.12641                               \n",
      "\n",
      "[39]\ttrain-error:0.11855\ttest-error:0.12617                               \n",
      "\n",
      "[40]\ttrain-error:0.11873\ttest-error:0.12629                               \n",
      "\n",
      "[41]\ttrain-error:0.11790\ttest-error:0.12641                               \n",
      "\n",
      "[42]\ttrain-error:0.11803\ttest-error:0.12709                               \n",
      "\n",
      "[43]\ttrain-error:0.11778\ttest-error:0.12684                               \n",
      "\n",
      "[44]\ttrain-error:0.11735\ttest-error:0.12654                               \n",
      "\n",
      "[45]\ttrain-error:0.11704\ttest-error:0.12733                               \n",
      "\n",
      "[46]\ttrain-error:0.11726\ttest-error:0.12697                               \n",
      "\n",
      "[47]\ttrain-error:0.11717\ttest-error:0.12666                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48]\ttrain-error:0.11720\ttest-error:0.12721                               \n",
      "\n",
      "[49]\ttrain-error:0.11701\ttest-error:0.12647                               \n",
      "\n",
      "[50]\ttrain-error:0.11646\ttest-error:0.12783                               \n",
      "\n",
      "[51]\ttrain-error:0.11652\ttest-error:0.12776                               \n",
      "\n",
      "[52]\ttrain-error:0.11594\ttest-error:0.12764                               \n",
      "\n",
      "[53]\ttrain-error:0.11597\ttest-error:0.12740                               \n",
      "\n",
      "[54]\ttrain-error:0.11615\ttest-error:0.12795                               \n",
      "\n",
      "[55]\ttrain-error:0.11606\ttest-error:0.12752                               \n",
      "\n",
      "[56]\ttrain-error:0.11582\ttest-error:0.12709                               \n",
      "\n",
      "[57]\ttrain-error:0.11579\ttest-error:0.12721                               \n",
      "\n",
      "[58]\ttrain-error:0.11529\ttest-error:0.12697                               \n",
      "\n",
      "[59]\ttrain-error:0.11533\ttest-error:0.12733                               \n",
      "\n",
      "[60]\ttrain-error:0.11505\ttest-error:0.12783                               \n",
      "\n",
      "[61]\ttrain-error:0.11471\ttest-error:0.12752                               \n",
      "\n",
      "[62]\ttrain-error:0.11462\ttest-error:0.12727                               \n",
      "\n",
      "[63]\ttrain-error:0.11456\ttest-error:0.12746                               \n",
      "\n",
      "[64]\ttrain-error:0.11456\ttest-error:0.12715                               \n",
      "\n",
      "[65]\ttrain-error:0.11425\ttest-error:0.12752                               \n",
      "\n",
      "[66]\ttrain-error:0.11416\ttest-error:0.12801                               \n",
      "\n",
      "[67]\ttrain-error:0.11434\ttest-error:0.12832                               \n",
      "\n",
      "[68]\ttrain-error:0.11404\ttest-error:0.12862                               \n",
      "\n",
      "[69]\ttrain-error:0.11397\ttest-error:0.12862                               \n",
      "\n",
      "[70]\ttrain-error:0.11373\ttest-error:0.12819                               \n",
      "\n",
      "[71]\ttrain-error:0.11330\ttest-error:0.12887                               \n",
      "\n",
      "[72]\ttrain-error:0.11299\ttest-error:0.12856                               \n",
      "\n",
      "[73]\ttrain-error:0.11265\ttest-error:0.12826                               \n",
      "\n",
      "[74]\ttrain-error:0.11213\ttest-error:0.12819                               \n",
      "\n",
      "[75]\ttrain-error:0.11219\ttest-error:0.12838                               \n",
      "\n",
      "[76]\ttrain-error:0.11146\ttest-error:0.12801                               \n",
      "\n",
      "[77]\ttrain-error:0.11133\ttest-error:0.12893                               \n",
      "\n",
      "[78]\ttrain-error:0.11075\ttest-error:0.12869                               \n",
      "\n",
      "[79]\ttrain-error:0.11063\ttest-error:0.12862                               \n",
      "\n",
      "[80]\ttrain-error:0.11112\ttest-error:0.12924                               \n",
      "\n",
      "[81]\ttrain-error:0.11081\ttest-error:0.12930                               \n",
      "\n",
      "[82]\ttrain-error:0.11050\ttest-error:0.12887                               \n",
      "\n",
      "[83]\ttrain-error:0.11035\ttest-error:0.12930                               \n",
      "\n",
      "[84]\ttrain-error:0.11047\ttest-error:0.12850                               \n",
      "\n",
      "[85]\ttrain-error:0.11032\ttest-error:0.12875                               \n",
      "\n",
      "[86]\ttrain-error:0.11050\ttest-error:0.12826                               \n",
      "\n",
      "[87]\ttrain-error:0.11044\ttest-error:0.12869                               \n",
      "\n",
      "[88]\ttrain-error:0.11020\ttest-error:0.12887                               \n",
      "\n",
      "[89]\ttrain-error:0.11010\ttest-error:0.12844                               \n",
      "\n",
      "[90]\ttrain-error:0.11010\ttest-error:0.12875                               \n",
      "\n",
      "[91]\ttrain-error:0.10986\ttest-error:0.12918                               \n",
      "\n",
      "[92]\ttrain-error:0.11001\ttest-error:0.12924                               \n",
      "\n",
      "[93]\ttrain-error:0.10967\ttest-error:0.12912                               \n",
      "\n",
      "[94]\ttrain-error:0.10915\ttest-error:0.12912                               \n",
      "\n",
      "[95]\ttrain-error:0.10924\ttest-error:0.12930                               \n",
      "\n",
      "[96]\ttrain-error:0.10924\ttest-error:0.12967                               \n",
      "\n",
      "[97]\ttrain-error:0.10918\ttest-error:0.12930                               \n",
      "\n",
      "[98]\ttrain-error:0.10848\ttest-error:0.12893                               \n",
      "\n",
      "[99]\ttrain-error:0.10823\ttest-error:0.12918                               \n",
      "\n",
      "100%|██████████| 100/100 [1:55:38<00:00, 69.39s/trial, best loss: 0.122543]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, space_eval\n",
    "\n",
    "best_val = 1.0\n",
    "\n",
    "def objective(param):\n",
    "    global best_val\n",
    "    watchlist = [(dtrain,'train'),(dtest,'test')]\n",
    "    ed1_results = dict()\n",
    "    print(param)\n",
    "    wbst = wxgb.train(param, dtrain, 100,watchlist,evals_result=ed1_results)\n",
    "    \n",
    "    if min(ed1_results['test']['error']) < best_val:\n",
    "        print(\"NEW BEST VALUE!\")\n",
    "        best_val = min(ed1_results['test']['error'])\n",
    "    \n",
    "    return {'loss': min(ed1_results['test']['error']), 'status': STATUS_OK }\n",
    "\n",
    "spc = {\n",
    "    'btype': hp.choice('btype',['R','I','Rn','In']),\n",
    "    'extra_dims': hp.choice('extra_dims',range(16)),\n",
    "    'objective': hp.choice('objective',['binary:logistic']),\n",
    "    'eval_metric':hp.choice('eval_metric',[['error']]),\n",
    "    'eta': hp.loguniform('eta', -7, 0),\n",
    "    'max_depth' : hp.choice('max_depth',range(1,11)),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.5, 1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -16, 5),\n",
    "    'alpha': hp.choice('alpha', [0, hp.loguniform('alpha_positive', -16, 2)]),\n",
    "    'lambda': hp.choice('lambda', [0, hp.loguniform('lambda_positive', -16, 2)]),\n",
    "    'gamma': hp.choice('gamma', [0, hp.loguniform('gamma_positive', -16, 2)])\n",
    "}\n",
    "\n",
    "best = fmin(objective,\n",
    "    space=spc,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.122543\n",
      "{'alpha': 0, 'btype': 'Rn', 'colsample_bylevel': 0.6261447955477483, 'colsample_bytree': 0.5598675876323314, 'eta': 0.06740445691747836, 'eval_metric': ('error',), 'extra_dims': 14, 'gamma': 0, 'lambda': 0.03173665561441266, 'max_depth': 5, 'min_child_weight': 0.08047493164421338, 'objective': 'binary:logistic', 'subsample': 0.9968065361821689}\n"
     ]
    }
   ],
   "source": [
    "print(best_val)\n",
    "print(space_eval(spc, best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hyperopt.pyll.base.Apply at 0x7fd8753cb5b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 2.555696689429851e-07, 'btype': 'R', 'colsample_bylevel': 0.5808673095736296, 'colsample_bytree': 0.7454363436382125, 'eta': 0.09028896383501842, 'eval_metric': ('error',), 'extra_dims': 6, 'gamma': 0, 'lambda': 0.010496473733789414, 'max_depth': 5, 'min_child_weight': 0.003416504180607806, 'objective': 'binary:logistic', 'subsample': 0.6545637422401163}\n",
      "Overwriting param `num_class`                         \n",
      "Overwriting param `objective` while setting `obj` in train.\n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.               \n",
      "Setting param `disable_default_eval_metric` to 1.     \n",
      "[21:57:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14435\ttest-error:0.14509            \n",
      "\n",
      "[1]\ttrain-error:0.14036\ttest-error:0.13692            \n",
      "\n",
      "[2]\ttrain-error:0.13907\ttest-error:0.13593            \n",
      "\n",
      "[3]\ttrain-error:0.13811\ttest-error:0.13409            \n",
      "\n",
      "[4]\ttrain-error:0.13661\ttest-error:0.13372            \n",
      "\n",
      "{'alpha': 4.247261809153864e-07, 'btype': 'Rn', 'colsample_bylevel': 0.6923101058420698, 'colsample_bytree': 0.6284664714863257, 'eta': 0.006598618015661889, 'eval_metric': ('error',), 'extra_dims': 12, 'gamma': 0, 'lambda': 0, 'max_depth': 3, 'min_child_weight': 0.016426676822569514, 'objective': 'binary:logistic', 'subsample': 0.5150691019191727}\n",
      "Overwriting param `num_class`                                         \n",
      "Overwriting param `objective` while setting `obj` in train.           \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                               \n",
      "Setting param `disable_default_eval_metric` to 1.                     \n",
      "[21:57:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14893\ttest-error:0.14803                            \n",
      "\n",
      "[1]\ttrain-error:0.15660\ttest-error:0.15547                            \n",
      "\n",
      "[2]\ttrain-error:0.15519\ttest-error:0.15467                            \n",
      "\n",
      "[3]\ttrain-error:0.15528\ttest-error:0.15454                            \n",
      "\n",
      "[4]\ttrain-error:0.15494\ttest-error:0.15491                            \n",
      "\n",
      "{'alpha': 0, 'btype': 'In', 'colsample_bylevel': 0.5398758352347661, 'colsample_bytree': 0.7732587495011325, 'eta': 0.46045280939021194, 'eval_metric': ('error',), 'extra_dims': 10, 'gamma': 0, 'lambda': 3.8272863930904466e-07, 'max_depth': 9, 'min_child_weight': 1.0330261715665018e-06, 'objective': 'binary:logistic', 'subsample': 0.7078708900564323}\n",
      "Overwriting param `num_class`                                         \n",
      "Overwriting param `objective` while setting `obj` in train.           \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                               \n",
      "Setting param `disable_default_eval_metric` to 1.                     \n",
      "[21:57:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.12915\ttest-error:0.13716                            \n",
      "\n",
      "[1]\ttrain-error:0.80753\ttest-error:0.81290                            \n",
      "\n",
      " 20%|██        | 2/10 [00:08<00:24,  3.06s/trial, best loss: 0.133722]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhorrell/github/tensorflow/wideboost/wideboost/objectives/binarylogloss.py:20: RuntimeWarning: overflow encountered in exp\n",
      "  P = 1 / (1 + np.exp(-logits))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\ttrain-error:0.17964\ttest-error:0.17862                            \n",
      "\n",
      "[3]\ttrain-error:0.29395\ttest-error:0.29324                            \n",
      "\n",
      "[4]\ttrain-error:0.32368\ttest-error:0.32027                            \n",
      "\n",
      "{'alpha': 1.2189564334503284, 'btype': 'R', 'colsample_bylevel': 0.5154745819953641, 'colsample_bytree': 0.5593323791661391, 'eta': 0.18416194279229148, 'eval_metric': ('error',), 'extra_dims': 15, 'gamma': 0, 'lambda': 0, 'max_depth': 5, 'min_child_weight': 7.906588429791388e-07, 'objective': 'binary:logistic', 'subsample': 0.6948883932449246}\n",
      "Overwriting param `num_class`                                         \n",
      "Overwriting param `objective` while setting `obj` in train.           \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                               \n",
      "Setting param `disable_default_eval_metric` to 1.                     \n",
      "[21:57:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14404\ttest-error:0.14509                            \n",
      "\n",
      "[1]\ttrain-error:0.52580\ttest-error:0.53059                            \n",
      "\n",
      "[2]\ttrain-error:0.22359\ttest-error:0.21941                            \n",
      "\n",
      "[3]\ttrain-error:0.75921\ttest-error:0.76370                            \n",
      "\n",
      "[4]\ttrain-error:0.24082\ttest-error:0.23624                            \n",
      "\n",
      "{'alpha': 0, 'btype': 'I', 'colsample_bylevel': 0.6749984935245196, 'colsample_bytree': 0.8703177024015909, 'eta': 0.008602342835149695, 'eval_metric': ('error',), 'extra_dims': 0, 'gamma': 1.4138517084236805e-07, 'lambda': 0, 'max_depth': 3, 'min_child_weight': 3.7823036576141197e-07, 'objective': 'binary:logistic', 'subsample': 0.9738355855701835}\n",
      "Overwriting param `num_class`                                         \n",
      "Overwriting param `objective` while setting `obj` in train.           \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                               \n",
      "Setting param `disable_default_eval_metric` to 1.                     \n",
      "[21:57:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.16066\ttest-error:0.16136                            \n",
      "\n",
      "[1]\ttrain-error:0.15550\ttest-error:0.15553                            \n",
      "\n",
      "[2]\ttrain-error:0.15540\ttest-error:0.15547                            \n",
      "\n",
      "[3]\ttrain-error:0.15989\ttest-error:0.16038                            \n",
      "\n",
      "[4]\ttrain-error:0.15528\ttest-error:0.15577                            \n",
      "\n",
      "{'alpha': 0.005818411675207622, 'btype': 'I', 'colsample_bylevel': 0.9946839673628001, 'colsample_bytree': 0.7073049877617541, 'eta': 0.02613762243358045, 'eval_metric': ('error',), 'extra_dims': 4, 'gamma': 8.543074504626588e-07, 'lambda': 0, 'max_depth': 5, 'min_child_weight': 0.000369388365624629, 'objective': 'binary:logistic', 'subsample': 0.8260166269640797}\n",
      "Overwriting param `num_class`                                         \n",
      "Overwriting param `objective` while setting `obj` in train.           \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                               \n",
      "Setting param `disable_default_eval_metric` to 1.                     \n",
      "[21:57:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14552\ttest-error:0.14625                            \n",
      "\n",
      "[1]\ttrain-error:0.14284\ttest-error:0.14183                            \n",
      "\n",
      "[2]\ttrain-error:0.14343\ttest-error:0.14208                            \n",
      "\n",
      "[3]\ttrain-error:0.14349\ttest-error:0.14171                            \n",
      "\n",
      "[4]\ttrain-error:0.14327\ttest-error:0.14343                            \n",
      "\n",
      "{'alpha': 0.4123771850167154, 'btype': 'R', 'colsample_bylevel': 0.746781214637873, 'colsample_bytree': 0.8248526767598137, 'eta': 0.6595960363782091, 'eval_metric': ('error',), 'extra_dims': 7, 'gamma': 2.971686916283569e-07, 'lambda': 0, 'max_depth': 4, 'min_child_weight': 81.39136706451964, 'objective': 'binary:logistic', 'subsample': 0.6328216990652435}\n",
      "Overwriting param `num_class`                                         \n",
      "Overwriting param `objective` while setting `obj` in train.           \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                               \n",
      "Setting param `disable_default_eval_metric` to 1.                     \n",
      "[21:58:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.18759\ttest-error:0.18464                            \n",
      "\n",
      "[1]\ttrain-error:0.75918\ttest-error:0.76376                            \n",
      "\n",
      "[2]\ttrain-error:0.24082\ttest-error:0.23624                            \n",
      "\n",
      "[3]\ttrain-error:0.75918\ttest-error:0.76376                            \n",
      "\n",
      "[4]\ttrain-error:0.24082\ttest-error:0.23624                            \n",
      "\n",
      "{'alpha': 5.451157092633447, 'btype': 'I', 'colsample_bylevel': 0.7910144739848161, 'colsample_bytree': 0.9086081699265853, 'eta': 0.5613908544289778, 'eval_metric': ('error',), 'extra_dims': 7, 'gamma': 6.941745285593542, 'lambda': 0, 'max_depth': 2, 'min_child_weight': 0.0008935314463074719, 'objective': 'binary:logistic', 'subsample': 0.8386236727691267}\n",
      "Overwriting param `num_class`                                         \n",
      "Overwriting param `objective` while setting `obj` in train.           \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                               \n",
      "Setting param `disable_default_eval_metric` to 1.                     \n",
      "[21:58:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.16001\ttest-error:0.16050                            \n",
      "\n",
      "[1]\ttrain-error:0.79696\ttest-error:0.79982                            \n",
      "\n",
      "[2]\ttrain-error:0.24082\ttest-error:0.23624                            \n",
      "\n",
      "[3]\ttrain-error:0.46443\ttest-error:0.47371                            \n",
      "\n",
      "[4]\ttrain-error:0.30614\ttest-error:0.30645                            \n",
      "\n",
      "{'alpha': 0.18255829992026934, 'btype': 'Rn', 'colsample_bylevel': 0.7447854654607773, 'colsample_bytree': 0.5371300582129952, 'eta': 0.11343440179435076, 'eval_metric': ('error',), 'extra_dims': 5, 'gamma': 0, 'lambda': 0, 'max_depth': 7, 'min_child_weight': 3.1074262385367577, 'objective': 'binary:logistic', 'subsample': 0.8643752080852718}\n",
      "Overwriting param `num_class`                                         \n",
      "Overwriting param `objective` while setting `obj` in train.           \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                               \n",
      "Setting param `disable_default_eval_metric` to 1.                     \n",
      "[21:58:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14705\ttest-error:0.14767                            \n",
      "\n",
      "[1]\ttrain-error:0.14281\ttest-error:0.14251                            \n",
      "\n",
      "[2]\ttrain-error:0.13959\ttest-error:0.13833                            \n",
      "\n",
      "[3]\ttrain-error:0.13867\ttest-error:0.13790                            \n",
      "\n",
      "[4]\ttrain-error:0.13787\ttest-error:0.13698                            \n",
      "\n",
      "{'alpha': 2.9056515181582688e-05, 'btype': 'I', 'colsample_bylevel': 0.9223699612135592, 'colsample_bytree': 0.6342776618553354, 'eta': 0.013338701038718924, 'eval_metric': ('error',), 'extra_dims': 3, 'gamma': 0, 'lambda': 4.208167549205524e-05, 'max_depth': 5, 'min_child_weight': 2.863799546642419e-07, 'objective': 'binary:logistic', 'subsample': 0.9730576907754682}\n",
      "Overwriting param `num_class`                                         \n",
      "Overwriting param `objective` while setting `obj` in train.           \n",
      "Taking first argument of eval_metric. Multiple evals not supported using xgboost backend.\n",
      "Moving param `eval_metric` to an feval.                               \n",
      "Setting param `disable_default_eval_metric` to 1.                     \n",
      "[21:58:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { btype } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-error:0.14481\ttest-error:0.14490                            \n",
      "\n",
      "[1]\ttrain-error:0.14306\ttest-error:0.14288                            \n",
      "\n",
      "[2]\ttrain-error:0.14288\ttest-error:0.14269                            \n",
      "\n",
      "[3]\ttrain-error:0.14229\ttest-error:0.14244                            \n",
      "\n",
      "[4]\ttrain-error:0.14297\ttest-error:0.14330                            \n",
      "\n",
      "100%|██████████| 10/10 [00:28<00:00,  2.85s/trial, best loss: 0.133722]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, space_eval\n",
    "\n",
    "def objective(param):\n",
    "    watchlist = [(dtrain,'train'),(dtest,'test')]\n",
    "    ed1_results = dict()\n",
    "    print(param)\n",
    "    wbst = wxgb.train(param, dtrain, 5,watchlist,evals_result=ed1_results)\n",
    "    return {'loss': min(ed1_results['test']['error']), 'status': STATUS_OK }\n",
    "\n",
    "spc = {\n",
    "    'btype': hp.choice('btype',['R','I','Rn','In']),\n",
    "    'extra_dims': hp.choice('extra_dims',range(16)),\n",
    "    'objective': hp.choice('objective',['binary:logistic']),\n",
    "    'eval_metric':hp.choice('eval_metric',[['error']]),\n",
    "    'eta': hp.loguniform('eta', -7, 0),\n",
    "    'max_depth' : hp.choice('max_depth',range(1,11)),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.5, 1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -16, 5),\n",
    "    'alpha': hp.choice('alpha', [0, hp.loguniform('alpha_positive', -16, 2)]),\n",
    "    'lambda': hp.choice('lambda', [0, hp.loguniform('lambda_positive', -16, 2)]),\n",
    "    'gamma': hp.choice('gamma', [0, hp.loguniform('gamma_positive', -16, 2)])\n",
    "}\n",
    "\n",
    "best = fmin(objective,\n",
    "    space=spc,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1, 'alpha_positive': 2.555696689429851e-07, 'btype': 0, 'colsample_bylevel': 0.5808673095736296, 'colsample_bytree': 0.7454363436382125, 'eta': 0.09028896383501842, 'eval_metric': 0, 'extra_dims': 6, 'gamma': 0, 'lambda': 1, 'lambda_positive': 0.010496473733789414, 'max_depth': 4, 'min_child_weight': 0.003416504180607806, 'objective': 0, 'subsample': 0.6545637422401163}\n",
      "{'alpha': 2.555696689429851e-07, 'btype': 'R', 'colsample_bylevel': 0.5808673095736296, 'colsample_bytree': 0.7454363436382125, 'eta': 0.09028896383501842, 'eval_metric': ('error',), 'extra_dims': 6, 'gamma': 0, 'lambda': 0.010496473733789414, 'max_depth': 5, 'min_child_weight': 0.003416504180607806, 'objective': 'binary:logistic', 'subsample': 0.6545637422401163}\n"
     ]
    }
   ],
   "source": [
    "print(best)\n",
    "print(space_eval(spc, best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'btype': 0,\n",
       " 'colsample_bytree': 0,\n",
       " 'eta': 0,\n",
       " 'eval_metric': 0,\n",
       " 'extra_dims': 4,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 0,\n",
       " 'num_class': 0,\n",
       " 'objective': 0,\n",
       " 'subsample': 0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': <hyperopt.pyll.base.Apply at 0x7fd87547a310>,\n",
       " 'max_depth': <hyperopt.pyll.base.Apply at 0x7fd87547a550>,\n",
       " 'num_leaves': <hyperopt.pyll.base.Apply at 0x7fd87547a8e0>,\n",
       " 'min_data_in_leaf': <hyperopt.pyll.base.Apply at 0x7fd875404d00>,\n",
       " 'feature_fraction': <hyperopt.pyll.base.Apply at 0x7fd8754abb20>,\n",
       " 'subsample': <hyperopt.pyll.base.Apply at 0x7fd8754abc40>}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spc = {\n",
    "    'btype': hp.choice('btype',['R','I','Rn','In']),\n",
    "    'extra_dims': hp.quniform('extra_dims',0,16,1),\n",
    "    'eta': hp.loguniform('eta', -7, 0),\n",
    "    'max_depth' : hp.quniform('max_depth', 2, 10, 1),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.5, 1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -16, 5),\n",
    "    'alpha': hp.choice('alpha', [0, hp.loguniform('alpha_positive', -16, 2)]),\n",
    "    'lambda': hp.choice('lambda', [0, hp.loguniform('lambda_positive', -16, 2)]),\n",
    "    'gamma': hp.choice('gamma', [0, hp.loguniform('gamma_positive', -16, 2)])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_params = {\n",
    "    'btype':['R','I','Rn','In'],\n",
    "    'extra_dims':[0,1,4,8,16],\n",
    "    'max_depth':[1,2,4,8],\n",
    "    'eta':[0.1],\n",
    "    'objective':['binary:logistic'],\n",
    "    'subsample':[1.0],\n",
    "    'colsample_bytree':[1.0],\n",
    "    'n_estimators':[50,75],\n",
    "    'min_child_weight':[1],\n",
    "    'num_class':[1],\n",
    "    'eval_metric':[['error']]\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
